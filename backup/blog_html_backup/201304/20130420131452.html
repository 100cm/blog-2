<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">PostgreSQL notreal-time insert-delete count(*) performance tuning case - 4</h2>
	<h5 id="">2013-04-20 13:14:52&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/16387704020133156636579/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;">前面三篇blog针对PostgreSQL的coung(*)如何优化做了比较详细的分析和测试, 如下 :&nbsp;<div><a href="http://blog.163.com/digoal@126/blog/static/163877040201331252945440/"   >http://blog.163.com/digoal@126/blog/static/163877040201331252945440/</a></div><div><a href="http://blog.163.com/digoal@126/blog/static/16387704020133151402415/"   >http://blog.163.com/digoal@126/blog/static/16387704020133151402415/</a></div><div><a href="http://blog.163.com/digoal@126/blog/static/16387704020133155179877/"   >http://blog.163.com/digoal@126/blog/static/16387704020133155179877/</a><br><div><br></div><div>但是都是实时的方式进行的优化, 特别是第三篇, 对于按列进行统计分析的场景, 因为统计维度较多, 实时的更新count(*)会带来较大的插入性能瓶颈. 例如有8个维度表的时候, 单步插入的性能会下降到insert = 6500 qps左右.</div><div>这个时候, 你可能需要非实时批量统计. 也就是异步的更新维度表的统计数据. 例如每100条数据更新一次, 或者每1秒更新一次. 来减少维度表的更新频率. 降低数据库, 但是统计数据是非实时的, 这点必须清楚. 如果需要查询实时的count还需要查询未计入统计表的明细表数据.</div><div>但是异步处理会遇到以下问题 :&nbsp;</div><div><div>1. 气泡问题.</div><div>自增长字段作为分段统计的分隔字段安全吗?&nbsp;</div><div>如果明细表的插入是当线程的, 回答是安全的. 但是如果明细表是并行插入的, 那么就不安全了.</div><div>举个例子(这里以时间为分隔字段) :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >t1:<span style="line-height: 22px;"   >2013-03-01 11:01:00</span><span style="line-height: 22px;"   >&nbsp;SESSION A :&nbsp;</span></font></div><div><font size="2"   >begin;</font></div><div><font size="2"   >insert into log(id,info,crt_time) values (1,'test1',clock_timestamp()); &nbsp;-- 假设clock_timestamp()='2013-03-01 11:01:00'</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >t2:<span style="line-height: 22px;"   >2013-03-01 11:01:02</span><span style="line-height: 22px;"   >&nbsp;SESSION B :&nbsp;</span></font></div><div><font size="2"   >begin;</font></div><div><font size="2"   ><span style="line-height: 22px;"   >insert into log(id,info,crt_time) values (2,'test2',</span><span style="line-height: 22px;"   >clock_timestamp</span><span style="line-height: 22px;"   >()); &nbsp;</span><span style="line-height: 22px;"   >-- 假设clock_timestamp()='2013-03-01 11:01:02'</span></font></div><div><span style="line-height: 22px;"   ><font size="2"   >commit;</font></span></div><div><font size="2"   ><br></font></div><div><font size="2"   >t3:<span style="line-height: 22px;"   >2013-03-01 11:01:03</span><span style="line-height: 22px;"   >&nbsp;统计操作1 :&nbsp;(由于此时a未提交,所以取不到a的数据)</span></font></div><div><font size="2"   >select * from log where crt_time &gt;='2013-03-01 11:01:00' and crt_time&lt;'<span style="line-height: 22px;"   >2013-03-01 11:01:02</span><span style="line-height: 22px;"   >';</span></font></div><div><span style="line-height: 22px;"   ><font size="2"   >然后对这批数据进行统计分析, 合并统计数据.</font></span></div><div><font size="2"   ><br></font></div><div><font size="2"   >t4:<span style="line-height: 22px;"   >2013-03-01 11:01:04</span><span style="line-height: 22px;"   >&nbsp;SESSION A :&nbsp;</span></font></div><div><font size="2"   >commit;</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >t5:<span style="line-height: 22px;"   >2013-03-01 11:01:05</span><span style="line-height: 22px;"   >&nbsp;统计操作2 :</span></font></div><div><font size="2"   ><span style="line-height: 22px;"   >select * from log where crt_time &gt;='2013-03-01 11:01:02' and crt_time&lt;'</span><span style="line-height: 22px;"   >?</span><span style="line-height: 22px;"   >';</span></font></div><div><font size="2"   ><span style="line-height: 22px;"   >此时进行统计显然会漏掉SESSION A</span><span style="line-height: 22px;"   >插入明细表的</span><span style="line-height: 22px;"   >数据.</span></font></div><div><span style="line-height: 22px;"   ><font size="2"   >使用序列同样会有这种问题.</font></span></div><p></p></pre></div><div>要避免以上问题, 统计数据分段截止改一个条件即可, 以上是截至到明细数据的最大值. 改为截至小于正在操作明细表的所有未提交的事务.</div><div>需要结合事务ID来操作, 因为事务id是自增长分配的同时又具备了mvcc的含义. 用来做分隔字段是可以的.</div><div>[方法一]</div><div>分析小于txid_snapshot_xmin的记录, 因为小于xmin的事务都已经提交或者回滚了. 可以规避气泡问题.</div><div>使用这种方法要注意长事务的问题, 长事务可能会带来巨大的分析延迟. (因为xmin可能远小于明细表当前最大的已提交事务号.)</div><div><span style="line-height: 22px;"   >使用这种方法以xmin为过滤条件时,&nbsp;</span>还要注意分辨锁级别, 只有insert, delete, alter, truncate, drop的锁需要过滤, 其他的不应该过滤. 以便减少延迟.</div><div>[方法二]</div><div>由于方法1的缺陷, 当数据库中存在较长事务时, 这种分析可能存在大的延迟.</div><div>所以采用另一种方法, 分析小于txid_snapshot_xmax的明细记录, 同时记录下txid_snapshot_xip() 或者txid_current_snapshot()的xip值. 这里的xip包含了未提交或未回滚的prepare transaction xid. 所以就不需要再去查找pg_prepared_xacts了.</div><div>为了得到一致的xmin,xmax,xip值, 最好都从<span style="line-height: 22px;"   >txid_current_snapshot()取.</span></div><div>具体的流程如下 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >begin;</font></div><div><font size="2"   >select agg(<span style="line-height: 22px;"   >txid_current_snapshot</span><span style="line-height: 22px;"   >) &nbsp;into v_xmin, v_xmax, v_xip;</span></font></div><div><font size="2"   ><span style="line-height: 22px;"   >-- 处理&nbsp;</span>select * from log where txid &lt;&nbsp;<span style="line-height: 22px;"   >v_xmax and txid&gt;=log_read_last_txid;</span></font></div><div><font size="2"   ><span style="line-height: 22px;"   >-- 处理&nbsp;</span><span style="line-height: 22px;"   >select * from log_del where txid &lt;&nbsp;</span><span style="line-height: 22px;"   >v_xmax&nbsp;</span><span style="line-height: 22px;"   >and txid&gt;=log_read_last_txid;</span></font></div><div><font size="2"   >-- 处理<span style="line-height: 22px;"   >&nbsp;</span><span style="line-height: 22px;"   >select * from log where txid in&nbsp;</span><span style="line-height: 22px;"   >log_xip and not in v_xip;</span></font></div><div><font size="2"   ><span style="line-height: 22px;"   >-- 处理</span><span style="line-height: 22px;"   >&nbsp;</span><span style="line-height: 22px;"   >select * from log_del where txid in&nbsp;</span><span style="line-height: 22px;"   >log_xip and not in v_xip;</span></font></div><div><font size="2"   ><span style="line-height: 22px;"   >-- 记录处理截止点</span><span style="line-height: 22px;"   >log_read_last_txid;</span></font></div><div><span style="line-height: 22px;"   ><font size="2"   >-- 更新log_xip</font></span></div><div><span style="line-height: 22px;"   ><font size="2"   >end;</font></span></div><p></p></pre></div><div><span style="line-height: 22px;"   >本例将采用方法二的解决办法.</span></div><div><span style="line-height: 22px;"   ><br></span></div><div>2. 并行处理的问题, 如何保证并行安全, 高效.&nbsp;</div><div>本例不涉及并行处理, 所以等下一篇BLOG再来解决这个问题. 感兴趣的朋友可以关注一下.</div><div><br></div><div>3. 如何减少取数次数(扫描次数).&nbsp;</div><div>多个统计维度使用同一份数据. 这个本例已经解决.</div><div><br></div><div>4. 明细表delete带来的问题. 可能造成被删除的数据无法被统计.</div><div>解决办法 :&nbsp;</div><div>1. 加一个字段用来标识(记录是否删除). 应用程序查询数据是需要过滤删除数据.</div><div>2. 增加del明细表.</div><div>本例已经解决.</div><div><br></div></div></div><div>【详细的实施过程如下 : 】</div><div><div>-- # 测试表 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >create table log&nbsp;</font></div><div><font size="2"   >(</font></div><div><font size="2"   >&nbsp; id serial primary key,&nbsp;</font></div><div><font size="2"   >&nbsp; xid int8 default txid_current() not null,&nbsp;</font></div><div><font size="2"   >&nbsp; isdel boolean default false not null,&nbsp;</font></div><div><font size="2"   >&nbsp; c1 int not null,&nbsp;</font></div><div><font size="2"   >&nbsp; c2 int not null,&nbsp;</font></div><div><font size="2"   >&nbsp; c3 int not null,&nbsp;</font></div><div><font size="2"   >&nbsp; c4 text not null,&nbsp;</font></div><div><font size="2"   >&nbsp; crt_time timestamp default now()</font></div><div><font size="2"   >);</font></div><div><font size="2"   >create index idx_log_1 on log(xid);</font></div><p></p></pre></div><div><br></div><div>-- # 存放count(*)的表, 假设经常需要按log.c1以及log.crt_time分天, 周, 月, 年进行count(*)</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >create table log_c1_cnt_day (c1 int, cnt int8, stat_time text, primary key(c1,stat_time));</font></div><div><font size="2"   >create table log_c1_cnt_week (c1 int, cnt int8, stat_time text, primary key(c1,stat_time));</font></div><div><font size="2"   >create table log_c1_cnt_month (c1 int, cnt int8, stat_time text, primary key(c1,stat_time));</font></div><div><font size="2"   >create table log_c1_cnt_year (c1 int, cnt int8, stat_time text, primary key(c1,stat_time));</font></div><p></p></pre></div><div><br></div><div>-- # 存放count(*)的表, 假设经常需要按log.c2, log.c3以及log.crt_time分天, 周, 月, 年进行count(*)</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >create table log_c2_c3_cnt_day (c2 int, c3 int, cnt int8, stat_time text, primary key(c2,c3,stat_time));</font></div><div><font size="2"   >create table log_c2_c3_cnt_week (c2 int, c3 int, cnt int8, stat_time text, primary key(c2,c3,stat_time));</font></div><div><font size="2"   >create table log_c2_c3_cnt_month (c2 int, c3 int, cnt int8, stat_time text, primary key(c2,c3,stat_time));</font></div><div><font size="2"   >create table log_c2_c3_cnt_year (c2 int, c3 int, cnt int8, stat_time text, primary key(c2,c3,stat_time));</font></div><p></p></pre></div><div><br></div><div>-- # 存放删除记录的表,&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >create table log_del (xid int8 default txid_current() not null, log_rec log not null);</font></div><div><font size="2"   >create index idx_log_del_1 on log_del(xid);</font></div><p></p></pre></div><div><br></div><div>-- # 创建删除触发器函数, 更新log.isdel标记, 不删除log表. 同时插入log_del.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >create or replace function tg_log_del() returns trigger as $$</font></div><div><font size="2"   >declare</font></div><div><font size="2"   >begin</font></div><div><font size="2"   >&nbsp; -- 避免重复删除</font></div><div><font size="2"   >&nbsp; if not OLD.isdel then</font></div><div><font size="2"   >&nbsp; &nbsp; update log set isdel=true where id=OLD.id;</font></div><div><font size="2"   >&nbsp; &nbsp; insert into log_del(log_rec) values (OLD);</font></div><div><font size="2"   >&nbsp; &nbsp; return null;</font></div><div><font size="2"   >&nbsp; else</font></div><div><font size="2"   >&nbsp; &nbsp; -- 如果已经删除, 则直接返回空, 不处理.</font></div><div><font size="2"   >&nbsp; &nbsp; return null;</font></div><div><font size="2"   >&nbsp; end if;</font></div><div><font size="2"   >end;</font></div><div><font size="2"   >$$ language plpgsql;</font></div><p></p></pre></div><div><br></div><div>-- # 在log上创建before删除触发器, 注意是before. 必须的.</div><div><pre class="prettyprint"   ><p><font size="2"   >create trigger tg1 before delete on log for each row execute procedure tg_log_del();</font></p></pre></div><div><br></div><div>-- 插入测试数据</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >insert into log (c1,c2,c3,c4) values (1,1,1,1);</font></div><div><font size="2"   >insert into log (c1,c2,c3,c4) values (2,2,2,2);</font></div><p></p></pre></div><div><br></div><div>-- 验证</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >digoal=# select * from log;</font></div><div><font size="2"   >&nbsp;id | &nbsp; &nbsp;xid &nbsp; &nbsp;| isdel | c1 | c2 | c3 | c4 | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;crt_time &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</font></div><div><font size="2"   >----+-----------+-------+----+----+----+----+----------------------------</font></div><div><font size="2"   >&nbsp; 2 | 444403112 | f &nbsp; &nbsp; | &nbsp;2 | &nbsp;2 | &nbsp;2 | 2 &nbsp;| 2013-04-19 11:47:17.140624</font></div><div><font size="2"   >&nbsp; 1 | 444403111 | f &nbsp; &nbsp; | &nbsp;1 | &nbsp;1 | &nbsp;1 | 1 &nbsp;| 2013-04-19 11:47:16.778672</font></div><div><font size="2"   >(2 rows)</font></div><p></p></pre></div><div><br></div><div>-- 删除验证</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >digoal=# delete from log where id=1;</font></div><div><font size="2"   >DELETE 0</font></div><div><font size="2"   >digoal=# select * from log_del;</font></div><div><font size="2"   >&nbsp; &nbsp; xid &nbsp; &nbsp;| &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; log_rec &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</font></div><div><font size="2"   >-----------+------------------------------------------------------</font></div><div><font size="2"   >&nbsp;444403113 | (1,444403111,f,1,1,1,1,"2013-04-19 11:47:16.778672")</font></div><div><font size="2"   >(1 row)</font></div><div><font size="2"   >digoal=# select * from log;</font></div><div><font size="2"   >&nbsp;id | &nbsp; &nbsp;xid &nbsp; &nbsp;| isdel | c1 | c2 | c3 | c4 | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;crt_time &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</font></div><div><font size="2"   >----+-----------+-------+----+----+----+----+----------------------------</font></div><div><font size="2"   >&nbsp; 2 | 444403112 | f &nbsp; &nbsp; | &nbsp;2 | &nbsp;2 | &nbsp;2 | 2 &nbsp;| 2013-04-19 11:47:17.140624</font></div><div><font size="2"   >&nbsp; 1 | 444403111 | t &nbsp; &nbsp; | &nbsp;1 | &nbsp;1 | &nbsp;1 | 1 &nbsp;| 2013-04-19 11:47:16.778672</font></div><div><font size="2"   >(2 rows)</font></div><div><font size="2"   >digoal=# select xid,(log_rec::log).* from log_del ;</font></div><div><font size="2"   >&nbsp; &nbsp; xid &nbsp; &nbsp;| id | &nbsp; &nbsp;xid &nbsp; &nbsp;| isdel | c1 | c2 | c3 | c4 | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;crt_time &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</font></div><div><font size="2"   >-----------+----+-----------+-------+----+----+----+----+----------------------------</font></div><div><font size="2"   >&nbsp;444403113 | &nbsp;1 | 444403111 | f &nbsp; &nbsp; | &nbsp;1 | &nbsp;1 | &nbsp;1 | 1 &nbsp;| 2013-04-19 11:47:16.778672</font></div><div><font size="2"   >(1 row)</font></div><p></p></pre></div><div><br></div><div>-- # 创建分析维度注册表, 记录每个明细表每次分析的截止xid, xip. (未来可以精细化, 每个统计维度一条记录. 增加dime 字段. tablename+dime组合pk)</div><div>-- # xid 记录统计到哪个xid了, xip记录当前活动事务, 不计入当前统计范畴. 避免气泡问题.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ><span style="line-height: 19px;"   >create table log_read <br>(<br>tablename name not null, <br>xid int8 not null, <br>xip int8[], <br>xip_res int8[],  -- 用于与xid比对的数据. 必须保留所有&gt;=xid的xip信息.<br>mod_time timestamp, <br>primary key (tablename)<br>);<br>insert into log_read values ('log', 0, null, null, now());<br>insert into log_read values ('log_del', 0, null, null, now());</span></font></div><p></p></pre></div><div>-- # 创建串行批量数据分析函数</div><div>-- # 注意xid边界的选取. 如果单事务插入的语句过多, 可能造成内存溢出.&nbsp;</div><div>-- # 生产环境中也尽量避免单事务过大, 控制在10万条以内一个事务比较好.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ><span style="line-height: 19px;"   >create or replace function analyze_log(v_limit int) returns void as $$<br>declare<br>  v_advisory_xact_lock int8 := null;  -- 串行处理锁.<br>  <br>  v_xid_snap txid_snapshot := null;  -- 当前事务状态快照<br>  v_xmin int8 := null;  -- 当前事务状态快照中未完成的最小事务<br>  v_xmax int8 := null;  -- 当前事务状态快照中未分配的最小事务<br>  v_xip int8[] := null;  -- 当前事务状态快照中未完成的事务数组<br><br>  v_log_read_log_xid int8 := null;  -- 上次log的xid分析截止位<br>  v_log_read_log_del_xid int8 := null;  -- 上次log_del的xid分析截止位<br>  v_log_read_log_xid_update int8 := null;  -- 更新值, 不能为空<br>  v_log_read_log_del_xid_update int8 := null;  -- 更新值, 不能为空<br><br>  v_log_read_log_xip int8[] := null;  -- 上次log_read.xip(tablename=log)<br>  v_log_read_log_xip_do int8[] := null;  -- 解析本次log_read.xip(tablename=log) where (xip !@ txid_snapshot)<br>  v_log_read_log_xip_update int8[] := null;  -- xip更新值<br>  v_log_read_log_xip_res int8[] := null;  -- xip保留值<br>  v_log_read_log_xip_res_update int8[] := null;  -- xip保留更新值, 所有大于v_log_read_log_xid_update的元素必须保留.<br><br>  v_log_read_log_del_xip int8[] := null;  -- 上次log_read.xip(tablename=log_del)<br>  v_log_read_log_del_xip_do int8[] := null;  -- 解析本次log_read.xip(tablename=log_del) where (xip !@ txid_snapshot)<br>  v_log_read_log_del_xip_update int8[] := null;  -- xip更新值<br>  v_log_read_log_del_xip_res int8[] := null;  -- xip保留值<br>  v_log_read_log_del_xip_res_update int8[] := null;  -- xip保留更新值, 所有大于v_log_read_log_del_xid_update的元素必须保留.<br><br>  v_log log[] := null;  -- 聚合本次log的分析数组, [末尾调用,false]<br>  v_log_doxip log[] := null;  -- 聚合本次分析log数组: <br>                          -- where log.xid (@ log_read.xip(tablename=log) and !@ txid_snapshot) , [末尾调用,false]<br><br>  v_log_del_log_rec log[] := null;  -- 聚合本次分析log_del.log_rec数组: <br>                            -- where log_del.xid ( &gt; log_read.xid(tablename=log_del) ) order by log_del.xid ), [末尾调用,true]<br>  v_log_del_log_rec_doxip log[] := null;  -- 聚合本次分析log_del.log_rec数组: <br>                                  -- where log_del.xid (@ log_read.xip(tablename=log_del) and !@ txid_snapshot) , [末尾调用,true]<br>begin<br>  -- 判断limit<br>  if v_limit &lt;=0 then<br>    raise notice 'please ensure v_limit &gt; 0 .';<br>    return;<br>  end if;<br><br>  -- 串行处理, 如果不能获得锁则直接退出. 确保v_advisory_xact_lock全局唯一.<br>  v_advisory_xact_lock := 1;<br>  if not pg_try_advisory_xact_lock(v_advisory_xact_lock) then<br>    raise notice 'Another function is calling, this call will exit.';<br>    return;<br>  end if;<br><br>  -- 生成 xid snapshot 数据.<br>  v_xid_snap := txid_current_snapshot();<br>  v_xmin := txid_snapshot_xmin(v_xid_snap);<br>  v_xmax := txid_snapshot_xmax(v_xid_snap);<br>  select array_agg(t) into v_xip from txid_snapshot_xip(v_xid_snap) g(t);<br><br>  -- 取v_log_read_log_xid截止值, v_log_read_log_xip数组.<br>  select xid,xip,xip_res into v_log_read_log_xid,v_log_read_log_xip,v_log_read_log_xip_res from log_read where tablename='log';<br>  if not found then<br>    raise notice 'log_read no log entry. please add it in log_read table first.';<br>    return;<br>  end if;<br><br>  -- 取v_log_read_log_del_xid截止值, v_log_read_log_del_xip数组.<br>  select xid,xip,xip_res into v_log_read_log_del_xid,v_log_read_log_del_xip,v_log_read_log_del_xip_res from log_read where tablename='log_del';<br>  if not found then<br>    raise notice 'log_read no log_del entry. please add it in log_read table first.';<br>    return;<br>  end if;<br><br>  -- 取log1(取非xip中的数据, 隔离log2操作)<br>  -- 取xid临界点<br>  select max(xid) into v_log_read_log_xid_update from (select xid from log where xid &gt; v_log_read_log_xid and xid &lt; v_xmax and xid not in (select * from unnest(v_xip) union all select * from unnest(v_log_read_log_xip_res)) order by xid limit v_limit) t;<br>  if v_log_read_log_xid_update is not null then<br>    raise notice '取log1';<br>    -- 根据临界点,取log数据<br>    select array_agg(log) into v_log from (select log from log where xid &gt; v_log_read_log_xid and xid&lt;=v_log_read_log_xid_update and xid not in (select * from unnest(v_xip) union all select * from unnest(v_log_read_log_xip_res)) order by xid) t;<br>  else <br>    -- 如果没有数据, 更新值不变<br>    v_log_read_log_xid_update := v_log_read_log_xid;<br>  end if;<br><br>  -- 取log_del1(取非xip中的数据, 隔离log_del2操作)<br>  -- 取xid临界点<br>  select max(xid) into v_log_read_log_del_xid_update from (select xid from log_del where xid &gt; v_log_read_log_del_xid and xid &lt; v_xmax and xid not in (select * from unnest(v_xip) union all select * from unnest(v_log_read_log_del_xip_res)) order by xid limit v_limit) t;<br>  if v_log_read_log_del_xid_update is not null then<br>    raise notice '取log_del1';<br>    -- 根据临界点,取log_del.log_rec数据<br>    select array_agg(log_rec) into v_log_del_log_rec from (select (log_del).log_rec as log_rec from log_del where xid &gt; v_log_read_log_del_xid and xid&lt;=v_log_read_log_del_xid_update and xid not in (select * from unnest(v_xip) union all select * from unnest(v_log_read_log_del_xip_res)) order by xid) t;<br>  else <br>    -- 如果没有数据, 更新值不变<br>    v_log_read_log_del_xid_update := v_log_read_log_del_xid;<br>  end if;<br><br>  -- 取log2 (log_xip - v_xip) (取xip中的数据, 隔离log1操作)<br>  -- 生成log_read.xip(tablename=log) do数组(已经完成的事务)<br>  select array_agg(i) into v_log_read_log_xip_do from (select * from unnest(v_log_read_log_xip) i except select * from unnest(v_xip))t where i is not null;<br>  -- 生成log_read.xip(tablename=log) update数组(未完成的事务)<br>  select array_agg(i) into v_log_read_log_xip_update from <br>  (  select i from (select * from unnest(v_log_read_log_xip) i union all select * from unnest(v_xip)<br>     except select * from unnest(v_log_read_log_xip_do)) t where i is not null group by i ) t;<br>  -- 生成xip_res更新值<br>  select array_agg(i) into v_log_read_log_xip_res_update from (select * from unnest(v_log_read_log_xip_res) i union select * from unnest(v_log_read_log_xip) union select * from unnest(v_xip))t where i&gt;v_log_read_log_xid_update;<br>  -- 生成log do数组<br>  select array_agg(log) into v_log_doxip from log where xid in (select * from unnest(v_log_read_log_xip_do));<br><br>  -- 取log_del2 (log_xip - v_xip) (取xip中的数据, 隔离log_del1操作)<br>  -- 生成log_read.xip(tablename=log_del) do数组(已经完成的事务)<br>  select array_agg(i) into v_log_read_log_del_xip_do from (select * from unnest(v_log_read_log_del_xip) i except select * from unnest(v_xip))t where i is not null;<br>  -- 生成log_read.xip(tablename=log_del) update数组(未完成的事务)<br>  select array_agg(i) into v_log_read_log_del_xip_update from <br>  (  select i from (select * from unnest(v_log_read_log_del_xip) i union all select * from unnest(v_xip)<br>     except select * from unnest(v_log_read_log_del_xip_do)) t where i is not null group by i ) t;<br>  -- 生成xip_res更新值<br>  select array_agg(i) into v_log_read_log_del_xip_res_update from (select * from unnest(v_log_read_log_del_xip_res) i union select * from unnest(v_log_read_log_del_xip) union select * from unnest(v_xip)) t where i&gt;v_log_read_log_del_xid_update;<br>  -- 生成log_del.log_rec do数组<br>  select array_agg(log_rec) into v_log_del_log_rec_doxip from log_del where xid in (select * from unnest(v_log_read_log_del_xip_do));<br><br>  -- 更新log_read(tablename=log)<br>  update log_read set <br>    xip=v_log_read_log_xip_update, <br>    xid=v_log_read_log_xid_update, <br>    xip_res=v_log_read_log_xip_res_update,<br>    mod_time=now() <br>  where tablename='log';<br> &nbsp;-- DEBUG</span></font></div><div><font size="2"   ><span style="line-height: 19px;"   >  -- raise notice 'log_read.oldxip(log): %.', v_log_read_log_xip;<br>  -- raise notice 'log_read.newxip(log): %.', v_log_read_log_xip_update;<br>  -- raise notice 'log_read.newxipres(log): %.', v_log_read_log_xip_res_update;<br><br>  -- 更新log_read(tablename=log_del)<br>  update log_read set <br>    xip=v_log_read_log_del_xip_update, <br>    xid=v_log_read_log_del_xid_update, <br>    xip_res=v_log_read_log_del_xip_res_update,<br>    mod_time=now()<br>  where tablename='log_del';<br> &nbsp;-- DEBUG</span></font></div><div><font size="2"   ><span style="line-height: 19px;"   >  -- raise notice 'log_read.oldxip(log_del): %.', v_log_read_log_del_xip;<br>  -- raise notice 'log_read.newxip(log_del): %.', v_log_read_log_del_xip_update;<br>  -- raise notice 'log_read.newxipres(log_del): %.', v_log_read_log_del_xip_res_update;<br><br>  -- 分析函数可以另外写, 在此调用.<br>  perform stat_log_c1(v_log, false);<br>  perform stat_log_c1(v_log_doxip, false);<br>  perform stat_log_c1(v_log_del_log_rec, true);<br>  perform stat_log_c1(v_log_del_log_rec_doxip, true);<br><br>return;<br>end;<br>$$ language plpgsql;</span></font><br></div><p></p></pre></div><div>-- # 统计函数stat_log_c1</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >CREATE OR REPLACE FUNCTION public.stat_log_c1(v_log log[], isdel boolean DEFAULT false)</font></div><div><font size="2"   >&nbsp;RETURNS void</font></div><div><font size="2"   >&nbsp;LANGUAGE plpgsql</font></div><div><font size="2"   >AS $function$</font></div><div><font size="2"   >declare</font></div><div><font size="2"   >&nbsp; v_stat_time text;</font></div><div><font size="2"   >&nbsp; v_c1 int;</font></div><div><font size="2"   >&nbsp; v_cnt int8;</font></div><div><font size="2"   >begin</font></div><div><font size="2"   >&nbsp; -- 统计log_c1_cnt_day</font></div><div><font size="2"   >&nbsp; for v_stat_time, v_c1, v_cnt in select to_char(crt_time, 'yyyymmdd'), c1 , count(*) from (select ((unnest(v_log)::log)).*) t group by to_char(crt_time, 'yyyymmdd'), c1 loop</font></div><div><font size="2"   >&nbsp; &nbsp; perform 1 from log_c1_cnt_day where c1=v_c1 and stat_time=v_stat_time;</font></div><div><font size="2"   >&nbsp; &nbsp; if not found then</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; if isdel then</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; insert into log_c1_cnt_day(c1, cnt, stat_time) values (v_c1, -v_cnt, v_stat_time);</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; else</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; insert into log_c1_cnt_day(c1, cnt, stat_time) values (v_c1, v_cnt, v_stat_time);</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; end if;</font></div><div><font size="2"   >&nbsp; &nbsp; else</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; if isdel then</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; update log_c1_cnt_day set cnt=cnt-v_cnt where c1=v_c1 and stat_time=v_stat_time;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; else</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; update log_c1_cnt_day set cnt=cnt+v_cnt where c1=v_c1 and stat_time=v_stat_time;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; end if;</font></div><div><font size="2"   >&nbsp; &nbsp; end if;</font></div><div><font size="2"   >&nbsp; end loop;</font></div><div><font size="2"   >&nbsp; -- 统计log_c1_cnt_week , .... 略</font></div><div><font size="2"   >end;</font></div><div><font size="2"   >$function$;</font></div><p></p></pre></div><div><br></div><div>-- # 测试, 清理原始数据</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >truncate log;</font></div><div><font size="2"   >truncate log_del;</font></div><div><font size="2"   >truncate log_c1_cnt_day;</font></div><div><font size="2"   >update log_read set xid=0, xip=null<span style="line-height: 19px;"   >, xip_res=null;</span></font></div><p></p></pre></div><div>-- # pgbench脚本, 测试插入场景</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >cat ins.sql&nbsp;</font></div><div><font size="2"   >insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);</font></div><p></p></pre></div><div>-- # pgbench</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ><span style="line-height: 19px;"   >pg92@digoal-PowerEdge-R610-&gt; pgbench -M prepared -f ./ins.sql -r -n -h $PGDATA -U postgres -T 60 -c 8 -j 2<br>transaction type: Custom query<br>scaling factor: 1<br>query mode: prepared<br>number of clients: 8<br>number of threads: 2<br>duration: 60 s<br>number of transactions actually processed: 2679540<br>tps = 44658.871978 (including connections establishing)<br>tps = 44668.857300 (excluding connections establishing)<br>statement latencies in milliseconds:<br>        0.177730        insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);</span></font></div><p></p></pre></div><div><br></div><div>-- # 压力测试的同时执行analyze_log. 确保pgbench同时执行analyze_log.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ><span style="line-height: 19px;"   >pg92@digoal-PowerEdge-R610-&gt; cat analyze.sh <br>#!/bin/bash<br>for ((i=0;i&lt;100;i++))<br>do<br>psql -c "select * from analyze_log(1);"<br>psql -c "select * from analyze_log(1000000);"<br>done</span></font></div><p></p></pre></div><div><br></div><div>-- # 验证数据是否准确</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ><span style="line-height: 19px;"   >digoal=# select c1,count(*),to_char(crt_time,'yyyymmdd') from log where not isdel group by c1,to_char(crt_time,'yyyymmdd') order by c1;<br> c1 |  count  | to_char  <br>----+---------+----------<br>  0 |  643764 | 20130426<br>  1 | 1291330 | 20130426<br>  2 | 1289282 | 20130426<br>  3 | 1289503 | 20130426<br>  4 | 1290164 | 20130426<br>  5 | 1290816 | 20130426<br>  6 | 1290268 | 20130426<br>  7 | 1288713 | 20130426<br>  8 | 1289126 | 20130426<br>  9 | 1288201 | 20130426<br> 10 |  645811 | 20130426<br>(11 rows)<br><br>digoal=# select * from log_c1_cnt_day where cnt&lt;&gt;0 order by c1;<br> c1 |   cnt   | stat_time <br>----+---------+-----------<br>  0 |  643764 | 20130426<br>  1 | 1291330 | 20130426<br>  2 | 1289282 | 20130426<br>  3 | 1289503 | 20130426<br>  4 | 1290164 | 20130426<br>  5 | 1290816 | 20130426<br>  6 | 1290268 | 20130426<br>  7 | 1288713 | 20130426<br>  8 | 1289126 | 20130426<br>  9 | 1288201 | 20130426<br> 10 |  645811 | 20130426<br>(11 rows)<br></span></font></div><p></p></pre></div><div><br></div><div>-- # 测试insert, delete混合场景</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ><span style="line-height: 19px;"   >postgres=# select min(id),max(id) from log;<br>    min    |    max    <br>-----------+-----------<br> 109027255 | 121036868<br>(1 row)</span></font></div><p></p></pre></div><div>-- # pgbench脚本, 测试包含delete, rollback的场景, 同时测试单事务包含多条SQL的场景.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ><span style="line-height: 19px;"   >pg92@digoal-PowerEdge-R610-&gt; cat ins.sql <br>\setrandom id 109027255 131036868<br>begin;<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>end;<br>begin;<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>rollback;<br>begin;<br>delete from log where id=:id;<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>delete from log where id=:id;<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>delete from log where id=:id;<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>delete from log where id=:id;<br>end;<br>begin;<br>delete from log where id=:id;<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>insert into log (c1,c2,c3,c4) values(round(random()*10),1,2,3);<br>delete from log where id=:id;<br>delete from log where id=:id;<br>delete from log where id=:id;<br>delete from log where id=:id;<br>delete from log where id=:id;<br>delete from log where id=:id;<br>rollback;</span></font></div><p></p></pre></div><div>-- # pgbench</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ><span style="line-height: 19px;"   >pg92@digoal-PowerEdge-R610-&gt; pgbench -M prepared -f ./ins.sql -r -n -h $PGDATA -U postgres -T 60 -c 32 -j 2<br>transaction type: Custom query<br>scaling factor: 1<br>query mode: prepared<br>number of clients: 32<br>number of threads: 2<br>duration: 60 s<br>number of transactions actually processed: 22635<br>tps = 376.649815 (including connections establishing)<br>tps = 376.980475 (excluding connections establishing)</span></font></div><div><font size="2"   ><span style="line-height: 19px;"   >.....语句略</span></font></div><p></p></pre></div><div><br></div><div>-- pgbench过程中同时调用analyze_log.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >pg92@digoal-PowerEdge-R610-&gt; cat analyze.sh <br>#!/bin/bash<br>for ((i=0;i&lt;100;i++))<br>do<br>psql -c "select * from analyze_log(1);"<br>psql -c "select * from analyze_log(1000000);"<br>done</font></div><div><font size="2"   ># 多次调用, 直到取完所有数据.<br>pg92@digoal-PowerEdge-R610-&gt; ./analyze.sh</font></div><p></p></pre></div><div><br></div><div>-- # 验证数据是否准确</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ><span style="line-height: 19px;"   >digoal=# select c1,count(*),to_char(crt_time,'yyyymmdd') from log where not isdel group by c1,to_char(crt_time,'yyyymmdd') order by c1;<br> c1 |  count  | to_char  <br>----+---------+----------<br>  0 |  960617 | 20130426<br>  1 | 1926373 | 20130426<br>  2 | 1924853 | 20130426<br>  3 | 1924954 | 20130426<br>  4 | 1923913 | 20130426<br>  5 | 1924408 | 20130426<br>  6 | 1924650 | 20130426<br>  7 | 1924305 | 20130426<br>  8 | 1923113 | 20130426<br>  9 | 1924381 | 20130426<br> 10 |  962460 | 20130426<br>(11 rows)<br><br>digoal=# select * from log_c1_cnt_day where cnt&lt;&gt;0 order by c1;<br> c1 |   cnt   | stat_time <br>----+---------+-----------<br>  0 |  960617 | 20130426<br>  1 | 1926373 | 20130426<br>  2 | 1924853 | 20130426<br>  3 | 1924954 | 20130426<br>  4 | 1923913 | 20130426<br>  5 | 1924408 | 20130426<br>  6 | 1924650 | 20130426<br>  7 | 1924305 | 20130426<br>  8 | 1923113 | 20130426<br>  9 | 1924381 | 20130426<br> 10 |  962460 | 20130426<br>(11 rows)<br><br>digoal=# select count(*) from log_del ;<br> count <br>-------<br> 46085<br>(1 row)</span></font></div><p></p></pre></div><div><br></div><div>-- insert, delete的问题.</div><div>1. 可能出现insert未被统计到, 但是delete被统计到的情况.</div><div>&nbsp; &nbsp;解决办法 :&nbsp;</div><div>&nbsp; &nbsp;log加个isdel字段, del时不真实的删除记录. 这样就可以避免insert未被统计到, 但是delete被统计到的情况.</div><div>&nbsp; &nbsp;应用程序在对log表查询时加上isdel is false条件.</div><div>2. log_del表的清理, 以及log.isdel=true清理. 使用如下在线过程.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >&nbsp; &nbsp;do language plpgsql $$</font></div><div><font size="2"   >&nbsp; &nbsp;declare</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;v_xid int8;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;v_xip int8[];</font></div><div><font size="2"   >&nbsp; &nbsp;begin</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;select xid,xip into v_xid,v_xip from log_read where tablename='log';</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;if found then</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp;delete from log where isdel and xid&lt;=v_xid and xid not in (select unnest(v_xip));</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;end if;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;select xid,xip into v_xid,v_xip from log_read where tablename='log_del';</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;if found then</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp;delete from log_del where xid&lt;=v_xid and xid not in (select unnest(v_xip));</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;end if;</font></div><div><font size="2"   >&nbsp; &nbsp;end;</font></div><div><font size="2"   >&nbsp; &nbsp;$$;</font></div><p></p></pre></div><div><br></div><div>【特别注意】</div><div>由于本例采用了PostgreSQL系统xid来解决气泡问题, 所以特别需要注意以下问题 :&nbsp;</div><div>-- xid的问题, 当使用pg_resetxlog修改xid时(如果xid改小)将打破使用该方法的统计. 所以安全的做法是xid改大可以, 改小不行.</div><div>-- 当使用pg_dump导出明细数据到另一个库后, 记得先使用pg_resetxlog将新集群的xid调整到大于明细表的max(xid)</div><div><br></div></div><span style="color: rgb(51, 51, 51); font-family: Arial, Helvetica, simsun, u5b8bu4f53; line-height: 25px;"   >[参考]</span><div style="line-height: 25px; color: rgb(51, 51, 51); font-family: Arial, Helvetica, simsun, u5b8bu4f53;"   ><div style="line-height: 25px;"   >为方便大家查询, 汇总PostgreSQL实时和非实时数据统计的案例分析文章系列 - 如下 :&nbsp;</div><div style="line-height: 25px;"   >1.&nbsp;<a style="line-height: 25px; text-decoration: none; color: rgb(85, 108, 136);" target="_blank" href="http://blog.163.com/digoal@126/blog/static/163877040201331252945440/"   >http://blog.163.com/digoal@126/blog/static/163877040201331252945440/</a></div><div style="line-height: 25px;"   >2.&nbsp;<a style="line-height: 25px; text-decoration: none; color: rgb(85, 108, 136);" target="_blank" href="http://blog.163.com/digoal@126/blog/static/16387704020133151402415/"   >http://blog.163.com/digoal@126/blog/static/16387704020133151402415/</a></div><div style="line-height: 25px;"   >3.&nbsp;<a style="line-height: 25px; text-decoration: none; color: rgb(85, 108, 136);" target="_blank" href="http://blog.163.com/digoal@126/blog/static/16387704020133155179877/"   >http://blog.163.com/digoal@126/blog/static/16387704020133155179877/</a></div><div style="line-height: 25px;"   >4.&nbsp;<a style="line-height: 25px; text-decoration: none; color: rgb(85, 108, 136);" target="_blank" href="http://blog.163.com/digoal@126/blog/static/16387704020133156636579/"   >http://blog.163.com/digoal@126/blog/static/16387704020133156636579/</a></div><div style="line-height: 25px;"   >5.&nbsp;<a style="line-height: 25px; text-decoration: none; color: rgb(85, 108, 136);" target="_blank" href="http://blog.163.com/digoal@126/blog/static/16387704020133218305242/"   >http://blog.163.com/digoal@126/blog/static/16387704020133218305242/</a></div><div style="line-height: 25px;"   >6.&nbsp;<a style="line-height: 25px; text-decoration: none; color: rgb(85, 108, 136);" target="_blank" href="http://blog.163.com/digoal@126/blog/static/16387704020133224161563/"   >http://blog.163.com/digoal@126/blog/static/16387704020133224161563/</a></div></div><span style="line-height: 22px;"   >7.&nbsp;</span><a style="line-height: 22px;" href="http://blog.163.com/digoal@126/blog/static/16387704020133271134563/"   >http://blog.163.com/digoal@126/blog/static/16387704020133271134563/</a><br><div><span style="color: rgb(51, 51, 51); font-family: Arial, Helvetica, simsun, u5b8bu4f53; line-height: 25px;"   >8.&nbsp;</span><a style="line-height: 25px; text-decoration: none; color: rgb(85, 108, 136); font-family: Arial, Helvetica, simsun, u5b8bu4f53;" href="http://blog.163.com/digoal@126/blog/static/16387704020134311144755/"   >http://blog.163.com/digoal@126/blog/static/16387704020134311144755/</a></div></div>
	</div>
</div>
</body>
</html>