<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">bulk update OR per row update case</h2>
	<h5 id="">2011-08-13 18:34:44&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/163877040201171341241995/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;">前几天一位开发人员与我聊到一个业务需求，需要批量的给用户下发一批优惠券。怎么做比较好？<br>这个需求在数据库的操作就是更新某个表的用户记录。如给前100名的用户下发优惠券，首先要获得这100名的用户名单，然后更新他们的记录。<br>一般开发人员的写法如下,一个事务中更新掉这100名用户记录。<br>update user_table set .... where ..... ;<br>如果这条SQL执行很快的话，这种方法是没有问题的。<br>但是一需要更新的用户量大（如向所有人发放的优惠券），SQL执行时间长，会发生什么？<br>1、堵塞并发的用户数据更新SQL请求，例如并发用户的消费其他优惠券行为。（Oracle和PostgreSQL都将如此）<br>2、PostgreSQL里面会导致用户表和用户表上的索引膨胀，因为在SQL提交之前，前后TUPLE版本都不能被VACUUM掉。在ORACLE里面的体现是UNDO表空间膨胀，甚至出现SNAPSHOT TOO OLD的报错致使UPDATE失败，数据回滚。<br><br>避免这种情况的发生，举例：<br>1、更新表结构，不同的优惠券使用不同的券类型ID，避免发放优惠券的时候堵塞其他优惠券的使用。<br>2、不要使用批量发放，将长事务打散成小事务，如每发放100条COMMIT一次。<br><br>下面是简化的测试，（略去了获取user_info，解析user_info，以及锁定user_info的过程，正常的流程中需要这几个过程，因为这里只测试bluk update和单行UPDATE。） ： <br>测试表 : <br>tbl_update_test<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table "digoal.tbl_update_test"<br>&nbsp;&nbsp; Column&nbsp;&nbsp;&nbsp; |&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Type&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | Modifiers <br>-------------+-----------------------------+-----------<br>&nbsp;id&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | integer&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | not null<br>user_info | text | <br>&nbsp;crt_time&nbsp;&nbsp;&nbsp; | timestamp without time zone | <br>&nbsp;mod_time&nbsp;&nbsp;&nbsp; | timestamp without time zone | <br>Indexes:<br>&nbsp;&nbsp;&nbsp; "tbl_update_test_pkey" PRIMARY KEY, btree (id)<br>插入测试数据:<br>insert into tbl_update_test select generate_series(1,30000000),'nickname:digoal,card_type:1,card_status:true',now(),now();<br>记录下当前的表和索引SIZE：<br>tbl_update_test ： 1.7GB<br>tbl_update_test_pkey ： 640MB<br><br>1. 在没有发放优惠券操作时，测试一下用户消费优惠券行为的QPS：<br>在另一台服务器上使用PGBENCH测试<br>测试脚本 : update1.sql <br>\setrandom randomid 1 30000000<br>update tbl_update_test set user_info='nickname:digoal,card_type:1,card_status:false' and mod_time=now() where id=:randomid;<br>测试结果 : <br>postgres@db-172-16-3-33-&gt; pgbench -M extended -c 2 -f /home/postgres/pgbench/update1.sql -j 2 -n -T 180 -h 172.16.3.176 -p 1921 -U digoal digoal<br>transaction type: Custom query<br>scaling factor: 1<br>query mode: extended<br>number of clients: 2<br>number of threads: 2<br>duration: 180 s<br>number of transactions actually processed: 1139405<br>tps = 6329.984593 (including connections establishing)<br>tps = 6330.129798 (excluding connections establishing)<br><br> 2. 在批量发放优惠券操作时，测试一下用户消费优惠券行为的QPS：<br> 在数据库PSQL终端使用 update tbl_update_test set user_info=user_info||',card_type:2,card_status:true' and mod_time=now(); 批量发放优惠券card_type:2,card_status:true。这条SQL执行了大约20分钟。也就是堵塞了20分钟的并发。并且数据表和索引都膨胀了一倍。<br>同时在另一台服务器上使用PGBENCH测试,<br> 测试脚本 : update.sql <br> \setrandom randomid 1 30000000<br> update tbl_update_test set user_info='nickname:digoal,card_type:1,card_status:false' and mod_time=now() where id=:randomid;<br> <br>测试结果 : <br> postgres@db-172-16-3-33-&gt; pgbench -M extended -c 2 -f /home/postgres/pgbench/update.sql -j 2 -n -T 180 -h 172.16.3.176 -p 1921 -U digoal digoal<br>transaction type: Custom query<br>scaling factor: 1<br>query mode: extended<br>number of clients: 2<br>number of threads: 2<br>duration: 180 s<br>number of transactions actually processed: 9680<br>tps = 8.053994 (including connections establishing)<br>tps = 8.054026 (excluding connections establishing)<br>测试过程中，pgbench的几个进程一直处于wait状态。<br>29022 postgres&nbsp; 15&nbsp;&nbsp; 0 2324m 209m 206m S&nbsp;&nbsp;&nbsp; 0&nbsp; 1.3&nbsp;&nbsp; 0:01.38 postgres: digoal digoal 172.16.3.33(28801) UPDATE waiting&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br>29023 postgres&nbsp; 15&nbsp;&nbsp; 0 2324m 153m 151m S&nbsp;&nbsp;&nbsp; 0&nbsp; 1.0&nbsp;&nbsp; 0:00.90 postgres: digoal digoal 172.16.3.33(28802) UPDATE waiting <br>结论显然是，bulk update在这种情况下非常糟糕。<br><br>3. 改为per row update试试，在测试之前，大家想想会发生什么？<br>首先，SQL并发问题肯定是解决了，但是会带来另外的问题。<br>还记得正常UPDATE的QPS吗？6300多，要UPDATE3000W条记录的话需要80分钟。<br>发一次优惠券要这么久，实在难以忍受。<br>下面是测试脚本,更新100W条记录花的时间比预期的长很多，原因是SHELL的效率低下，还需要频繁的建立连接:<br>#!/bin/bash<br>date<br>for ((i=1;i&lt;=1000000;i++)) do <br>psql -h 127.0.0.1 digoal digoal -c "update tbl_update_test set card_status=false where id=$i"<br>done<br>date<br><br>改用以下方法来测试：<br>create sequence seq_update_test start with 1 cache 1 increment by 1;<br>digoal=&gt; create or replace function f_update_test () returns void as $BODY$<br>digoal$&gt; declare<br>digoal$&gt; v_id int;<br>digoal$&gt; begin<br>digoal$&gt; select nextval('seq_update_test'::regclass) into v_id;<br>digoal$&gt; update tbl_update_test set user_info='nickname:digoal,card_type:1,card_status:false' and mod_time=now() where id=v_id;<br>digoal$&gt; end;<br>digoal$&gt; $BODY$ language plpgsql;<br><br>vi /home/postgres/pgbench/update.sql<br>select f_update_test();<br>然后执行 pgbench -M extended -c 2 -f /home/postgres/pgbench/update.sql -j 2 -n -t 500000 -h 172.16.3.176 -p 1921 -U digoal digoal<br>测试结果 : <br>postgres@db-172-16-3-33-&gt; pgbench -M extended -c 2 -f /home/postgres/pgbench/update.sql -j 2 -n -t 500000 -h 172.16.3.176 -p 1921 -U digoal digoal<br>transaction type: Custom query<br>scaling factor: 1<br>query mode: extended<br>number of clients: 2<br>number of threads: 2<br>number of transactions per client: 500000<br>number of transactions actually processed: 1000000/1000000<br>tps = 6125.607405 (including connections establishing)<br>tps = 6125.807072 (excluding connections establishing)<br>TPS比前面高很多，原因是改用了简单的函数调用，没有函数参数传入，生产中效率要比这个低，因为还要传入参数。<br>这里耗时是163秒，如果更新3000W条记录就是4890秒，需要80多分钟。 这种情况下，表没有膨胀一倍，原因前面已经阐述了。<br><br>同时在另一个窗口执行用户消费优惠券的操作。<br>pgbench -M extended -c 2 -f /home/postgres/pgbench/update1.sql -j 2 -n -T 180 -h 172.16.3.176 -p 1921 -U digoal digoal<br>结果 : <br>postgres@db-172-16-3-33-&gt; pgbench -M extended -c 2 -f  /home/postgres/pgbench/update1.sql -j 2 -n -T 180 -h 172.16.3.176 -p  1921 -U digoal digoal<br> transaction type: Custom query<br> scaling factor: 1<br> query mode: extended<br> number of clients: 2<br> number of threads: 2<br> duration: 180 s<br> number of transactions actually processed: 1076026<br> tps = 5977.849957 (including connections establishing)<br> tps = 5977.970710 (excluding connections establishing)<br>使用per row update基本上不会导致并发能力下降。<br><br>最终解决办法结论,最不推荐的是bluk update,per row update可以在小数据量下使用,大数据量下更新时间长 : <br>1. 使用多维字段，用户ID+优惠券ID+优惠券使用状态。<br>例如 digoal=&gt; insert into tbl_update_test(id,card_type,card_status,crt_time,mod_time) select generate_series(1,3000000),1,true,now(),now();<br>INSERT 0 3000000<br>Time: 20064.692 ms<br>3000W条插入耗时将会是200秒.并且不影响并发。<br>2. （可选）使用表继承根据优惠券ID拆分成多个子表。<br>3. 发放优惠券使用插入，而不是更新用户记录。<br>4. 消费优惠券后，删除用户该优惠券的记录。</div>
	</div>
</div>
</body>
</html>