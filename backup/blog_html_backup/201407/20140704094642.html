<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">flashcache usage guide</h2>
	<h5 id="">2014-07-04 9:46:42&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/163877040201463101652528/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;"><div>前几天写过一篇关于使用flashcache提升PostgreSQL IOPS性能的文章</div><div><a target="_blank" href="http://blog.163.com/digoal@126/blog/static/1638770402014528115551323/"   >http://blog.163.com/digoal@126/blog/static/1638770402014528115551323/</a></div><div>本文将要介绍一下flashcache的使用注意事项, 更好的使用flashcache.</div><div><br></div><div>1. 内核的适配, 目前flashcache在2.6.18到2.6.38之间的Linux内核做过测试, 可以使用. 其他内核的话, 不建议使用.</div><div><br></div><div>2. 缓存模式的选择, flashcache目前支持3种模式</div><div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >Writethrough - safest, all writes are cached to ssd but also written to disk</font></div><div><font size="2"   >immediately. &nbsp;If your ssd has slower write performance than your disk (likely</font></div><div><font size="2"   >for early generation SSDs purchased in 2008-2010), this may limit your system&nbsp;</font></div><div><font size="2"   >write performance. &nbsp;All disk reads are cached (tunable). &nbsp;</font></div><p></p></pre></div><div><span style="line-height: 28px;"   >写操作, 会写SSD(flashcache盘), 同时写磁盘(数据盘).&nbsp;</span></div><div><span style="line-height: 28px;"   >读操作, 所有读操作的数据都会读入SSD</span><span style="line-height: 28px;"   >(flashcache盘), 但可以通过sysctl调整.&nbsp;</span>dev.flashcache.&lt;cachedev&gt;.cache_all</div><div><br></div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >Writearound - again, very safe, writes are not written to ssd but directly to</font></div><div><font size="2"   >disk. &nbsp;Disk blocks will only be cached after they are read. &nbsp;All disk reads</font></div><div><font size="2"   >are cached (tunable).</font></div><p></p></pre></div><div>写操作, 直接写磁盘(数据盘), 不写SSD(flashcache盘).</div><div><div style="line-height: 28px;"   ><span style="line-height: 28px;"   >读操作, 所有读操作的数据都会读入SSD</span><span style="line-height: 28px;"   >(flashcache盘), 但可以通过sysctl调整.&nbsp;</span>dev.flashcache.&lt;cachedev&gt;.cache_all</div></div><div><br></div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >Writeback - fastest but less safe. &nbsp;Writes only go to the ssd initially, and</font></div><div><font size="2"   >based on various policies are written to disk later. &nbsp;All disk reads are</font></div><div><font size="2"   >cached (tunable). &nbsp;</font></div><p></p></pre></div></div><div><div style="line-height: 28px;"   >写操作, 写SSD(flashcache盘), 然后异步的写入磁盘(数据盘).</div><div style="line-height: 28px;"   ><div style="line-height: 28px;"   ><span style="line-height: 28px;"   >读操作, 所有读操作的数据都会读入SSD</span><span style="line-height: 28px;"   >(flashcache盘), 但可以通过sysctl调整.&nbsp;</span>dev.flashcache.&lt;cachedev&gt;.cache_all</div><div style="line-height: 28px;"   ><br></div><div style="line-height: 28px;"   >对于顺序写入, 一般的SSD和普通15K转速的磁盘性能差别不是特别大. 如果普通盘的性能更好的话, writearound更合算. 一般的场景的话三种模式差不多.</div><div style="line-height: 28px;"   >对于离散写入, SSD性能要比普通磁盘好很多. writeback很适合.</div><div style="line-height: 28px;"   >后面会提到如何优化顺序写入.</div></div></div><div><br></div><div>3. 缓存持久化.</div><div>只有writeback会持久化到ssd(flashcache盘), 因为它<span style="line-height: 28px;"   >是异步写入到磁盘的. 所以必须持久化</span><span style="line-height: 28px;"   >不能丢.&nbsp;</span></div><div><span style="line-height: 28px;"   >而对于writethrough 和 writearound 重启或设备remove后, 数据就丢了, 也不影响数据一致性.</span></div><div><span style="line-height: 28px;"   ><br></span></div><div><span style="line-height: 28px;"   >4. 已知的BUG</span></div><div><a target="_blank" rel="nofollow" href="https://github.com/facebook/flashcache/issues"   >https://github.com/facebook/flashcache/issues</a></div><div><br></div><div>5. cachedev块设备的管理, dmsetup命令, 或者使用flashcache封装好的3个命令.</div><div>5.1 创建cache dev设备</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >flashcache_create, flashcache_load and&nbsp;<span style="line-height: 28px;"   >flashcache_destroy.&nbsp;</span></font></div><div><font size="2"   ><span style="line-height: 28px;"   >These utilities use dmsetup internally, presenting&nbsp;</span><span style="line-height: 28px;"   >a simpler interface to create,&nbsp;</span></font></div><div><span style="line-height: 28px;"   ><font size="2"   >load and destroy flashcache volumes.</font></span></div><div><font size="2"   >It is expected that the majority of users can use these utilities&nbsp;<span style="line-height: 28px;"   >instead of using dmsetup.</span></font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >flashcache_create : Create a new flashcache volume.</font></div><div><font size="2"   ><br></font></div><div><div><font size="2"   ># flashcache_create&nbsp;</font></div><div><font size="2"   >Usage: flashcache_create [-v] [-p back|thru|around] [-b block size] [-m md block size] [-s cache size] [-a associativity] cachedev ssd_devname disk_devname</font></div><div><font size="2"   >Usage : flashcache_create Cache Mode back|thru|around is required argument</font></div><div><font size="2"   >Usage : flashcache_create Default units for -b, -m, -s are sectors, or specify in k/M/G. Default associativity is 512.</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   >-v : verbose.</font></div><div><font size="2"   >-p : cache mode (writeback/writethrough/writearound).</font></div><div><font size="2"   >-s : cache size. Optional. If this is not specified, the entire ssd device</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;is used as cache. The default units is sectors. But you can specify&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;k/m/g as units as well.</font></div><div><font size="2"   >-b : block size. Optional. Defaults to 4KB. Must be a power of 2. &nbsp;建议和SSD设备(flashcache设备) 的扇区大小一致.&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;The default units is sectors. But you can specify k as units as well.</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;(A 4KB blocksize is the correct choice for the vast majority of&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;applications. But see the section "Cache Blocksize selection" below).</font></div><div><font size="2"   >-f : force create. by pass checks (eg for ssd sectorsize).</font></div><div><span style="line-height: 28px;"   ><font size="2"   ><br></font></span></div><div><span style="line-height: 28px;"   ><font size="2"   >Examples :</font></span></div><div><font size="2"   >flashcache_create -p back -s 1g -b 4k cachedev /dev/sdc /dev/sdb</font></div><div><font size="2"   >Creates a 1GB writeback cache volume with a 4KB block size on ssd&nbsp;</font></div><div><font size="2"   >device /dev/sdc to cache the disk volume /dev/sdb. The name of the device&nbsp;</font></div><div><font size="2"   >created is "cachedev".</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >flashcache_create -p thru -s 2097152 -b 8 cachedev /dev/sdc /dev/sdb</font></div><div><font size="2"   >Same as above but creates a write through cache with units specified in&nbsp;</font></div><div><font size="2"   >sectors instead. The name of the device created is "cachedev".</font></div></div><p></p></pre></div><div><div><br></div><div>注意指定-s cache size, 否则整个ssd或ssd分区全部使用.</div><div>-b cache dev blocksize 和 -m cache dev metadata blocksize</div><div>cache数据块和metadata 数据块大小的选择原则 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >Cache Blocksize selection : 推荐和底层SSD设备一致.</font></div><div><font size="2"   >=========================</font></div><div><font size="2"   >Cache blocksize selection is critical for good cache utilization and&nbsp;<span style="line-height: 28px;"   >performance.&nbsp;</span></font></div><div><font size="2"   >A 4KB cache blocksize for the vast majority of workloads (and filesystems).</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Cache Metadata Blocksize selection : 推荐和底层SSD设备一致.</font></div><div><font size="2"   >==================================</font></div><div><font size="2"   >This section only applies to the writeback cache mode. 只有writeback需要存储metadata块.</font></div><div><font size="2"   >Writethrough and&nbsp;<span style="line-height: 28px;"   >writearound modes store no cache metadata at all.</span></font></div><div><font size="2"   ><br></font></div><div><font size="2"   >In Flashcache version 1, the metadata blocksize was fixed at 1 (512b) sector.</font></div><div><font size="2"   >Flashcache version 2 removes this limitation. In version 2, we can configure&nbsp;</font></div><div><font size="2"   >a larger flashcache metadata blocksize.&nbsp;</font></div><div><font size="2"   >Version 2 maintains backwards compatibility&nbsp;<span style="line-height: 28px;"   >for caches created with Version 1.&nbsp;</span></font></div><div><font size="2"   ><span style="line-height: 28px;"   >For these cases, a metadata blocksize of 512&nbsp;</span><span style="line-height: 28px;"   >will continue to be used.</span></font></div><div><font size="2"   ><br></font></div><div><font size="2"   >flashcache_create -m can be used to optionally configure the metadata blocksize.</font></div><div><font size="2"   >Defaults to 4KB.&nbsp;</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Ideal choices for the metadata blocksize are 4KB (default) or 8KB. There is&nbsp;</font></div><div><font size="2"   >little benefit to choosing a metadata blocksize greater than 8KB. The choice&nbsp;</font></div><div><font size="2"   >of metadata blocksize is subject to the following rules :</font></div><div><font size="2"   >metadata blocksize的选择原则 :&nbsp;</font></div><div><font size="2"   >1) Metadata blocksize must be a power of 2.</font></div><div><font size="2"   >2) Metadata blocksize cannot be smaller than sector size configured on the&nbsp;</font></div><div><font size="2"   >ssd device. &nbsp; &nbsp; metadata blocksize不能小于SSD(flashcache设备)的扇区大小.</font></div><div><font size="2"   >3) A single metadata block cannot contain metadata for 2 cache sets.&nbsp;</font></div><div><font size="2"   >In other&nbsp;<span style="line-height: 28px;"   >words,&nbsp;</span></font></div><div><font size="2"   ><span style="line-height: 28px;"   >with the default associativity of 512 (with each cache metadata slot&nbsp;</span><span style="line-height: 28px;"   >sizing at 16 bytes),&nbsp;</span></font></div><div><span style="line-height: 28px;"   ><font size="2"   >the entire metadata for a given set fits in 8KB (512*16b).</font></span></div><div><font size="2"   >For an associativity of 512, we cannot configure a metadata blocksize greater&nbsp;<span style="line-height: 28px;"   >than 8KB.</span></font></div><div><font size="2"   >&nbsp;选择大metadata blocksize的好处</font></div><div><font size="2"   >Advantages of choosing a larger (than 512b) metadata blocksize :</font></div><div><font size="2"   >- Allows the ssd to be configured to larger sectors. For example, some ssds</font></div><div><font size="2"   >&nbsp; allow choosing a 4KB sector, often a more performant choice. &nbsp;允许配置大的SSD扇区.</font></div><div><font size="2"   >- Allows flashache to do better batching of metadata updates, potentially&nbsp;</font></div><div><font size="2"   >&nbsp; reducing metadata updates, small ssd writes, reducing write amplification</font></div><div><font size="2"   >&nbsp; and higher ssd lifetimes. 减少SSD些操作, 提高SSD使用寿命.</font></div><div><font size="2"   >Thanks due to Earle Philhower of Virident for this feature !</font></div><p></p></pre></div><div><br></div><div>5.2 &nbsp;加载已经存在的write back cache dev设备.</div><div>使用flashcache_load加载已经存在的writeback flashcache设备.</div><div>因为重启需要重新加载, 或者使用chkconfig来管理自动加载.</div><div>writearound和writethrough不需要加载.(前面已经说过了, 这两只缓存不持久化到ssd, 重启即删了).</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >flashcache_load : Load an existing writeback cache volume. &nbsp;</font></div><div><font size="2"   >flashcache_load ssd_devname [cachedev_name]</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Example :</font></div><div><font size="2"   >flashcache_load /dev/sd</font></div><div><font size="2"   >Load the existing writeback cache on /dev/sdc, using the virtual&nbsp;<span style="line-height: 28px;"   >cachedev_name from when the device was created.&nbsp;</span></font></div><div><font size="2"   ><span style="line-height: 28px;"   >If you're upgrading from&nbsp;</span><span style="line-height: 28px;"   >an older flashcache device format that didn't store the cachedev name&nbsp;</span><span style="line-height: 28px;"   >internally, or you want to change the cachedev name use, you can specify&nbsp;</span><span style="line-height: 28px;"   >it as an optional second argument to flashcache_load.</span></font></div><div><font size="2"   ><br></font></div><div><font size="2"   >For writethrough and writearound caches flashcache_load is not needed; flashcache_create&nbsp;</font></div><div><font size="2"   >should be used each time.</font></div><p></p></pre></div><div><br></div><div>5.3 删除flashcache dev.</div><div>删除write backup设备的flashcache设备, 比较危险, 所有flashcache中的数据将被删除(未说明是否写脏数据).</div><div>writeback的flashcache设备不推荐这么做. 如果要删除的话, 建议使用dmsetup删除cache dev, 因为dmsetup会自动将脏数据写入磁盘.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >flashcache_destroy : Destroy an existing writeback flashcache. All data will be lost !!!</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >flashcache_destroy ssd_devname</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Example :</font></div><div><font size="2"   >flashcache_destroy /dev/sdc</font></div><div><font size="2"   >Destroy the existing cache on /dev/sdc. All data is lost !!!</font></div><div><font size="2"   >For writethrough and writearound caches this is not necessary.</font></div><p></p></pre></div></div><div><br></div><div>6. 移除flashcache cache dev设备(即device mapper设备).</div><div>对于writeback的cache dev, 先把脏数据自动写入磁盘再移除.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >Removing a flashcache volume :</font></div><div><font size="2"   >============================</font></div><div><font size="2"   >Use dmsetup remove to remove a flashcache volume. For writeback&nbsp;</font></div><div><font size="2"   >cache mode, &nbsp;the default behavior on a remove is to clean all dirty&nbsp;</font></div><div><font size="2"   >cache blocks to disk. The remove will not return until all blocks&nbsp;</font></div><div><font size="2"   >are cleaned. Progress on disk cleaning is reported on the console&nbsp;</font></div><div><font size="2"   >(also see the "fast_remove" flashcache sysctl).</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >A reboot of the node will also result in all dirty cache blocks being</font></div><div><font size="2"   >cleaned synchronously&nbsp;</font></div><div><font size="2"   >(again see the note about "fast_remove" in the&nbsp;<span style="line-height: 28px;"   >sysctls section).</span></font></div><div><font size="2"   ><br></font></div><div><font size="2"   >For writethrough and writearound caches, the device removal or reboot</font></div><div><font size="2"   >results in the cache being destroyed. &nbsp;However, there is no harm is</font></div><div><font size="2"   >doing a 'dmsetup remove' to tidy up before boot, and indeed</font></div><div><font size="2"   >this will be needed if you ever need to unload the flashcache kernel</font></div><div><font size="2"   >module (for example to load an new version into a running system).</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Example:</font></div><div><font size="2"   >dmsetup remove cachedev</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >This removes the flashcache volume name cachedev. Cleaning</font></div><div><font size="2"   >all blocks prior to removal.&nbsp;</font></div></div><div><font size="2"   >快速移除选项如果配置为1的话, 不会同步脏数据到磁盘. 非常危险, 不推荐这么做.</font></div><div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.fast_remove = 0</font></div><div><font size="2"   ><span>	</span>Don't sync dirty blocks when removing cache. On a reload</font></div><div><font size="2"   ><span>	</span>both DIRTY and CLEAN blocks persist in the cache. This&nbsp;</font></div><div><font size="2"   ><span>	</span>option can be used to do a quick cache remove.&nbsp;</font></div><div><font size="2"   ><span>	</span>CAUTION: The cache still has uncommitted (to disk) dirty</font></div><div><font size="2"   ><span>	</span>blocks after a fast_remove.</font></div></div><p></p></pre></div><div><br></div><div>7. flashcache cache dev设备统计信息的查看, 通过dmsetup status或dmsetup table来查看.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >Cache Stats :</font></div><div><font size="2"   >===========</font></div><div><font size="2"   >Use 'dmsetup status' for cache statistics.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >'dmsetup table' also dumps a number of cache related statistics.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Examples :</font></div><div><font size="2"   >dmsetup status cachedev</font></div><div><font size="2"   >dmsetup table cachedev</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >或者直接查看设备的状态文件</font></div><div><font size="2"   >Flashcache errors are reported in&nbsp;</font></div><div><font size="2"   >/proc/flashcache/&lt;cache name&gt;/flashcache_errors</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Flashcache stats are also reported in&nbsp;</font></div><div><font size="2"   >/proc/flashcache/&lt;cache name&gt;/flashcache_stats</font></div><div><font size="2"   >for easier parseability.</font></div><p></p></pre></div><div>例如</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 sda1+sdc3]# dmsetup table cachedev1</font></div><div><font size="2"   >0 207254565 flashcache conf:</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; ssd dev (/dev/sda1), disk dev (/dev/sdc3) cache mode(WRITE_BACK)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; capacity(10216M), associativity(512), data block size(8K) metadata block size(4096b)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; disk assoc(256K)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; skip sequential thresh(0K)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; total blocks(1307648), cached blocks(0), cache percent(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; dirty blocks(0), dirty percent(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; nr_queued(0)</font></div><div><font size="2"   >Size Hist: 512:2660 1024:851 2048:832 4096:8159776 8192:317&nbsp;</font></div><div><font size="2"   >[root@db-172-16-3-150 sda1+sdc3]# dmsetup status cachedev1</font></div><div><font size="2"   >0 207254565 flashcache stats:&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; reads(2477), writes(6)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; read hits(0), read hit percent(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write hits(0) write hit percent(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; dirty write hits(0) dirty write hit percent(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; replacement(0), write replacement(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write invalidates(0), read invalidates(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; pending enqueues(0), pending inval(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; metadata dirties(0), metadata cleans(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; metadata batch(0) metadata ssd writes(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; cleanings(0) fallow cleanings(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; no room(0) front merge(0) back merge(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; force_clean_block(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; disk reads(2477), disk writes(6) ssd reads(0) ssd writes(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; uncached reads(2477), uncached writes(6), uncached IO requeue(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; disk read errors(0), disk write errors(0) ssd read errors(0) ssd write errors(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; uncached sequential reads(0), uncached sequential writes(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; pid_adds(0), pid_dels(0), pid_drops(0) pid_expiry(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; lru hot blocks(653824), lru warm blocks(653824)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; lru promotions(0), lru demotions(0)</font></div><p></p></pre></div><div>或者直接查看设备状态文件</div><div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 sda1+sdc3]# cat /proc/flashcache/sda1+sdc3/flashcache_</font></div><div><font size="2"   >flashcache_errors &nbsp; &nbsp; &nbsp; flashcache_iosize_hist &nbsp;flashcache_pidlists &nbsp; &nbsp; flashcache_stats &nbsp; &nbsp; &nbsp; &nbsp;</font></div><p></p></pre></div><div>错误统计</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 sda1+sdc3]# cat /proc/flashcache/sda1+sdc3/flashcache_errors&nbsp;</font></div><div><font size="2"   >disk_read_errors=0 disk_write_errors=0 ssd_read_errors=0 ssd_write_errors=0 memory_alloc_errors=0</font></div><p></p></pre></div><div>进程白名单和黑名单, 通过sysctl设置使用flashcache设备的PID白名单和黑名单列表 .</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 sda1+sdc3]# cat /proc/flashcache/sda1+sdc3/flashcache_pidlists&nbsp;</font></div><div><font size="2"   >Blacklist:&nbsp;</font></div><div><font size="2"   >Whitelist:&nbsp;</font></div><p></p></pre></div><div>IOSIZE历史</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 sda1+sdc3]# cat /proc/flashcache/sda1+sdc3/flashcache_iosize_hist&nbsp;</font></div><div><font size="2"   >512:2660 1024:851 1536:0 2048:832 2560:0 3072:0 3584:0 4096:8159776 4608:0 5120:0 5632:0 6144:0 6656:0 7168:0 7680:0 8192:317 8704:0 9216:0 9728:0 10240:0 10752:0 11264:0 11776:0 12288:0 12800:0 13312:0 13824:0 14336:0 14848:0 15360:0 15872:0 16384:0&nbsp;</font></div><p></p></pre></div><div>状态信息</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 sda1+sdc3]# cat /proc/flashcache/sda1+sdc3/flashcache_stats&nbsp;</font></div><div><font size="2"   >reads=2477 writes=6&nbsp;</font></div><div><font size="2"   >read_hits=0 read_hit_percent=0 write_hits=0 write_hit_percent=0 dirty_write_hits=0 dirty_write_hit_percent=0 replacement=0 write_replacement=0 write_invalidates=0 read_invalidates=0 pending_enqueues=0 pending_inval=0 metadata_dirties=0 metadata_cleans=0 metadata_batch=0 metadata_ssd_writes=0 cleanings=0 fallow_cleanings=0 no_room=0 front_merge=0 back_merge=0 disk_reads=2477 disk_writes=6 ssd_reads=0 ssd_writes=0 uncached_reads=2477 uncached_writes=6 uncached_IO_requeue=0 uncached_sequential_reads=0 uncached_sequential_writes=0 pid_adds=0 pid_dels=0 pid_drops=0 pid_expiry=0</font></div><p></p></pre></div></div><div><br></div><div>8. 红帽或centos的自启动脚本, 脚本内容见&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="https://github.com/facebook/flashcache/blob/master/utils/flashcache"   >https://github.com/facebook/flashcache/blob/master/utils/flashcache</a></div><div>用于开机时自动加载flashcache模块, 自动创建cache dev, 自动挂载.&nbsp;</div><div>关机时自动remove device mapper block dev. &nbsp;(注意关机时如果没有remove cache dev, 可能导致关机失败.)</div><div>需要在脚本中配置几个变量:&nbsp;SSD_DISK, BACKEND_DISK, CACHEDEV_NAME, MOUNTPOINT, FLASHCACHE_NAME</div><div>但是这个目前仅支持1个cachedev的自动加载和自动卸载.</div><div><pre class="prettyprint"   ><p></p><div><span style="line-height: 28px;"   ><font size="2"   >Using Flashcache sysVinit script (Redhat based systems):</font></span></div><div><div><font size="2"   >=======================================================</font></div><div><font size="2"   >Kindly note that, this sections only applies to the Redhat based systems. Use</font></div><div><font size="2"   >'utils/flashcache' from the repository as the sysvinit script.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >This script is to load, unload and get statistics of an existing flashcache&nbsp;</font></div><div><font size="2"   >writeback cache volume. It helps in loading the already created cachedev during&nbsp;</font></div><div><font size="2"   >system boot and removes the flashcache volume before system halt happens.</font></div><div><font size="2"   ><br></font></div><div><font color="#ff0000"   size="2"   >This script is necessary, because, when a flashcache volume is not removed&nbsp;</font></div><div><font color="#ff0000"   size="2"   >before the system halt, kernel panic occurs.</font></div><div><span style="line-height: 28px;"   ><font size="2"   >注意关机时如果没有remove cache dev, 可能导致关机失败.</font></span></div><div><font size="2"   ><br></font></div><div><font size="2"   >Configuring the script using chkconfig:</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >1. Copy 'utils/flashcache' from the repo to '/etc/init.d/flashcache'</font></div><div><font size="2"   >2. Make sure this file has execute permissions,</font></div><div><font size="2"   >&nbsp; &nbsp;'sudo chmod +x /etc/init.d/flashcache'.</font></div><div><font size="2"   >3. Edit this file and specify the values for the following variables</font></div><div><font size="2"   >&nbsp; &nbsp;SSD_DISK, BACKEND_DISK, CACHEDEV_NAME, MOUNTPOINT, FLASHCACHE_NAME</font></div><div><font size="2"   >4. Modify the headers in the file if necessary.</font></div><div><font size="2"   >&nbsp; &nbsp;By default, it starts in runlevel 3, with start-stop priority 90-10</font></div><div><font size="2"   >5. Register this file using chkconfig</font></div><div><font size="2"   >&nbsp; &nbsp;'chkconfig --add /etc/init.d/flashcache'</font></div></div><p></p></pre></div><div><br></div><div>例如 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@db-172-16-3-150 ~]# cp /opt/soft_bak/flashcache/flashcache-master/utils/flashcache /etc/init.d/</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# chmod 755 /etc/init.d/flashcache&nbsp;</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# vi /etc/init.d/flashcache</font></div></div><div><div><font size="2"   >SSD_DISK=/dev/sda1</font></div><div><font size="2"   >BACKEND_DISK=/dev/sdc3</font></div><div><font size="2"   >CACHEDEV_NAME=cachedev1</font></div><div><font size="2"   >MOUNTPOINT=/opt</font></div><div><font size="2"   >FLASHCACHE_NAME=sda1+sdc3</font></div></div><div><div><font size="2"   >[root@db-172-16-3-150 ~]# service flashcache start</font></div><div><font size="2"   >Starting Flashcache...</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# df -h</font></div></div><div><div><font size="2"   >/dev/mapper/cachedev1</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;98G &nbsp; 51G &nbsp; 42G &nbsp;55% /opt</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@db-172-16-3-150 ~]# service flashcache status</font></div><div><font size="2"   >Flashcache status: loaded</font></div><div><font size="2"   >0 207254565 flashcache stats:&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; reads(1598), writes(1)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; read hits(0), read hit percent(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write hits(0) write hit percent(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; dirty write hits(0) dirty write hit percent(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; replacement(0), write replacement(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write invalidates(0), read invalidates(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; pending enqueues(0), pending inval(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; metadata dirties(0), metadata cleans(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; metadata batch(0) metadata ssd writes(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; cleanings(0) fallow cleanings(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; no room(0) front merge(0) back merge(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; force_clean_block(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; disk reads(1598), disk writes(1) ssd reads(0) ssd writes(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; uncached reads(1598), uncached writes(1), uncached IO requeue(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; disk read errors(0), disk write errors(0) ssd read errors(0) ssd write errors(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; uncached sequential reads(0), uncached sequential writes(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; pid_adds(0), pid_dels(0), pid_drops(0) pid_expiry(0)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; lru hot blocks(6144), lru warm blocks(6144)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; lru promotions(0), lru demotions(0)</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@db-172-16-3-150 ~]# service flashcache stop</font></div><div><font size="2"   >dev.flashcache.sda1+sdc3.fast_remove = 0</font></div><div><font size="2"   >Flushing flashcache: Flushes to /dev/sdc3</font></div></div><p></p></pre></div><div><br></div><div>9. flashcache 模块参数设置, 需要针对ssd devname+disk devname配置 &nbsp;:&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >FlashCache Sysctls :</font></div><div><font size="2"   >==================</font></div><div><font size="2"   >Flashcache sysctls operate on a <font color="#ff0000"   >per-cache device</font> basis. A couple of examples</font></div><div><font size="2"   >first.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Sysctls for a writearound or writethrough mode cache :</font></div><div><font size="2"   >cache device /dev/ram3, disk device /dev/ram4</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >dev.flashcache.ram3+ram4.cache_all = 1</font></div><div><font size="2"   >dev.flashcache.ram3+ram4.zero_stats = 0</font></div><div><font size="2"   >dev.flashcache.ram3+ram4.reclaim_policy = 0</font></div><div><font size="2"   >dev.flashcache.ram3+ram4.pid_expiry_secs = 60</font></div><div><font size="2"   >dev.flashcache.ram3+ram4.max_pids = 100</font></div><div><font size="2"   >dev.flashcache.ram3+ram4.do_pid_expiry = 0</font></div><div><font size="2"   >dev.flashcache.ram3+ram4.io_latency_hist = 0</font></div><div><font size="2"   >dev.flashcache.ram3+ram4.skip_seq_thresh_kb = 0</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Sysctls for a writeback mode cache :</font></div><div><font size="2"   >cache device /dev/sdb, disk device /dev/cciss/c0d2</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.fallow_delay = 900</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.fallow_clean_speed = 2</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.cache_all = 1</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.fast_remove = 0</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.zero_stats = 0</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.reclaim_policy = 0</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.pid_expiry_secs = 60</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.max_pids = 100</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.do_pid_expiry = 0</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.max_clean_ios_set = 2</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.max_clean_ios_total = 4</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.dirty_thresh_pct = 20</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.stop_sync = 0</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.do_sync = 0</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.io_latency_hist = 0</font></div><div><font size="2"   >dev.flashcache.sdb+c0d2.skip_seq_thresh_kb = 0</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Sysctls common to all cache modes :</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.cache_all:</font></div><div><font size="2"   ><span>	</span>Global caching mode to cache everything or cache nothing.</font></div><div><font size="2"   ><span>	</span>See section on Caching Controls. Defaults to "cache everything". 时候缓存所有或啥都不缓存( 另外可以通过进程ID白名单和黑名单控制) , 如果要用白名单, cache_all=0, 如果要用黑名单, 那就设置为cache_all=1;</font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.zero_stats:</font></div><div><font size="2"   ><span>	</span>Zero stats (once).</font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.reclaim_policy: 缓存回收策略, 可以动态调整.</font></div><div><font size="2"   ><span>	</span>FIFO (0) vs LRU (1). Defaults to FIFO. Can be switched at&nbsp;</font></div><div><font size="2"   ><span>	</span>runtime.</font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.io_latency_hist: &nbsp;是否统计IO延迟柱状图, 对clocksource慢的机器有比较大的性能影响.&nbsp;</font></div><div><font size="2"   ><span>	</span>Compute IO latencies and plot these out on a histogram.</font></div><div><font size="2"   ><span>	</span>The scale is 250 usecs. This is disabled by default since&nbsp;</font></div><div><font size="2"   ><span>	</span>internally flashcache uses gettimeofday() to compute latency</font></div><div><font size="2"   ><span>	</span>and this can get expensive depending on the clocksource used.</font></div><div><font size="2"   ><span>	</span>Setting this to 1 enables computation of IO latencies.</font></div><div><font size="2"   ><span>	</span>The IO latency histogram is appended to 'dmsetup status'.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >以下不建议调整</font></div><div><font size="2"   >(There is little reason to tune these)</font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.max_pids:</font></div><div><font size="2"   ><span>	</span>Maximum number of pids in the white/black lists.</font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.do_pid_expiry:</font></div><div><font size="2"   ><span>	</span>Enable expiry on the list of pids in the white/black lists.</font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.pid_expiry_secs:</font></div><div><font size="2"   ><span>	</span>Set the expiry on the pid white/black lists.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.skip_seq_thresh_kb: &nbsp;有点类似ZFS在ARC的设计, 跳过连续IO扫描的CACHE, 例如数据库大表的全表扫描, 可能不推荐加载到CACHE中. 但是因为是后触发的, 所以必须先达到这么大的IO量才会关闭后续的写入CACHE, 也就是说连续IO的开始部分(触发skip前)的数据还是写入SSD了. 结合cache dev所对应的机械盘的连续IO能力来判断, 例如100MB.</font></div><div><font size="2"   ><span>	</span>Skip (don't cache) sequential IO larger than this number (in kb).</font></div><div><font size="2"   ><span>	</span>0 (default) means cache all IO, both sequential and random.</font></div><div><font size="2"   ><span>	</span>Sequential IO can only be determined 'after the fact', so</font></div><div><font size="2"   ><span>	</span>this much of each sequential I/O will be cached before we skip&nbsp;</font></div><div><font size="2"   ><span>	</span>the rest. &nbsp;Does not affect searching for IO in an existing cache.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >以下只有writeback模式才允许的设置 :&nbsp;</font></div><div><font size="2"   >Sysctls for writeback mode only :</font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.fallow_delay = 900 &nbsp; 多少秒之后, 未有读写的缓存脏数据会写入磁盘.</font></div><div><font size="2"   ><span>	</span>In seconds. Clean dirty blocks that have been "idle" (not&nbsp;</font></div><div><font size="2"   ><span>	</span>read or written) for fallow_delay seconds. Default is 15</font></div><div><font size="2"   ><span>	</span>minutes. &nbsp;</font></div><div><font size="2"   ><span>	</span>Setting this to 0 disables idle cleaning completely.</font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.fallow_clean_speed = 2</font></div><div><font size="2"   ><span>	</span>The maximum number of "fallow clean" disk writes per set&nbsp;</font></div><div><font size="2"   ><span>	</span>per second. Defaults to 2.</font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.fast_remove = 0 &nbsp;是否在remove device mapper设备前将脏数据写入对应的磁盘.</font></div><div><font size="2"   ><span>	</span>Don't sync dirty blocks when removing cache. On a reload</font></div><div><font size="2"   ><span>	</span>both DIRTY and CLEAN blocks persist in the cache. This&nbsp;</font></div><div><font size="2"   ><span>	</span>option can be used to do a quick cache remove.&nbsp;</font></div><div><font size="2"   ><span>	</span>CAUTION: The cache still has uncommitted (to disk) dirty</font></div><div><font size="2"   ><span>	</span>blocks after a fast_remove.</font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.dirty_thresh_pct = 20 &nbsp; 允许的脏数据的比例.</font></div><div><font size="2"   ><span>	</span>Flashcache will attempt to keep the dirty blocks in each set&nbsp;</font></div><div><font size="2"   ><span>	</span>under this %. A lower dirty threshold increases disk writes,&nbsp;</font></div><div><font size="2"   ><span>	</span>and reduces block overwrites, but increases the blocks</font></div><div><font size="2"   ><span>	</span>available for read caching.</font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.stop_sync = 0 &nbsp; &nbsp;停止sync.</font></div><div><font size="2"   ><span>	</span>Stop the sync in progress.</font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.do_sync = 0 &nbsp; &nbsp;执行sync, 将脏数据写入磁盘.</font></div><div><font size="2"   ><span>	</span>Schedule cleaning of all dirty blocks in the cache.&nbsp;</font></div><div><font size="2"   >以下不建议调整 &nbsp;:&nbsp;</font></div><div><font size="2"   >(There is little reason to tune these)</font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.max_clean_ios_set = 2</font></div><div><font size="2"   ><span>	</span>Maximum writes that can be issues per set when cleaning</font></div><div><font size="2"   ><span>	</span>blocks.</font></div><div><font size="2"   >dev.flashcache.&lt;cachedev&gt;.max_clean_ios_total = 4</font></div><div><font size="2"   ><span>	</span>Maximum writes that can be issued when syncing all blocks.</font></div><p></p></pre></div><div><br></div><div>10. 直接使用dmsetup管理cache device. 可以直接使用flashcache_xxx来封装管理, 所以dmsetup可以不必使用.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >Using dmsetup to create and load flashcache volumes :</font></div><div><font size="2"   >===================================================</font></div><div><font size="2"   >Few users will need to use dmsetup natively to create and load&nbsp;</font></div><div><font size="2"   >flashcache volumes. This section covers that.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >dmsetup create device_name table_file</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >where</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >device_name: name of the flashcache device being created or loaded.</font></div><div><font size="2"   >table_file : other cache args (format below). If this is omitted, dmsetup&nbsp;</font></div><div><font size="2"   ><span>	</span> &nbsp; &nbsp; attempts to read this from stdin.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >table_file format :</font></div><div><font size="2"   >0 &lt;disk dev sz in sectors&gt; flashcache &lt;disk dev&gt; &lt;ssd dev&gt; &lt;dm virtual name&gt; &lt;cache mode&gt; &lt;flashcache cmd&gt; &lt;blksize in sectors&gt; [size of cache in sectors] [cache set size]</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >cache mode:</font></div><div><font size="2"   ><span>	</span> &nbsp; 1: Write Back</font></div><div><font size="2"   ><span>	</span> &nbsp; 2: Write Through</font></div><div><font size="2"   ><span>	</span> &nbsp; 3: Write Around</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >flashcache cmd:&nbsp;</font></div><div><font size="2"   ><span>	</span> &nbsp; 1: load existing cache</font></div><div><font size="2"   ><span>	</span> &nbsp; 2: create cache</font></div><div><font size="2"   ><span>	</span> &nbsp; 3: force create cache (overwriting existing cache). USE WITH CAUTION</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >blksize in sectors:</font></div><div><font size="2"   ><span>	</span> &nbsp; 4KB (8 sectors, PAGE_SIZE) is the right choice for most applications.</font></div><div><font size="2"   ><span>	</span> &nbsp; See note on block size selection below.</font></div><div><font size="2"   ><span>	</span> &nbsp; Unused (can be omitted) for cache loads.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >size of cache in sectors:</font></div><div><font size="2"   ><span>	</span> &nbsp; Optional. if size is not specified, the entire ssd device is used as</font></div><div><font size="2"   ><span>	</span> &nbsp; cache. Needs to be a power of 2.</font></div><div><font size="2"   ><span>	</span> &nbsp; Unused (can be omitted) for cache loads.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >cache set size:</font></div><div><font size="2"   ><span>	</span> &nbsp; Optional. The default set size is 512, which works well for most&nbsp;</font></div><div><font size="2"   ><span>	</span> &nbsp; applications. Little reason to change this. Needs to be a</font></div><div><font size="2"   ><span>	</span> &nbsp; power of 2.</font></div><div><font size="2"   ><span>	</span> &nbsp; Unused (can be omitted) for cache loads.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Example :</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >echo 0 `blockdev --getsize /dev/cciss/c0d1p2` flashcache /dev/cciss/c0d1p2 /dev/fioa2 cachedev 1 2 8 522000000 | dmsetup create cachedev</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >This creates a writeback cache device called "cachedev" (/dev/mapper/cachedev)</font></div><div><font size="2"   >with a 4KB blocksize to cache /dev/cciss/c0d1p2 on /dev/fioa2.</font></div><div><font size="2"   >The size of the cache is 522000000 sectors.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >(TODO : Change loading of the cache happen via "dmsetup load" instead</font></div><div><font size="2"   >of "dmsetup create").</font></div><p></p></pre></div><div><br></div><div>11. 缓存的控制 , 白名单和黑名单.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >Caching Controls</font></div><div><font size="2"   >================</font></div><div><font size="2"   >Flashcache can be put in one of 2 modes - Cache Everything or&nbsp;</font></div><div><font size="2"   >Cache Nothing (dev.flashcache.cache_all). The defaults is to "cache</font></div><div><font size="2"   >everything".</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >These 2 modes have a blacklist and a whitelist.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >The tgid (thread group id) for a group of pthreads can be used as a</font></div><div><font size="2"   >shorthand to tag all threads in an application. The tgid for a pthread</font></div><div><font size="2"   >is returned by getpid() and the pid of the individual thread is</font></div><div><font size="2"   >returned by gettid().</font></div><div><font size="2"   >pid和tgid分别使用getpid()和gettid()获取, 可以用systemtap试一试. 参见</font></div><div><a target="_blank" rel="nofollow" href="https://sourceware.org/systemtap/documentation.html"   ><font size="2"   >https://sourceware.org/systemtap/documentation.html</font></a></div><div><a target="_blank" rel="nofollow" href="http://blog.163.com/digoal@126/blog/#m=0&amp;t=1&amp;c=fks_084068084086080075085082085095085080082075083081086071084"   ><font size="2"   >http://blog.163.com/digoal@126/blog/#m=0&amp;t=1&amp;c=fks_084068084086080075085082085095085080082075083081086071084</font></a></div><div><font size="2"   ><br></font></div><div><font size="2"   >The algorithm works as follows :</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >In "cache everything" mode, 缓存所有, 先查黑名单(不缓存), 再查白名单(缓存), 最后达到连续IO限制的话跳过缓存.</font></div><div><font size="2"   >1) If the pid of the process issuing the IO is in the blacklist, do</font></div><div><font size="2"   >not cache the IO. ELSE,</font></div><div><font size="2"   >2) If the tgid is in the blacklist, don't cache this IO. UNLESS</font></div><div><font size="2"   >3) The particular pid is marked as an exception (and entered in the</font></div><div><font size="2"   >whitelist, which makes the IO cacheable).</font></div><div><font size="2"   >4) Finally, even if IO is cacheable up to this point, skip sequential IO&nbsp;</font></div><div><font size="2"   >if configured by the sysctl.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Conversely, in "cache nothing" mode, 不<span style="line-height: 28px;"   >缓存任何, 先查白名单(缓存), 再查黑名单(不换成), 最后达到连续IO限制的话跳过缓存.</span></font></div><div><font size="2"   >1) If the pid of the process issuing the IO is in the whitelist,</font></div><div><font size="2"   >cache the IO. ELSE,</font></div><div><font size="2"   >2) If the tgid is in the whitelist, cache this IO. UNLESS</font></div><div><font size="2"   >3) The particular pid is marked as an exception (and entered in the</font></div><div><font size="2"   >blacklist, which makes the IO non-cacheable).</font></div><div><font size="2"   >4) Anything whitelisted is cached, regardless of sequential or random</font></div><div><font size="2"   >IO.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Examples :</font></div><div><font size="2"   >--------</font></div><div><font size="2"   >1) You can make the global cache setting "cache nothing", and add the</font></div><div><font size="2"   >tgid of your pthreaded application to the whitelist. Which makes only</font></div><div><font size="2"   >IOs issued by your application cacheable by Flashcache.&nbsp;</font></div><div><font size="2"   >2) You can make the global cache setting "cache everything" and add</font></div><div><font size="2"   >tgids (or pids) of other applications that may issue IOs on this</font></div><div><font size="2"   >volume to the blacklist, which will make those un-interesting IOs not</font></div><div><font size="2"   >cacheable.&nbsp;</font></div><div><font size="2"   ><br></font></div><div><font color="#ff0000"   size="2"   >Note that this only works for O_DIRECT IOs. For buffered IOs, pdflush,</font></div><div><font color="#ff0000"   size="2"   >kswapd would also do the writes, with flashcache caching those. 只对O_DIRECT IO请求有效控制.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >The following cacheability ioctls are supported on /dev/mapper/&lt;cachedev&gt;&nbsp;</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >FLASHCACHEADDBLACKLIST: add the pid (or tgid) to the blacklist.</font></div><div><font size="2"   >FLASHCACHEDELBLACKLIST: Remove the pid (or tgid) from the blacklist.</font></div><div><font size="2"   >FLASHCACHEDELALLBLACKLIST: Clear the blacklist. This can be used to</font></div><div><font size="2"   >cleanup if a process dies.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >FLASHCACHEADDWHITELIST: add the pid (or tgid) to the whitelist.</font></div><div><font size="2"   >FLASHCACHEDELWHITELIST: Remove the pid (or tgid) from the whitelist.</font></div><div><font size="2"   >FLASHCACHEDELALLWHITELIST: Clear the whitelist. This can be used to</font></div><div><font size="2"   >cleanup if a process dies.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >/proc/flashcache_pidlists shows the list of pids on the whitelist&nbsp;<span style="line-height: 28px;"   >and the blacklist.</span></font></div><p></p></pre></div><div><span style="line-height: 28px;"   ><br></span></div><div><span style="line-height: 28px;"   >12. 缓存安全, 用户进程可能在只有只读权限的情况下, 破坏缓存盘的数据.</span></div><div><span style="line-height: 28px;"   >现在的解决办法是, 收紧权限, 哪怕只读权限也不给其他用户.</span></div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >Security Note :</font></div><div><font size="2"   >=============</font></div><div><font size="2"   >With Flashcache, it is possible for a malicious user process to&nbsp;</font></div><div><font size="2"   >corrupt data in files with only read access. In a future revision</font></div><div><font size="2"   >of flashcache, this will be addressed (with an extra data copy).</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Not documenting the mechanics of how a malicious process could&nbsp;</font></div><div><font size="2"   >corrupt data here.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >You can work around this by setting file permissions on files in&nbsp;</font></div><div><font size="2"   >the flashcache volume appropriately.</font></div><p></p></pre></div><div><br></div><div>13. &nbsp;SSD使用率过低的问题.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >因为SSD sets和HDD sets是一对多的关系, 也就是说多个HDD数据块可能竞争一个SSD cache区域.</font></div><div><font size="2"   >如果竞争同一个SSD CACHE区域的块都是需要缓存的块, 而不发生竞争的块都不需要缓存的话, 最糟糕的的情况就发生了, 利用率会极低. 看个例子 :&nbsp;</font></div><div><div><font size="2"   >Why is my cache only (&lt;&lt; 100%) utilized ?</font></div><div><font size="2"   >=======================================</font></div><div><font size="2"   >(Answer contributed by Will Smith)</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >- There is essentially a &nbsp;1:many mapping between SSD blocks and HDD blocks. (ssd blocks和hdd blocks是一对多的映射关系.)</font></div><div><font size="2"   >- In more detail, a HDD block gets hashed to a set on SSD which contains by&nbsp;</font></div><div><font size="2"   >&nbsp; default 512 blocks. &nbsp;It can only be stored in that set on SSD, nowhere else.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >So with a simplified SSD containing only 3 sets:</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >SSD = 1 2 3 , and a HDD with 9 sets worth of data, the HDD sets would map to the SSD&nbsp;</font></div><div><font size="2"   >sets like this:</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >HDD: 1 2 3 4 5 6 7 8 9</font></div><div><font size="2"   >SSD: 1 2 3 1 2 3 1 2 3</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >So if your data only happens to live in HDD sets 1 and 4, they will compete for&nbsp;</font></div><div><font size="2"   >SSD set 1 and your SSD will at most become 33% utilized.</font></div><div><font size="2"   >HDD 数据集1和4都存储在SSD的1号集, 如果HDD1,4都是需要缓存的, 其他HDD集(2,3,5,6,7,8,9)都不是活跃数据不需要缓存, 那么最糟的情况就是SSD只有33%在使用, 为了提高使用率, XFS文件系统支持调整agsize和agcount来实现目的.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >If you use XFS you can tune the XFS agsize/agcount to try and mitigate this&nbsp;</font></div><div><font size="2"   >(described next section).</font></div></div><p></p></pre></div><div><br></div><div>14. XFS文件系统优化, 应对CACHE 使用率过低的问题.</div><div>通过调整xfs的allocation group参数agsize, agcount来优化SSD的使用.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >Tuning XFS for better flashcache performance :</font></div><div><font size="2"   >============================================</font></div><div><font size="2"   >If you run XFS/Flashcache, it is worth tuning XFS' allocation group</font></div><div><font size="2"   >parameters (agsize/agcount) to achieve better flashcache performance.</font></div><div><font color="#ff0000"   size="2"   >XFS allocates blocks for files in a given directory in a new &nbsp;(利用XFS可以将一个目录中的多个文件分散到多个agroup来分散数据块存储)</font></div><div><font size="2"   ><font color="#ff0000"   >allocation group. </font>By tuning agsize and agcount (mkfs.xfs parameters),</font></div><div><font size="2"   >we can achieve much better distribution of blocks across</font></div><div><font size="2"   >flashcache. <font color="#ff0000"   >Better distribution of blocks across flashcache will</font></font></div><div><font color="#ff0000"   size="2"   >decrease collisions on flashcache sets considerably, increase cache</font></div><div><font color="#ff0000"   size="2"   >hit rates significantly and result in lower IO latencies. (分散的数据块可以优化FLASHCACHE的冲突, 13章节已经提到了这个原因)</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >We can achieve this by computing agsize (and implicitly agcount) using</font></div><div><font size="2"   >these equations,</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >计算公式 :&nbsp;</font></div><div><font color="#ff0000"   size="2"   >C = Cache size,&nbsp;</font></div><div><font color="#ff0000"   size="2"   >V = Size of filesystem Volume.</font></div><div><font color="#ff0000"   size="2"   ><br></font></div><div><font color="#ff0000"   size="2"   >agsize % C = (1/agcount)*C</font></div><div><font color="#ff0000"   size="2"   >agsize * agcount ~= V</font></div><div><font color="#ff0000"   size="2"   ><br></font></div><div><font color="#ff0000"   size="2"   >where agsize &lt;= 1000g (XFS limits on agsize).</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >A couple of examples that illustrate the formula,</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >For agcount = 4, let's divide up the cache into 4 equal parts (each</font></div><div><font size="2"   >part is size C/agcount). Let's call the parts C1, C2, C3, C4. One</font></div><div><font size="2"   >ideal way to map the allocation groups onto the cache is as follows.</font></div><div><font size="2"   >理想的HDD和CACHE对应的条带组合, 每个条带错位, 得到好CACHE的分布, 减少CACHE SET征用的冲突.</font></div><div><font size="2"   >Ag1<span>	</span> &nbsp; &nbsp; Ag2<span>	</span>Ag3<span>	</span> &nbsp; &nbsp; &nbsp; Ag4</font></div><div><font size="2"   >--<span>	</span> &nbsp; &nbsp; --<span>		</span>--<span>	</span> &nbsp; &nbsp; &nbsp; --</font></div><div><font size="2"   >C1<span>	</span> &nbsp; &nbsp; C2<span>		</span>C3<span>	</span> &nbsp; &nbsp; &nbsp; C4<span>	</span>(stripe 1)</font></div><div><font size="2"   >C2<span>	</span> &nbsp; &nbsp; C3<span>		</span>C4<span>	</span> &nbsp; &nbsp; &nbsp; C1<span>	</span>(stripe 2)</font></div><div><font size="2"   >C3<span>	</span> &nbsp; &nbsp; C4<span>		</span>C1<span>	</span> &nbsp; &nbsp; &nbsp; C2<span>	</span>(stripe 3)</font></div><div><font size="2"   >C4<span>	</span> &nbsp; &nbsp; C1<span>		</span>C2<span>	</span> &nbsp; &nbsp; &nbsp; C3<span>	</span>(stripe 4)</font></div><div><font size="2"   >C1<span>	</span> &nbsp; &nbsp; C2<span>		</span>C3<span>	</span> &nbsp; &nbsp; &nbsp; C4<span>	</span>(stripe 5)</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >In this simple example, note that each "stripe" has 2 properties</font></div><div><font size="2"   >1) Each element of the stripe is a unique part of the cache.</font></div><div><font size="2"   >2) The union of all the parts for a stripe gives us the entire cache.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Clearly, this is an ideal mapping, from a distribution across the</font></div><div><font size="2"   >cache point of view.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Another example, this time with agcount = 5, the cache is divided into</font></div><div><font size="2"   >5 equal parts C1, .. C5.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Ag1<span>	</span> &nbsp; &nbsp; Ag2<span>	</span>Ag3<span>	</span> &nbsp; &nbsp; &nbsp; Ag4<span>	</span>Ag5</font></div><div><font size="2"   >--<span>	</span> &nbsp; &nbsp; --<span>		</span>--<span>	</span> &nbsp; &nbsp; &nbsp; --<span>	</span>--</font></div><div><font size="2"   >C1<span>	</span> &nbsp; &nbsp; C2<span>		</span>C3<span>	</span> &nbsp; &nbsp; &nbsp; C4<span>	</span>C5<span>	</span>(stripe 1)</font></div><div><font size="2"   >C2<span>	</span> &nbsp; &nbsp; C3<span>		</span>C4<span>	</span> &nbsp; &nbsp; &nbsp; C5<span>	</span>C1<span>	</span>(stripe 2)</font></div><div><font size="2"   >C3<span>	</span> &nbsp; &nbsp; C4<span>		</span>C5<span>	</span> &nbsp; &nbsp; &nbsp; C1<span>	</span>C2<span>	</span>(stripe 3)</font></div><div><font size="2"   >C4<span>	</span> &nbsp; &nbsp; C5<span>		</span>C1<span>	</span> &nbsp; &nbsp; &nbsp; C2<span>	</span>C3<span>	</span>(stripe 4)</font></div><div><font size="2"   >C5<span>	</span> &nbsp; &nbsp; C1<span>		</span>C2<span>	</span> &nbsp; &nbsp; &nbsp; C3<span>	</span>C4<span>	</span>(stripe 5)</font></div><div><font size="2"   >C1<span>	</span> &nbsp; &nbsp; C2<span>		</span>C3<span>	</span> &nbsp; &nbsp; &nbsp; C4<span>	</span>C5<span>	</span>(stripe 6)</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >A couple of examples that compute the optimal agsize for a given</font></div><div><font size="2"   >Cachesize and Filesystem volume size.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >a) C = 600g, V = 3,5TB</font></div><div><font size="2"   >Consider agcount = 5</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >agsize % 600 = (1/5)*600</font></div><div><font size="2"   >agsize % 600 = 120</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >So an agsize of 720g would work well, and 720*5 = 3.6TB (~ 3.5TB)</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >b) C = 150g, V = 3.5TB</font></div><div><font size="2"   >Consider agcount=4</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >agsize % 150 = (1/4)*150</font></div><div><font size="2"   >agsize % 150 = 37.5</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >So an agsize of 937g would work well, and 937*4 = 3.7TB (~ 3.5TB)</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >As an alternative,&nbsp;</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >agsize % C = (1 - (1/agcount))*C</font></div><div><font size="2"   >agsize * agcount ~= V</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Works just as well as the formula above.</font></div><div><font size="2"   >不想自己计算的话, 可以尝试一下直接使用flashcache提供的get_agsize工具.</font></div><div><font size="2"   >This computation has been implemented in the utils/get_agsize utility.</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   >使用mkfs.xfs创建文件系统时指定agsize, agcount.</font></div><div><font size="2"   >man mkfs.xfs</font></div><div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp;-d data_section_options</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; These &nbsp;options &nbsp;specify &nbsp;the location, size, and other parameters of the data section of the filesystem.</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; The valid data_section_options are:</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;agcount=value</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; This is used to specify the number of allocation groups. The data section of the &nbsp;filesystem</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; is &nbsp;divided into allocation groups to improve the performance of XFS. More allocation groups</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; imply that more parallelism can be achieved when allocating blocks and inodes. &nbsp;The &nbsp;minimum</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; allocation &nbsp;group size is 16 MiB; the maximum size is just under 1 TiB. &nbsp;The data section of</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; the filesystem is divided into value allocation groups (default value &nbsp;is &nbsp;scaled &nbsp;automati-</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cally based on the underlying device size).</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;agsize=value</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; This &nbsp;is an alternative to using the agcount suboption. The value is the desired size of the</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; allocation group expressed in bytes (usually using the m or g suffixes). &nbsp;This value must be</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; a &nbsp;multiple of the filesystem block size, and must be at least 16MiB, and no more than 1TiB,</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; and may be automatically adjusted to properly align with the stripe geometry. &nbsp; The &nbsp;agcount</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; and agsize suboptions are mutually exclusive.</font></div></div><p></p></pre></div><div><br></div><div>15. 连续IO载入SSD是否影响性能, 如果影响, 如何通过跳过连续IO载入缓存来优化性能.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >如果开启了cache all io, 可能存在连续IO载入SSD后带来的问题.</font></div><div><div><font size="2"   >Tuning Sequential IO Skipping for better flashcache performance</font></div><div><font size="2"   >===============================================================</font></div><div><font size="2"   >Skipping sequential IO makes sense in two cases:</font></div><div><font size="2"   >1) your sequential write speed of your SSD is slower than</font></div><div><font size="2"   >&nbsp; &nbsp;the sequential write speed or read speed of your disk. &nbsp;In&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp;particular, for implementations with RAID disks (especially&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp;modes 0, 10 or 5) sequential reads may be very fast. &nbsp;If&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp;'cache_all' mode is used, every disk read miss must also be&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp;written to SSD. &nbsp;If you notice slower sequential reads and writes&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp;after enabling flashcache, this is likely your problem.</font></div><div><font size="2"   >如果数据设备是RAID磁盘, 并且RAID组较大或有RAID缓存的情况下, 连续IO的读写性能可能很好, 甚至超越SSD的性能(当然PCI-E的SSD几乎很难超越).</font></div><div><font size="2"   >这种情况下, 连续IO加载到SSD就带来负面影响了, 一个是占据了大量的SSD空间, 另一方面还得不到好的性能提升(仅仅当SSD连续IO的性能低于RAID组的情况).</font></div><div><font size="2"   >如果你遇到以上情况, 那么说明要调整一下flashcache的模块参数, 跳过连续IO载入SSD缓存.</font></div><div><font size="2"   >2) Your 'resident set' of disk blocks that you want cached, i.e.</font></div><div><font size="2"   >&nbsp; &nbsp;those that you would hope to keep in cache, is smaller</font></div><div><font size="2"   >&nbsp; &nbsp;than the size of your SSD. &nbsp;You can check this by monitoring</font></div><div><font size="2"   >&nbsp; &nbsp;how quick your cache fills up ('dmsetup table'). &nbsp;If this</font></div><div><font size="2"   >&nbsp; &nbsp;is the case, it makes sense to prioritize caching of random IO,</font></div><div><font size="2"   >&nbsp; &nbsp;since SSD performance vastly exceeds disk performance for&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp;random IO, but is typically not much better for sequential IO.</font></div><div><font size="2"   >如果SSD很快被填满, 可能出现了连续IO读载入SSD的情况, 如果带来了负面影响, 那么也<span style="line-height: 28px;"   >说明要调整一下flashcache的模块参数, 跳过连续IO载入SSD缓存.</span></font></div><div><font size="2"   ><br></font></div><div><font size="2"   >如果已经出现负面影响(例如加SSD后性能反而下降), 并且通过以上观察, 已经发现确实是连续IO载入缓存引起的, 那么可以通过以下方法来调整.&nbsp;</font></div><div><span style="line-height: 28px;"   ><font size="2"   >通过sysctl 设置 dev.flashcache.&lt;device&gt;.skip_seq_thresh_kb的阈值, 从1024k开始, 每设置一个值, 使用测试模型测试, 查看是否有效果, 如果没有效果, 调小这个值, 重新测试, 直到有效果为止.</font></span></div><div><font size="2"   >In the above cases, start with a high value (say 1024k) for</font></div><div><font size="2"   >sysctl dev.flashcache.&lt;device&gt;.skip_seq_thresh_kb, so only the</font></div><div><font size="2"   >largest sequential IOs are skipped, and gradually reduce</font></div><div><font size="2"   >if benchmarks show it's helping. &nbsp;Don't leave it set to a very</font></div><div><font size="2"   >high value, return it to 0 (the default), since there is some</font></div><div><font size="2"   >overhead in categorizing IO as random or sequential.</font></div><div><font size="2"   >如果没有遇到问题, 那么继续使用cache all io即可.</font></div><div><font size="2"   >If neither of the above hold, continue to cache all IO,&nbsp;</font></div><div><font size="2"   >(the default) you will likely benefit from it.</font></div></div><p></p></pre></div><div><br></div><div><br></div>[参考]<wbr><div>1.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="https://raw.githubusercontent.com/facebook/flashcache/master/doc/flashcache-sa-guide.txt"   >https://raw.githubusercontent.com/facebook/flashcache/master/doc/flashcache-sa-guide.txt</a></div><div>2.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="https://github.com/facebook/flashcache/issues"   >https://github.com/facebook/flashcache/issues</a></div><div>3.&nbsp;<a style="line-height: 28px;" target="_blank" href="http://blog.163.com/digoal@126/blog/static/1638770402014528115551323/"   >http://blog.163.com/digoal@126/blog/static/1638770402014528115551323/</a></div><div>4.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="https://github.com/facebook/flashcache/blob/master/utils/flashcache"   >https://github.com/facebook/flashcache/blob/master/utils/flashcache</a></div><div><br></div>
<a rel="nofollow" href="http://info.flagcounter.com/h9V1"   ><img title="flashcache usage guide - 德哥@Digoal - PostgreSQL research"   src="http://s03.flagcounter.com/count/h9V1/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_12/viewers_0/labels_0/pageviews_0/flags_0/"   alt="Flag Counter"   border="0"   ></a></div>
	</div>
</div>
</body>
</html>