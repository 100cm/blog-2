<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">GlusterFS on ZFS on CentOS 6.x x64</h2>
	<h5 id="">2014-07-30 11:48:05&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/16387704020146301126698/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;"><div>原文如下, 但是这里有几点不推荐按照原文来做.</div><div>1.&nbsp;zfs set sync=disabled sp1 &nbsp;(不推荐)</div><div>如果没有UPS的话, 不推荐关闭sync, 因为任何异常都可能会导致数据丢失.&nbsp;</div><div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sync=standard | always | disabled</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Controls &nbsp;the &nbsp;behavior &nbsp;of &nbsp;synchronous &nbsp;requests &nbsp;(e.g. fsync, O_DSYNC). &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1. standard is the POSIX specified&nbsp;<span style="line-height: 28px;"   >behavior of ensuring all synchronous requests are written to stable storage and all devices are flushed &nbsp;to&nbsp;</span><span style="line-height: 28px;"   >ensure &nbsp;data &nbsp;is &nbsp;not &nbsp;cached &nbsp;by device controllers (this is the default).&nbsp;</span></div><div><span style="line-height: 28px;"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2. always causes every file system&nbsp;</span><span style="line-height: 28px;"   >transaction to be written and flushed before its system call returns. This has a large performance penalty.</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3. disabled disables synchronous requests.&nbsp;<span style="line-height: 28px;"   >File system transactions are only committed to stable storage peri</span><span style="line-height: 28px;"   >odically. This option will give the highest performance. &nbsp;However, it is very dangerous &nbsp;as &nbsp;ZFS &nbsp;would &nbsp;be&nbsp;</span><span style="line-height: 28px;"   >ignoring &nbsp;the &nbsp;synchronous &nbsp;transaction &nbsp;demands &nbsp;of applications such as databases or NFS. &nbsp;Administrators&nbsp;</span><span style="line-height: 28px;"   >should only use this option when the risks are understood.</span></div></div><div><br></div><div>2.&nbsp;Disable read prefetch because it is almost completely useless and does nothing in our environment but work the drives unnecessarily. I see &lt;10% prefetch cache hits, so it's really not required and actually hurts performance. (需要斟酌)</div><div>&nbsp; &nbsp; 和应用程序有关, 如果是流媒体服务或者需要读取大文件的服务(例如OLAP). 建议打开, 如果是小的离散IO读, 则建议关闭(例如数据库的OLTP) , 如果是GlusterFS for 虚拟化应用, 跑的是虚拟机镜像, 建议打开prefetch. 最终还是看具体应用.</div><div><h1 style="margin: 1em 0px 0.2em; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); font-family: arial, arial, sans-serif; color: rgb(123, 45, 0); font-size: 22px; font-weight: normal;"   >GlusterOnZFS</h1><div id="contentSub"   style="font-size: 12px; line-height: 1.2em; margin: 0px 0px 1.4em 1em; color: rgb(125, 125, 125); width: auto; font-family: arial, sans-serif;"   ></div><div id="mw-content-text"   lang="en"   dir="ltr"   style="font-family: arial, sans-serif; font-size: small; line-height: 16.899999618530273px;"   ><p>This is a step-by-step set of instructions to install Gluster on top of ZFS as the backing file store. There are some commands which were specific to my installation, specifically, the ZFS tuning section.&nbsp;<i>Moniti estis.</i></p><h2 style="margin: 1em 0px 0.2em; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); font-family: arial, arial, sans-serif; color: rgb(123, 45, 0); font-size: 20px; font-weight: normal;"   ><span id="Preparation"   >Preparation</span></h2><ul><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Install CentOS 6.3</li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Assumption is that your hostname is&nbsp;<tt>gfs01</tt></li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Run all commands as the root user</li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >yum update</li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Disable IP Tables</li></ul><pre style="font-size: 1em; border: 1px dashed rgb(102, 102, 102); padding: 15px 20px; overflow: auto; background: rgb(238, 238, 238);"   >chkconfig iptables off
service iptables stop
</pre><ul><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Disable SELinux<ul><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >edit /etc/selinux/config</li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >set SELINUX=disabled</li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >reboot</li></ul></li></ul><h2 style="margin: 1em 0px 0.2em; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); font-family: arial, arial, sans-serif; color: rgb(123, 45, 0); font-size: 20px; font-weight: normal;"   ><span id="Install_ZFS_on_Linux"   >Install ZFS on Linux</span></h2><pre style="font-size: 1em; border: 1px dashed rgb(102, 102, 102); padding: 15px 20px; overflow: auto; background: rgb(238, 238, 238);"   >yum groupinstall "Development Tools"
</pre><ul><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Download &amp; unpack latest SPL and ZFS tarballs from&nbsp;<a rel="nofollow" href="http://www.zfsonlinux.org/"   >zfsonlinux.org</a></li></ul><h3 style="margin: 1em 0px 0.2em; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); font-family: arial, arial, sans-serif; color: rgb(123, 45, 0); font-size: 1.3em;"   ><span id="Install_DKMS"   >Install DKMS</span></h3><p>We want automatically rebuild the kernel modules when we upgrade the kernel, so you definitely want DKMS with ZFS on Linux.</p><ul><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Download latest RPM from&nbsp;<a rel="nofollow" href="http://linux.dell.com/dkms"   >http://linux.dell.com/dkms</a></li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Install DKMS<pre style="font-size: 1em; border: 1px dashed rgb(102, 102, 102); padding: 15px 20px; overflow: auto; background: rgb(238, 238, 238);"   >rpm -Uvh dkms*.rpm</pre></li></ul><h3 style="margin: 1em 0px 0.2em; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); font-family: arial, arial, sans-serif; color: rgb(123, 45, 0); font-size: 1.3em;"   ><span id="Build_.26_Install_SPL"   >Build &amp; Install SPL</span></h3><ul><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Enter SPL source directory</li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >The following commands create two source &amp; three binary RPMs. Remove the static module RPM (we are using DKMS) and install the rest:</li></ul><pre style="font-size: 1em; border: 1px dashed rgb(102, 102, 102); padding: 15px 20px; overflow: auto; background: rgb(238, 238, 238);"   >./configure
make rpm
rm spl-modules-0.6.0*.x86_64.rpm
rpm -Uvh spl*.x86_64.rpm spl*.noarch.rpm
</pre><h3 style="margin: 1em 0px 0.2em; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); font-family: arial, arial, sans-serif; color: rgb(123, 45, 0); font-size: 1.3em;"   ><span id="Build_.26_Install_ZFS"   >Build &amp; Install ZFS</span></h3><ul><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   ><i>If you plan to use the 'xattr=sa' filesystem option, make sure you have the ZFS fix for<a rel="nofollow" href="https://github.com/zfsonlinux/zfs/issues/1648"   >https://github.com/zfsonlinux/zfs/issues/1648</a>&nbsp;<b>so your symlinks don't get corrupted.</b></i></li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Enter ZFS source directory</li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >The following commands create two source &amp; five binary RPMs. Remove the static module RPM and install the rest. Note we have a few preliminary packages to install before we can compile.</li></ul><pre style="font-size: 1em; border: 1px dashed rgb(102, 102, 102); padding: 15px 20px; overflow: auto; background: rgb(238, 238, 238);"   >yum install zlib-devel libuuid-devel libblkid-devel libselinux-devel parted lsscsi
./configure
make rpm
rm zfs-modules-0.6.0*.x86_64.rpm
rpm -Uvh zfs*.x86_64.rpm zfs*.noarch.rpm
</pre><h3 style="margin: 1em 0px 0.2em; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); font-family: arial, arial, sans-serif; color: rgb(123, 45, 0); font-size: 1.3em;"   ><span id="Finish_ZFS_Configuration"   >Finish ZFS Configuration</span></h3><ul><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Reboot to allow all changes to take effect, if desired</li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Create ZFS storage pool. This is a simple example of 4 HDDs in RAID10. NOTE: Check the latest&nbsp;<a rel="nofollow" href="http://zfsonlinux.org/faq.html"   >ZFS on Linux FAQ</a>&nbsp;about configuring the /etc/zfs/zdev.conf file. You want to create mirrored devices across controllers to maximize performance. Make sure to run&nbsp;<tt>udevadm trigger</tt>&nbsp;after creating zdev.conf.</li></ul><pre style="font-size: 1em; border: 1px dashed rgb(102, 102, 102); padding: 15px 20px; overflow: auto; background: rgb(238, 238, 238);"   >zpool create -f sp1 mirror A0 B0 mirror A1 B1
zpool status sp1
df -h
</pre><ul><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >You should see the /sp1 mount point</li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Enable ZFS compression to save disk space:</li></ul><pre style="font-size: 1em; border: 1px dashed rgb(102, 102, 102); padding: 15px 20px; overflow: auto; background: rgb(238, 238, 238);"   >zfs set compression=on sp1
</pre><ul><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Completely disable the ZIL. NOTE: Requires the storage server to have a UPS backup unless you like losing the last 5 seconds or so of data.</li></ul><pre style="font-size: 1em; border: 1px dashed rgb(102, 102, 102); padding: 15px 20px; overflow: auto; background: rgb(238, 238, 238);"   >zfs set sync=disabled sp1
</pre><ul><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Set ZFS tunables. This is specific to my environment.<ul><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Set ARC cache min to 33% and max to 75% of installed RAM. Since this is a dedicated storage node, I can get away with this. In my case my servers have 24G of RAM. More RAM is better with ZFS.</li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >We use SATA drives which do not accept command tagged queuing, therefore set the min and max pending requests to 1</li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Disable read prefetch because it is almost completely useless and does nothing in our environment but work the drives unnecessarily. I see &lt;10% prefetch cache hits, so it's really not required and actually hurts performance.</li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Set transaction group timeout to 5 seconds instead of the default of 30 to prevent the volume from appearing to freeze due to a large batch of writes</li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Ignore client flush/sync commands; let ZFS handle this with the transaction group timeout flush. NOTE: Requires a UPS backup solution unless you don't mind losing that 5 seconds worth of data.</li></ul></li></ul><pre style="font-size: 1em; border: 1px dashed rgb(102, 102, 102); padding: 15px 20px; overflow: auto; background: rgb(238, 238, 238);"   >echo "options zfs zfs_arc_min=8G zfs_arc_max=18G zfs_vdev_min_pending=1 zfs_vdev_max_pending=1 zfs_prefetch_disable=1 zfs_txg_timeout=5 zfs_nocacheflush=1" &gt; /etc/modprobe.d/zfs.conf
reboot
</pre><h2 style="margin: 1em 0px 0.2em; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); font-family: arial, arial, sans-serif; color: rgb(123, 45, 0); font-size: 20px; font-weight: normal;"   ><span id="Install_GlusterFS"   >Install GlusterFS</span></h2><pre style="font-size: 1em; border: 1px dashed rgb(102, 102, 102); padding: 15px 20px; overflow: auto; background: rgb(238, 238, 238);"   >wget -P /etc/yum.repos.d <a rel="nofollow" href="http://download.gluster.org/pub/gluster/glusterfs/LATEST/EPEL.repo/glusterfs-epel.repo"   >http://download.gluster.org/pub/gluster/glusterfs/LATEST/EPEL.repo/glusterfs-epel.repo</a>
yum install glusterfs{-fuse,-server}
service glusterd start
service glusterd status
chkconfig glusterd on
</pre><ul><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Continue with your GFS peer probe, volume creation, &amp;c.</li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >To mount GFS volumes automatically after reboot, add these lines to /etc/rc.local (assuming your gluster volume is called "export" and your desired mount point is /export:</li></ul><pre style="font-size: 1em; border: 1px dashed rgb(102, 102, 102); padding: 15px 20px; overflow: auto; background: rgb(238, 238, 238);"   ># Mount GFS Volumes
mount -t glusterfs gfs01:/export /export
</pre><h2 style="margin: 1em 0px 0.2em; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); font-family: arial, arial, sans-serif; color: rgb(123, 45, 0); font-size: 20px; font-weight: normal;"   ><span id="Miscellaneous_Notes_.26_TODO"   >Miscellaneous Notes &amp; TODO</span></h2><h3 style="margin: 1em 0px 0.2em; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); font-family: arial, arial, sans-serif; color: rgb(123, 45, 0); font-size: 1.3em;"   ><span id="Daily_e-mail_status_reports"   >Daily e-mail status reports</span></h3><p>Python script source; put your desired e-mail address in the 'toAddr' variable. Add a crontab entry to run this daily.</p><pre style="font-size: 1em; border: 1px dashed rgb(102, 102, 102); padding: 15px 20px; overflow: auto; background: rgb(238, 238, 238);"   >#!/usr/bin/python
import datetime,socket,smtplib,subprocess

def doShellCmd(cmd):
  subproc=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE,)
  cmdOutput=subproc.communicate()[0]
  return cmdOutput

hostname=socket.gethostname()
statusLine="Status of " + hostname + " at " + str(datetime.datetime.now())
zpoolList=doShellCmd('zpool list')
zpoolStatus=doShellCmd('zpool status')
zfsList=doShellCmd('zfs list')

report=(statusLine + "\n" +
	"-----------------------------------------------------------\n" +
	zfsList +
	"-----------------------------------------------------------\n" +
	zpoolList + 
	"-----------------------------------------------------------\n" +
        zpoolStatus)

fromAddr="From: root@" + hostname + "\r\n"
toAddr="To: user@your.com\r\n"
subject="Subject: ZFS Status from " + hostname + "\r\n"
msg = (subject + report)

server = smtplib.SMTP('localhost')
server.set_debuglevel(1)
server.sendmail(fromAddr, toAddr, msg)
server.quit()
</pre><h3 style="margin: 1em 0px 0.2em; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); font-family: arial, arial, sans-serif; color: rgb(123, 45, 0); font-size: 1.3em;"   ><span id="Restoring_files_from_ZFS_Snapshots"   >Restoring files from ZFS Snapshots</span></h3><p>Show which node a file is on (for restoring files from ZFS snapshots):</p><pre style="font-size: 1em; border: 1px dashed rgb(102, 102, 102); padding: 15px 20px; overflow: auto; background: rgb(238, 238, 238);"   >getfattr -n trusted.glusterfs.pathinfo &lt;file&gt;
</pre><h3 style="margin: 1em 0px 0.2em; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); font-family: arial, arial, sans-serif; color: rgb(123, 45, 0); font-size: 1.3em;"   ><span id="Recurring_ZFS_Snapshots"   >Recurring ZFS Snapshots</span></h3><p>Since the community site will not let me actually post the script due to some random bug with Akismet spam blocking, I'll just post links instead.</p><ul><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   ><a rel="nofollow" href="http://community.spiceworks.com/how_to/show/15303-recurring-zfs-snapshots"   >Recurring ZFS Snapshots</a></li><li style="margin-top: 0.2em; margin-bottom: 0.2em;"   >Or use&nbsp;<a rel="nofollow" href="https://github.com/zfsonlinux/zfs-auto-snapshot"   >https://github.com/zfsonlinux/zfs-auto-snapshot</a></li></ul></div></div><wbr><div><br></div>[参考]<wbr><div>1.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="http://www.gluster.org/community/documentation/index.php/GlusterOnZFS"   >http://www.gluster.org/community/documentation/index.php/GlusterOnZFS</a></div><div><br></div>
<a rel="nofollow" href="http://info.flagcounter.com/h9V1"   ><img title="GlusterFS on ZFS on CentOS 6.x x64 - 德哥@Digoal - PostgreSQL research"   src="http://s03.flagcounter.com/count/h9V1/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_12/viewers_0/labels_0/pageviews_0/flags_0/"   alt="Flag Counter"   border="0"   ></a></div>
	</div>
</div>
</body>
</html>