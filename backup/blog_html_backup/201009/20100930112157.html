<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">[转]PostgreSQL::Snapshots aka Materialized Views</h2>
	<h5 id="">2010-09-30 11:21:57&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/1638770402010830111515931/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;"><P><FONT size="3" >一个巴西兄弟写的，几年前在ORACLE到PG的数据迁移中用过。感谢这位巴西哥们。</FONT></P>  <P><FONT size="3" >[原文]:</FONT></P>  <P><A rel="nofollow" href="http://cunha17.cristianoduarte.pro.br/postgresql/snapshots.en_us.php"  ><FONT size="3" >http://cunha17.cristianoduarte.pro.br/postgresql/snapshots.en_us.php</FONT></A></P>  <P><BIG><SPAN style="FONT-STYLE: italic;"  ><SPAN style="FONT-STYLE: italic;"  ><FONT size="3" >摘记:</FONT></SPAN></SPAN></BIG></P><BIG><SPAN style="FONT-STYLE: italic;"  ><SPAN style="FONT-STYLE: italic;"  >  <DIV style="FONT-WEIGHT: bold;"  ><BIG><A name="item1" rel="nofollow" ></A><FONT size="3" >1. Problem and motivation</FONT></BIG></DIV>  <P><BIG><FONT size="3" >When migrating&nbsp;from Oracle to PostgreSQL, we may face&nbsp;situations when we need the same data on both database servers. This situation could be "easily" resolved if we could make "database links" or dblinks between a PostgreSQL server and an Oracle server. That's when the problem arise.<BR><BR></FONT></BIG></P>  <DIV style="FONT-WEIGHT: bold;"  ><BIG><A name="item2" rel="nofollow" ></A><FONT size="3" >2. Available solutions</FONT></BIG></DIV>  <P><BIG><FONT size="3" >We have some solutions, like DBLink and&nbsp;DBI-Link. The first one make "views" that return the result of a function, which in turn makes a query to the remote database server. The second works almost the same way, but creates a whole bunch of structures like tables, types, views and functions to make the handling of remote tables as transparent as possible.<BR></FONT></BIG><BIG><BR></BIG></P>  <DIV style="FONT-WEIGHT: bold;"  ><BIG><A name="item3" rel="nofollow" ></A><FONT size="3" >3. Current implementation problems</FONT></BIG></DIV>  <P><BIG><FONT size="3" >Comparing the two approaches, it's evident that the DBI-Link is much more&nbsp;elegant and elaborated. But the two suffer from a severe problem: they bring the whole result from the remote query into the local database server. For instance:<BR><BR>Let's take a table on an Oracle database having a list of person (PERSON table). The primary key is the social security number (SSN), this table hold many other fields of person information and&nbsp; has about 250.000 records. The filesystem size of the table is about 122Mb.<BR></FONT></BIG><BIG><BR><FONT size="3" >If we make the following query on Oracle using SQLPlus:<BR><SPAN style="FONT-STYLE: italic;"  >SELECT name FROM person WHERE ssn='012345678'; (1)</SPAN><BR>the database server will search at the index(PK) for the given SSN and will return immediately (time &lt; 1 second) the name of the person whose SSN is&nbsp;012345678.<BR></FONT></BIG><BR><FONT size="3" ><BIG>Now we want a new application, that is being written to use PostgreSQL, to transparently access this Oracle table, that is, to access this table through the PostgreSQL server(like if it was a native table).</BIG><BR><BIG>Using&nbsp;DBLink we may create a view named "PERSON" based on a call to dblink's query function passing&nbsp;"<SPAN style="FONT-STYLE: italic;"  >SELECT * FROM PERSON</SPAN>" </BIG><BIG>(2)</BIG></FONT><BIG><FONT size="3" >.<BR>Using DBI-Link we may create a local mirror of the remote schema structure, and with this, at the local schema, we would find a view called "PERSON", that&nbsp;invoke a function that makes a remote query&nbsp;[2], besides many types and associated functions.<BR><BR>If we make the same query as we did before on&nbsp;Oracle [1], we will have a considerable delay and an absurd computational waste (in my experience, time ~ 5 minutes and process memory consumption&nbsp;~ 1Gb), what makes these solutions inviable for any corporate project.<BR><BR></FONT></BIG></P>  <DIV style="FONT-WEIGHT: bold;"  ><BIG><A name="item4" rel="nofollow" ></A><FONT size="3" >4. Internals and the origin of the problems</FONT></BIG></DIV>  <P><FONT size="3" ><BIG>On the two solutions, the request that originate the function execution was:<BR></BIG><BIG style="FONT-STYLE: italic;"  >SELECT name FROM person WHERE ssn='012345678';</BIG><SPAN style="FONT-STYLE: italic;"  > (1)</SPAN><BR></FONT><BIG><BR><FONT size="2" ><FONT size="3" >However, we must notice that both functions were created to make the following remote query:<BR><SPAN style="FONT-STYLE: italic;"  >SELECT * FROM PERSON; (2)</SPAN></FONT><BR></FONT></BIG></P>  <DIV><IMG title="[转]PostgreSQL::Snapshots aka Materialized Views - 德哥@Digoal - The Heart,The World."  alt="[转]PostgreSQL::Snapshots aka Materialized Views - 德哥@Digoal - The Heart,The World."  style="MARGIN: 0px 10px 0px 0px;"  src="http://img775.ph.126.net/e4oegwyUv0c7Z1t3KMfxaw==/4852628598491960969.jpg"  ></DIV>  <P>&nbsp;<FONT size="3" >What really happen is that the query present on these functions[2] is always executed, no matter the filter clauses present on the request query that originated the function execution[1]. The result of these functions[2] is, finally, processed by PostgreSQL (on this case filtered by the SSN column) sequentially and the final result is returned(3).<BR><BR>A not so simple way would be to intercept the PostgreSQL planner and gather information about the&nbsp;query that originated the function execution and pass, dynamically, additional parameters to the remote database query. Unfortunately, this doesn't exist yet.<BR><BR>However, we can take another way, when the information access doesn't need to be done in real-time. On these cases, we can make a local copy of the remote table. The previous problem is solved, right? Nope.<BR><BR>How would this copy be made? Using a DBLink or DBI-Link connection we could execute a <SPAN style="FONT-STYLE: italic;"  >CREATE TABLE PERSON AS SELECT * FROM REMOTE_PERSON</SPAN>,&nbsp; what would create a copy of the remote table at the local database. Now, any query executed at PostgreSQL would use the local table, which is much faster and efficient. But this approach suffer from one of the previous related problems, the excessive memory consumption when the function gets called (in my experience, the process grew to&nbsp;~ 1Gb). Even if this operation needs to be done only a few times per day, the high memory consumption makes this approach not practical.<BR><BR></FONT></P>  <DIV style="FONT-WEIGHT: bold;"  ><BIG><A name="item5" rel="nofollow" ></A><FONT size="3" >5. Solving with Materialized Views: the PostgreSQL::Snapshots</FONT></BIG></DIV>  <P><BIG><FONT size="3" >That's the reason why I created the PostgreSQL::Snapshots project, as an efficient and corporate way to address the current DBLinks solutions problems. This solution was based and inspired by the DBI-LINK project.<BR><BR>The implemented functionalities include:<BR><BR><SPAN style="FONT-WEIGHT: bold;"  >CREATE DBLINK</SPAN><BR>This command, available on Oracle, but not on&nbsp;PostgreSQL, create a link between two databases, using a user, a password and the location of the server on the network.<BR>On our case, we use a&nbsp;PL/Perl function (create_dblink) that takes the&nbsp;DBLink name, a DBI:Perl connection string, the user name, the password and some additional attributes needed for the connection establishment.<BR>The table where those data will be saved is </FONT></BIG><BIG><FONT size="3" >pg_dblink and it's worthy remind that access to this table should only be allowed to the DBA(postgres user), despite it's created on the public schema.<BR>Before inserting a record on this table, we check if we can successfully establish a connection with the remote database using the given parameters.<BR><BR><SPAN style="FONT-WEIGHT: bold;"  >DROP DBLINK</SPAN><BR></FONT></BIG><BIG><FONT size="3" >This command, available on Oracle, but not on PostgreSQL, removes a link between two databases, taking only the DBLink name.<BR></FONT></BIG><FONT size="3" ><BIG>On our case, we use a PL/Perl function (drop_dblink) that takes the DBLink name and removes the entry at the pg_dblinks table. The foreign key disallow the deletion if any snapshot references the DBLink to be removed.<BR><BR><SPAN style="FONT-WEIGHT: bold;"  >CREATE SNAPSHOT</SPAN><BR></BIG><BIG>This command, available on Oracle, but not on PostgreSQL,&nbsp;</BIG></FONT><FONT size="3" ><BIG>creates a materialized view (aka SNAPSHOT) based on a query. This query may, or may not, be referencing a DBLink.<BR></BIG><BIG>On our case, we use a PL/Perl function (create_snapshot) that takes the schema name, the Snapshot name, the query,&nbsp;the&nbsp;DBLink name and the refresh method. The DBLink name&nbsp;is optional and, when not given(NULL), create a snapshot based on a query to the local database. </BIG></FONT><BIG><FONT size="3" >The refresh method can be:<BR></FONT></BIG></P>  <UL>  <LI><BIG><FONT size="3" >COMPLETE: allows only complete refreshes, that is, at the refresh time, the snapshot is truncated and all data from the query is inseted.</FONT></BIG></LI>  <LI><BIG><FONT size="3" >FAST: allows only fast refreshes (based on materialized view logs), that is, at the refresh time, only the modified records get removed from the snapshot and inserted from the query.</FONT></BIG></LI>  <LI><BIG><FONT size="3" >FORCE: try a FAST refresh and if it's not possible, try a COMPLETE refresh.</FONT></BIG></LI></UL>  <P><BIG></BIG><FONT size="3" ><BIG>The query is executed with a&nbsp;<SPAN style="FONT-STYLE: italic;"  >WHERE 1=0</SPAN> clause as a way to bring only the query result structure. With this structure, a type mapping is done and an empty local table is created with that same structure. Finally, an entry on the snapshots table (<SPAN style="FONT-STYLE: italic;"  >pg_snapshots)</SPAN> is added.<BR>The table is not filled by this command.<BR><BR><SPAN style="FONT-WEIGHT: bold;"  >DROP SNAPSHOT</SPAN><BR></BIG><BIG>This command, available on Oracle, but not on PostgreSQL,&nbsp;</BIG></FONT><BIG><FONT size="3" >removes a materialized view(aka&nbsp;SNAPSHOT) taking only the Snapshot name.<BR></FONT></BIG><BIG><FONT size="3" >On our case, we use a&nbsp;PL/Perl function (drop_snapshot) that takes the schema name and the Snapshot name,&nbsp;removes the object and the entry at the <SPAN style="FONT-STYLE: italic;"  >pg_snapshots</SPAN> table.<BR></FONT></BIG><BIG><BR></BIG><BIG><FONT size="3" ><SPAN style="FONT-WEIGHT: bold;"  >CREATE SNAPSHOT LOG</SPAN><BR></FONT></BIG><BIG><FONT size="3" >This command, available on Oracle, but not on PostgreSQL, creates a materialized view log(aka SNAPSHOT LOG) bound to another table(called master table). When a snapshot is created with a query that references this master table, it will be possible to use fast refreshes (REFRESH FAST) based on the log. This allows, for instance, that, at the snapshot refreshing time&nbsp;, only the deleted, updated and inserted records be retrieved, highly increasing the performance and the refresh time.<BR></FONT></BIG><BIG><FONT size="3" >On our case, we use a PL/Perl function (create_snapshot_log) that takes the schema name, the master table name and the comma-separated field list on which the log filter will be applied. This list can contain a keyword like "primary key" or "oid" or field names.<BR>To make&nbsp;"snapshot log" functional, this function created a log table with the&nbsp;"mlog$_" prefix and a dynamically coded trigger that monitors any modifications on the master table and records the necessary information on the log table. Finally, an entry on the&nbsp;snapshot log table (<SPAN style="FONT-STYLE: italic;"  >pg_mlogs)</SPAN> is created, along with the necessary entries on the snapshot log columns table (pg_mlog_refcols).<BR><BR><SPAN style="FONT-WEIGHT: bold;"  >DROP SNAPSHOT LOG</SPAN><BR></FONT></BIG><BIG><FONT size="3" >This command, available on Oracle, but not on&nbsp;PostgreSQL, removes a materialzed view log (aka SNAPSHOT LOG) taking only the schema name and the master table name. <BR></FONT></BIG><FONT size="3" ><BIG>On our case, we use a&nbsp;PL/Perl function (drop_snapshot_log) that takes the schema name and the master table name and removes the materialized view log table, along with the master table trigger, the&nbsp;pg_mlogs entry and the pg_mlog_refcols entries.<BR></BIG><BIG><SPAN style="FONT-WEIGHT: bold;"  ></SPAN></BIG><BR></FONT><FONT size="3" ><BIG><SPAN style="FONT-WEIGHT: bold;"  >REFRESH SNAPSHOT</SPAN><BR></BIG><BIG>This command, available on Oracle as a "Stored Procedure", but not on PostgreSQL, </BIG></FONT><BIG><FONT size="3" >refreshes the data on a materialized view (aka&nbsp;SNAPSHOT) taking only the Snapshot name.<BR></FONT></BIG><BIG><FONT size="3" >On our case, we use a PL/Perl function (refresh_snapshot) that takes the schema name and the snapshot name and fill it with the results of its creation query.<BR>The secret behind is the use of distinct connections for SPI communications with the backend, for data insertion in the Snapshot and for remote data reading. The insertion process is done in one transaction of 1000 records at a time and make use of "Prepared Statements" to make the process faster and smarter (in my test with the PERSON table, the rate was&nbsp;~ 650 records/second).<BR></FONT></BIG><FONT size="3" ><BIG>At this function we also check the refresh method and do fast refreshes when configured(or allowed). The fast refreshes depend on the chosen method, on the materialized view log presence, on the log row count and on the row count of the result query. For big tables with few updates/inserts/deletes, the&nbsp;FAST method can refresh the snapshot within a few seconds.<BR>The fast refresh (REFRESH FAST) is only available on driver-supported databases (at the moment, only on PostgreSQL and Oracle) since operations will be performed on internal system tables at the master database (where the query will be executed). On&nbsp;Oracle, for example, tables like&nbsp;SLOG$, MLOG$, MLOG_REFCOL$, etc. needs to be directly&nbsp;accessed and the&nbsp;SLOG$ table must be accessed for modifications.<BR></BIG><BR></FONT></P>  <DIV style="FONT-WEIGHT: bold;"  ><BIG><A name="item6" rel="nofollow" ></A><FONT size="3" >6. Conclusion</FONT></BIG></DIV>  <P><BIG><FONT size="3" >With the PostgreSQL::Snapshots, the basic functionalities of Materialized Views are implemented, what does not avoid a future association with&nbsp;an efficient DBLink solution. The use of Materialized Views is not restricted to table copies from other databases, they can be used as a way to persist results of highly complex and slow queries, giving the responsiveness that front-end systems need.</FONT></BIG></P></SPAN></SPAN></BIG>  <P><BIG><FONT size="3" >&nbsp;</FONT></BIG></P>  <P><BIG><SPAN style="FONT-STYLE: italic;"  ><SPAN style="FONT-STYLE: italic;"  ></SPAN></SPAN></BIG>&nbsp;</P></div>
	</div>
</div>
</body>
</html>