<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">Thinking PostgreSQL PL/Proxy Used in weibo(微博) Case</h2>
	<h5 id="">2011-11-04 21:37:57&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/16387704020111049738347/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;">最近和网络的同事聊组播的技术，对于IP电视来说，这个技术可以大大降低网络的开销。<div>突然想到微博其实也是很耗带宽的一种东西，之前也没去了解过，我的理解是微博就类似留言，留言上带上了撰写人，标签，是否公开，接收人，发送时间等属性。</div><div>如 ，&nbsp;</div><div>普通的一条微博，有了撰写人，那么关注撰写人的用户在登录微博时就需要看到这部分微博信息。</div><div>另外，也可以定点给某人或者某些人发送信息，那么就有了接收人的属性。</div><div><br></div><div>如果用户量很大，活跃用户比较多的情况下，信息量也是巨大的。特别是明星用户。关注或被关注的人比较多的情况下。信息推送都会带来比较大的流量。</div><div><br></div><div>组播就值得借鉴了，如在10毫秒内发起的请求，如果有相同的，只请求一次。</div><div><br></div><div>另外，为了获得好的扩展性，数据库设计的时候要充分考虑数据暴增带来的问题。</div><div>如下：</div><div><div><img title="Thinking PostgreSQL PL/Proxy Used in weibo Case - 德哥@Digoal - The Heart,The World."  alt="Thinking PostgreSQL PL/Proxy Used in weibo Case - 德哥@Digoal - The Heart,The World."  style="margin:0 10px 0 0;"  src="http://img3.ph.126.net/EG_zt97UPONerjc9c0SrJQ==/2726648099413185343.jpg"  ></div>&nbsp;</div><div>发微博为了提高响应速度可以考虑异步消息，记录撰写人的USERID，私信接收人的USERID，如果是回复的话记录子msgid等属性。</div><div>MQ异步写入到索引库和消息数据库。</div><div><br></div><div>热索引主要用来存储收微博时需要用到的索引，如根据关注者的USERID（s）来检索msgid，根据自己的USERID来检索MSGID(私信)，根据标签来检索MSGID。</div><div><br></div><div>索引库和消息数据库都可以使用PostgreSQL数据库，使用PL/Proxy可以不用担心数据库的扩展能力(读用流复制扩展(毫秒延时)，写用bit&amp;分库扩展)。</div><div>PostgreSQL的pgfincore插件能实现数据文件块级别的内存映射，并能记录下数据块的位置，重启之后通过位置信息进行预加载数据或索引数据至内存，非常灵活。（灵活性超越ORACLE的buffer pool keep）</div><div>写能力的提高除了分库之外，单库写能力的提高也可以使用异步事务提交, 分组提交等。</div><div><br></div><div>持久数据(历史数据), 每日/小时从热数据库同步。热库定期删除时间比较OLD的数据。</div><div><br></div><div>收微博的时候，到关系库取出关注者的userid(s)，根据关注者的USERID检索索引库，按时间倒序取出MSGID。然后根据msgid(s)去数据库取出数据。</div><div><br></div><div>收取私信的时候，根据自己的USERID到索引库检索MSGID，按时间倒序取出MSGID。然后根据msgid(s)去数据库取出数据。</div><div><br></div><div>如图 :&nbsp;</div><div><div><img title="Thinking PostgreSQL PL/Proxy Used in weibo Case - 德哥@Digoal - The Heart,The World."  alt="Thinking PostgreSQL PL/Proxy Used in weibo Case - 德哥@Digoal - The Heart,The World."  style="margin:0 10px 0 0;"  src="http://img7.ph.126.net/yKVxVcHs8o96F3O_qby5hg==/2841771364887838187.jpg"  ></div><div><br></div><div>热数据和热索引在这里只的是时间比较接近当前时间的数据，怎么理解呢？</div><div>因为微博里面的信息量非常大，推送给用户的时候是按照时间倒序显示的。所以时间约新鲜，数据越热。被回复和转发的概率越大。</div><div>而时间比较久远的数据，相对来说不太会被查询或修改。</div><div><br></div><div><div><img title="Thinking PostgreSQL PL/Proxy Used in weibo Case - 德哥@Digoal - The Heart,The World."  alt="Thinking PostgreSQL PL/Proxy Used in weibo Case - 德哥@Digoal - The Heart,The World."  style="margin:0 10px 0 0;"  src="http://img2.ph.126.net/1GKKkby3gZ7bWltj2IBl6A==/97671816935654762.jpg"  ></div><div>分库规则：</div><div>1. 索引库分库因子: userid(int8) bit&amp; 操作, attr(int4) bit&amp;操作.库的个数为2^n次方。当然plproxy允许重复条目。所以最粗的时候服务器不需要完全按照实际分库的个数来配置，可以后期几乎平滑的扩展。</div><div>2. 数据库分库因子: msgid(int8) bit&amp; 操作,&nbsp;库的个数为2^n次方。当然plproxy允许重复条目。所以最粗的时候服务器不需要完全按照实际分库的个数来配置，可以后期几乎平滑的扩展。</div><div>3. 关系库分库因子: userid(int8) bit&amp; 操作。当然plproxy允许重复条目。所以最粗的时候服务器不需要完全按照实际分库的个数来配置，可以后期几乎平滑的扩展。</div><div><br></div><div>CACHE：</div><div>pgmemcached, 通过这个PostgreSQL插件,CACHE操作可以更加灵活的和数据库紧密结合起来(通过PG函数增删改查memcache的内容)。</div><div><div><img title="Thinking PostgreSQL PL/Proxy Used in weibo(微博) Case - 德哥@Digoal - The Heart,The World."  alt="Thinking PostgreSQL PL/Proxy Used in weibo(微博) Case - 德哥@Digoal - The Heart,The World."  style="margin:0 10px 0 0;"  src="http://img3.ph.126.net/-HeeRH1QFNJn1nwvbigu1A==/30962247455233353.jpg"  ></div>&nbsp;</div><div><br></div><div>关系库：</div><div>正向数据结构 : userid(int8)，attention_userid（int8） 。(是否需要限制关注上限,关注的人越多,每次获取关注人信息的数据量越庞大)</div><div>反向数据结构 : userid(int8)，attentioned_userid（int8） 。(明星用户可能被百万甚至千万人关注)</div><div><br></div><div>其他：</div>按USERID来分库 ，在数据库的扩展性方面比较灵活。</div></div><div>当然还要考虑msgid取出的时候需要merge后排序，这个比较麻烦。</div><div><br></div><div>按时间来分库比较麻烦的是，热点将集中在最近的库。</div><div>按时间，然后在下面再按用户ID来分，或许也是一种选择。</div><div><div><br></div><div>【能力预估】</div><div>假设 1台8核72G内存,500G硬盘服务器, 1.5W rw tps.&nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; 缓存服务器, 15W rw tps.</div><div>用户1亿，平均关注100用户。正向关系100亿，反向关系100亿。</div><div>10%活跃用户。平均每人每天发微博10条。一天1亿条新增微博信息。</div><div>关系库预计投入：100/8=12.5 台, 对外提供18W rw tps</div><div>反向关系库预计投入：100/8=12.5 台, 对外提供18W rw tps</div><div>（每一维度）热索引库预计投入：2/8=1 台, 对外提供1.5W r/w tps (可能不能满足rTPS要求，通过复制或者pgmemcache解决)</div><div>热数据库预计投入：2/1=2 台, 对外提供3W r/w tps (可能不能满足rwTPS要求，r通过复制或者pgmemcache解决,w增加分区服务器或者MQ异步消息解决)</div><div>（每一维度）历史索引库预计投入：视存储量</div><div>数据库预计投入：视存储量</div><div>缓存服务器预计投入：视实际请求量</div><div>hot standby服务器预计投入：视实际请求量</div><div><br></div><div>【压力测试】</div><div><br></div><div>有待完善.</div><div><br></div><div><div>【参考】</div><div><a href="http://blog.163.com/digoal@126/blog/static/163877040201192535630895/"  >http://blog.163.com/digoal@126/blog/static/163877040201192535630895/</a></div><div><a rel="nofollow" href="http://pgfoundry.org/projects/pgmemcache/"  >http://pgfoundry.org/projects/pgmemcache/</a></div><div><a rel="nofollow" href="http://timyang.net/tag/weibo/"  >http://timyang.net/tag/weibo/</a><b><br></b><br><wbr></div></div></div></div>
	</div>
</div>
</body>
</html>