<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">ZFS deduplicate</h2>
	<h5 id="">2014-05-19 10:02:08&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/163877040201441992944647/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;"><div>前一篇BLOG介绍了ZFS的压缩特性, 本文将介绍一下ZFS的另一个特性deduplicate, 同compress的目标差不多, 都是节约存储空间的.</div><div>但是deduplicate带来的副作用会比较明显, 同时deduplicate的数据不是atomic事务写入的, 可能导致数据损坏.&nbsp;<span style="line-height: 28px;"   >一般不建议开启dedup.</span></div><div><pre class="prettyprint"   ><p><font size="2"   >Further, deduplicated data is not flushed to disk as an atomic transaction. Instead, the blocks are written to disk serially, one block at a time. Thus, this does open you up for corruption in the event of a power failure before the blocks have been written.</font></p></pre></div><div>deduplicate分3种粒度: 文件, 数据块, 字节.</div><div>文件的粒度最粗, 只有当一个文件的所有字节都完全一致时, 只需要存储1个文件的数据, &nbsp;因为文件中任何一个字节改变, 都会导致无法利用deduplicate.</div><div>数据块级别的deduplicate显然比文件级别的好用, 但是数据块级别的dedup, 需要一个内存区域来跟踪共享数据块(即唯一的块, 假设10个数据块同样, 那么只需要1个共享数据块). 每个共享数据块需要耗费320字节来跟踪, 具体有多少个数据块可以通过zdb来查看.</div><div><pre class="prettyprint"   ><p><font size="2"   >If my total storage was 1 TB in size, then 1 TB divided by 100 KB per block is about 10737418 blocks. Multiplied by 320 bytes per block, leaves us with 3.2 GB of RAM, which is close to the previous number we got.</font></p></pre></div><div>具体需要多少内存的话可以计算(和实际存储的唯一数据块的个数有关, 但是最多需要多少内存则直接使用zpool占用的块数计算), 因为ZFS还需要耗费大量的内存用作ARC, 所以能给ZFS dedup跟踪的内存必须减去一些必要的内存 :&nbsp;</div><div><pre class="prettyprint"   ><p><font size="2"   >ZFS stores more than just the deduplication table in RAM. It also stores the ARC as well as other ZFS metadata. And, guess what? The deduplication table is capped at 25% the size of the ARC. This means, you don't need 60 GB of RAM for a 12 TB storage array. You need 240 GB of RAM to ensure that your deduplication table fits. In other words, if you plan on doing deduplication, make sure you quadruple your RAM footprint, or you'll be hurting.</font></p></pre></div><div>在有二级缓存的情况下, dedup block级别可以有更好的发挥. 因为如果内存不够的话, dedup带来的性能下降会非常明显.</div><div>以下是dedup的测试 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@spark01 digoal]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp;Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/sda1 &nbsp; &nbsp; &nbsp; &nbsp;31G &nbsp;1.2G &nbsp; 29G &nbsp; 5% /</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;12G &nbsp; &nbsp; 0 &nbsp; 12G &nbsp; 0% /dev/shm</font></div><div><font size="2"   >/dev/sda3 &nbsp; &nbsp; &nbsp; &nbsp;89G &nbsp; 11G &nbsp; 74G &nbsp;13% /home</font></div><div><font size="2"   >zp &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;5.3G &nbsp; &nbsp; 0 &nbsp;5.3G &nbsp; 0% /zp</font></div><div><font size="2"   >zp/test &nbsp; &nbsp; &nbsp; &nbsp; 5.9G &nbsp;615M &nbsp;5.3G &nbsp;11% /zp/test</font></div></div><div><div><font size="2"   >[root@spark01 ~]# cd /home/digoal</font></div><div><font size="2"   >[root@spark01 digoal]# zfs set dedup=on zp/test</font></div><div><font size="2"   >[root@spark01 digoal]# rm -rf /zp/test/*</font></div><div><font size="2"   >[root@spark01 digoal]# date +%F%T; cp -r hadoop-2.4.0* spl-0.6.2* zfs-0.6.2* /zp/test/ ; date +%F%T;</font></div><div><font size="2"   >2014-05-1917:48:06</font></div><div><font size="2"   >2014-05-1917:48:21 &nbsp;15秒</font></div></div><div><div><font size="2"   >[root@spark01 digoal]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp;Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/sda1 &nbsp; &nbsp; &nbsp; &nbsp;31G &nbsp;1.2G &nbsp; 29G &nbsp; 5% /</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;12G &nbsp; &nbsp; 0 &nbsp; 12G &nbsp; 0% /dev/shm</font></div><div><font size="2"   >/dev/sda3 &nbsp; &nbsp; &nbsp; &nbsp;89G &nbsp; 11G &nbsp; 74G &nbsp;13% /home</font></div><div><font size="2"   >zp &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;5.4G &nbsp; &nbsp; 0 &nbsp;5.4G &nbsp; 0% /zp</font></div><div><font size="2"   >zp/test &nbsp; &nbsp; &nbsp; &nbsp; 6.0G &nbsp;615M &nbsp;5.4G &nbsp;11% /zp/test</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@spark01 digoal]# zpool get dedupratio zp</font></div><div><font size="2"   >NAME &nbsp;PROPERTY &nbsp; &nbsp;VALUE &nbsp;SOURCE</font></div><div><font size="2"   >zp &nbsp; &nbsp;dedupratio &nbsp;1.24x &nbsp;-</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   >同样的文件再生成一份, dedup比例上升为2.49</font></div><div><div><font size="2"   >[root@spark01 digoal]# cd /zp/test</font></div><div><font size="2"   >[root@spark01 test]# mkdir new</font></div><div><font size="2"   >[root@spark01 test]# cp -r hadoop-2.4.0* spl-0.6.2* zfs-0.6.2* new/</font></div></div><div><div><font size="2"   >[root@spark01 test]# zpool get dedupratio zp</font></div><div><font size="2"   >NAME &nbsp;PROPERTY &nbsp; &nbsp;VALUE &nbsp;SOURCE</font></div><div><font size="2"   >zp &nbsp; &nbsp;dedupratio &nbsp;2.49x &nbsp;-</font></div></div><p></p></pre></div><div>注意avail没有变化, 说明deduplicate起到作用了, used显示的是使用的空间, 实际上是假的. 因为存储池也"放大"了.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@spark01 test]# zfs list</font></div><div><font size="2"   >NAME &nbsp; &nbsp; &nbsp;USED &nbsp;AVAIL &nbsp;REFER &nbsp;MOUNTPOINT</font></div><div><font size="2"   >zp &nbsp; &nbsp; &nbsp; 1.20G &nbsp;5.34G &nbsp;43.4K &nbsp;/zp</font></div><div><font size="2"   >zp/test &nbsp;1.20G &nbsp;5.34G &nbsp;1.20G &nbsp;/zp/test</font></div><p></p></pre></div><div>可能是我这里的配置问题, zdb无法使用 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@spark01 test]# zdb</font></div><div><font size="2"   >cannot open '/etc/zfs/zpool.cache': No such file or directory</font></div><div><font size="2"   >[root@spark01 test]# zdb -b zp</font></div><div><font size="2"   >zdb: can't open 'zp': No such file or directory</font></div><p></p></pre></div><div>生成这个默认的配置, 当然也可以写在其他位置. 然后就可以正常使用zdb了.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@spark01 test]# mkdir /etc/zfs</font></div><div><font size="2"   >[root@spark01 test]# zpool set cachefile=/etc/zfs/zpool.cache zp</font></div><div><font size="2"   >[root@spark01 test]# zpool get cachefile zp</font></div><div><font size="2"   >NAME &nbsp;PROPERTY &nbsp; VALUE &nbsp; &nbsp; &nbsp;SOURCE</font></div><div><font size="2"   >zp &nbsp; &nbsp;cachefile &nbsp;- &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;default</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@spark01 test]# zdb -b zp</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Traversing all blocks to verify nothing leaked ...</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; No leaks (block sum matches space maps exactly)</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; bp count: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 26452</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; bp logical: &nbsp; &nbsp;1306227200 &nbsp; &nbsp; &nbsp;avg: &nbsp;49381</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; bp physical: &nbsp; 1280552960 &nbsp; &nbsp; &nbsp;avg: &nbsp;48410 &nbsp; &nbsp; compression: &nbsp; 1.02</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; bp allocated: &nbsp;1727905792 &nbsp; &nbsp; &nbsp;avg: &nbsp;65322 &nbsp; &nbsp; compression: &nbsp; 0.76</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; bp deduped: &nbsp; &nbsp;1022530560 &nbsp; &nbsp;ref&gt;1: &nbsp; 8794 &nbsp; deduplication: &nbsp; 1.59</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; SPA allocated: &nbsp;705375232 &nbsp; &nbsp; used: &nbsp;8.28%</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@spark01 test]# cp -r new new1</font></div><div><font size="2"   >[root@spark01 test]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp;Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/sda1 &nbsp; &nbsp; &nbsp; &nbsp;31G &nbsp;1.2G &nbsp; 29G &nbsp; 5% /</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;12G &nbsp; &nbsp; 0 &nbsp; 12G &nbsp; 0% /dev/shm</font></div><div><font size="2"   >/dev/sda3 &nbsp; &nbsp; &nbsp; &nbsp;89G &nbsp; 11G &nbsp; 74G &nbsp;13% /home</font></div><div><font size="2"   >zp &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;5.4G &nbsp; &nbsp; 0 &nbsp;5.4G &nbsp; 0% /zp</font></div><div><font size="2"   >zp/test &nbsp; &nbsp; &nbsp; &nbsp; 7.0G &nbsp;1.7G &nbsp;5.4G &nbsp;24% /zp/test</font></div><div><font size="2"   >注意到zp/test的空间又放大了, 现在是7.0GB. 实际的pool只有5.4GB.</font></div><div><font size="2"   >[root@spark01 test]# zpool get cachefile zp</font></div><div><font size="2"   >NAME &nbsp;PROPERTY &nbsp; VALUE &nbsp; &nbsp; &nbsp;SOURCE</font></div><div><font size="2"   >zp &nbsp; &nbsp;cachefile &nbsp;- &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;default</font></div><div><font size="2"   >[root@spark01 test]# zdb -b zp</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Traversing all blocks to verify nothing leaked ...</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; No leaks (block sum matches space maps exactly)</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; bp count: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 39633</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; bp logical: &nbsp; &nbsp;1958756352 &nbsp; &nbsp; &nbsp;avg: &nbsp;49422</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; bp physical: &nbsp; 1921044480 &nbsp; &nbsp; &nbsp;avg: &nbsp;48470 &nbsp; &nbsp; compression: &nbsp; 1.02</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; bp allocated: &nbsp;2592529408 &nbsp; &nbsp; &nbsp;avg: &nbsp;65413 &nbsp; &nbsp; compression: &nbsp; 0.76</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; bp deduped: &nbsp; &nbsp;1876494336 &nbsp; &nbsp;ref&gt;1: &nbsp; 8794 &nbsp; deduplication: &nbsp; 1.72</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; SPA allocated: &nbsp;716035072 &nbsp; &nbsp; used: &nbsp;8.40%</font></div></div><p></p></pre></div><div><br></div>[参考]<wbr><div>1.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="https://pthree.org/2012/12/18/zfs-administration-part-xi-compression-and-deduplication/"   >https://pthree.org/2012/12/18/zfs-administration-part-xi-compression-and-deduplication/</a></div><div>2.&nbsp;<a style="line-height: 28px;" target="_blank" href="http://blog.163.com/digoal@126/blog/static/16387704020144197501438/"   >http://blog.163.com/digoal@126/blog/static/16387704020144197501438/</a></div><div><br></div>
<a rel="nofollow" href="http://info.flagcounter.com/h9V1"   ><img title="ZFS deduplicate - 德哥@Digoal - PostgreSQL"   src="http://s03.flagcounter.com/count/h9V1/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_12/viewers_0/labels_0/pageviews_0/flags_0/"   alt="Flag Counter"   border="0"   ></a></div>
	</div>
</div>
</body>
</html>