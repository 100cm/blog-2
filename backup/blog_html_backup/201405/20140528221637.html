<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">PostgreSQL Share-disk HA configure Best Practices with CentOS or RHEL Cluster Suite</h2>
	<h5 id="">2014-05-28 22:16:37&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/163877040201442842625169/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;"><div><div>接上一篇BLOG</div><div><a target="_blank" href="http://blog.163.com/digoal@126/blog/static/1638770402014428985260/"   >http://blog.163.com/digoal@126/blog/static/1638770402014428985260/</a></div><div>本文讲一下PostgreSQL共享存储的HA配置.</div><div>本文环境基于上一篇BLOG的配置, 但是已经加了共享存储, 换了主机.&nbsp;</div><div><br></div><div>首先要配置multipath</div><div>CentOS 5.x可以使用scsi_id得到wwn</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># for i in `cat /proc/partitions | awk '{print $4}' |grep sd`; do echo "### $i: `scsi_id -g -u -s /block/$i`"; done</font></div><div><font size="2"   >### sda: 36001438005de97860000b00000d20000</font></div><div><font size="2"   >### sdb: 36001438005de97860000b00000d60000</font></div><div><font size="2"   >### sdc: 36001438005de97860000b00000d20000</font></div><div><font size="2"   >### sdd: 36001438005de97860000b00000d60000</font></div><div><font size="2"   >### sde: 36001438005de97860000b00000d20000</font></div><div><font size="2"   >### sdf: 36001438005de97860000b00000d60000</font></div><div><font size="2"   >### sdg: 36001438005de97860000b00000d20000</font></div><div><font size="2"   >### sdh: 36001438005de97860000b00000d60000</font></div><p></p></pre></div><div>然后根据这些ID编写/etc/multipath.conf</div><div>CentOS 6的话, 不需要这么麻烦, 只要启动multipathd进程, 就可以得到wwn, 然后编写multipath.conf</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_204 ~]# multipath -ll</font></div><div><font size="2"   >mpathc (36001438005de97860000b00000ce0000) dm-1 HP,HSV400</font></div><div><font size="2"   >size=350G features='1 queue_if_no_path' hwhandler='0' wp=rw</font></div><div><font size="2"   >|-+- policy='round-robin 0' prio=130 status=active</font></div><div><font size="2"   >| |- 1:0:1:2 sde 8:64 &nbsp;active ready running</font></div><div><font size="2"   >| `- 2:0:1:2 sdi 8:128 active ready running</font></div><div><font size="2"   >`-+- policy='round-robin 0' prio=10 status=enabled</font></div><div><font size="2"   >&nbsp; |- 1:0:0:2 sdc 8:32 &nbsp;active ready running</font></div><div><font size="2"   >&nbsp; `- 2:0:0:2 sdg 8:96 &nbsp;active ready running</font></div><div><font size="2"   >mpathb (36001438005de97860000b00000ca0000) dm-0 HP,HSV400</font></div><div><font size="2"   >size=350G features='1 queue_if_no_path' hwhandler='0' wp=rw</font></div><div><font size="2"   >|-+- policy='round-robin 0' prio=130 status=active</font></div><div><font size="2"   >| |- 1:0:1:1 sdd 8:48 &nbsp;active ready running</font></div><div><font size="2"   >| `- 2:0:1:1 sdh 8:112 active ready running</font></div><div><font size="2"   >`-+- policy='round-robin 0' prio=10 status=enabled</font></div><div><font size="2"   >&nbsp; |- 1:0:0:1 sdb 8:16 &nbsp;active ready running</font></div><div><font size="2"   >&nbsp; `- 2:0:0:1 sdf 8:80 &nbsp;active ready running</font></div><p></p></pre></div><div>如果您的环境使用了其他多路径软件, 则不需要配置multipathd, 例如EMC的PowerPath.</div><div>编写multipath.conf, 两个节点都需要配置, 注意如果两个主机的本地硬盘命名规则不一样的话, blacklist也需要注意.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_204 ~]# vi /etc/multipath.conf</font></div><div><font size="2"   ># multipath.conf written by anaconda</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >defaults {</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;udev_dir &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /dev</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;polling_interval &nbsp; &nbsp; &nbsp; &nbsp; 10</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;path_grouping_policy &nbsp; &nbsp; failover</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;getuid_callout &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "/sbin/scsi_id -g -u -s /block/%n"</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;path_checker &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; readsector0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;rr_min_io &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;100</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;rr_weight &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;priorities</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;failback &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; immediate</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;no_path_retry &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;fail</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;user_friendly_names &nbsp; &nbsp; &nbsp;yes</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;flush_on_last_del &nbsp; &nbsp; &nbsp; &nbsp;yes</font></div><div><font size="2"   >}</font></div><div><font size="2"   >blacklist {</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;devnode "^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*"</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;devnode "^hd[a-z]"</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;devnode "^cciss!c[0-9]d[0-9]*"</font></div><div><font size="2"   >}</font></div><div><font size="2"   >multipaths {</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; multipath {</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; wwid "36001438005de97860000b00000ca0000"</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; alias &nbsp; &nbsp;e06_eva_vd4</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; }</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; multipath {</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; wwid "36001438005de97860000b00000ce0000"</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; alias &nbsp; &nbsp;e06_eva_vd3</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; }</font></div><div><font size="2"   >}</font></div><p></p></pre></div><div>重启multipathd 服务, 加入自动启动</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_204 ~]# service multipathd restart</font></div><div><font size="2"   >ok</font></div><div><font size="2"   >Stopping multipathd daemon: [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >Starting multipathd daemon: [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >[root@172_16_13_204 ~]# multipath -ll</font></div><div><font size="2"   >e06_eva_vd4 (36001438005de97860000b00000ca0000) dm-0 HP,HSV400</font></div><div><font size="2"   >size=350G features='1 queue_if_no_path' hwhandler='0' wp=rw</font></div><div><font size="2"   >|-+- policy='round-robin 0' prio=130 status=active</font></div><div><font size="2"   >| |- 1:0:1:1 sdd 8:48 &nbsp;active ready running</font></div><div><font size="2"   >| `- 2:0:1:1 sdh 8:112 active ready running</font></div><div><font size="2"   >`-+- policy='round-robin 0' prio=10 status=enabled</font></div><div><font size="2"   >&nbsp; |- 1:0:0:1 sdb 8:16 &nbsp;active ready running</font></div><div><font size="2"   >&nbsp; `- 2:0:0:1 sdf 8:80 &nbsp;active ready running</font></div><div><font size="2"   >e06_eva_vd3 (36001438005de97860000b00000ce0000) dm-1 HP,HSV400</font></div><div><font size="2"   >size=350G features='1 queue_if_no_path' hwhandler='0' wp=rw</font></div><div><font size="2"   >|-+- policy='round-robin 0' prio=130 status=active</font></div><div><font size="2"   >| |- 1:0:1:2 sde 8:64 &nbsp;active ready running</font></div><div><font size="2"   >| `- 2:0:1:2 sdi 8:128 active ready running</font></div><div><font size="2"   >`-+- policy='round-robin 0' prio=10 status=enabled</font></div><div><font size="2"   >&nbsp; |- 1:0:0:2 sdc 8:32 &nbsp;active ready running</font></div><div><font size="2"   >&nbsp; `- 2:0:0:2 sdg 8:96 &nbsp;active ready running</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >chkconfig multipathd on</font></div><p></p></pre></div><div><br></div><div>接下来要参考以下配置HA-lvm.</div><div><a target="_blank" rel="nofollow" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Cluster_Administration/ap-ha-halvm-CA.html"   >https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Cluster_Administration/ap-ha-halvm-CA.html</a></div><div><br></div><div>在任意节点, 创建pv</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_204 ~]# pvcreate /dev/mapper/e06_eva_vd3</font></div><div><font size="2"   >&nbsp; Physical volume "/dev/mapper/e06_eva_vd3" successfully created</font></div><div><font size="2"   >[root@172_16_13_204 ~]# pvcreate /dev/mapper/e06_eva_vd4</font></div><div><font size="2"   >&nbsp; Physical volume "/dev/mapper/e06_eva_vd4" successfully created</font></div><p></p></pre></div><div><br></div><div>修改lvm锁, 2台主机都需要修改.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># vi /etc/lvm/lvm.conf</font></div><div><font size="2"   >locking_type = 3</font></div><p></p></pre></div><div><br></div><div>2台主机都启动clvmd服务. (必须在cman启动后才能启动clvmd, 大多数依赖集群的服务都需要先启动cman后启动, 如果要关闭cman服务, 也需要先关闭依赖cman的服务, 例如clvmd, rgmanager)</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >chkconfig clvmd on</font></div><div><font size="2"   >service clvmd start</font></div><p></p></pre></div><div><br></div><div>在任意节点创建集群卷组.</div><pre class="prettyprint"   ><p></p><div><font size="2"   ># vgcreate -cy shared_vg /dev/mapper/e06_eva_vd3 /dev/mapper/e06_eva_vd4</font></div><div></div><p></p></pre><div><span style="line-height: 28px;"   >在其他节点扫描pv和vg</span></div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_204 ~]# pvs</font></div><div><font size="2"   >&nbsp; PV &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;VG &nbsp; &nbsp; &nbsp; &nbsp;Fmt &nbsp;Attr PSize &nbsp; PFree &nbsp;</font></div><div><font size="2"   >&nbsp; /dev/mapper/e06_eva_vd3 shared_vg lvm2 a-- &nbsp;350.00g 350.00g</font></div><div><font size="2"   >&nbsp; /dev/mapper/e06_eva_vd4 shared_vg lvm2 a-- &nbsp;350.00g 350.00g</font></div><div><font size="2"   >[root@172_16_13_204 ~]# vgs</font></div><div><font size="2"   >&nbsp; VG &nbsp; &nbsp; &nbsp; &nbsp;#PV #LV #SN Attr &nbsp; VSize &nbsp; VFree &nbsp;</font></div><div><font size="2"   >&nbsp; shared_vg &nbsp; 2 &nbsp; 0 &nbsp; 0 wz--nc 699.99g 699.99g</font></div><p></p></pre></div><div><br></div><div>在任意节点创建逻辑卷</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_203 ~]# lvcreate -L 100G -n lv01 shared_vg</font></div><div><font size="2"   >&nbsp; Logical volume "lv01" created</font></div><div><font size="2"   >[root@172_16_13_203 ~]# lvs</font></div><div><font size="2"   >&nbsp; LV &nbsp; VG &nbsp; &nbsp; &nbsp; &nbsp;Attr &nbsp; &nbsp; &nbsp; LSize &nbsp; Pool Origin Data% &nbsp;Move Log Cpy%Sync Convert</font></div><div><font size="2"   >&nbsp; lv01 shared_vg -wi-a----- 100.00g &nbsp;&nbsp;</font></div><p></p></pre></div><div><br></div><div>在任意节点创建集群文件系统, 如果要多个节点同时mount一个文件系统的话, 需要多个journal区域.</div><div>本例使用2个journal区域.</div><div>所以在格式化文件系统的时候需要设置好.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_203 ~]# mkfs.gfs2 -p lock_dlm -t yumdemo:lv01 -j 2 /dev/mapper/shared_vg-lv01&nbsp;</font></div><div><font size="2"   >This will destroy any data on /dev/mapper/shared_vg-lv01.</font></div><div><font size="2"   >It appears to contain: symbolic link to `../dm-2'</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Are you sure you want to proceed? [y/n] y</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Device: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/dev/mapper/shared_vg-lv01</font></div><div><font size="2"   >Blocksize: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 4096</font></div><div><font size="2"   >Device Size &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;100.00 GB (26214400 blocks)</font></div><div><font size="2"   >Filesystem Size: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 100.00 GB (26214398 blocks)</font></div><div><font size="2"   >Journals: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2</font></div><div><font size="2"   >Resource Groups: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 400</font></div><div><font size="2"   >Locking Protocol: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"lock_dlm"</font></div><div><font size="2"   >Lock Table: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"yumdemo:lv01"</font></div><div><font size="2"   >UUID: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;7c1531b1-e1e5-b746-a2ec-c1244bbb51eb</font></div><p></p></pre></div><div><br></div><div>加载文件系统</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_204 ~]# mkdir /data01</font></div><div><font size="2"   >[root@172_16_13_204 ~]# mount.gfs2 -o lockproto=lock_dlm /dev/mapper/shared_vg-lv01 /data01</font></div><div><font size="2"   >/dev/mapper/shared_vg-lv01 on /data01 type gfs2 (rw,relatime,lockproto=lock_dlm,hostdata=jid=0)</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@172_16_13_203 ~]# mkdir /data01</font></div><div><font size="2"   >[root@172_16_13_203 ~]# mount.gfs2 -o lockproto=lock_dlm /dev/mapper/shared_vg-lv01 /data01</font></div><div><font size="2"   >/dev/mapper/shared_vg-lv01 on /data01 type gfs2 (rw,relatime,lockproto=lock_dlm,hostdata=jid=1)</font></div><p></p></pre></div><div><br></div><div>接下来要把文件系统卸载掉</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_204 ~]# umount /data01</font></div><div></div><p></p></pre></div><div>因为多个节点都要使用这个共享存储, 所以可以把它作为全局资源, 添加到独立的service, 并且设置为启动cman时自动启动.</div><div>当然不自动启动也没有问题. 可以和VIP的资源放一起, 跟随指定的service一起启动.</div><div>查看系统支持的资源和对应的配置选项.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_203 ~]# ccs -f /etc/cluster/cluster.conf --lsresourceopts</font></div><div><font size="2"   >service - Defines a service (resource group).</font></div><div><font size="2"   >ASEHAagent - Sybase ASE Failover Instance</font></div><div><font size="2"   >SAPDatabase - Manages any SAP database (based on Oracle, MaxDB, or DB2)</font></div><div><font size="2"   >SAPInstance - SAP instance resource agent</font></div><div><font size="2"   >apache - Defines an Apache web server</font></div><div><font size="2"   >clusterfs - Defines a cluster file system mount.</font></div><div><font size="2"   >fs - Defines a file system mount.</font></div><div><font size="2"   >ip - This is an IP address.</font></div><div><font size="2"   >lvm - LVM Failover script</font></div><div><font size="2"   >mysql - Defines a MySQL database server</font></div><div><font size="2"   >named - Defines an instance of named server</font></div><div><font size="2"   >netfs - Defines an NFS/CIFS file system mount.</font></div><div><font size="2"   >nfsclient - Defines an NFS client.</font></div><div><font size="2"   >nfsexport - This defines an NFS export.</font></div><div><font size="2"   >nfsserver - This defines an NFS server resource.</font></div><div><font size="2"   >openldap - Defines an Open LDAP server</font></div><div><font size="2"   >oracledb - Oracle 10g/11g Failover Instance</font></div><div><font size="2"   >orainstance - Oracle 10g Failover Instance</font></div><div><font size="2"   >oralistener - Oracle 10g Listener Instance</font></div><div><font size="2"   >postgres-8 - Defines a PostgreSQL server</font></div><div><font size="2"   >samba - Dynamic smbd/nmbd resource agent</font></div><div><font size="2"   >script - LSB-compliant init script as a clustered resource.</font></div><div><font size="2"   >tomcat-6 - Defines a Tomcat server</font></div><div><font size="2"   >vm - Defines a Virtual Machine</font></div><div><font size="2"   >[root@172_16_13_203 ~]# ccs -f /etc/cluster/cluster.conf --lsresourceopts lvm</font></div><div><font size="2"   >lvm - LVM Failover script</font></div><div><font size="2"   >&nbsp; Required Options:</font></div><div><font size="2"   >&nbsp; &nbsp; name: Name</font></div><div><font size="2"   >&nbsp; &nbsp; vg_name: Volume group name</font></div><div><font size="2"   >&nbsp; Optional Options:</font></div><div><font size="2"   >&nbsp; &nbsp; lv_name: Logical Volume name (optional).</font></div><div><font size="2"   >&nbsp; &nbsp; self_fence: Fence the node if it is not able to clean up LVM tags</font></div><div><font size="2"   >&nbsp; &nbsp; nfslock: Enable NFS lock workarounds</font></div><div><font size="2"   >&nbsp; &nbsp; __independent_subtree: Treat this and all children as an independent subtree.</font></div><div><font size="2"   >&nbsp; &nbsp; __enforce_timeouts: Consider a timeout for operations as fatal.</font></div><div><font size="2"   >&nbsp; &nbsp; __max_failures: Maximum number of failures before returning a failure to a status check.</font></div><div><font size="2"   >&nbsp; &nbsp; __failure_expire_time: Amount of time before a failure is forgotten.</font></div><div><font size="2"   >&nbsp; &nbsp; __max_restarts: Maximum number restarts for an independent subtree before giving up.</font></div><div><font size="2"   >&nbsp; &nbsp; __restart_expire_time: Amount of time before a failure is forgotten for an independent subtree.</font></div><div><font size="2"   >[root@172_16_13_204 ~]# ccs -f /etc/cluster/cluster.conf --lsresourceopts fs</font></div><div><font size="2"   >fs - Defines a file system mount.</font></div><div><font size="2"   >&nbsp; Required Options:</font></div><div><font size="2"   >&nbsp; &nbsp; name: File System Name</font></div><div><font size="2"   >&nbsp; &nbsp; mountpoint: Mount Point</font></div><div><font size="2"   >&nbsp; &nbsp; device: Device or Label</font></div><div><font size="2"   >&nbsp; Optional Options:</font></div><div><font size="2"   >&nbsp; &nbsp; fstype: File system type</font></div><div><font size="2"   >&nbsp; &nbsp; force_unmount: Force Unmount</font></div><div><font size="2"   >&nbsp; &nbsp; quick_status: Quick/brief status checks.</font></div><div><font size="2"   >&nbsp; &nbsp; self_fence: Seppuku Unmount</font></div><div><font size="2"   >&nbsp; &nbsp; nfslock: Enable NFS lock workarounds</font></div><div><font size="2"   >&nbsp; &nbsp; nfsrestart: Enable NFS daemon and lockd workaround</font></div><div><font size="2"   >&nbsp; &nbsp; fsid: NFS File system ID</font></div><div><font size="2"   >&nbsp; &nbsp; force_fsck: Force fsck support</font></div><div><font size="2"   >&nbsp; &nbsp; options: Mount Options</font></div><div><font size="2"   >&nbsp; &nbsp; use_findmnt: Utilize findmnt to detect if and where filesystems are mounted</font></div><div><font size="2"   >&nbsp; &nbsp; __independent_subtree: Treat this and all children as an independent subtree.</font></div><div><font size="2"   >&nbsp; &nbsp; __enforce_timeouts: Consider a timeout for operations as fatal.</font></div><div><font size="2"   >&nbsp; &nbsp; __max_failures: Maximum number of failures before returning a failure to a status check.</font></div><div><font size="2"   >&nbsp; &nbsp; __failure_expire_time: Amount of time before a failure is forgotten.</font></div><div><font size="2"   >&nbsp; &nbsp; __max_restarts: Maximum number restarts for an independent subtree before giving up.</font></div><div><font size="2"   >&nbsp; &nbsp; __restart_expire_time: Amount of time before a failure is forgotten for an independent subtree.</font></div><p></p></pre></div><div><br></div><div>把2个节点的服务停了再开始配置/etc/cluster/cluster.conf</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >clusvcadmin -d yumdemo_pg</font></div><div><font size="2"   >service rgmanager stop</font></div><div><font size="2"   >service clvmd stop</font></div><div><font size="2"   >service cman stop</font></div><p></p></pre></div><div><p><br></p></div><div>接下来我们需要做的是把LVM添加进资源, GFS2文件系统添加进资源.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_203 cluster]# ccs -f /etc/cluster/cluster.conf --addresource lvm name=lvm vg_name=shared_vg lv_name=lv01</font></div><div><font size="2"   >[root@172_16_13_203 cluster]# ccs -f /etc/cluster/cluster.conf --addresource fs name="fs" mountpoint="/data01" device="/dev/mapper/shared_vg-lv01" options="lockproto=lock_dlm"</font></div><p></p></pre></div><div><br></div><div>把这两个资源添加到yumdemo_pg服务中.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_203 cluster]# ccs -f /etc/cluster/cluster.conf --addsubservice yumdemo_pg lvm ref="LVM"</font></div><div><font size="2"   >[root@172_16_13_203 cluster]# ccs -f /etc/cluster/cluster.conf --addsubservice yumdemo_pg fs ref="FS"</font></div><div><font size="2"   >[root@172_16_13_203 cluster]# vi /etc/cluster/cluster.conf&nbsp;</font></div><div><font size="2"   >&lt;cluster config_version="26" name="yumdemo"&gt;</font></div><div><font size="2"   >&nbsp; &lt;fence_daemon post_fail_delay="6" post_join_delay="30"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="172.16.13.203" nodeid="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="ILO"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="reboot" name="fence_203"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="172.16.13.204" nodeid="2"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="ILO"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="reboot" name="fence_204"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &lt;/clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &lt;cman expected_votes="1" two_node="1"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ilo" ipaddr="172.16.12.12" login="2010" name="fence_203" passwd="2010"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ilo" ipaddr="172.16.12.13" login="2010" name="fence_204" passwd="2010"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &lt;rm&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;failoverdomains&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;failoverdomain name="yumdemo_fd" nofailback="1" ordered="1" restricted="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;failoverdomainnode name="172.16.13.203" priority="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;failoverdomainnode name="172.16.13.204" priority="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/failoverdomain&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/failoverdomains&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;resources&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;ip address="172.16.13.156" monitor_link="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;lvm lv_name="lv01" name="LVM" vg_name="shared_vg"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fs device="/dev/mapper/shared_vg-lv01" mountpoint="/data01" name="FS" options="lockproto=lock_dlm"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/resources&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;service autostart="0" domain="yumdemo_fd" name="yumdemo_pg"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;ip ref="172.16.13.156"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;lvm ref="LVM"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fs ref="FS"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/service&gt;</font></div><div><font size="2"   >&nbsp; &lt;/rm&gt;</font></div><div><font size="2"   >&nbsp; &lt;logging/&gt;</font></div><div><font size="2"   >&lt;/cluster&gt;</font></div><p></p></pre></div><div><br></div><div>把生成的/etc/cluster/cluster.conf内容拷贝到另一台服务器.</div><div>同时启动两台主机的cman服务.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_203 cluster]# service cman start</font></div><div><font size="2"   >Starting cluster:&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp;Checking if cluster has been disabled at boot... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Checking Network Manager... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Global setup... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Loading kernel modules... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Mounting configfs... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting cman... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Waiting for quorum... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting fenced... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting dlm_controld... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Tuning DLM kernel config... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting gfs_controld... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Unfencing self... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Joining fence domain... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >[root@172_16_13_204 ~]# service cman start</font></div><div><font size="2"   >Starting cluster:&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp;Checking if cluster has been disabled at boot... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Checking Network Manager... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Global setup... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Loading kernel modules... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Mounting configfs... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting cman... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Waiting for quorum... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting fenced... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting dlm_controld... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Tuning DLM kernel config... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting gfs_controld... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Unfencing self... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Joining fence domain... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >[root@172_16_13_204 ~]# clustat</font></div><div><font size="2"   >Cluster Status for yumdemo @ Wed May 28 19:49:04 2014</font></div><div><font size="2"   >Member Status: Quorate</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp;Member Name &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ID &nbsp; Status</font></div><div><font size="2"   >&nbsp;------ ---- &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ---- ------</font></div><div><font size="2"   >&nbsp;172.16.13.203 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1 Online</font></div><div><font size="2"   >&nbsp;172.16.13.204 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2 Online, Local</font></div><p></p></pre></div><div>启动clvmd, rgmanager服务.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_203 cluster]# service clvmd start</font></div><div><font size="2"   >Starting clvmd:&nbsp;</font></div><div><font size="2"   >Activating VG(s): &nbsp; 1 logical volume(s) in volume group "shared_vg" now active</font></div><div><font size="2"   >[ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >[root@172_16_13_203 cluster]# service rgmanager start</font></div><div><font size="2"   >Starting Cluster Service Manager: [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >[root@172_16_13_204 ~]# service clvmd start</font></div><div><font size="2"   >Starting clvmd:&nbsp;</font></div><div><font size="2"   >Activating VG(s): &nbsp; 1 logical volume(s) in volume group "shared_vg" now active</font></div><div><font size="2"   >&nbsp; clvmd not running on node 172.16.13.203</font></div><div><font size="2"   >[ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >[root@172_16_13_204 ~]# service rgmanager start</font></div><div><font size="2"   >Starting Cluster Service Manager: [ &nbsp;OK &nbsp;]</font></div><p></p></pre></div><div><br></div><div>启动yumdemo_pg服务, 自动加载文件系统.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_203 cluster]# clusvcadm -e yumdemo_pg</font></div><div><font size="2"   >Local machine trying to enable service:yumdemo_pg...Success</font></div><div><font size="2"   >service:yumdemo_pg is now running on 172.16.13.203</font></div><div><font size="2"   >[root@172_16_13_203 cluster]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/sda1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;32G &nbsp;1.7G &nbsp; 29G &nbsp; 6% /</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;12G &nbsp; 32M &nbsp; 12G &nbsp; 1% /dev/shm</font></div><div><font size="2"   >/dev/sda3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;96G &nbsp;206M &nbsp; 91G &nbsp; 1% /opt</font></div><div><font size="2"   >/dev/mapper/shared_vg-lv01 &nbsp;100G &nbsp;259M &nbsp;100G &nbsp; 1% /data01</font></div><p></p></pre></div><div><br></div><div>关闭服务, 自动卸载配置在服务中的文件系统.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_203 cluster]# clusvcadm -d yumdemo_pg</font></div><div><font size="2"   >Local machine disabling service:yumdemo_pg...Success</font></div><div><font size="2"   >[root@172_16_13_203 cluster]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp;Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/sda1 &nbsp; &nbsp; &nbsp; &nbsp;32G &nbsp;1.7G &nbsp; 29G &nbsp; 6% /</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;12G &nbsp; 26M &nbsp; 12G &nbsp; 1% /dev/shm</font></div><div><font size="2"   >/dev/sda3 &nbsp; &nbsp; &nbsp; &nbsp;96G &nbsp;206M &nbsp; 91G &nbsp; 1% /opt</font></div><p></p></pre></div><div><br></div><div>接下来要做的是安装数据库软件, 在2台主机各自安装PostgreSQL 9.3.4软件.</div><div>软件安装在本地目录中,</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_204 ~]# useradd postgres</font></div><div><font size="2"   >[root@172_16_13_203 cluster]# useradd postgres</font></div><div><font size="2"   >[root@172_16_13_203 cluster]# cd /opt</font></div><div><font size="2"   >[root@172_16_13_203 opt]# mkdir soft_bak</font></div><div><font size="2"   >cd soft_bak</font></div><div><font size="2"   >wget http://ftp.postgresql.org/pub/source/v9.3.4/postgresql-9.3.4.tar.bz2</font></div><div><font size="2"   >tar -jxvf postgresql-9.3.4.tar.bz2</font></div><div><font size="2"   >cd postgresql-9.3.4</font></div><div><font size="2"   >yum -y install lrzsz sysstat e4fsprogs ntp readline-devel zlib zlib-devel openssl openssl-devel pam-devel libxml2-devel libxslt-devel python-devel tcl-devel gcc make smartmontools flex bison perl perl-devel perl-ExtUtils* OpenIPMI-tools openldap*</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >./configure --prefix=/opt/pgsql9.3.4 --with-pgport=1921 --with-perl --with-tcl --with-python --with-openssl --with-pam --with-ldap --with-libxml --with-libxslt --enable-thread-safety &amp;&amp; gmake world &amp;&amp; gmake install-world</font></div><div><font size="2"   >ln -s /opt/pgsql9.3.4 /opt/pgsql</font></div><p></p></pre></div><div><br></div><div>安装完后, 启动集群服务, 挂载共享存储, 在任意节点初始化数据库到共享存储.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >node A,B:</font></div><div><font size="2"   >service cman start</font></div><div><font size="2"   >node A,B:</font></div><div><font size="2"   >service clvmd start</font></div><div><font size="2"   >service rgmanager start</font></div><div><font size="2"   >clusvcadmin -e yumdemo_pg</font></div><div><font size="2"   >[root@172_16_13_204 postgresql-9.3.4]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/sda1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;32G &nbsp;1.7G &nbsp; 29G &nbsp; 6% /</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;12G &nbsp; 32M &nbsp; 12G &nbsp; 1% /dev/shm</font></div><div><font size="2"   >/dev/sda3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;96G &nbsp;413M &nbsp; 90G &nbsp; 1% /opt</font></div><div><font size="2"   >/dev/mapper/shared_vg-lv01 &nbsp;100G &nbsp;259M &nbsp;100G &nbsp; 1% /data01</font></div><div><font size="2"   >[root@172_16_13_204 postgresql-9.3.4]# mkdir /data01/pgdata</font></div><div><font size="2"   >[root@172_16_13_204 postgresql-9.3.4]# chown postgres:postgres /data01/pgdata</font></div><p></p></pre></div><div><br></div><div>配置2个节点的postgres用户的.bash_profile</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># vi /home/postgres/.bash_profile</font></div><div><font size="2"   ># add by digoal</font></div><div><font size="2"   >export PS1="$USER@`/bin/hostname -s`-&gt; "</font></div><div><font size="2"   >export PGPORT=1921</font></div><div><font size="2"   >export PGDATA=/data01/pgdata/pg_root</font></div><div><font size="2"   >export LANG=en_US.utf8</font></div><div><font size="2"   >export PGHOME=/opt/pgsql</font></div><div><font size="2"   >export LD_LIBRARY_PATH=$PGHOME/lib:/lib64:/usr/lib64:/usr/local/lib64:/lib:/usr/lib:/usr/local/lib:$LD_LIBRARY_PATH</font></div><div><font size="2"   >export DATE=`date +"%Y%m%d%H%M"`</font></div><div><font size="2"   >export PATH=$PGHOME/bin:$PATH:.</font></div><div><font size="2"   >export MANPATH=$PGHOME/share/man:$MANPATH</font></div><div><font size="2"   >export PGUSER=postgres</font></div><div><font size="2"   >export PGHOST=$PGDATA</font></div><div><font size="2"   >export PGDATABASE=postgres</font></div><div><font size="2"   >alias rm='rm -i'</font></div><div><font size="2"   >alias ll='ls -lh'</font></div><p></p></pre></div><div><br></div><div>在任意节点初始化数据库, 数据目录使用共享存储.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >su - postgres</font></div><div><font size="2"   >postgres@172_16_13_204-&gt; initdb -D $PGDATA -E UTF8 --locale=C -U postgres -W</font></div><p></p></pre></div><div><br></div><div>配置pg_hba.conf, postgresql.conf</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >postgres@172_16_13_204-&gt; cd $PGDATA</font></div><div><font size="2"   >vi postgresql.conf</font></div><div><font size="2"   >listen_addresses = '0.0.0.0' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# what IP address(es) to listen on;</font></div><div><font size="2"   >max_connections = 1000 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# (change requires restart)</font></div><div><font size="2"   >superuser_reserved_connections = 13 &nbsp; &nbsp; # (change requires restart)</font></div><div><font size="2"   >unix_socket_directories = '.' &nbsp; # comma-separated list of directories</font></div><div><font size="2"   >unix_socket_permissions = 0700 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# begin with 0 to use octal notation</font></div><div><font size="2"   >password_encryption = on</font></div><div><font size="2"   >tcp_keepalives_idle = 60 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# TCP_KEEPIDLE, in seconds;</font></div><div><font size="2"   >tcp_keepalives_interval = 10 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# TCP_KEEPINTVL, in seconds;</font></div><div><font size="2"   >tcp_keepalives_count = 10 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # TCP_KEEPCNT;</font></div><div><font size="2"   >shared_buffers = 2048MB &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # min 128kB</font></div><div><font size="2"   >maintenance_work_mem = 512MB &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# min 1MB</font></div><div><font size="2"   >shared_preload_libraries = 'pg_stat_statements,auto_explain' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# (change requires restart)</font></div><div><font size="2"   >vacuum_cost_delay = 10 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 0-100 milliseconds</font></div><div><font size="2"   >vacuum_cost_limit = 10000 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # 1-10000 credits</font></div><div><font size="2"   >bgwriter_delay = 10ms &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # 10-10000ms between rounds</font></div><div><font size="2"   >wal_level = hot_standby &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # minimal, archive, or hot_standby</font></div><div><font size="2"   >synchronous_commit = off &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# synchronization level;</font></div><div><font size="2"   >wal_buffers = 16384kB &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # min 32kB, -1 sets based on shared_buffers</font></div><div><font size="2"   >wal_writer_delay = 10ms &nbsp; &nbsp; &nbsp; &nbsp; # 1-10000 milliseconds</font></div><div><font size="2"   >checkpoint_segments = 128 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # in logfile segments, min 1, 16MB each</font></div><div><font size="2"   >archive_mode = on &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # allows archiving to be done</font></div><div><font size="2"   >archive_command = '/bin/date' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # command to use to archive a logfile segment</font></div><div><font size="2"   >max_wal_senders = 32 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# max number of walsender processes</font></div><div><font size="2"   >wal_keep_segments = 512 &nbsp; &nbsp; &nbsp; &nbsp; # in logfile segments, 16MB each; 0 disables</font></div><div><font size="2"   >hot_standby = on &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# "on" allows queries during recovery</font></div><div><font size="2"   >max_standby_archive_delay = 300s &nbsp; &nbsp; &nbsp; &nbsp;# max delay before canceling queries</font></div><div><font size="2"   >max_standby_streaming_delay = 300s &nbsp; &nbsp; &nbsp;# max delay before canceling queries</font></div><div><font size="2"   >wal_receiver_status_interval = 1s &nbsp; &nbsp; &nbsp; # send replies at least this often</font></div><div><font size="2"   >hot_standby_feedback = on &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # send info from standby to prevent</font></div><div><font size="2"   >effective_cache_size = 24000MB</font></div><div><font size="2"   >log_destination = 'csvlog' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Valid values are combinations of</font></div><div><font size="2"   >logging_collector = on &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Enable capturing of stderr and csvlog</font></div><div><font size="2"   >log_directory = 'pg_log' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# directory where log files are written,</font></div><div><font size="2"   >log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log' # log file name pattern,</font></div><div><font size="2"   >log_file_mode = 0600 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# creation mode for log files,</font></div><div><font size="2"   >log_truncate_on_rotation = on &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # If on, an existing log file with the</font></div><div><font size="2"   >log_rotation_age = 1d &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Automatic rotation of logfiles will</font></div><div><font size="2"   >log_rotation_size = 10MB &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Automatic rotation of logfiles will</font></div><div><font size="2"   >log_min_duration_statement = 1s # -1 is disabled, 0 logs all statements</font></div><div><font size="2"   >log_checkpoints = on</font></div><div><font size="2"   >log_connections = on</font></div><div><font size="2"   >log_disconnections = on</font></div><div><font size="2"   >log_error_verbosity = verbose &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # terse, default, or verbose messages</font></div><div><font size="2"   >log_lock_waits = on &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # log lock waits &gt;= deadlock_timeout</font></div><div><font size="2"   >log_statement = 'ddl' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # none, ddl, mod, all</font></div><div><font size="2"   >log_timezone = 'PRC'</font></div><div><font size="2"   >track_activity_query_size = 2048 &nbsp; &nbsp; &nbsp; &nbsp;# (change requires restart)</font></div><div><font size="2"   >autovacuum = on &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Enable autovacuum subprocess? &nbsp;'on'</font></div><div><font size="2"   >log_autovacuum_min_duration = 0 # -1 disables, 0 logs all actions and</font></div><div><font size="2"   >datestyle = 'iso, mdy'</font></div><div><font size="2"   >timezone = 'PRC'</font></div><div><font size="2"   >lc_messages = 'C' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # locale for system error message</font></div><div><font size="2"   >lc_monetary = 'C' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # locale for monetary formatting</font></div><div><font size="2"   >lc_numeric = 'C' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# locale for number formatting</font></div><div><font size="2"   >lc_time = 'C' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # locale for time formatting</font></div><div><font size="2"   >default_text_search_config = 'pg_catalog.english'</font></div><div><font size="2"   >pg_stat_statements.max = 1000</font></div><div><font size="2"   >pg_stat_statements.track = all</font></div><div><font size="2"   >pg_stat_statements.save = on</font></div><div><font size="2"   >auto_explain.log_min_duration = 1s</font></div><div><font size="2"   >auto_explain.log_analyze = on</font></div><div><font size="2"   >auto_explain.log_verbose = on</font></div><div><font size="2"   >auto_explain.log_buffers = on</font></div><div><font size="2"   >auto_explain.log_timing = on</font></div><div><font size="2"   >auto_explain.log_nested_statements = on</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >vi pg_hba.conf</font></div><div><font size="2"   >local &nbsp; all &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; all &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; trust</font></div><div><font size="2"   >host &nbsp; &nbsp;all &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; all &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 127.0.0.1/32 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;trust</font></div><div><font size="2"   >host &nbsp; &nbsp;all &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; all &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ::1/128 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; trust</font></div><div><font size="2"   >host all all 0.0.0.0/0 md5</font></div><div><font size="2"   >host replication postgres 0.0.0.0/0 md5</font></div><p></p></pre></div><div><br></div><div>编写启动数据库的脚本, 遵循LSB.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >vi /usr/local/bin/pgctl.sh</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >#!/bin/bash</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ># environment.</font></div><div><font size="2"   ># Get the aliases and functions</font></div><div><font size="2"   >if [ -f ~/.bashrc ]; then</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; . ~/.bashrc</font></div><div><font size="2"   >fi</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ># User specific environment and startup programs</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >export PGHOME=/opt/pgsql</font></div><div><font size="2"   >export PATH=$PGHOME/bin:$PATH</font></div><div><font size="2"   >export PGDATA=/data01/pgdata/pg_root</font></div><div><font size="2"   >export PGPORT=1921</font></div><div><font size="2"   >export LD_LIBRARY_PATH=$PGHOME/lib:/lib64:/usr/lib64:/usr/local/lib64:/lib:/usr/lib:/usr/local/lib</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ><br></font></div><div><font size="2"   >start() {</font></div><div><font size="2"   >su - postgres -c "$PGHOME/bin/pg_ctl start"</font></div><div><font size="2"   >return 0</font></div><div><font size="2"   >}</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >stop() {</font></div><div><font size="2"   >su - postgres -c "$PGHOME/bin/pg_ctl stop -m fast"</font></div><div><font size="2"   >return 0&nbsp;</font></div><div><font size="2"   >}</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >reload() {</font></div><div><font size="2"   >su - postgres -c "$PGHOME/bin/pg_ctl reload"</font></div><div><font size="2"   >return 0</font></div><div><font size="2"   >}</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >status() {</font></div><div><font size="2"   >su - postgres -c "$PGHOME/bin/pg_ctl status"</font></div><div><font size="2"   >return $?</font></div><div><font size="2"   >}</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ># See how we were called.</font></div><div><font size="2"   >case "$1" in</font></div><div><font size="2"   >&nbsp; start)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; start</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; exit $?</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; ;;</font></div><div><font size="2"   >&nbsp; stop)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; stop</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; exit $?</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; ;;</font></div><div><font size="2"   >&nbsp; restart)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; stop</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; start</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; exit $?</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; ;;</font></div><div><font size="2"   >&nbsp; reload)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; reload</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; exit $?</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; ;;</font></div><div><font size="2"   >&nbsp; status)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; status</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; exit $?</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; ;;</font></div><div><font size="2"   >&nbsp; *)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; echo $"Usage: $prog {start|stop|restart|reload|status}"</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; exit 0</font></div><div><font size="2"   >esac</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >chmod 500 /usr/local/bin/pgctl.sh</font></div><p></p></pre></div><div><br></div><div>将脚本添加到/etc/cluster/cluster.conf</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_203 ~]# ccs -f /etc/cluster/cluster.conf --lsresourceopts script</font></div><div><font size="2"   >script - LSB-compliant init script as a clustered resource.</font></div><div><font size="2"   >&nbsp; Required Options:</font></div><div><font size="2"   >&nbsp; &nbsp; name: Name</font></div><div><font size="2"   >&nbsp; &nbsp; file: Path to script</font></div><div><font size="2"   >&nbsp; Optional Options:</font></div><div><font size="2"   >&nbsp; &nbsp; service_name: Inherit the service name.</font></div><div><font size="2"   >&nbsp; &nbsp; __independent_subtree: Treat this and all children as an independent subtree.</font></div><div><font size="2"   >&nbsp; &nbsp; __enforce_timeouts: Consider a timeout for operations as fatal.</font></div><div><font size="2"   >&nbsp; &nbsp; __max_failures: Maximum number of failures before returning a failure to a status check.</font></div><div><font size="2"   >&nbsp; &nbsp; __failure_expire_time: Amount of time before a failure is forgotten.</font></div><div><font size="2"   >&nbsp; &nbsp; __max_restarts: Maximum number restarts for an independent subtree before giving up.</font></div><div><font size="2"   >&nbsp; &nbsp; __restart_expire_time: Amount of time before a failure is forgotten for an independent subtree.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@172_16_13_203 ~]# ccs -f /etc/cluster/cluster.conf --addresource script name=pgctl file=/usr/local/bin/pgctl.sh</font></div><div><font size="2"   >[root@172_16_13_203 ~]# ccs -f /etc/cluster/cluster.conf --addsubservice yumdemo_pg script ref=pgctl</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@172_16_13_203 ~]# ccs -f /etc/cluster/cluster.conf --lsservices</font></div><div><font size="2"   >service: name=yumdemo_pg, domain=yumdemo_fd, autostart=0</font></div><div><font size="2"   >&nbsp; ip: ref=172.16.13.156</font></div><div><font size="2"   >&nbsp; lvm: ref=LVM</font></div><div><font size="2"   >&nbsp; fs: ref=FS</font></div><div><font size="2"   >&nbsp; script: ref=pgctl</font></div><div><font size="2"   >resources:&nbsp;</font></div><div><font size="2"   >&nbsp; ip: monitor_link=1, address=172.16.13.156</font></div><div><font size="2"   >&nbsp; lvm: name=LVM, vg_name=shared_vg, lv_name=lv01</font></div><div><font size="2"   >&nbsp; fs: name=FS, device=/dev/mapper/shared_vg-lv01, mountpoint=/data01, options=lockproto=lock_dlm</font></div><div><font size="2"   >&nbsp; script: name=pgctl, file=/usr/local/bin/pgctl.sh</font></div><p></p></pre></div><div>注意这里的subservice的顺序, 启动数据库前必须先启动FS, 如果顺序不对, 必须调整一下, 直接编辑/etc/cluster/cluster.conf即可. 编辑后记得加版本号和同步, 重启集群.</div><div><br></div><div>同步/etc/cluster/cluster.conf</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_203 ~]# cat /etc/cluster/cluster.conf&nbsp;</font></div><div><font size="2"   >&lt;cluster config_version="32" name="yumdemo"&gt;</font></div><div><font size="2"   >&nbsp; &lt;fence_daemon post_fail_delay="6" post_join_delay="30"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="172.16.13.203" nodeid="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="ILO"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="reboot" name="fence_203"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="172.16.13.204" nodeid="2"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="ILO"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="reboot" name="fence_204"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &lt;/clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &lt;cman expected_votes="1" two_node="1"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ilo" ipaddr="172.16.12.12" login="2010" name="fence_203" passwd="2010"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ilo" ipaddr="172.16.12.13" login="2010" name="fence_204" passwd="2010"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &lt;rm&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;failoverdomains&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;failoverdomain name="yumdemo_fd" nofailback="1" ordered="1" restricted="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;failoverdomainnode name="172.16.13.203" priority="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;failoverdomainnode name="172.16.13.204" priority="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/failoverdomain&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/failoverdomains&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;resources&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;ip address="172.16.13.156" monitor_link="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;lvm lv_name="lv01" name="LVM" vg_name="shared_vg"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fs device="/dev/mapper/shared_vg-lv01" mountpoint="/data01" name="FS" options="lockproto=lock_dlm"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;script file="/usr/local/bin/pgctl.sh" name="pgctl"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/resources&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;service autostart="0" domain="yumdemo_fd" name="yumdemo_pg"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;ip ref="172.16.13.156"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;lvm ref="LVM"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fs ref="FS"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;script ref="pgctl"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/service&gt;</font></div><div><font size="2"   >&nbsp; &lt;/rm&gt;</font></div><div><font size="2"   >&nbsp; &lt;logging/&gt;</font></div><div><font size="2"   >&lt;/cluster&gt;</font></div><p></p></pre></div><div><br></div><div>重启集群的2个节点</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># clusvcadm -d yumdemo_pg</font></div><div><font size="2"   ># service clvmd stop</font></div><div><font size="2"   ># service rgmanager stop</font></div><div><font size="2"   ># service cman stop</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >node A,B :&nbsp;</font></div><div><font size="2"   ># service cman start</font></div><div><font size="2"   >node A,B :&nbsp;</font></div><div><font size="2"   ># service clvmd start</font></div><div><font size="2"   ># service rgmanager start</font></div><p></p></pre></div><div>在任意节点启动集群服务.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >node One :</font></div><div><font size="2"   ># clusvcadm -e yumdemo_pg</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@172_16_13_203 ~]# clustat</font></div><div><font size="2"   >Cluster Status for yumdemo @ Wed May 28 21:51:19 2014</font></div><div><font size="2"   >Member Status: Quorate</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp;Member Name &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ID &nbsp; Status</font></div><div><font size="2"   >&nbsp;------ ---- &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ---- ------</font></div><div><font size="2"   >&nbsp;172.16.13.203 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1 Online, Local, rgmanager</font></div><div><font size="2"   >&nbsp;172.16.13.204 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2 Online, rgmanager</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp;Service Name &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Owner (Last) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; State &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp;------- ---- &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ----- ------ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ----- &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp;service:yumdemo_pg &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 172.16.13.203 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;started &nbsp; &nbsp; &nbsp;&nbsp;</font></div><p></p></pre></div><div>查看服务所在节点的日志, 我们看到LSB模式的脚本status是用来检测服务状态的, 30秒检查一次.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_203 ~]# tail -f -n 1 /var/log/messages&nbsp;</font></div><div><font size="2"   >May 28 21:51:11 172_16_13_203 rgmanager[13987]: Service service:yumdemo_pg started</font></div><div><font size="2"   >May 28 21:51:45 172_16_13_203 rgmanager[15614]: [script] Executing /usr/local/bin/pgctl.sh status</font></div><div><font size="2"   >May 28 21:52:15 172_16_13_203 rgmanager[15985]: [script] Executing /usr/local/bin/pgctl.sh status</font></div><div><font size="2"   >May 28 21:52:45 172_16_13_203 rgmanager[16408]: [script] Executing /usr/local/bin/pgctl.sh status</font></div><p></p></pre></div><div><br></div><div>关闭数据库, 自动恢复, 因为我们脚本中已经定义了status返回异常.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >$ pg_ctl stop -m fast</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >May 28 21:59:45 172_16_13_203 rgmanager[20418]: [script] script:pgctl: status of /usr/local/bin/pgctl.sh failed (returned 3)</font></div><div><font size="2"   >May 28 21:59:45 172_16_13_203 rgmanager[13987]: status on script "pgctl" returned 1 (generic error)</font></div><div><font size="2"   >May 28 21:59:45 172_16_13_203 rgmanager[13987]: Stopping service service:yumdemo_pg</font></div><div><font size="2"   >May 28 21:59:46 172_16_13_203 rgmanager[20459]: [script] Executing /usr/local/bin/pgctl.sh stop</font></div><div><font size="2"   >May 28 21:59:46 172_16_13_203 rgmanager[20541]: [ip] Removing IPv4 address 172.16.13.156/24 from eth0</font></div><div><font size="2"   >May 28 21:59:56 172_16_13_203 rgmanager[20600]: [fs] unmounting /data01</font></div><div><font size="2"   >May 28 21:59:56 172_16_13_203 multipathd: dm-2: remove map (uevent)</font></div><div><font size="2"   >May 28 21:59:56 172_16_13_203 multipathd: dm-2: devmap not registered, can't remove</font></div><div><font size="2"   >May 28 21:59:56 172_16_13_203 multipathd: dm-2: remove map (uevent)</font></div><div><font size="2"   >May 28 21:59:56 172_16_13_203 multipathd: dm-2: devmap not registered, can't remove</font></div><div><font size="2"   >May 28 21:59:56 172_16_13_203 rgmanager[13987]: Service service:yumdemo_pg is recovering</font></div><div><font size="2"   >May 28 21:59:56 172_16_13_203 rgmanager[13987]: Recovering failed service service:yumdemo_pg</font></div><div><font size="2"   >May 28 21:59:57 172_16_13_203 rgmanager[20744]: [fs] mounting /dev/dm-2 on /data01</font></div><div><font size="2"   >May 28 21:59:57 172_16_13_203 kernel: GFS2: fsid=: Trying to join cluster "lock_dlm", "yumdemo:lv01"</font></div><div><font size="2"   >May 28 21:59:57 172_16_13_203 kernel: GFS2: fsid=yumdemo:lv01.0: Joined cluster. Now mounting FS...</font></div><div><font size="2"   >May 28 21:59:57 172_16_13_203 kernel: GFS2: fsid=yumdemo:lv01.0: jid=0, already locked for use</font></div><div><font size="2"   >May 28 21:59:57 172_16_13_203 kernel: GFS2: fsid=yumdemo:lv01.0: jid=0: Looking at journal...</font></div><div><font size="2"   >May 28 21:59:57 172_16_13_203 kernel: GFS2: fsid=yumdemo:lv01.0: jid=0: Done</font></div><div><font size="2"   >May 28 21:59:57 172_16_13_203 kernel: GFS2: fsid=yumdemo:lv01.0: jid=1: Trying to acquire journal lock...</font></div><div><font size="2"   >May 28 21:59:57 172_16_13_203 kernel: GFS2: fsid=yumdemo:lv01.0: jid=1: Looking at journal...</font></div><div><font size="2"   >May 28 21:59:57 172_16_13_203 kernel: GFS2: fsid=yumdemo:lv01.0: jid=1: Done</font></div><div><font size="2"   >May 28 21:59:57 172_16_13_203 rgmanager[20853]: [ip] Adding IPv4 address 172.16.13.156/24 to eth0</font></div><div><font size="2"   >May 28 22:00:01 172_16_13_203 rgmanager[20936]: [script] Executing /usr/local/bin/pgctl.sh start</font></div><div><font size="2"   >May 28 22:00:01 172_16_13_203 rgmanager[13987]: Service service:yumdemo_pg started</font></div><p></p></pre></div><div><br></div><div>断开IP, 自动切换到另一台主机</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_203 ~]# ifdown eth0</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ><br></font></div><div><font size="2"   >May 28 22:03:32 172_16_13_204 corosync[31497]: &nbsp; [TOTEM ] A processor failed, forming new configuration.</font></div><div><font size="2"   >May 28 22:03:34 172_16_13_204 corosync[31497]: &nbsp; [QUORUM] Members[1]: 2</font></div><div><font size="2"   >May 28 22:03:34 172_16_13_204 corosync[31497]: &nbsp; [TOTEM ] A processor joined or left the membership and a new membership was formed.</font></div><div><font size="2"   >May 28 22:03:34 172_16_13_204 corosync[31497]: &nbsp; [CPG &nbsp; ] chosen downlist: sender r(0) ip(172.16.13.204) ; members(old:2 left:1)</font></div><div><font size="2"   >May 28 22:03:34 172_16_13_204 corosync[31497]: &nbsp; [MAIN &nbsp;] Completed service synchronization, ready to provide service.</font></div><div><font size="2"   >May 28 22:03:34 172_16_13_204 rgmanager[31785]: State change: 172.16.13.203 DOWN</font></div><div><font size="2"   >May 28 22:03:35 172_16_13_204 kernel: dlm: closing connection to node 1</font></div><div><font size="2"   >May 28 22:03:40 172_16_13_204 fenced[31552]: fencing node 172.16.13.203</font></div><div><font size="2"   >May 28 22:03:53 172_16_13_204 fenced[31552]: fence 172.16.13.203 success</font></div><div><font size="2"   >May 28 22:03:54 172_16_13_204 rgmanager[31785]: Taking over service service:yumdemo_pg from down member 172.16.13.203</font></div><div><font size="2"   >May 28 22:03:57 172_16_13_204 rgmanager[973]: [fs] mounting /dev/dm-2 on /data01</font></div><div><font size="2"   >May 28 22:03:58 172_16_13_204 kernel: GFS2: fsid=: Trying to join cluster "lock_dlm", "yumdemo:lv01"</font></div><div><font size="2"   >May 28 22:03:58 172_16_13_204 kernel: GFS2: fsid=yumdemo:lv01.0: Joined cluster. Now mounting FS...</font></div><div><font size="2"   >May 28 22:03:58 172_16_13_204 kernel: GFS2: fsid=yumdemo:lv01.0: jid=0, already locked for use</font></div><div><font size="2"   >May 28 22:03:58 172_16_13_204 kernel: GFS2: fsid=yumdemo:lv01.0: jid=0: Looking at journal...</font></div><div><font size="2"   >May 28 22:03:58 172_16_13_204 kernel: GFS2: fsid=yumdemo:lv01.0: jid=0: Done</font></div><div><font size="2"   >May 28 22:03:58 172_16_13_204 kernel: GFS2: fsid=yumdemo:lv01.0: jid=1: Trying to acquire journal lock...</font></div><div><font size="2"   >May 28 22:03:58 172_16_13_204 kernel: GFS2: fsid=yumdemo:lv01.0: jid=1: Looking at journal...</font></div><div><font size="2"   >May 28 22:03:58 172_16_13_204 kernel: GFS2: fsid=yumdemo:lv01.0: jid=1: Done</font></div><div><font size="2"   >May 28 22:03:58 172_16_13_204 rgmanager[1082]: [ip] Adding IPv4 address 172.16.13.156/24 to eth0</font></div><div><font size="2"   >May 28 22:04:01 172_16_13_204 rgmanager[1176]: [script] Executing /usr/local/bin/pgctl.sh start</font></div><div><font size="2"   >May 28 22:04:01 172_16_13_204 rgmanager[31785]: Service service:yumdemo_pg started</font></div><p></p></pre></div><div><br></div><div>[其他]</div><div>1. 个人不建议将lvm , gfs的加载放到HA服务中来启动, 因为很不方便, 包括后面的排错, 如果你想在多个节点同时挂载共享磁盘文件系统的话, 放在HA服务启动就不行, 因为一个服务只能在1个节点启动.</div><div>所以建议lvm和gfs放在启动cman和clvmd后, 手工挂载.&nbsp;</div><div>VIP和pg启动脚本建议放在一起.</div><div>2. 修改资源的检测间隔.</div><div>参考</div><div><a target="_blank" rel="nofollow" href="https://fedorahosted.org/cluster/wiki/ResourceActions"   >https://fedorahosted.org/cluster/wiki/ResourceActions</a></div><div>或/etc/cluster/cluster.conf</div><div>例如把pgctl.sh的资源检测时间改成10秒一次.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   ># vi /etc/cluster/cluster.conf&nbsp;</font></div><div><font size="2"   >&lt;cluster config_version="36" name="yumdemo"&gt;</font></div></div><div><font size="2"   >...</font></div><div><div><font size="2"   >&nbsp; &nbsp; &lt;resources&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;ip address="192.168.173.156" monitor_link="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;lvm lv_name="lv01" name="LVM" vg_name="shared_vg"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fs device="/dev/mapper/shared_vg-lv01" mountpoint="/data01" name="FS" options="lockproto=lock_dlm"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;script file="/usr/local/bin/pgctl.sh" name="pgctl"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;action name="status" interval="10"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/script&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/resources&gt;</font></div></div><div><font size="2"   >...</font></div><p></p></pre></div><div>同步cluster.conf, 重启集群后, 生效.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@192_168_173_204 ~]# tail -f -n 1 /var/log/messages&nbsp;</font></div><div><font size="2"   >May 29 09:00:39 192_168_173_204 rgmanager[32323]: Service service:yumdemo_pg started</font></div><div><font size="2"   >May 29 09:00:55 192_168_173_204 rgmanager[1317]: [script] Executing /usr/local/bin/pgctl.sh status</font></div><div><font size="2"   >May 29 09:01:06 192_168_173_204 rgmanager[1550]: [script] Executing /usr/local/bin/pgctl.sh status</font></div><div><font size="2"   >May 29 09:01:25 192_168_173_204 rgmanager[1755]: [script] Executing /usr/local/bin/pgctl.sh status</font></div><div><font size="2"   >May 29 09:01:35 192_168_173_204 rgmanager[1875]: [script] Executing /usr/local/bin/pgctl.sh status</font></div><div><font size="2"   >May 29 09:01:46 192_168_173_204 rgmanager[2136]: [script] Executing /usr/local/bin/pgctl.sh status</font></div><p></p></pre></div><div><br></div><div>[参考]</div><div>1.&nbsp;<a style="line-height: 28px;" target="_blank" href="http://blog.163.com/digoal@126/blog/static/1638770402014428985260/"   >http://blog.163.com/digoal@126/blog/static/1638770402014428985260/</a></div><div>2.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Cluster_Administration/ap-ha-halvm-CA.html"   >https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Cluster_Administration/ap-ha-halvm-CA.html</a></div><div>3. man mkfs.gfs2</div><div>4. man mount.gfs2</div></div><div>5.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="https://access.redhat.com/site/articles/40051"   >https://access.redhat.com/site/articles/40051</a></div><div>6.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="https://fedorahosted.org/cluster/wiki/ResourceActions"   >https://fedorahosted.org/cluster/wiki/ResourceActions</a></div><div><br></div>
<a rel="nofollow" href="http://info.flagcounter.com/h9V1"   ><img title="PostgreSQL Share-disk HA configure Best Practices with CentOS or RHEL Cluster Suite - 德哥@Digoal - PostgreSQL"   src="http://s03.flagcounter.com/count/h9V1/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_12/viewers_0/labels_0/pageviews_0/flags_0/"   alt="Flag Counter"   border="0"   ></a></div>
	</div>
</div>
</body>
</html>