<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">zfs on CentOS 6.5 x64 compare performance with ext4 use postgresql pgbench</h2>
	<h5 id="">2014-05-16 22:10:14&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/163877040201441694022110/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;"><div>zfs可以认为是raid和文件系统的结合体.</div><div>解决了动态条带和数据与校验位的一致性问题, 所以具有极高的可靠性和性能.</div><div><a target="_blank" rel="nofollow" href="https://pthree.org/2012/12/05/zfs-administration-part-ii-raidz/"   >https://pthree.org/2012/12/05/zfs-administration-part-ii-raidz/</a></div><div>因为zfs需要接管硬盘, 所以在有RAID卡的环境中, 需要设置为 JBOD模式.</div><div><a target="_blank" rel="nofollow" href="http://en.wikipedia.org/wiki/Non-RAID_drive_architectures"   >http://en.wikipedia.org/wiki/Non-RAID_drive_architectures</a></div><div>同时ZFS利用SLOG(Separate Intent Log)设备存储ZIL(ZFS Intent Log)来提升写性能.</div><div>(使用slog后, 即使断电, 也不会导致数据不一致, 只是会导致ZFS中新的数据没有FLUSH到磁盘, 呈现老的状态, 类似PostgreSQL 的async commit.)</div><div><pre class="prettyprint"   ><p><font size="2"   >(It's important to identify that all three devices listed above can maintain data persistence during a power outage. The SLOG and the ZIL are critical in getting your data to spinning platter. If a power outage occurs, and you have a volatile SLOG, the worst thing that will happen is the new data is not flushed, and you are left with old data. However, it's important to note, that in the case of a power outage, you won't have corrupted data, just lost data. Your data will still be consistent on disk.)</font></p></pre></div><div>建议将SLOG放在ssd或者nvram设备中, 提升写性能.</div><div>甚至可以拿slog来做增量文件系统恢复, 有点和PostgreSQL的xlog功能类似呢.</div><div>因为slog的重要性, 一般加slog设备使用mirror.</div><div>例如 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># zpool create tank mirror /tmp/file1 /tmp/file2 mirror /tmp/file3 /tmp/file4 log mirror sde sdf cache sdg sdh</font></div><div><font size="2"   ># zpool status tank</font></div><div><font size="2"   >&nbsp; pool: tank</font></div><div><font size="2"   >&nbsp;state: ONLINE</font></div><div><font size="2"   >&nbsp;scan: none requested</font></div><div><font size="2"   >config:</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >	NAME &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;STATE &nbsp; &nbsp; READ WRITE CKSUM</font></div><div><font size="2"   >	tank &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >	 &nbsp;mirror-0 &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >	 &nbsp; &nbsp;/tmp/file1 &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >	 &nbsp; &nbsp;/tmp/file2 &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >	 &nbsp;mirror-1 &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >	 &nbsp; &nbsp;/tmp/file3 &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >	 &nbsp; &nbsp;/tmp/file4 &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >	logs</font></div><div><font size="2"   >	 &nbsp;mirror-2 &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >	 &nbsp; &nbsp;sde &nbsp; &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >	 &nbsp; &nbsp;sdf &nbsp; &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >	cache</font></div><div><font size="2"   >	 &nbsp;sdg &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >	 &nbsp;sdh &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >errors: No known data errors</font></div><p></p></pre></div><div>另外需要注意: SLOG如果使用SSD来做的话, 因为SSD的使用寿命是和擦写次数相关的, 所以我们可以根据SLOG的写入速度来评估SLOG能用多久.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >SLOG Life Expectancy</font></div><div><font size="2"   >Because you will likely be using a consumer-grade SSD for your SLOG in your GNU/Linux server, we need to make some mention of the wear and tear of SSDs for write-intensive scenarios. Of course, this will largely vary based on manufacturer, but we can setup some generalities.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >First and foremost, ZFS has advanced wear-leveling algorithms that will evenly wear each chip on the SSD. There is no need for TRIM support, which in all reality, is really just a garbage collection support more than anything. The wear-leveling of ZFS in inherent due to the copy-on-write nature of the filesystem.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Second, various drives will be implemented with different nanometer processes. The smaller the nanometer process, the shorter the life of your SSD. As an example, the Intel 320 is a 25 nanometer MLC 300 GB SSD, and is rated at roughly 5000 P/E cycles. This means you can write to your entire SSD 5000 times if using wear leveling algorithms. This produces 1500000 GB of total written data, or 1500 TB. My ZIL maintains about 3 MB of data per second. As a result, I can maintain about 95 TB of written data per year. This gives me a life of about 15 years for this Intel SSD.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >However, the Intel 335 is a 20 nanometer MLC 240 GB SSD, and is rated at roughly 3000 P/E cycles. With wear leveling, this means you can write you entire SSD 3000 times, which produces 720 TB of total written data. This is only 7 years for my 3 MBps ZIL, which is less than 1/2 the life expectancy the Intel 320. Point is, you need to keep an eye on these things when planning out your pool.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Now, if you are using a battery-backed DRAM drive, then wear leveling is not a problem, and the DIMMs will likely last the duration of your server. Same might be said for 10k+ SAS or FC drives.</font></div><p></p></pre></div><div>ZIL的空间一般不需要太大, 作者用了4GB的分区作为SLOG设备.</div><div><br></div><div>ZFS另一个强大之处是CACHE算法, 结合了LRU,LFU, 保留最近使用的和使用最频繁的块在缓存中.</div><div>同时ZFS还支持二级缓存, 可以使用IOPS能力强大的块设备作为二级缓存设备.</div><div><a target="_blank" rel="nofollow" href="https://pthree.org/2012/12/07/zfs-administration-part-iv-the-adjustable-replacement-cache/"   >https://pthree.org/2012/12/07/zfs-administration-part-iv-the-adjustable-replacement-cache/</a></div><div>创建zpool时, 尽量使用设备ID (/dev/disk/by-id/*) , 不要使用别名如sda, 因为别名可能重启后会发生变化.</div><div><br></div><div>以CentOS 6.4 x64为例, 介绍一下zfs的安装.</div><div><span style="line-height: 28px;"   >下载</span></div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ><span style="line-height: 28px;"   >[root@db-172-16-3-150 soft_bak]#</span>&nbsp;wget http://archive.zfsonlinux.org/downloads/zfsonlinux/spl/spl-0.6.2.tar.gz</font></div><div><font size="2"   >[root@db-172-16-3-150 soft_bak]# wget http://archive.zfsonlinux.org/downloads/zfsonlinux/zfs/zfs-0.6.2.tar.gz</font></div><p></p></pre></div><div>安装spl</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 spl-0.6.2]# tar -zxvf spl-0.6.2.tar.gz</font></div><div><font size="2"   >[root@db-172-16-3-150 soft_bak]# cd spl-0.6.2</font></div><div><font size="2"   >[root@db-172-16-3-150 spl-0.6.2]# ./autogen.sh&nbsp;</font></div><div><font size="2"   >[root@db-172-16-3-150 spl-0.6.2]# ./configure --prefix=/opt/spl0.6.2</font></div><div><font size="2"   >[root@db-172-16-3-150 spl-0.6.2]# make &amp;&amp; make install</font></div><p></p></pre></div><div>安装zfs</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@db-172-16-3-150 soft_bak]# cd /opt/soft_bak/</font></div><div><font size="2"   >[root@db-172-16-3-150 soft_bak]# tar -zxvf zfs-0.6.2.tar.gz&nbsp;</font></div></div><div><font size="2"   >[root@db-172-16-3-150 soft_bak]# cd zfs-0.6.2</font></div><div><font size="2"   >[root@db-172-16-3-150 zfs-0.6.2]# yum install -y libuuid-devel</font></div><div><font size="2"   >[root@db-172-16-3-150 zfs-0.6.2]# ./configure --prefix=/opt/zfs0.6.2</font></div><div><font size="2"   >[root@db-172-16-3-150 zfs-0.6.2]# make &amp;&amp; make install</font></div><p></p></pre></div><div><br></div><div>测试所在系统的<span style="line-height: 28px;"   >Solaris的移植性, 使用splat前需要加载splat模块, 否则会报错.</span></div><div><span style="line-height: 28px;"   >如果遇到错误, 使用-vv输出详细信息, 找到错误原因.</span></div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >splat - Solaris Porting LAyer Tests</font></div><div><font size="2"   >[root@db-172-16-3-150 soft_bak]# cd /opt/spl0.6.2/sbin/</font></div><div><div><font size="2"   >[root@db-172-16-3-150 sbin]# ./splat -a</font></div><div><font size="2"   >Unable to open /dev/splatctl: 2</font></div><div><font size="2"   >Is the splat module loaded?</font></div></div><div><span style="line-height: 28px;"   ><font size="2"   >[root@db-172-16-3-150 spl0.6.2]# modprobe splat</font></span></div><div><span style="line-height: 28px;"   ><font size="2"   ><div>[root@db-172-16-3-150 spl0.6.2]# /opt/spl0.6.2/sbin/splat -a</div><div>------------------------------ Running SPLAT Tests ------------------------------</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:kmem_alloc &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:kmem_zalloc &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:vmem_alloc &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:vmem_zalloc &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:slab_small &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:slab_large &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:slab_align &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:slab_reap &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:slab_age &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:slab_lock &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:vmem_size &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:slab_reclaim &nbsp; &nbsp; &nbsp; &nbsp; Fail &nbsp;Timer expired</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:single &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:multiple &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:system &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:wait &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:order &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:front &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:recurse &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:contention &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:delay &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:cancel &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; krng:freq &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mutex:tryenter &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mutex:race &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mutex:owned &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mutex:owner &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;condvar:signal1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;condvar:broadcast1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;condvar:signal2 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;condvar:broadcast2 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;condvar:timeout &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; thread:create &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; thread:exit &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; thread:tsd &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rwlock:N-rd/1-wr &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rwlock:0-rd/N-wr &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rwlock:held &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rwlock:tryenter &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rwlock:rw_downgrade &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rwlock:rw_tryupgrade &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; time:time1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; time:time2 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;vnode:vn_open &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;vnode:vn_openat &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;vnode:vn_rdwr &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;vnode:vn_rename &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;vnode:vn_getattr &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;vnode:vn_sync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kobj:open &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kobj:size/read &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; atomic:64-bit &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list:create/destroy &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list:ins/rm head &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list:ins/rm tail &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list:insert_after &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list:insert_before &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list:remove &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list:active &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;generic:ddi_strtoul &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;generic:ddi_strtol &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;generic:ddi_strtoull &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;generic:ddi_strtoll &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;generic:udivdi3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;generic:divdi3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cred:cred &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cred:kcred &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cred:groupmember &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; zlib:compress/uncompress &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;linux:shrink_dcache &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;linux:shrink_icache &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;linux:shrinker &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass</div></font></span></div><p></p></pre></div><div><br></div><div>接下来创建几个测试文件, 分别作为磁盘, 二级缓存, LOG.</div><div>其中二级缓存使用SSD硬盘分区, LOG使用SSD上的两个文件.</div><div><pre class="prettyprint"   ><p></p><div><span style="line-height: 28px;"   ><font size="2"   >[root@db-172-16-3-150 ~]# cd /ssd4</font></span></div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# dd if=/dev/zero of=./zfs.log1 bs=1k count=1024000</font></div><div><span style="line-height: 28px;"   ><font size="2"   >[root@db-172-16-3-150 ssd4]# dd if=/dev/zero of=./zfs.log2 bs=1k count=1024000</font></span></div><div><font size="2"   >[root@db-172-16-3-150 ~]# cd /opt</font></div><div><font size="2"   >[root@db-172-16-3-150 opt]# dd if=/dev/zero of=./zfs.disk1 bs=1k count=1024000</font></div><div><span style="line-height: 28px;"   ><font size="2"   >[root@db-172-16-3-150 opt]# dd if=/dev/zero of=./zfs.disk2 bs=1k count=1024000</font></span></div><div><span style="line-height: 28px;"   ><font size="2"   >[root@db-172-16-3-150 opt]# dd if=/dev/zero of=./zfs.disk3 bs=1k count=1024000</font></span></div><div><span style="line-height: 28px;"   ><font size="2"   >[root@db-172-16-3-150 opt]# dd if=/dev/zero of=./zfs.disk4 bs=1k count=1024000</font></span></div><p></p></pre></div><div>创建zpool, 测试性能(cache必需使用块设备, 不能直接用文件).</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# ll /dev/disk/by-id/</font></div><div><font size="2"   >total 0</font></div><div><font size="2"   >lrwxrwxrwx 1 root root &nbsp;9 Apr 23 08:59 ata-OCZ-REVODRIVE3_OCZ-886PWVEQ351TAPNH -&gt; ../../sdb</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 Apr 23 08:59 ata-OCZ-REVODRIVE3_OCZ-886PWVEQ351TAPNH-part1 -&gt; ../../sdb1</font></div><div><font size="2"   >lrwxrwxrwx 1 root root &nbsp;9 Apr 23 08:59 ata-OCZ-REVODRIVE3_OCZ-Z2134R0TLQBNE659 -&gt; ../../sda</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 Apr 23 08:59 ata-OCZ-REVODRIVE3_OCZ-Z2134R0TLQBNE659-part1 -&gt; ../../sda1</font></div><div><font size="2"   >lrwxrwxrwx 1 root root &nbsp;9 Apr 23 08:59 scsi-360026b902fe2ce001261fa4506592f80 -&gt; ../../sdc</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 Apr 23 08:59 scsi-360026b902fe2ce001261fa4506592f80-part1 -&gt; ../../sdc1</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 Apr 23 08:59 scsi-360026b902fe2ce001261fa4506592f80-part2 -&gt; ../../sdc2</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 Apr 23 08:59 scsi-360026b902fe2ce001261fa4506592f80-part3 -&gt; ../../sdc3</font></div><div><font size="2"   >lrwxrwxrwx 1 root root &nbsp;9 Apr 23 08:59 scsi-360026b902fe2ce0018993f2f0c5734b3 -&gt; ../../sdd</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 Apr 23 08:59 scsi-360026b902fe2ce0018993f2f0c5734b3-part1 -&gt; ../../sdd1</font></div><div><font size="2"   >lrwxrwxrwx 1 root root &nbsp;9 Apr 23 08:59 scsi-SATA_OCZ-REVODRIVE3_OCZ-886PWVEQ351TAPNH -&gt; ../../sdb</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 Apr 23 08:59 scsi-SATA_OCZ-REVODRIVE3_OCZ-886PWVEQ351TAPNH-part1 -&gt; ../../sdb1</font></div><div><font size="2"   >lrwxrwxrwx 1 root root &nbsp;9 Apr 23 08:59 scsi-SATA_OCZ-REVODRIVE3_OCZ-Z2134R0TLQBNE659 -&gt; ../../sda</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 Apr 23 08:59 scsi-SATA_OCZ-REVODRIVE3_OCZ-Z2134R0TLQBNE659-part1 -&gt; ../../sda1</font></div><div><font size="2"   >lrwxrwxrwx 1 root root &nbsp;9 Apr 23 08:59 wwn-0x5e83a97e5dbf17f7 -&gt; ../../sdb</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 Apr 23 08:59 wwn-0x5e83a97e5dbf17f7-part1 -&gt; ../../sdb1</font></div><div><font size="2"   >lrwxrwxrwx 1 root root &nbsp;9 Apr 23 08:59 wwn-0x5e83a97e827c316e -&gt; ../../sda</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 Apr 23 08:59 wwn-0x5e83a97e827c316e-part1 -&gt; ../../sda1</font></div><div><font size="2"   >lrwxrwxrwx 1 root root &nbsp;9 Apr 23 08:59 wwn-0x60026b902fe2ce001261fa4506592f80 -&gt; ../../sdc</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 Apr 23 08:59 wwn-0x60026b902fe2ce001261fa4506592f80-part1 -&gt; ../../sdc1</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 Apr 23 08:59 wwn-0x60026b902fe2ce001261fa4506592f80-part2 -&gt; ../../sdc2</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 Apr 23 08:59 wwn-0x60026b902fe2ce001261fa4506592f80-part3 -&gt; ../../sdc3</font></div><div><font size="2"   >lrwxrwxrwx 1 root root &nbsp;9 Apr 23 08:59 wwn-0x60026b902fe2ce0018993f2f0c5734b3 -&gt; ../../sdd</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 Apr 23 08:59 wwn-0x60026b902fe2ce0018993f2f0c5734b3-part1 -&gt; ../../sdd1</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# /opt/zfs0.6.2/sbin/zpool create zptest /opt/zfs.disk1 /opt/zfs.disk2 /opt/zfs.disk3 /opt/zfs.disk4 log mirror /ssd4/zfs.log1 /ssd4/zfs.log2 cache /dev/disk/by-id/scsi-SATA_OCZ-REVODRIVE3_OCZ-Z2134R0TLQBNE659-part1</font></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# /opt/zfs0.6.2/sbin/zpool status zptest</font></div><div><font size="2"   >&nbsp; pool: zptest</font></div><div><font size="2"   >&nbsp;state: ONLINE</font></div><div><font size="2"   >&nbsp; scan: none requested</font></div><div><font size="2"   >config:</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; NAME &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;STATE &nbsp; &nbsp; READ WRITE CKSUM</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; zptest &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /opt/zfs.disk1 &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /opt/zfs.disk2 &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /opt/zfs.disk3 &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /opt/zfs.disk4 &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; logs</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mirror-4 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /ssd4/zfs.log1 &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /ssd4/zfs.log2 &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; cache</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sda1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >errors: No known data errors</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/sdc1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;29G &nbsp;9.3G &nbsp; 19G &nbsp;34% /</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;48G &nbsp; &nbsp; 0 &nbsp; 48G &nbsp; 0% /dev/shm</font></div><div><font size="2"   >/dev/sdc3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;98G &nbsp; 34G &nbsp; 59G &nbsp;37% /opt</font></div><div><font size="2"   >/dev/sdd1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 183G &nbsp; 33G &nbsp;142G &nbsp;19% /ssd1</font></div><div><font size="2"   >/dev/sdb1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 221G &nbsp; 42G &nbsp;168G &nbsp;20% /ssd4</font></div><div><font size="2"   >zptest &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3.9G &nbsp; &nbsp; 0 &nbsp;3.9G &nbsp; 0% /zptest</font></div></div><p></p></pre></div><div>重启后需要使用zfs来mount.</div><div># /opt/zfs0.6.2/sbin/zfs mount zptest</div><div><br></div><div>使用pg_test_fsync测试fsync接口的性能 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 ssd4]# cd /zptest</font></div><div><font size="2"   >[root@db-172-16-3-150 zptest]# mkdir pg93</font></div><div><font size="2"   >[root@db-172-16-3-150 zptest]# chown pg93:pg93 pg93</font></div><div><font size="2"   >[root@db-172-16-3-150 zptest]# su - pg93</font></div><div><font size="2"   >cpg93@db-172-16-3-150-&gt; cd /zptest/pg93/</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pg_test_fsync&nbsp;</font></div><div><font size="2"   >5 seconds per test</font></div><div><font size="2"   >O_DIRECT supported on this platform for open_datasync and open_sync.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare file sync methods using one 64kB write:</font></div><div><font size="2"   >(in wal_sync_method preference order, except fdatasync</font></div><div><font size="2"   >is Linux's default)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_datasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a*</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fdatasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 778.117 ops/sec &nbsp; &nbsp;1285 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 756.724 ops/sec &nbsp; &nbsp;1321 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync_writethrough &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_sync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a*</font></div><div><font size="2"   >* This file system and its mount options do not support direct</font></div><div><font size="2"   >I/O, e.g. ext4 in journaled mode.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare file sync methods using two 64kB writes:</font></div><div><font size="2"   >(in wal_sync_method preference order, except fdatasync</font></div><div><font size="2"   >is Linux's default)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_datasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a*</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fdatasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;96.185 ops/sec &nbsp; 10397 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 369.918 ops/sec &nbsp; &nbsp;2703 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync_writethrough &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_sync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a*</font></div><div><font size="2"   >* This file system and its mount options do not support direct</font></div><div><font size="2"   >I/O, e.g. ext4 in journaled mode.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare open_sync with different write sizes:</font></div><div><font size="2"   >(This is designed to compare the cost of writing 16kB</font></div><div><font size="2"   >in different write open_sync sizes.)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1 * 16kB open_sync write &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a*</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2 * &nbsp;8kB open_sync writes &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; n/a*</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4 * &nbsp;4kB open_sync writes &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; n/a*</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;8 * &nbsp;2kB open_sync writes &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; n/a*</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; 16 * &nbsp;1kB open_sync writes &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; n/a*</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Test if fsync on non-write file descriptor is honored:</font></div><div><font size="2"   >(If the times are similar, fsync() can sync data written</font></div><div><font size="2"   >on a different descriptor.)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write, fsync, close &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 746.761 ops/sec &nbsp; &nbsp;1339 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write, close, fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 217.356 ops/sec &nbsp; &nbsp;4601 usecs/op</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Non-Sync'ed 64kB writes:</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 37511.610 ops/sec &nbsp; &nbsp; &nbsp;27 usecs/op</font></div><p></p></pre></div><div><span style="line-height: 28px;"   >测试过程中, 使用iostat发现, 大量的写实际上集中在zptest的LOG设备上. 符合zfs的log的原理.</span></div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >avg-cpu: &nbsp;%user &nbsp; %nice %system %iowait &nbsp;%steal &nbsp; %idle</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp;4.05 &nbsp; &nbsp;7.59 &nbsp; &nbsp;0.00 &nbsp; 88.35</font></div><div><font size="2"   >Device: &nbsp; &nbsp; &nbsp; &nbsp; rrqm/s &nbsp; wrqm/s &nbsp; &nbsp; r/s &nbsp; &nbsp; w/s &nbsp; rsec/s &nbsp; wsec/s avgrq-sz avgqu-sz &nbsp; await &nbsp;svctm &nbsp;%util</font></div><div><font size="2"   >sdc &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 &nbsp; 0.00 &nbsp; 0.00</font></div><div><font size="2"   >sdd &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 &nbsp; 0.00 &nbsp; 0.00</font></div><div><font size="2"   >sdb &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 26688.00 &nbsp; &nbsp;0.00 2502.00 &nbsp; &nbsp; 0.00 226848.00 &nbsp; &nbsp;90.67 &nbsp; &nbsp; 1.29 &nbsp; &nbsp;0.52 &nbsp; 0.31 &nbsp;78.10</font></div><div><font size="2"   >sda &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 &nbsp; 0.00 &nbsp; 0.00</font></div><p></p></pre></div><div><br></div><div>使用postgresql测试读写, 并使用同步提交, 减少shared buffer更能体现ZFS的性能.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >pg93@db-172-16-3-150-&gt; initdb -E UTF8 --locale=C -D /zptest/pg93/pg_root -U postgres -W</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; cd /zptest/pg93/pg_root</font></div><div><font size="2"   >vi postgresql.conf</font></div><div><div><font size="2"   >listen_addresses = '0.0.0.0' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# what IP address(es) to listen on;</font></div><div><font size="2"   >port = 1922 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # (change requires restart)</font></div><div><font size="2"   >max_connections = 100 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # (change requires restart)</font></div><div><font size="2"   >unix_socket_directories = '.' &nbsp; # comma-separated list of directories</font></div><div><font size="2"   >tcp_keepalives_idle = 60 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# TCP_KEEPIDLE, in seconds;</font></div><div><font size="2"   >tcp_keepalives_interval = 10 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# TCP_KEEPINTVL, in seconds;</font></div><div><font size="2"   >tcp_keepalives_count = 10 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # TCP_KEEPCNT;</font></div><div><font size="2"   >shared_buffers = 32MB &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # min 128kB</font></div><div><font size="2"   >maintenance_work_mem = 512MB &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# min 1MB</font></div><div><font size="2"   >vacuum_cost_delay = 10 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 0-100 milliseconds</font></div><div><font size="2"   >vacuum_cost_limit = 10000 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # 1-10000 credits</font></div><div><font size="2"   >bgwriter_delay = 10ms &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # 10-10000ms between rounds</font></div><div><font size="2"   >checkpoint_segments = 3 &nbsp; &nbsp; &nbsp; &nbsp; # in logfile segments, min 1, 16MB each</font></div><div><font size="2"   >effective_cache_size = 96000MB</font></div><div><font size="2"   >log_destination = 'csvlog' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Valid values are combinations of</font></div><div><font size="2"   >logging_collector = on &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Enable capturing of stderr and csvlog</font></div><div><font size="2"   >log_truncate_on_rotation = off &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# If on, an existing log file with the</font></div><div><font size="2"   >log_checkpoints = on</font></div><div><font size="2"   >log_connections = on</font></div><div><font size="2"   >log_disconnections = on</font></div><div><font size="2"   >log_error_verbosity = verbose &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # terse, default, or verbose messages</font></div><div><font size="2"   >log_timezone = 'PRC'</font></div><div><font size="2"   >autovacuum = on &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Enable autovacuum subprocess? &nbsp;'on'</font></div><div><font size="2"   >log_autovacuum_min_duration = 0 # -1 disables, 0 logs all actions and</font></div><div><font size="2"   >datestyle = 'iso, mdy'</font></div><div><font size="2"   >timezone = 'PRC'</font></div><div><font size="2"   >lc_messages = 'C' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # locale for system error message</font></div><div><font size="2"   >lc_monetary = 'C' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # locale for monetary formatting</font></div><div><font size="2"   >lc_numeric = 'C' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# locale for number formatting</font></div><div><font size="2"   >lc_time = 'C' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # locale for time formatting</font></div><div><font size="2"   >default_text_search_config = 'pg_catalog.english'</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pg_ctl start -D /zptest/pg93/pg_root</font></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; psql -h /zptest/pg93/pg_root -p 1922 -U postgres postgres</font></div><div><font size="2"   >psql (9.3.3)</font></div><div><font size="2"   >Type "help" for help.</font></div><div><font size="2"   >postgres=# create table test(id int primary key, info text, crt_time timestamp);</font></div><div><font size="2"   >CREATE TABLE</font></div></div><div><div><font size="2"   >postgres=# create or replace function f_test(v_id int) returns void as $$</font></div><div><font size="2"   >declare</font></div><div><font size="2"   >begin</font></div><div><font size="2"   >&nbsp; update test set info=md5(random()::text),crt_time=now() where id=v_id;</font></div><div><font size="2"   >&nbsp; if not found then&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; insert into test values (v_id, md5(random()::text), now());</font></div><div><font size="2"   >&nbsp; end if;</font></div><div><font size="2"   >&nbsp; exception when SQLSTATE '23505' then</font></div><div><font size="2"   >&nbsp; &nbsp; return;</font></div><div><font size="2"   >end;</font></div><div><font size="2"   >$$ language plpgsql strict;</font></div><div><font size="2"   >CREATE FUNCTION</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >postgres=# select f_test(1);</font></div><div><font size="2"   >&nbsp;f_test&nbsp;</font></div><div><font size="2"   >--------</font></div><div><font size="2"   >&nbsp;</font></div><div><font size="2"   >(1 row)</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >postgres=# select * from test;</font></div><div><font size="2"   >&nbsp;id | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; info &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;crt_time &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</font></div><div><font size="2"   >----+----------------------------------+----------------------------</font></div><div><font size="2"   >&nbsp; 1 | 80fe8163f44df605621a557624740681 | 2014-05-16 22:01:38.677335</font></div><div><font size="2"   >(1 row)</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >postgres=# select f_test(1);</font></div><div><font size="2"   >&nbsp;f_test&nbsp;</font></div><div><font size="2"   >--------</font></div><div><font size="2"   >&nbsp;</font></div><div><font size="2"   >(1 row)</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >postgres=# select * from test;</font></div><div><font size="2"   >&nbsp;id | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; info &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;crt_time &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</font></div><div><font size="2"   >----+----------------------------------+----------------------------</font></div><div><font size="2"   >&nbsp; 1 | 5b17eb0ba878e15f40f213716c05a3c5 | 2014-05-16 22:01:42.130284</font></div><div><font size="2"   >(1 row)</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; vi test.sql</font></div><div><font size="2"   >\setrandom id 1 500000</font></div><div><font size="2"   >select f_test(:id);</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pgbench -M prepared -n -r -f ./test.sql -h /zptest/pg93/pg_root -p 1922 -U postgres -c 16 -j 8 -T 30 postgres&nbsp;</font></div><div><font size="2"   >transaction type: Custom query</font></div><div><font size="2"   >scaling factor: 1</font></div><div><font size="2"   >query mode: prepared</font></div><div><font size="2"   >number of clients: 16</font></div><div><font size="2"   >number of threads: 8</font></div><div><font size="2"   >duration: 30 s</font></div><div><font size="2"   >number of transactions actually processed: 121879</font></div><div><font size="2"   >tps = 4060.366837 (including connections establishing)</font></div><div><font size="2"   >tps = 4062.166607 (excluding connections establishing)</font></div><div><font size="2"   >statement latencies in milliseconds:</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; 0.004635 &nbsp; &nbsp; &nbsp; &nbsp;\setrandom id 1 500000</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; 3.930118 &nbsp; &nbsp; &nbsp; &nbsp;select f_test(:id);</font></div></div><p></p></pre></div><div><br></div><div>接下来是直接对ZFS4个文件所在机械硬盘做测试, 测试EXT4的性能.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >/dev/sdc3 on /opt type ext4 (rw,noatime,nodiratime)</font></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pg_ctl stop -m fast -D /zptest/pg93/pg_root</font></div><div><font size="2"   >waiting for server to shut down.... done</font></div><div><font size="2"   >server stopped</font></div></div><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; exit</font></div><div><font size="2"   >logout</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# cp -r /zptest/pg93/pg_root /opt/pg_root</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# chown -R pg93:pg93 /opt/pg_root</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# su - pg93</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pg_ctl start -D /opt/pg_root</font></div><div><font size="2"   >server starting</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; LOG: &nbsp;00000: redirecting log output to logging collector process</font></div><div><font size="2"   >HINT: &nbsp;Future log output will appear in directory "pg_log".</font></div><div><font size="2"   >LOCATION: &nbsp;SysLogger_Start, syslogger.c:649</font></div></div><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; psql -h 127.0.0.1 -p 1922 -U postgres postgres</font></div><div><font size="2"   >psql (9.3.3)</font></div><div><font size="2"   >Type "help" for help.</font></div><div><font size="2"   >postgres=# truncate test;</font></div><div><font size="2"   >TRUNCATE TABLE</font></div><div><font size="2"   >postgres=# \q</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; cd</font></div><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pgbench -M prepared -n -r -f ./test.sql -h /opt/pg_root -p 1922 -U postgres -c 16 -j 8 -T 30 postgres</font></div><div><font size="2"   >transaction type: Custom query</font></div><div><font size="2"   >scaling factor: 1</font></div><div><font size="2"   >query mode: prepared</font></div><div><font size="2"   >number of clients: 16</font></div><div><font size="2"   >number of threads: 8</font></div><div><font size="2"   >duration: 30 s</font></div><div><font size="2"   >number of transactions actually processed: 39062</font></div><div><font size="2"   >tps = 1301.492448 (including connections establishing)</font></div><div><font size="2"   >tps = 1302.085710 (excluding connections establishing)</font></div><div><font size="2"   >statement latencies in milliseconds:</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; 0.004463 &nbsp; &nbsp; &nbsp; &nbsp;\setrandom id 1 500000</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; 12.278317 &nbsp; &nbsp; &nbsp; select f_test(:id);</font></div></div><p></p></pre></div><div>显然, ZFS在使用了LOG和二级缓存的情况下性能完胜.</div><div><br></div><div>最后, 直接使用SSD, 对比一下性能, 因为本例LOG是使用两个文件来代替块设备的, 而不是文件系统, 所以和直接在SSD上的EXT4有性能差距 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pg_ctl stop -m fast -D /opt/pg_root</font></div><div><font size="2"   >waiting for server to shut down.... done</font></div><div><font size="2"   >server stopped</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; exit</font></div><div><font size="2"   >logout</font></div><div><font size="2"   >You have new mail in /var/spool/mail/root</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# cp -r /zptest/pg93/pg_root /ssd4/</font></div><div><font size="2"   >database/ &nbsp; pg92/ &nbsp; &nbsp; &nbsp; pg931/ &nbsp; &nbsp; &nbsp;pgxl/ &nbsp; &nbsp; &nbsp; test.pl &nbsp; &nbsp; zfs.log2 &nbsp; &nbsp;</font></div><div><font size="2"   >lost+found/ pg93/ &nbsp; &nbsp; &nbsp; pg94/ &nbsp; &nbsp; &nbsp; ssd3/ &nbsp; &nbsp; &nbsp; zfs.log1 &nbsp; &nbsp;</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# cp -r /zptest/pg93/pg_root /ssd4/pg_root</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# chown -R pg93:pg93 /ssd4/pg_root</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# su - pg93</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pg_ctl start -D /ssd4/pg_root</font></div><div><font size="2"   >server starting</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; LOG: &nbsp;00000: redirecting log output to logging collector process</font></div><div><font size="2"   >HINT: &nbsp;Future log output will appear in directory "pg_log".</font></div><div><font size="2"   >LOCATION: &nbsp;SysLogger_Start, syslogger.c:649</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; psql -h 127.0.0.1 -p 1922 -U postgres postgres</font></div><div><font size="2"   >psql (9.3.3)</font></div><div><font size="2"   >Type "help" for help.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >postgres=# truncate test;</font></div><div><font size="2"   >TRUNCATE TABLE</font></div><div><font size="2"   >postgres=# \q</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pgbench -M prepared -n -r -f ./test.sql -h /ssd4/pg_root -p 1922 -U postgres -c 16 -j 8 -T 30 postgres</font></div><div><font size="2"   >transaction type: Custom query</font></div><div><font size="2"   >scaling factor: 1</font></div><div><font size="2"   >query mode: prepared</font></div><div><font size="2"   >number of clients: 16</font></div><div><font size="2"   >number of threads: 8</font></div><div><font size="2"   >duration: 30 s</font></div><div><font size="2"   >number of transactions actually processed: 266565</font></div><div><font size="2"   >tps = 8876.805761 (including connections establishing)</font></div><div><font size="2"   >tps = 8881.884999 (excluding connections establishing)</font></div><div><font size="2"   >statement latencies in milliseconds:</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; 0.003877 &nbsp; &nbsp; &nbsp; &nbsp;\setrandom id 1 500000</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; 1.793971 &nbsp; &nbsp; &nbsp; &nbsp;select f_test(:id);</font></div></div><p></p></pre></div><div><br></div><div>接下来把EXT4放到文件中对比.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@db-172-16-3-150 ~]# cd /ssd4</font></div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# dd if=/dev/zero of=./test.img bs=1024k count=1024</font></div></div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# mkfs.ext4 ./test.img&nbsp;</font></div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# mount -o loop ./test.img /mnt</font></div><div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# su - pg93</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pg_ctl stop -m fast -D /ssd4/pg_root</font></div><div><font size="2"   >waiting for server to shut down.... done</font></div><div><font size="2"   >server stopped</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; exit</font></div><div><font size="2"   >logout</font></div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# cp -r /ssd4/pg_root /mnt/</font></div></div><div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# chown -R pg93:pg93 /mnt/pg_root</font></div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# su - pg93</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pg_ctl start -D /mnt/pg_root</font></div><div><font size="2"   >server starting</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; LOG: &nbsp;00000: redirecting log output to logging collector process</font></div><div><font size="2"   >HINT: &nbsp;Future log output will appear in directory "pg_log".</font></div><div><font size="2"   >LOCATION: &nbsp;SysLogger_Start, syslogger.c:649</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; psql -h 127.0.0.1 -p 1922 -U postgres postgres</font></div><div><font size="2"   >psql (9.3.3)</font></div><div><font size="2"   >Type "help" for help.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >postgres=# truncate test;</font></div><div><font size="2"   >TRUNCATE TABLE</font></div><div><font size="2"   >postgres=# \q</font></div></div><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pgbench -M prepared -n -r -f ./test.sql -h /mnt/pg_root -p 1922 -U postgres -c 16 -j 8 -T 30 postgres</font></div><div><font size="2"   >transaction type: Custom query</font></div><div><font size="2"   >scaling factor: 1</font></div><div><font size="2"   >query mode: prepared</font></div><div><font size="2"   >number of clients: 16</font></div><div><font size="2"   >number of threads: 8</font></div><div><font size="2"   >duration: 30 s</font></div><div><font size="2"   >number of transactions actually processed: 192445</font></div><div><font size="2"   >tps = 6410.026454 (including connections establishing)</font></div><div><font size="2"   >tps = 6412.254485 (excluding connections establishing)</font></div><div><font size="2"   >statement latencies in milliseconds:</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; 0.004118 &nbsp; &nbsp; &nbsp; &nbsp;\setrandom id 1 500000</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; 2.486914 &nbsp; &nbsp; &nbsp; &nbsp;select f_test(:id);</font></div></div><p></p></pre></div><div><br></div>[参考]<wbr><div>1.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="http://zfsonlinux.org/docs.html"   >http://zfsonlinux.org/docs.html</a></div><div>2.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="http://zfsonlinux.org/"   >http://zfsonlinux.org/</a></div><div>3.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="https://pthree.org/2012/12/05/zfs-administration-part-ii-raidz/"   >https://pthree.org/2012/12/05/zfs-administration-part-ii-raidz/</a></div>4.&nbsp;<a target="_blank" rel="nofollow" href="http://en.wikipedia.org/wiki/Non-RAID_drive_architectures"   >http://en.wikipedia.org/wiki/Non-RAID_drive_architectures</a><br><div>5.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="https://github.com/zfsonlinux"   >https://github.com/zfsonlinux</a></div><div>6.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="http://open-zfs.org/wiki/Main_Page"   >http://open-zfs.org/wiki/Main_Page</a></div><div>7.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="http://rudd-o.com/linux-and-free-software/ways-in-which-zfs-is-better-than-btrfs"   >http://rudd-o.com/linux-and-free-software/ways-in-which-zfs-is-better-than-btrfs</a></div><div>8.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="https://java.net/projects/solaris-zfs/pages/Home"   >https://java.net/projects/solaris-zfs/pages/Home</a></div><div>9.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="http://www.oracle.com/technetwork/server-storage/solaris11/documentation/index.html"   >http://www.oracle.com/technetwork/server-storage/solaris11/documentation/index.html</a></div><div><a style="line-height: 28px;" target="_blank" rel="nofollow" href="http://open-zfs.org/wiki/Main_Page"   ><br></a><span style="line-height: 28px;"   >
</span><a style="line-height: 28px;" rel="nofollow" href="http://info.flagcounter.com/h9V1"   ><img title="zfs on CentOS 6.5 x64 compare performance with ext4 use postgresql pgbench - 德哥@Digoal - PostgreSQL"   src="http://s03.flagcounter.com/count/h9V1/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_12/viewers_0/labels_0/pageviews_0/flags_0/"   alt="Flag Counter"   border="0"   ></a></div></div>
	</div>
</div>
</body>
</html>