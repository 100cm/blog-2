PostgreSQL research

Realtime update in redis merge to PostgreSQL case

2013-06-20 16:33:56   查看原文>>

PostgreSQL 的update操作实际上是修改了老记录的xmax信息以及新增一条更新后的记录, 以此来提供并发控制. 
因此在更新完成后, 老的记录需要vacuum进程来进行回收.
另外, 更新还可能带来新行写新块, 此时还会带来索引的变更. 所以在PostgreSQL中update的开销比insert大很多.
一位朋友想把redis中的实时更新在PostgreSQL中也保留一份实时的状态, 但是又担心更新太多.
redis中存储了key, value的最新状态.
因此想了一个办法如下,
在PostgreSQL中把实时的更新改掉, 由实时的插入来替代实时的更新, 所以插入的数据key值会有重复的现象, 同时定期对插入的数据进行合并. 
数据合并时将key对应的最新状态更新到总状态表中.

过程如下 : 
总状态表 : 

digoal=# create table tp_cache_info(key int8, value text, stamp timestamp without time zone default now());
CREATE TABLE


提供插入的临时表1 : 

digoal=# create table tmp_cache_info_1(like tp_cache_info including all);
CREATE TABLE


提供插入的临时表2 : 

digoal=# create table tmp_cache_info_2(like tp_cache_info including all);
CREATE TABLE


记录合并状态信息的表 : 

digoal=# create table tp_cache_manage(tablename name primary key, key int8);
CREATE TABLE



合并数据的函数, 如果当前正在插入tmp_cache_info_2, 那么此时可以合并tmp_cache_info_1的数据.

create or replace function merge_tp(i_tablename name, i_batch smallint, i_advisory_key int8) returns void as
$$
declare
  v_key int8;
  v_key_loop int8;
  v_value_loop text;
  v_key_init int8 := 0;
begin
  if pg_try_advisory_lock(i_advisory_key) then
    select key into v_key from tp_cache_manage where tablename=i_tablename;
    if found then 
      for v_key_loop,v_value_loop in execute format('select key,value from (select key,value,row_number() over (partition by key order by stamp desc) AS rn from %I) t where key>$1 and rn=1 order by key limit $2', i_tablename) USING v_key,i_batch loop
            update tp_cache_info set value=v_value_loop where key=v_key_loop;
        if not found then
          insert into tp_cache_info values (v_key_loop,v_value_loop);
        end if;
      end loop;
      if v_key_loop is null then
        raise notice '所有数据已合并完, 清除数据';
        delete from tp_cache_manage where tablename=i_tablename;
        execute 'truncate table '||i_tablename;
        return;
      else
        update tp_cache_manage set key=v_key_loop where tablename=i_tablename;
      end if;
    else
      insert into tp_cache_manage (tablename, key) values (i_tablename, v_key_init);
      raise notice '初始化';
      return;
    end if;
  else
    raise notice '禁止并行调用.';
  end if;
  return;
end;
$$ language plpgsql;


# 插入测试数据

digoal=# insert into tp_cache_info select generate_series(1,1000),'test';
INSERT 0 1000
digoal=# insert into tmp_cache_info_1 select generate_series(100,2000),'new';
INSERT 0 1901
digoal=# insert into tmp_cache_info_1 select generate_series(800,3000),'new1';
INSERT 0 2201


# 合并

digoal=# select * from merge_tp('tmp_cache_info_1', 10::int2, 10);
NOTICE:  初始化
 merge_tp 
----------
 
(1 row)


查看合并信息表 : 

digoal=# select * from tp_cache_manage ;
    tablename     | key 
------------------+-----
 tmp_cache_info_1 |   0
(1 row)


# 合并

digoal=# select * from merge_tp('tmp_cache_info_1', 10::int2, 10);
 merge_tp 
----------
 
(1 row)


查看合并信息表 : 

digoal=# select * from tp_cache_manage ;
    tablename     | key 
------------------+-----
 tmp_cache_info_1 | 109
(1 row)


# 合并

digoal=# select * from merge_tp('tmp_cache_info_1', 100::int2, 10);
 merge_tp 
----------
 
(1 row)


查看合并信息表 : 

digoal=# select * from tp_cache_manage ;
    tablename     | key 
------------------+-----
 tmp_cache_info_1 | 209
(1 row)


# 合并

digoal=# select * from merge_tp('tmp_cache_info_1', 10000::int2, 10);
 merge_tp 
----------
 
(1 row)


# 合并, 所有数据已取完.

digoal=# select * from merge_tp('tmp_cache_info_1', 10000::int2, 10);
NOTICE:  所有数据已合并完, 清除数据
 merge_tp 
----------
 
(1 row)


查看合并后的数据 : 

digoal=# select value,count(*) from tp_cache_info group by value;
 value | count 
-------+-------
 test  |    99
 new1  |  2201
 new   |   700
(3 rows)



[小结]
1. 为什么要分批合并呢, 一次性搞定不就好了吗?
前面已经提到了, update是会造成表的膨胀的, 如果一次update很多记录的话, 那么膨胀系数就很大了, 因为在update的时候无法回收垃圾.
所以分批做的话, 数据库的autovacuum进程可以有效的回收tp_cache_info表的垃圾, 不会导致tp_cache_info表膨胀过大的现象.
Flag Counter
