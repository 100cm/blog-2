PostgreSQL research

thinking PostgreSQL in lottery seller proxy

2014-09-09 17:24:46   查看原文>>

和做彩票代理的朋友聊了一些程序相关的东西.
大概对彩票销售有一些片面的了解, 
用户下单购买后, 实际上并没有真正的从彩票中心购买, 只是在代理这里记录了购买记录.
代理公司会在后台异步的向彩票中心提交购买请求.
所以对代理来说, 用户购买彩票时, 数据到达自己的数据库是同步的, 其他大多数操作都是异步的.

对数据库层面来说, 可能涉及的一些比较粗重的操作有 : 
1. 用户资金的变更(更新).
2. 彩票发售期内的操作, 用户购买流水(插入), (更新和查询)流水记录的状态变更(因为是代理销售, 所以用户下单后, 不是立即就购买成功的, 后台还需要代理用户的请求, 到彩票中心购买, 所以流水记录在整个彩票生命周期内会有多个状态, 因此一条流水记录会涉及到多次更新.)
    流水记录的状态变更可能是异步分批的批量操作, 只要在生命周期内完成即可(即开奖前, 代用户到彩票中心购买成功即可).
3. 流水记录, 彩票开奖后, 其实只要保留一段时间, 就可以清除了.
4. 需要注意彩票的生命周期, 即发布到开奖, 有些彩票可能几分钟就一期.
了解以上情况后, 我们大概知道了数据的热点在哪里, 数据库的SQL大概会集中在哪些地方.
热点数据 : 
1. 用户账户数据, 因为会不断的更新用户的余额, 所以更新很多.
2. 彩票的流水数据, 插入, 查询, 更新都比较多, 基本上一次插入, 会有多次查询, 多次更新.
3. 彩票的流水数据, 历史数据需要定期的删除.
优化手段 : 
因为PostgreSQL的MVCC机制, 当更新数据时, 会产生新的版本, 所以我们尽量的将需要频繁更新的数据行变小比较好.
所以优化手段可以考虑 : 
1. 用户账户表, PK+余额组成一个表, 这个表被频繁更新, PK+其他字段再组成一个不频繁变更的表. 这两个表构成完整的用户账户信息. 在更新的时候, 行越小, 产生的垃圾就越小.
2. 彩票的流水数据, PK+状态组成一个表, 这个表被频繁更新, PK+其他字段在组成一个不频繁更新的表. 这两个表构成完整的流水数据. 
流水数据的另一个优化手段, 把UPDATE转成插入, 例如 : 
PK+所有字段组成一个表记录初始状态(insert), PK+状态组成多个表记录变更状态的数据(还是insert). 查询的时候需要多个表关联.
3. 关于分区表, 因为彩票有生命周期, 同时还有彩票种类(例如6选一, 体彩, ....) , 所以按时间+彩票种类来分表是比较好的, 例如tbl, tbl_c1_201406, tbl_c2_201406, ... tbl_c20_201406, tbl_c1_201407, tbl_c2_201407, ... tbl_c20_201407, ......
分区后, 清理历史数据就比较好清理. 而且索引膨胀也在控制范围内.
4. 因为后台异步的处理流水数据, 所以可以分批操作, 为了减少扫描次数, 可以使用游标, 或者一次扫描多次使用的手段.
例如 : 
如果这个表都在内存里面的话, 不建议使用索引, 因为索引反而给更新带来负担, 性能影响较大.

create table t(c1 int, c2 int, c3 int, c4 timestamp);
insert into t select 1,0,generate_series(1,10000000),clock_timestamp();
digoal=# \dt+ t
                    List of relations
 Schema | Name | Type  |  Owner   |  Size  | Description 
--------+------+-------+----------+--------+-------------
 public | t    | table | postgres | 605 MB | 
(1 row)
digoal=# \d t
                 Table "public.t"
 Column |            Type             | Modifiers 
--------+-----------------------------+-----------
 c1     | integer                     | 
 c2     | integer                     | 
 c3     | integer                     | 
 c4     | timestamp without time zone | 

digoal=# do language plpgsql $$
declare
  cur1 refcursor;
begin
  open cur1 for select * from t where c1=1 and c2=0 limit 5000 ;
  loop
    move cur1; 
    if found then 
      update t set c2=1 where current of cur1; 
    else 
      return; 
    end if; 
  end loop; 
  close cur1; 
end; 
$$;


一次处理5000条大概100毫秒
Time: 99.314 ms
一次处理5W条大概1秒.

digoal=# do language plpgsql $$
declare
  cur1 refcursor;
begin
  open cur1 for select * from t where c1=1 and c2=0 limit 50000 ;
  loop
    move cur1; 
    if found then 
      update t set c2=1 where current of cur1; 
    else 
      return; 
    end if; 
  end loop; 
  close cur1; 
end; 
$$;
DO
Time: 1009.304 ms


一次处理50W条大概10秒.

当然, 这里可能过于理想化, 因为一般是将数据取出后, 程序处理完或和彩票中心交互完, 得到彩票中心的反馈后, 才继续操作数据库, 所以可能最后不能像上面这样在一个事务中完成, 可能是一条一条的更新, 所以程序需要记录下批量处理的PK, 在得到彩票中心的返回后, 再一条一条或批量在数据库中更新. 那就需要用到索引.
或者程序使用长事务, 用以上的游标的方法来处理(效率最高). 

最后, 关于HA.
1. 如果使用同步HA, 当同步STANDBY异常时, 会影响用户购买彩票.
2. 如果使用异步HA, 当主节点发生故障时, 如果切换到备机, 可能丢失少量的事务, 那么万一这些用户中奖了, 代理可能因为这部分数据丢失, 而没有提交给彩票中心落实购买, 会产生纠纷. 所以如果彩票周期较长, 或离开奖还有很多时间, 来得及补数据的话, 可以从业务层将数据补回, 然后提交彩票中心采购申请.

[参考]
1. 

Flag Counter
