PostgreSQL research

PostgreSQL query in function tuning case

2014-03-24 15:17:32   查看原文>>

帮一位朋友那边处理的一个优化案例.
情形大概是这样的, 一个函数, 调用比较慢.
一般的做法是在函数内的每个SQL前后加一个raise notice, 输出当前的clock_timestamp, 这样能够得到慢在处理哪个SQL上.
还有一种方法是使用pg_stat_statements 插件, 这个插件会记录包括函数本身在内, 以及函数内的所有SQL的调用时间.
因为是个测试库, 而且这个函数非常长, 还有大量的循环, 使用raise notice来输出时间不太合理, 看都看不过来.
所以我这里使用了pg_stat_statements来分析这个函数到底慢在什么地方.
函数内容涉及隐私就不列出来了.
我这里只说一下优化方法和过程.
1. 配置pg_stat_statements
2. 调用pg_stat_statements_reset()清除统计信息.
3. 调用这个执行较慢的函数.
4. 查看pg_stat_statements得到这个函数以及所有函数内部SQL的执行时间, 调用次数.

select query,calls,total_time,total_time/calls from pg_stat_statements where userid=(select oid from pg_roles where rolname='game') and dbid=(select oid from pg_database where datname='report') order by 3 desc limit 10;


total_time最大的就是罪魁祸首.

query      | select aid,server,chan_id as channel,
           |                sum(1),
           |                sum( (case when date_part('epoch',(v_t-p.recv_dt)) between 0 and 5*60 then 1 else 0 end) ),
           |                max(xid), max(recv_dt)
           |            from (select t.gusr_id, t.xid,t.aid,t.server,b.chan_id,t.recv_dt, row_number() over (partition by t.gusr_id order by t.recv_dt) as rn from t1 as t, t2 b where t.sess_seq=b.xid and (date_part('epoch',(v_t-t.recv_dt)) between 0 and v_minute*60+5*60) ) as p 
           |             where p.rn=1  
           |             group by aid,server,channel
calls      | 21
total_time | 23953.651
?column?   | 1140.65004761905


把这个SQL拿出来, 看看执行计划, 以及real time.

explain (analyze,verbose) SQL;


从real time来看, 大部分时间来自t表的分表全表扫描 : 

                                       ->  Seq Scan on t1 t  (cost=0.00..21.10 rows=2 width=40) 
(actual time=73.495..73.495 rows=0 loops=1)
                                             Output: t.gusr_id, t.xid, t.aid, t.server, t.recv_dt, t.sess_seq
                                             Filter: ((date_part('epoch'::text, (('2014-02-05 18:19:55'::timestamp without time zone
)::timestamp with time zone - t.recv_dt)) >= 0::double precision) AND (date_part('epoch'::text, (('2014-02-05 18:19:55'::timestamp w
ithout time zone)::timestamp with time zone - t.recv_dt)) <= 1440::double precision))
.. 


大约有几时个这样的分表, 累计开销占用了总开销的大部分, 1.5秒左右.
这个表在recv_dt 字段有索引, 但是因为SQL写法的关系, 没有使用这个索引.
把SQL语句的date_part('epoch',(v_t-t.recv_dt)) between 0 and v_minute*60+5*60部分优化成如下 : 

v_t >= t.recv_dt and v_t-(10*60+5*60||' sec')::interval <= t.recv_dt


修改后这个查询走recv_dt索引, 时间降到50毫秒左右.
使用原来的写法不走索引 , 原因很简单, 因为优化器不会帮你改成优化后的写法, 所以SQL的写法是特别需要注意的, 不要图省事.

如果可以调整函数内容的话, 可以在函数中加入raise notice '%', clock_timestamp();
每执行一次SQL, 输出一下时间. 以此来判断SQL的执行时间.
