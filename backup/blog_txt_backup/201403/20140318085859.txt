PostgreSQL research

PostgreSQL csvlog maintenance automatic

2014-03-18 8:58:59   查看原文>>

前面一篇文章我提了一下定制PostgreSQL日志记录级别, 因为目前只有all, none, ddl, mod几个级别, 还不够精细, 如果要记录除INSERT以外的DML语句需要修改获取COMMAND级别的函数, 比较麻烦, 如下 : 
http://blog.163.com/digoal@126/blog/static/163877040201421702248430/
还有一种情形是, 开启数据库MOD日志级别后, 会产生大量的日志, 对性能有一定影响同时也占用存储空间.
通过挂载网络存储来管理csvlog有一定的风险, 一旦网络故障, 将导致数据库需要些日志的进程堵塞. 大家可以测试一下如使用nfs作为csvlog目录, 打开mod日志级别, 然后开启pgbench进行INSERT测试, 然后试图把远端的nfs进程停掉. 这种情形下, insert将堵塞.
一个比较折中的方法是本地存储csvlog, 同时定时将csvlog上次到远端存储并删除本地文件.
例如使用rsync作为传输工具.
远端存储服务端配置.

[192.168.9.9 csvlog]# cat /etc/rsyncd.conf 
port = 873
hosts deny = 0.0.0.0/0
read only = false
write only = false
gid = 0
uid = 0
use chroot = no
max connections = 100
pid file = /var/run/rsync.pid
lock file = /var/run/rsync.lock
log file = /var/log/rsync.log

[csvlog]
path = /data01/csvlog
comment = PostgreSQL csvlog
hosts allow = 192.168.1.0/24,192.168.2.0/24,192.168.3.100


如果有新的数据库主机要加入, 先配置hosts allow.

启动rsync后台进程.

# /usr/bin/rsync -v --daemon --config=/etc/rsyncd.conf


创建和主机相关的目录, 例如数据库主机的IP为192.168.1.2 , 创建上次目录.

# mkdir -p /data01/csvlog/192.168.1.2/upload_dir



在数据库主机上使用rsync上传 : 

vi csvlog_upload.sh
#!/bin/bash

# .bash_profile
# Get the aliases and functions
if [ -f ~/.bashrc ]; then
        . ~/.bashrc
fi
# User specific environment and startup programs
PATH=$PATH:$HOME/bin
export PATH
. /home/postgres/.bash_profile

NET_DEV="`/sbin/route -n|grep UG|awk '{print $8}'|head -n 1`"
IP_ADDR="`/sbin/ip addr show $NET_DEV|grep inet|grep "global $NET_DEV$"|awk '{print $2}'|awk -F "/" '{print $1}'`"
LOCAL_IP="$IP_ADDR"
LOCAL_CSVLOG_DIR="`grep log_directory $PGDATA/postgresql.conf|awk -F "=" '{print $2}'|awk -F "'" '{print $2}'`"
RSYNC_IP="192.168.9.9"
RSYNC_DIR="csvlog/$LOCAL_IP/upload_dir/"


# find $LOCAL_CSVLOG_DIR -regextype posix-extended -regex '.*postgresql-[0-9]{4}-[0-9]{2}-[0-9]{2}.*csv' -type f -mmin +60
# find $LOCAL_CSVLOG_DIR -regextype posix-extended -regex '.*postgresql-[0-9]{4}-[0-9]{2}-[0-9]{2}.*log' -type f -mtime +1

cd $PGDATA
for ((i=1;i>0;i=1))
do
# 查找60分钟前修改过的CSV文件, 上传并删除
find $LOCAL_CSVLOG_DIR -regextype posix-extended -regex '.*postgresql-[0-9]{4}-[0-9]{2}-[0-9]{2}.*csv' -type f -mmin +60 -exec rsync -acvz {} $RSYNC_IP::$RSYNC_DIR \; -exec rm -f {} \;
# 查找2天前修改过的LOG文件, 上传并删除
find $LOCAL_CSVLOG_DIR -regextype posix-extended -regex '.*postgresql-[0-9]{4}-[0-9]{2}-[0-9]{2}.*log' -type f -mtime +1 -exec rsync -acvz {} $RSYNC_IP::$RSYNC_DIR \; -exec rm -f {} \;

sleep 60

done


修改权限

chmod 500 csvlog_upload.sh


启动

nohup ./csvlog_upload.sh >/dev/null 2>&1 &


放到rc.local

# vi /etc/rc.local
su - postgres -c "/home/postgres/script/csvlog_upload.sh >/dev/null 2>&1 &"


如果要限制上传速度, 可以使用rsync --bwlimit


后期的维护, 例如每个月打包成一个压缩文件.

cd /data01/csvlog/192.168.100.12/upload_dir
FILE="2014-03"; test -f ../$FILE.tar.bz2 || nohup tar --remove-files -jcvf
../$FILE.tar.bz2 postgresql-$FILE* >/dev/null 2>&1 &


如果文件数过多可能会造成tar的argments too many的错误, 而且后期的解压这种大目录也有弊端, 所以建议一个文件一个文件的压缩.

vi compress.sh
#!/bin/bash
FILE="2014-03"
DIR=/data01/csvlog/192.168.100.12/upload_dir
FILE=$2
DIR=$1
cd $DIR
for filename in ./postgresql-$FILE*; do
  tar --remove-files -jcvf ../$filename.tar.bz2 $filename >/dev/null 2>&1 &
done
chmod 500 compress.sh
./compress.sh /root "2014-03"




Flag Counter
