PostgreSQL research

使用eigne()求矩阵的特征值Eigenvalues 和特征向量Eigenvectors

2015-04-13 10:26:58   查看原文>>

矩阵的特征值和特征向量的含义请参考
1. http://zh.wikipedia.org/zh-cn/%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F
2. http://www.zhihu.com/question/21874816
引用知乎 : 
  特征值首先是描述特征的。比如你的图片是有特征的，并且图片是存在某个坐标系的。特征向量就代表这个坐标系，特征值就代表这个特征在这个坐标方向上的贡献。总之，就是代表在对应坐标轴上的特征大小的贡献.

在R中如何计算特征值和特征向量?
可以通过对矩阵A进行谱分解来得到矩阵的特征值和特征向量。矩阵A的谱分解如下：A=UΛU’，其中U的列为A的特征值所对应的特征向量，在R中可以用eigen()函数得到U和Λ。例如：
eigen函数参数如下 : 

> args(eigen)
function (x, symmetric, only.values = FALSE, EISPACK = FALSE)
NULL



其中，x参数输入矩阵；symmetric参数判断矩阵是否为对称矩阵，如果参数为空，系统将自动检测矩阵的对称性。例如：

> A=matrix(1:9,nrow=3,ncol=3)

> A
     [,1] [,2] [,3]
[1,]    1    4    7
[2,]    2    5    8
[3,]    3    6    9



eigen(A)得到一个list, 存储特征值和特征向量.

> class(eigen(A))
[1] "list"

> Aeigen=eigen(A)
> Aeigen
$values
[1]  1.611684e+01 -1.116844e+00 -4.054214e-16

$vectors
           [,1]       [,2]       [,3]
[1,] -0.4645473 -0.8829060  0.4082483
[2,] -0.5707955 -0.2395204 -0.8164966
[3,] -0.6770438  0.4038651  0.4082483



得到矩阵A的特征值：

> Aeigen$values
[1]  1.611684e+01 -1.116844e+00 -4.054214e-16



得到矩阵A的特征向量：

> Aeigen$vectors
           [,1]       [,2]       [,3]
[1,] -0.4645473 -0.8829060  0.4082483
[2,] -0.5707955 -0.2395204 -0.8164966
[3,] -0.6770438  0.4038651  0.4082483




[参考]
1. http://student.zjzk.cn/course_ware/web-gcsx/main.htm
2. http://zh.wikipedia.org/zh-cn/%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F
3. http://www.zhihu.com/question/21874816
4. > help(eigen)

eigen                   package:base                   R Documentation

Spectral Decomposition of a Matrix

Description:

     Computes eigenvalues and eigenvectors of numeric (double, integer,
     logical) or complex matrices.

Usage:

     eigen(x, symmetric, only.values = FALSE, EISPACK = FALSE)
     
Arguments:

       x: a numeric or complex matrix whose spectral decomposition is
          to be computed.  Logical matrices are coerced to numeric.

symmetric: if ‘TRUE’, the matrix is assumed to be symmetric (or
          Hermitian if complex) and only its lower triangle (diagonal
          included) is used.  If ‘symmetric’ is not specified, the
          matrix is inspected for symmetry.

only.values: if ‘TRUE’, only the eigenvalues are computed and returned,
          otherwise both eigenvalues and eigenvectors are returned.

 EISPACK: logical. Defunct and ignored.

Details:

     If ‘symmetric’ is unspecified, the code attempts to determine if
     the matrix is symmetric up to plausible numerical inaccuracies.
     It is faster and surer to set the value yourself.

     Computing the eigenvectors is the slow part for large matrices.

     Computing the eigendecomposition of a matrix is subject to errors
     on a real-world computer: the definitive analysis is Wilkinson
     (1965).  All you can hope for is a solution to a problem suitably
     close to ‘x’.  So even though a real asymmetric ‘x’ may have an
     algebraic solution with repeated real eigenvalues, the computed
     solution may be of a similar matrix with complex conjugate pairs
     of eigenvalues.

Value:

     The spectral decomposition of ‘x’ is returned as components of a
     list with components

  values: a vector containing the p eigenvalues of ‘x’, sorted in
          _decreasing_ order, according to ‘Mod(values)’ in the
          asymmetric case when they might be complex (even for real
          matrices).  For real asymmetric matrices the vector will be
          complex only if complex conjugate pairs of eigenvalues are
          detected.

 vectors: either a p * p matrix whose columns contain the eigenvectors
          of ‘x’, or ‘NULL’ if ‘only.values’ is ‘TRUE’.  The vectors
          are normalized to unit length.

          Recall that the eigenvectors are only defined up to a
          constant: even when the length is specified they are still
          only defined up to a scalar of modulus one (the sign for real
          matrices).
     If ‘r <- eigen(A)’, and ‘V <- r$vectors; lam <- r$values’, then

                              A = V Lmbd V^(-1)                         
     
     (up to numerical fuzz), where Lmbd =‘diag(lam)’.

Source:

     By default ‘eigen’ uses the LAPACK routines ‘DSYEVR’, ‘DGEEV’,
     ‘ZHEEV’ and ‘ZGEEV’ whereas

     LAPACK is from <URL: http://www.netlib.org/lapack> and its guide
     is listed in the references.

References:

     Anderson. E. and ten others (1999) _LAPACK Users' Guide_.  Third
     Edition.  SIAM.
     Available on-line at <URL:
     http://www.netlib.org/lapack/lug/lapack_lug.html>.

     Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S
     Language_.  Wadsworth & Brooks/Cole.  Springer-Verlag Lecture
     Notes in Computer Science *6*.

     Wilkinson, J. H. (1965) _The Algebraic Eigenvalue Problem._
     Clarendon Press, Oxford.

See Also:

     ‘svd’, a generalization of ‘eigen’; ‘qr’, and ‘chol’ for related
     decompositions.

     To compute the determinant of a matrix, the ‘qr’ decomposition is
     much more efficient: ‘det’.

Examples:

     eigen(cbind(c(1,-1), c(-1,1)))
     eigen(cbind(c(1,-1), c(-1,1)), symmetric = FALSE)
     # same (different algorithm).
     
     eigen(cbind(1, c(1,-1)), only.values = TRUE)
     eigen(cbind(-1, 2:1)) # complex values
     eigen(print(cbind(c(0, 1i), c(-1i, 0)))) # Hermite ==> real Eigenvalues
     ## 3 x 3:
     eigen(cbind( 1, 3:1, 1:3))
     eigen(cbind(-1, c(1:2,0), 0:2)) # complex values




Flag Counter
