PostgreSQL research

SAN Architectural Brief

2010-05-22 16:04:25   查看原文>>

今天与以前一位做存储的同事（现在支付宝）还有BROCADE上海那边的工程师聊了一些SAN的话题，在这里记录一下，顺便写一下我理解的SAN的设计概要，希望对大家有点帮助。

对于一个企业来说，数据是相当重要的（垃圾数据就不说了）。比如银行的个人账户信息，超时的销售记录等等。

在数据的生命周期中存在多种多样的特征（动态的和静态的）。如数据的存在形态，数据量，粒度，增长速度，使用频率等等

根据不同的场景，设计合理的存储架构即可以满足企业的当下需求，又要兼顾未来企业的发展，减少碳排放，注意投资保护等等。

设计合理的存储架构需要对当下企业存储情况进行调研，充分了解业务的发展和当下的需求。评估未来几年的存储需求（包括IO，吞吐量，容量等等），对于一个已有业务，可以取出历史数据进行趋势分析，推测未来几年的趋势。

扯了这么多，开始进入主题，今天的主题是SAN的架构设计，先来了解几个术语。

DAS(Direct-Attached Storage)  ：

也称为非网络共享存储，从字面上很好理解，这应该是比较早的共享存储的技术。典型的是SAS，ULTRA SCSI接口连接的存储等等。优点是比较便宜，缺点是天花板太低了，或者说可扩容的余地较小，投资回报也是比较小的，因为利用率较为低下。

NAS(Network-attached Storage)

或称为网络共享存储，如SMB,NFS,MFS,AFS等等。构建一个NAS需要一台提供共享服务的服务器，客户机需要支持共享服务的客户端。优点是共享方便，廉价等。确定是高度依赖网络，性能可能不稳定，普通的LAN中延时较大（INFINIBAND可能会较好，不过造价昂贵）。

SAN(Storage Area Network)

存储区域网络，也可以理解为存储专用网络。构建一个基本的SAN环境需要光纤交换机，连接设备，支持SAN的存储，服务器等。SAN的优点是传输速度快，扩容上限大大提高，扩容方便，投资保护大。缺点是造价较为昂贵，多了一个布线的环节（随着FCOE的发展，布线可能会简单很多）。

DAS,NAS,SAN三者的区别：

DAS的存储和服务器之间没有其他的中间层。NAS和SAN的存储和服务器之间都存在中间层（网络,交换机或提供共享服务的服务器）。

对于NAS和SAN，用一个图来加深一下认识:

SAN Architectural Brief - 德哥(DiGoal,Just Do It!) - Not Only DBA

 

 

接下来细说一下SAN：

首先,在SAN中存在两种最基本的角色,INITIOR（ACTIVE）,TARGET(PASSIVE)。initior就是发起请求的那一方（如HBA），TARGET是接受请求的那一方（如存储的FC口）。而FC SWITCH是将这两方串起来的设备（ZONE），同样FCSW还承担了管理和监控的角色。根据INITIOR的特性，FCSW的另一个功能是屏蔽两个INITIOR之间的交换。

被串起来的两个设备就像建立了一个独有的通道一样，被称为fibre channel,fibre channel 是一个二层的协议，正因为如此SAN的扩展也是有上限的，比以太网小得多。每一个FABRIC中的所有交换设备必须有相同的ZONE数据信息，换句话说，在一个FABRIC中的任意一个设备都必须知道initior和target的访问控制信息，这有点类似于mac地址信息表但是又不一样
，因为FABRIC网络是单向的，而LAN是双向的。

下面来看几个常见的SAN架构图，并解释一下各个架构的优缺点：

flat san top:

SAN Architectural Brief - 德哥(DiGoal,Just Do It!) - Not Only DBA

 

 

这个图上架设的是一个没有使用ISL（INTER-SWITCH Links）的单层SAN网络，呈现的特征是服务器和存储的交换不需要跨两个交换机，因为交换机之间的交换又增加了传输的延时，降低了IO响应速度。

冗余的话通过架设两个交换机来实现。使用FLAT架构的好处是服务器到存储的访问速度是最快的，也符合ras，（reliability,availability,serviceability）

如果要扩展FLAT架构的FABRIC网络，但是又不想使用ISL连接的话，需要增加交换机。如下：

SAN Architectural Brief - 德哥(DiGoal,Just Do It!) - Not Only DBA

 

 

从FLAT的架构上我们很容易看出，FLAT架构很快就会到达天花板，随着交换机的增加，存储的端口数将很快成为FLAT的瓶颈。如果使用SWITCH级联的方式，ISL的传输延时也将成为性能的瓶颈，通过与BROCADE原厂工程师了解，一般最多不要超过7个交换机进行级联，否则延时将成为严重瓶颈。

在FLAT中还要注意避免OVER-SUBSCRIPTion，也就是服务器和存储的比例，一般1GB链路是7：1，2GB链路是12：1，4GB链路是18：1。超过这个比例可能会产生性能问题，当然这不是必然，还是要根据服务器的IOPS需求来定义的。

mesh san top:

SAN Architectural Brief - 德哥(DiGoal,Just Do It!) - Not Only DBA

 

 

MESH架构的SAN环境，所有的FCSW之间都是互通的，服务器访问存储可能会跨越多个FCSW，造成通信延时。同时由于每个交换机都需要互联，将消耗大量的端口来进行ISL通信，在扩容上也是很麻烦的。这中设计一般是不推荐的。

core-edge top:

 

SAN Architectural Brief - 德哥(DiGoal,Just Do It!) - Not Only DBA

 

因为我们前面讲到FALT模式下，整张网很容易达到端口上限。于是出现了CORE-EDGE架构，它实际上是整合了多个FLAT FABRIC，使得各个FABRIC之间的存储可被共享。在CORE-EDGE的设计中，我们还是要尽量避免ISL通信，如将访问量最高的存储放在同一个FABRIC，而将访问量较小的并且需要多个FABRIC服务器共享的方在CORE层。

下面是一个三层结构的CORE-EDGE设计模型

SAN Architectural Brief - 德哥(DiGoal,Just Do It!) - Not Only DBA

 

 

其实总结起来将，就是考虑成本，考虑未来的发展趋势，按需要设计。

先写到这里

