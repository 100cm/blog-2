PostgreSQL research

RHCS abnormal case: network problem between cluster nodes

2012-04-09 23:52:27   查看原文>>

一个RHCS的异常案例，节点是redhat 5.5 64位的系统。集群由两个节点组成。

两个节点之间的通讯网络异常，导致双方都检测不到对方心跳，发出了fence对方的指令，而fence网络也出了问题，因此双方都在不停的fence对方。

就在FENCE对方的过程当中，还发现了一个问题。

因为我们在这个集群中只用到了GFS文件系统，在FENCE的过程中，我们发现两个节点的GFS文件系统都不可访问。

为什么呢?

host_2的日志是这样的 :

Apr  9 22:18:18 host_2 kernel: NETDEV WATCHDOG: eth0: transmit timed out
Apr  9 22:18:19 host_2 kernel: bnx2: eth0 NIC Copper Link is Down
Apr  9 22:18:28 host_2 openais[9376]: [TOTEM] The token was lost in the OPERATIONAL state.
Apr  9 22:18:28 host_2 openais[9376]: [TOTEM] Receive multicast socket recv buffer size (320000 bytes).
Apr  9 22:18:28 host_2 openais[9376]: [TOTEM] Transmit multicast socket send buffer size (320000 bytes).
Apr  9 22:18:28 host_2 openais[9376]: [TOTEM] entering GATHER state from 2.
Apr  9 22:18:48 host_2 openais[9376]: [TOTEM] entering GATHER state from 0.
Apr  9 22:18:48 host_2 openais[9376]: [TOTEM] Creating commit token because I am the rep.
Apr  9 22:18:48 host_2 openais[9376]: [TOTEM] Saving state aru c349 high seq received c349
Apr  9 22:18:48 host_2 openais[9376]: [TOTEM] Storing new sequence id for ring 884
Apr  9 22:18:48 host_2 openais[9376]: [TOTEM] entering COMMIT state.
Apr  9 22:18:48 host_2 openais[9376]: [TOTEM] entering RECOVERY state.
Apr  9 22:18:48 host_2 openais[9376]: [TOTEM] position [0] member host_2:
Apr  9 22:18:48 host_2 openais[9376]: [TOTEM] previous ring seq 2176 rep host_1
Apr  9 22:18:48 host_2 openais[9376]: [TOTEM] aru c349 high delivered c349 received flag 1
Apr  9 22:18:48 host_2 openais[9376]: [TOTEM] Did not need to originate any messages in recovery.
Apr  9 22:18:48 host_2 openais[9376]: [TOTEM] Sending initial ORF token
Apr  9 22:18:48 host_2 openais[9376]: [CLM  ] CLM CONFIGURATION CHANGE
Apr  9 22:18:48 host_2 openais[9376]: [CLM  ] New Configuration:
Apr  9 22:18:48 host_2 kernel: dlm: closing connection to node 1
Apr  9 22:18:48 host_2 openais[9376]: [CLM  ]         r(0) ip(host_2) 
Apr  9 22:18:48 host_2 openais[9376]: [CLM  ] Members Left:
Apr  9 22:18:48 host_2 openais[9376]: [CLM  ]         r(0) ip(host_1) 
Apr  9 22:18:48 host_2 openais[9376]: [CLM  ] Members Joined:
Apr  9 22:18:49 host_2 openais[9376]: [CLM  ] CLM CONFIGURATION CHANGE
Apr  9 22:18:49 host_2 openais[9376]: [CLM  ] New Configuration:
Apr  9 22:18:49 host_2 openais[9376]: [CLM  ]         r(0) ip(host_2) 
Apr  9 22:18:49 host_2 openais[9376]: [CLM  ] Members Left:
Apr  9 22:18:49 host_2 openais[9376]: [CLM  ] Members Joined:
Apr  9 22:18:49 host_2 openais[9376]: [SYNC ] This node is within the primary component and will provide service.
Apr  9 22:18:49 host_2 openais[9376]: [TOTEM] entering OPERATIONAL state.
Apr  9 22:18:49 host_2 openais[9376]: [CLM  ] got nodejoin message host_2
Apr  9 22:18:49 host_2 openais[9376]: [CPG  ] got joinlist message from node 2
Apr  9 22:19:18 host_2 fenced[9579]: host_1 not a cluster member after 30 sec post_fail_delay
Apr  9 22:19:18 host_2 fenced[9579]: fencing node "host_1"
Apr  9 22:19:29 host_2 fenced[9579]: agent "fence_ilo" reports: Unable to connect/login to fencing device

省略部分

Apr  9 22:25:38 host_2 kernel: INFO: task gfs_glockd:10447 blocked for more than 120 seconds.
Apr  9 22:25:38 host_2 kernel: "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
Apr  9 22:25:38 host_2 kernel: gfs_glockd    D ffff8102faa6b860     0 10447    231         10455 10446 (L-T
LB)
Apr  9 22:25:38 host_2 kernel:  ffff81030f4add40 0000000000000046 ffff81030f4add10 000000000000000e
Apr  9 22:25:38 host_2 kernel:  ffff81030d57ba20 000000000000000a ffff81061df63100 ffff8102faa6b860
Apr  9 22:25:38 host_2 kernel:  00296e817f38ba31 0000000000002424 ffff81061df632e8 0000000400000080
Apr  9 22:25:38 host_2 kernel: Call Trace:
Apr  9 22:25:38 host_2 kernel:  [<ffffffff800484d0>] pagevec_lookup_tag+0x1a/0x21
Apr  9 22:25:38 host_2 kernel:  [<ffffffff8004a66a>] wait_on_page_writeback_range+0xd6/0x12e
Apr  9 22:25:38 host_2 kernel:  [<ffffffff800a198c>] keventd_create_kthread+0x0/0xc4
Apr  9 22:25:38 host_2 kernel:  [<ffffffff800656ac>] __down_read+0x7a/0x92
Apr  9 22:25:38 host_2 kernel:  [<ffffffff8859cea3>] :dlm:dlm_unlock+0x37/0xcd
Apr  9 22:25:38 host_2 kernel:  [<ffffffff8865d802>] :gfs:ail_empty_gl+0x21/0xef
Apr  9 22:25:38 host_2 kernel:  [<ffffffff800a198c>] keventd_create_kthread+0x0/0xc4
Apr  9 22:25:38 host_2 kernel:  [<ffffffff88671d3e>] :gfs:gdlm_do_unlock+0x3b/0x85
Apr  9 22:25:38 host_2 kernel:  [<ffffffff886691c6>] :gfs:gfs_glock_drop_th+0x116/0x187
Apr  9 22:25:38 host_2 kernel:  [<ffffffff88667543>] :gfs:run_queue+0x12e/0x35e
Apr  9 22:25:38 host_2 kernel:  [<ffffffff800a198c>] keventd_create_kthread+0x0/0xc4
Apr  9 22:25:38 host_2 kernel:  [<ffffffff886680c8>] :gfs:unlock_on_glock+0x1b/0x24
Apr  9 22:25:38 host_2 kernel:  [<ffffffff88667389>] :gfs:gfs_reclaim_glock+0xed/0x179
Apr  9 22:25:38 host_2 kernel:  [<ffffffff8865d218>] :gfs:gfs_glockd+0x0/0xd1
Apr  9 22:25:38 host_2 kernel:  [<ffffffff8865d22d>] :gfs:gfs_glockd+0x15/0xd1
Apr  9 22:25:38 host_2 kernel:  [<ffffffff800a1ba4>] autoremove_wake_function+0x0/0x2e
Apr  9 22:25:38 host_2 kernel:  [<ffffffff800a198c>] keventd_create_kthread+0x0/0xc4
Apr  9 22:25:38 host_2 kernel:  [<ffffffff80032bdc>] kthread+0xfe/0x132
Apr  9 22:25:38 host_2 kernel:  [<ffffffff8005efb1>] child_rip+0xa/0x11
Apr  9 22:25:38 host_2 kernel:  [<ffffffff800a198c>] keventd_create_kthread+0x0/0xc4
Apr  9 22:25:38 host_2 kernel:  [<ffffffff80032ade>] kthread+0x0/0x132
Apr  9 22:25:38 host_2 kernel:  [<ffffffff8005efa7>] child_rip+0x0/0x11

后面每隔2分钟会报一次以上的gfs相关内核信息, 略去中间部分,

Apr  9 22:27:38 host_2 kernel: INFO: task gfs_glockd:10447 blocked for more than 120 seconds.

略
Apr  9 22:29:38 host_2 kernel: INFO: task gfs_glockd:10447 blocked for more than 120 seconds.

略
Apr  9 22:31:38 host_2 kernel: INFO: task gfs_glockd:10447 blocked for more than 120 seconds.
Apr  9 22:33:38 host_2 kernel: INFO: task gfs_glockd:10447 blocked for more than 120 seconds.
Apr  9 22:35:38 host_2 kernel: INFO: task gfs_glockd:10447 blocked for more than 120 seconds.
Apr  9 22:37:38 host_2 kernel: INFO: task gfs_glockd:10447 blocked for more than 120 seconds.
Apr  9 22:39:38 host_2 kernel: INFO: task gfs_glockd:10447 blocked for more than 120 seconds.
Apr  9 22:41:38 host_2 kernel: INFO: task gfs_glockd:10447 blocked for more than 120 seconds.
Apr  9 22:43:38 host_2 kernel: INFO: task gfs_glockd:10447 blocked for more than 120 seconds.

 

host_1的日志 :

Apr  9 22:18:22 host_1 openais[9265]: [TOTEM] The token was lost in the OPERATIONAL state.
Apr  9 22:18:22 host_1 openais[9265]: [TOTEM] Receive multicast socket recv buffer size (320000 bytes).
Apr  9 22:18:22 host_1 openais[9265]: [TOTEM] Transmit multicast socket send buffer size (320000 bytes).
Apr  9 22:18:22 host_1 openais[9265]: [TOTEM] entering GATHER state from 2.
Apr  9 22:18:42 host_1 openais[9265]: [TOTEM] entering GATHER state from 0.
Apr  9 22:18:42 host_1 openais[9265]: [TOTEM] Creating commit token because I am the rep.
Apr  9 22:18:42 host_1 openais[9265]: [TOTEM] Saving state aru c349 high seq received c349
Apr  9 22:18:42 host_1 openais[9265]: [TOTEM] Storing new sequence id for ring 884
Apr  9 22:18:42 host_1 openais[9265]: [TOTEM] entering COMMIT state.
Apr  9 22:18:42 host_1 openais[9265]: [TOTEM] entering RECOVERY state.
Apr  9 22:18:42 host_1 openais[9265]: [TOTEM] position [0] member host_1:
Apr  9 22:18:42 host_1 openais[9265]: [TOTEM] previous ring seq 2176 rep host_1
Apr  9 22:18:42 host_1 openais[9265]: [TOTEM] aru c349 high delivered c349 received flag 1
Apr  9 22:18:42 host_1 openais[9265]: [TOTEM] Did not need to originate any messages in recovery.
Apr  9 22:18:42 host_1 openais[9265]: [TOTEM] Sending initial ORF token
Apr  9 22:18:42 host_1 openais[9265]: [CLM  ] CLM CONFIGURATION CHANGE
Apr  9 22:18:42 host_1 openais[9265]: [CLM  ] New Configuration:
Apr  9 22:18:42 host_1 kernel: dlm: closing connection to node 2
Apr  9 22:18:42 host_1 openais[9265]: [CLM  ]         r(0) ip(host_1) 
Apr  9 22:18:42 host_1 openais[9265]: [CLM  ] Members Left:
Apr  9 22:18:42 host_1 openais[9265]: [CLM  ]         r(0) ip(host_2) 
Apr  9 22:18:42 host_1 openais[9265]: [CLM  ] Members Joined:
Apr  9 22:18:42 host_1 openais[9265]: [CLM  ] CLM CONFIGURATION CHANGE
Apr  9 22:18:42 host_1 openais[9265]: [CLM  ] New Configuration:
Apr  9 22:18:42 host_1 openais[9265]: [CLM  ]         r(0) ip(host_1) 
Apr  9 22:18:43 host_1 openais[9265]: [CLM  ] Members Left:
Apr  9 22:18:43 host_1 openais[9265]: [CLM  ] Members Joined:
Apr  9 22:18:43 host_1 openais[9265]: [SYNC ] This node is within the primary component and will provide service.
Apr  9 22:18:43 host_1 openais[9265]: [TOTEM] entering OPERATIONAL state.
Apr  9 22:18:43 host_1 openais[9265]: [CLM  ] got nodejoin message host_1
Apr  9 22:18:43 host_1 openais[9265]: [CPG  ] got joinlist message from node 1
Apr  9 22:19:12 host_1 fenced[9382]: host_2 not a cluster member after 30 sec post_fail_delay
Apr  9 22:19:12 host_1 fenced[9382]: fencing node "host_2"
Apr  9 22:19:18 host_1 fenced[9382]: agent "fence_ilo" reports: Unable to connect/login to fencing device

 在host_1节点未出现gfs的异常信息. 但是对应的GFS设备还是无法访问.

GFS文件系统无法访问原因是GFS的锁进程出了问题，我猜测导致两个节点死锁了.

GFS挂载信息 : 使用的是分布式锁.

  SB lock proto = "lock_dlm"
  SB lock table = "略"
  SB ondisk format = 1309
  SB multihost format = 1401
  Block size = 4096
  Journals = 2
  Resource Groups = 188
  Mounted lock proto = "lock_dlm"
  Mounted lock table = "略"
  Mounted host data = "jid=0:id=131073:first=0"
  Journal number = 0
  Lock module flags = 0
  Local flocks = FALSE
  Local caching = FALSE
  Oopses OK = FALSE

  Type           Total Blocks   Used Blocks    Free Blocks    use%          
  ------------------------------------------------------------------------
  inodes         132            132            0              100%
  metadata       205254         51282          153972         25%
  data           98026214       25613842       72412372       26%

对于可以避免使用GFS的环境还是要尽量避免使用GFS。例如ORACLE的RAC节点如果仅仅是拿GFS来放归档文件的话就没必要了, 备份归档时可以考虑所有节点同时备份，清除操作也一样，所有节点都清除。这样可以有效的避免类似情况发生。

而出现本次故障的原因是HOST_2的网络异常, 并且fence的网络异常，相互都无法FENCE对方。

eth0网络异常可能是网卡驱动BUG造成的, 见http://lists.us.dell.com/pipermail/linux-poweredge/2009-December/040770.html

由于无法获得机器的ROOT密码，只能在网络联通的情况下通过堡垒机正常登陆，最后故障排除是通过ILO重启了节点2，把节点2重新加入到集群后加载GFS，节点1的GFS文件系统重新挂载。

