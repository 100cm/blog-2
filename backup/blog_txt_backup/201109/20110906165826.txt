PostgreSQL research

chat with an ad-union developer

2011-09-06 16:58:26   查看原文>>

今天和一位广告联盟的兄弟聊天，得知他们在MySQL和PostgreSQL之间做选择。
其中的一个应用场景是:
  REDIS做每小时的数据统计，每小时把前一个小时的REDIS统计出来的数据写入数据库。
  写入的程序是PHP写的，从REDIS取出写入到RDBMS，连数据库只开了一个连接（这里我不太了解内情，反正只开一个连接，要开多个连接的话可能要改程序，还是极力推荐他修改为可以配置多连接的方式）。
  数据库服务器是一台普通的PC服务器，SATA硬盘，2GB内存，FREEBSD的操作系统。
  MySQL每秒约插入5000条（innodb引擎），24小时候后的平均插入约3000多条每秒，没有UK违反约束的错误。
  而PostgreSQL9.1beta3压下了插入每秒不到2000条，有UK违反约束的错误。
  我连到他的服务器上，在压时观察数据库服务器的压力情况，发现服务器基本上没有压力，但是每秒的写入只有2000多。
  PHP程序不方便贴出。就不多说了。
  （对于违反约束的错误，我怀疑是程序重复提交了同一SQL造成的。总不至于MYSQL不检查约束吧。）
   因为操作比较简单，所以我在我的系统里面模拟和他的程序同样的操作：
   表结构
digoal=> \d insert_test_log
                            Table "digoal.insert_test_log"
 Column |     Type      |                          Modifiers                           
--------+---------------+--------------------------------------------------------------
 id     | integer       | not null default nextval('insert_test_log_id_seq'::regclass)
 day    | date          | 
 hour   | integer       | 
 uid    | integer       | 
 siteid | integer       | 
 adid   | integer       | 
 num    | integer       | 
 md5    | character(32) | 
Indexes:
    "insert_test_log_pkey" PRIMARY KEY, btree (id)
    "insert_test_log_md5_key" UNIQUE CONSTRAINT, btree (md5)

测试使用插入函数:
CREATE OR REPLACE FUNCTION ins_insert_test_log
(i_day integer, i_hour integer, i_uid integer, i_siteid integer, i_adid integer, i_num integer)
 RETURNS integer
 LANGUAGE plpgsql
AS $function$
declare
begin
insert into insert_test_log (day,hour,uid,siteid,adid,num,md5) values (current_date+i_day,i_hour,i_uid,i_siteid,i_adid,i_num,md5(clock_timestamp()::text));
return 0;
exception
when others then
return 1;
end;
$function$;

测试使用的pgbench脚本文件:
\setrandom i_date -365 365
\setrandom i_hour 1 1999999999
\setrandom i_uid 1 1999999999
\setrandom i_siteid 1 1999999999
\setrandom i_adid 1 1999999999
\setrandom i_num 1 1999999999
select ins_insert_test_log(:i_date,:i_hour,:i_uid,:i_siteid,:i_adid,:i_num);

pgbench测试脚本，同样使用1个连接:
#!/bin/bash
. /home/postgres/.bash_profile
pgbench -M prepared -c 1 -f /home/postgres/pgbench/insert_test_unlog.sql -j 1 -n -T 180 -h xxx.xxx.xxx.xxx -p xxxx -U digoal digoal

测试结果:
transaction type: Custom query
scaling factor: 1
query mode: prepared
number of clients: 1
number of threads: 1
duration: 180 s
number of transactions actually processed: 624236
tps = 3467.965139 (including connections establishing)
tps = 3468.037698 (excluding connections establishing)
每秒处理的事务数是3400多.
数据库服务器90% idle ， 负载0.5左右。

来说说单连接和多连接的区别:
从上面的测试来看，PostgreSQL单连接处理的情况下，数据库服务器的资源还很空闲。单条SQL的平均响应时间是1000/3468=0.29毫秒.
如果开2个连接，并且数据库服务器的资源够用的情况下，并且单条SQL平均响应时间趋于不变，每秒应该可以处理一倍的SQL请求=6936。

虽然程序不支持多数据库连接，为了告知他多连接的好处，还是测试一下多连接的情况:
pgbench -M prepared -c 32 -f /home/postgres/pgbench/insert_test_unlog.sql -j 32 -n -T 180 -h xxx.xxx.xxx.xxx -p xxxx -U digoal digoal
transaction type: Custom query
scaling factor: 1
query mode: prepared
number of clients: 32
number of threads: 32
duration: 180 s
number of transactions actually processed: 4969116
tps = 27581.990980 (including connections establishing)
tps = 27585.349709 (excluding connections establishing)
开32个连接，数据库服务器25% idle ， 负载12左右。
每秒处理SQL请求27581次。单条SQL的平均响应时间=1000/(27581/32)=1.1毫秒。
虽然平均SQL响应时间长了，但是总的吞吐量变大了。

另一个应用场景是 : 
实时更新URL的访问次数。
比如访问http://blog.163.com/digoal@126/ 每次被访问，都要使点击率加1.
做法大概是 update table set uv=uv+1 where md5=$? ; 
在测试系统中压力测试，显示PG某些SQL会很慢，长的要好几秒。
对于数据库来说，这是一个比较常见的ROW LOCK等待问题，例如同一个时间段内频繁的更新同一条记录(对于热门访问的URL)，因为更新记录需要锁行，就是说一个SESSION在更新某一条记录时，其他SESSION要等待。所以就有可能出现长的要好几秒的情况。
之前写过一篇oracle和postgresql处理死锁的文章，如下，有兴趣的朋友可以参考一下。
http://blog.163.com/digoal@126/blog/static/16387704020113811711716/

解决这个问题的办法，
1. 提高数据库单条记录更新速度，注意PostgreSQL更新记录的做法是老的记录并没有实际的删除掉，而是修改了行的头部信息，有兴趣的朋友可以看看heaptuple的结构。因此每次不管更新啥，在物理存储上都会多出一条记录，后台VACUUM去回收已经标记为删除并且所有事务都不会看到的记录。当然PG选择这种MVCC模式，也带来了很多好处，比如并发能力非常
，可以把DDL封装到事务里面等等。
    因此要提高数据库单条UPDATE速度，可以考虑使用另外的MVCC模式的数据库，如 mongoDB , oracle . 
2. 缓存访问计数，非实时的更新数据库，就不存在热门URL频繁更新数据库的问题了。

个人还是推荐第二种解决办法。
