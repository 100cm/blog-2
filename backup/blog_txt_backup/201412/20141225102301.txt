PostgreSQL research

Ceph FINDING AN OBJECT LOCATION

2014-12-25 10:23:01   查看原文>>

CEPH作为对象存储时, 例如用于Openstack的对象存储. 如何查找对象在ceph的位置?
首选, 我们看看如何将数据作为对象存储到ceph : 
1. 需要选择一个池
2. 需要指定对象名
例如我把test.img放到ceph的pool1这个池.

[root@localhost rbd0]# ceph osd lspools
0 rbd,1 pool1,
[root@localhost rbd0]# rados lspools
rbd
pool1
[root@localhost rbd0]# ll
total 1024000
-rw-r--r-- 1 root root 1048576000 Dec 25 01:43 test.img


使用rados把这个文件放到pool1池, 对象名设置为test.img.digoal.

[root@localhost rbd0]# rados put test.img.digoal ./test.img --pool=pool1


查看池中的对象

[root@localhost rbd0]# rados ls --pool=pool1|grep test
test.img.digoal


查找对象在ceph集群的位置

[root@localhost rbd0]# ceph osd map pool1 test.img.digoal
osdmap e62 pool 'pool1' (1) object 'test.img.digoal' -> pg 1.79035c22 (1.22) -> up ([3,0], p3) acting ([3,0], p3)


导出对象

[root@localhost rbd0]# rm -f test.img 
[root@localhost rbd0]# rados get test.img.digoal ./test.img --pool=pool1
[root@localhost rbd0]# ll
total 1024000
-rw-r--r-- 1 root root 1048576000 Dec 25 18:19 test.img


查看对象的信息

[root@localhost rbd0]# rados stat test.img.digoal --pool=pool1
pool1/test.img.digoal mtime 1419502604, size 1048576000


删除对象

[root@localhost rbd0]# rados rm test.img.digoal --pool=pool1


[参考]
1. 

[root@localhost rbd0]# rados --help
usage: rados [options] [commands]
POOL COMMANDS
   lspools                          list pools
   mkpool <pool-name> [123[ 4]]     create pool <pool-name>'
                                    [with auid 123[and using crush rule 4]]
   cppool <pool-name> <dest-pool>   copy content of a pool
   rmpool <pool-name> [<pool-name> --yes-i-really-really-mean-it]
                                    remove pool <pool-name>'
   df                               show per-pool and total usage
   ls                               list objects in pool

   chown 123                        change the pool owner to auid 123

OBJECT COMMANDS
   get <obj-name> [outfile]         fetch object
   put <obj-name> [infile]          write object
   truncate <obj-name> length       truncate object
   create <obj-name> [category]     create object
   rm <obj-name> ...                remove object(s)
   cp <obj-name> [target-obj]       copy object
   clonedata <src-obj> <dst-obj>    clone object data
   listxattr <obj-name>
   getxattr <obj-name> attr
   setxattr <obj-name> attr val
   rmxattr <obj-name> attr
   stat objname                     stat the named object
   mapext <obj-name>
   lssnap                           list snaps
   mksnap <snap-name>               create snap <snap-name>
   rmsnap <snap-name>               remove snap <snap-name>
   rollback <obj-name> <snap-name>  roll back object to snap <snap-name>

   listsnaps <obj-name>             list the snapshots of this object
   bench <seconds> write|seq|rand [-t concurrent_operations] [--no-cleanup] [--run-name run_name]
                                    default is 16 concurrent IOs and 4 MB ops
                                    default is to clean up after write benchmark
                                    default run-name is 'benchmark_last_metadata'
   cleanup [--run-name run_name] [--prefix prefix]
                                    clean up a previous benchmark operation
                                    default run-name is 'benchmark_last_metadata'
   load-gen [options]               generate load on the cluster
   listomapkeys <obj-name>          list the keys in the object map
   listomapvals <obj-name>          list the keys and vals in the object map 
   getomapval <obj-name> <key> [file] show the value for the specified key
                                    in the object's object map
   setomapval <obj-name> <key> <val>
   rmomapkey <obj-name> <key>
   getomapheader <obj-name> [file]
   setomapheader <obj-name> <val>
   tmap-to-omap <obj-name>          convert tmap keys/values to omap
   listwatchers <obj-name>          list the watchers of this object
   set-alloc-hint <obj-name> <expected-object-size> <expected-write-size>
                                    set allocation hint for an object

IMPORT AND EXPORT
   import [options] <local-directory> <rados-pool>
       Upload <local-directory> to <rados-pool>
   export [options] <rados-pool> <local-directory>
       Download <rados-pool> to <local-directory>
   options:
       -f / --force                 Copy everything, even if it hasn't changed.
       -d / --delete-after          After synchronizing, delete unreferenced
                                    files or objects from the target bucket
                                    or directory.
       --workers                    Number of worker threads to spawn 
                                    (default 5)

ADVISORY LOCKS
   lock list <obj-name>
       List all advisory locks on an object
   lock get <obj-name> <lock-name>
       Try to acquire a lock
   lock break <obj-name> <lock-name> <locker-name>
       Try to break a lock acquired by another client
   lock info <obj-name> <lock-name>
       Show lock information
   options:
       --lock-tag                   Lock tag, all locks operation should use
                                    the same tag
       --lock-cookie                Locker cookie
       --lock-description           Description of lock
       --lock-duration              Lock duration (in seconds)
       --lock-type                  Lock type (shared, exclusive)

CACHE POOLS: (for testing/development only)
   cache-flush <obj-name>           flush cache pool object (blocking)
   cache-try-flush <obj-name>       flush cache pool object (non-blocking)
   cache-evict <obj-name>           evict cache pool object
   cache-flush-evict-all            flush+evict all objects
   cache-try-flush-evict-all        try-flush+evict all objects

GLOBAL OPTIONS:
   --object_locator object_locator
        set object_locator for operation
   -p pool
   --pool=pool
        select given pool by name
   --target-pool=pool
        select target pool by name
   -b op_size
        set the size of write ops for put or benchmarking
   -s name
   --snap name
        select given snap name for (read) IO
   -i infile
   --create
        create the pool or directory that was specified
   -N namespace
   --namespace=namespace
        specify the namespace to use for the object

BENCH OPTIONS:
   -t N
   --concurrent-ios=N
        Set number of concurrent I/O operations
   --show-time
        prefix output with date/time

LOAD GEN OPTIONS:
   --num-objects                    total number of objects
   --min-object-size                min object size
   --max-object-size                max object size
   --min-ops                        min number of operations
   --max-ops                        max number of operations
   --max-backlog                    max backlog (in MB)
   --percent                        percent of operations that are read
   --target-throughput              target throughput (in MB)
   --run-length                     total time (in seconds)


2. http://ceph.com/docs/master/rados/operations/monitoring-osd-pg/

To store object data in the Ceph Object Store, a Ceph client must:
1. Set an object name
2. Specify a pool

The Ceph client retrieves the latest cluster map and the CRUSH algorithm calculates how to map the object to a placement group, and then calculates how to assign the placement group to an OSD dynamically. To find the object location, all you need is the object name and the pool name. For example:

ceph osd map {poolname} {object-name}
Exercise: Locate an Object

As an exercise, lets create an object. Specify an object name, a path to a test file containing some object data and a pool name using the rados put command on the command line. For example:

rados put {object-name} {file-path} --pool=data
rados put test-object-1 testfile.txt --pool=data
To verify that the Ceph Object Store stored the object, execute the following:

rados -p data ls
Now, identify the object location:

ceph osd map {pool-name} {object-name}
ceph osd map data test-object-1
Ceph should output the object’s location. For example:

osdmap e537 pool 'data' (0) object 'test-object-1' -> pg 0.d1743484 (0.4) -> up [1,0] acting [1,0]
To remove the test object, simply delete it using the rados rm command. For example:

rados rm test-object-1 --pool=data
As the cluster evolves, the object location may change dynamically. One benefit of Ceph’s dynamic rebalancing is that Ceph relieves you from having to perform the migration manually. See the Architecture section for details.


Flag Counter
