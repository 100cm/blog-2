PostgreSQL research

PostgreSQL parallel realtime stat for stream data

2014-12-14 21:03:42   查看原文>>

    本文还是讲一下流式数据的并行处理方法. 为什么要解决这个问题呢?
    看以下图, 进程0的会话先开启, 但是相比进程15后提交. 当我们在统计时, 如果以序列或时间搓为截至点来区分统计offset的话, 可能导致进程0的事务信息在统计中统计不到.
PostgreSQL parallel realtime stat for stream data - 德哥@Digoal - PostgreSQL research
    前面写过一些例子, 使用XID来解决并行写入带来的数据统计信息量丢失的问题.
    具体可以参考 :
1. http://blog.163.com/digoal@126/blog/static/163877040201331252945440/
2. http://blog.163.com/digoal@126/blog/static/16387704020133151402415/
3. http://blog.163.com/digoal@126/blog/static/16387704020133155179877/
4. http://blog.163.com/digoal@126/blog/static/16387704020133156636579/
5. http://blog.163.com/digoal@126/blog/static/16387704020133218305242/
6. http://blog.163.com/digoal@126/blog/static/16387704020133224161563/
7. http://blog.163.com/digoal@126/blog/static/16387704020133271134563/
8. http://blog.163.com/digoal@126/blog/static/16387704020134311144755/
9. http://blog.163.com/digoal@126/blog/static/1638770402013113044354661/
10. http://blog.163.com/digoal@126/blog/static/16387704020137111254816/
    注意使用XID来规避统计信息量丢失的问题会带来流水数据插入的性能问题, 统计也有一定的影响, 并且设计比较复杂, 例如当需要逻辑迁移时, 数据库的控制文件中的XID必须做出调整来配合流水数据的实时统计持续可用.
    为了避免以上问题, 我在第10篇文档中指出, 可用用单线程插入来解决流水数据实时统计信息量丢失的问题.
    那么问题来了, 
    单线程的插入其实可能导致插入的性能有问题, 或者开发会认为这样设计是不合理的, 因为如果单线程出问题的话, 数据就无法实时入库, (例如线程堵塞).
    PostgreSQL parallel realtime stat for stream data - 德哥@Digoal - PostgreSQL research
    上图只有一个会话在插入流式数据, 所以单个会话来抽取数据统计不会造成信息量丢失.
    但是这种架构也有问题, 如果这个插入进程异常了, 数据就完全没法入库, (当然可以引入其他技术来保障)
    我们接下来看看其他解决办法, 要做到并行的插入和并行的统计.
方法较多,
1. 创建多个表, 每个进程对应一个表, 对于单表来说, 插入是串行的, 所以解决了上图的问题. 统计的话, 不同的表可以并行统计, 单表只能一个统计进程.
PostgreSQL parallel realtime stat for stream data - 德哥@Digoal - PostgreSQL research
 2. 方法2, 和上图唯一的区别是, 使用序列, 并且序列使用同样的步调, 但是设置不一样的起始值. 
例如 : 
CREATE SEQUENCE seq0  INCREMENT  BY 16
    MINVALUE 0
    START WITH 0;
CREATE SEQUENCE seq1  INCREMENT  BY 16
    MINVALUE 1
    START WITH 1;
....
CREATE SEQUENCE seq15  INCREMENT  BY 16
    MINVALUE 15
    START WITH 15;
这么做的好处是, 即使数据合并到一个表也没有问题, 接着看后面的图.
PostgreSQL parallel realtime stat for stream data - 德哥@Digoal - PostgreSQL research
 3. 方法3, 就是合并成一个表了, 因为每个进程的步调一致, 起始值不一致, 所以同样可以做到并行插入和并行统计.
需要注意的是, 并行统计也需要按规则隔开, 例如本例的mod.
统计进程0
select * from tbl where mod(id,16)=0 and id>=offset_id limit xx;
统计进程1
select * from tbl where mod(id,16)=1 and id>=offset_id limit xx;
统计进程15
select * from tbl where mod(id,16)=15 and id>=offset_id limit xx;
PostgreSQL parallel realtime stat for stream data - 德哥@Digoal - PostgreSQL research
 4. 方法4 , 方法和前面基本一致, 只是使用了触发器把单一的表又分开了.
这么做的坏处是, 写入时需要处理触发器逻辑
好处是, 统计时不需要加mod条件, 因为已经分表了.
统计进程0
select * from tbl_0 where id>=offset_id limit xx;
统计进程1
select * from tbl_1 where id>=offset_id limit xx;
统计进程15
select * from tbl_15 where id>=offset_id limit xx;
PostgreSQL parallel realtime stat for stream data - 德哥@Digoal - PostgreSQL research

关于插入的性能提升点 : 
1. 使用批量提交
例如insert into tbl values (),(),(),......();
2. XLOG使用异步flush
3. 建议使用大块(datafile block)
4. 建议使用huge page

统计性能提升点
1. 建议对条件ID建立索引
2. 建议使用大块(datafile block)
3. 建议使用huge page

最后, 怎么让单表的统计并行度提高呢?
方法1. 
使用更细粒度的模, 但是注意不能和当前插入模交叉, 
例如插入的模是16, 那么统计的模我们可以使用16的倍数, 例如32, 48, 64(但是建议采用2的N次方, 即48不建议使用). 
所以以上例子, 我们的统计并行可以增加到64 例如 : 
统计进程0
select * from tbl where mod(id,64)=0 and id>=offset_id limit xx;
统计进程1
select * from tbl where mod(id,64)=1 and id>=offset_id limit xx;
统计进程63
select * from tbl where mod(id,64)=63 and id>=offset_id limit xx;
如果是多表的话, 注意区间必须一致 
统计进程0,1,2,3分别对应统计SQL
select * from tbl_0 where mod(id,64)=0 and id>=offset_id limit xx;
select * from tbl_0 where mod(id,64)=16 and id>=offset_id limit xx;
select * from tbl_0 where mod(id,64)=32 and id>=offset_id limit xx;
select * from tbl_0 where mod(id,64)=48 and id>=offset_id limit xx;
统计进程4,5,6,7分别对应统计SQL
select * from tbl_1 where mod(id,64)=1 and id>=offset_id limit xx;
select * from tbl_1 where mod(id,64)=17 and id>=offset_id limit xx;
select * from tbl_1 where mod(id,64)=33 and id>=offset_id limit xx;
select * from tbl_1 where mod(id,64)=49 and id>=offset_id limit xx;
统计进程60,61,62,63分别对应统计SQL
select * from tbl_15 where mod(id,64)=15 and id>=offset_id limit xx;
select * from tbl_15 where mod(id,64)=31 and id>=offset_id limit xx;
select * from tbl_15 where mod(id,64)=47 and id>=offset_id limit xx;
select * from tbl_15 where mod(id,64)=63 and id>=offset_id limit xx;

[参考]
1. http://blog.163.com/digoal@126/blog/static/163877040201331252945440/
2. http://blog.163.com/digoal@126/blog/static/16387704020133151402415/
3. http://blog.163.com/digoal@126/blog/static/16387704020133155179877/
4. http://blog.163.com/digoal@126/blog/static/16387704020133156636579/
5. http://blog.163.com/digoal@126/blog/static/16387704020133218305242/
6. http://blog.163.com/digoal@126/blog/static/16387704020133224161563/
7. http://blog.163.com/digoal@126/blog/static/16387704020133271134563/
8. http://blog.163.com/digoal@126/blog/static/16387704020134311144755/
9. http://blog.163.com/digoal@126/blog/static/1638770402013113044354661/
10. http://blog.163.com/digoal@126/blog/static/16387704020137111254816/

Flag Counter
