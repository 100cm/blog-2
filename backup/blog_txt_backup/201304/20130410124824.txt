PostgreSQL research

Postgres-XC table inherits use caveat

2013-04-10 12:48:24   查看原文>>

上一篇blog介绍了Postgres-XC 1.1 devel版本对limit的改进, 可以将limit 限制forward到datanode节点.
但是这种forward仅限于没有子表的查询. 如果有子表的话, 将会收集本表以及所有子表的数据到coordiantor节点, 然后在结果集上做limit.
同样很有可能造成coordinator节点崩溃.
例如 : 
接上一个例子的环境 : 
http://blog.163.com/digoal@126/blog/static/16387704020133108138729/
一, 1.1devel : 

[pgxc@db-192-168-122-172 ~]$ psql
psql (PGXC 1.1devel, based on PG 9.2beta2)
Type "help" for help.
postgres=# create table test1 (like test including all) inherits(test) distribute by hash(id) to group gp0;
NOTICE:  merging column "id" with inherited definition
NOTICE:  merging column "info" with inherited definition
NOTICE:  merging column "crt_time" with inherited definition
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "test1_pkey" for table "test1"
CREATE TABLE
postgres=# insert into test1 select * from only test;
INSERT 0 10000


#在父表上使用limit, 无法forward limit到所有子表, 而是选择将所有数据收集到coordinator节点. not good.

postgres=# explain analyze verbose select * from test limit 1;
                                                                   QUERY PLAN                                                       
             
------------------------------------------------------------------------------------------------------------------------------------
-------------
 Limit  (cost=0.00..0.00 rows=1 width=44) (actual time=4.991..5.007 rows=1 loops=1)
   Output: public.test.id, public.test.info, public.test.crt_time
   ->  Result  (cost=0.00..0.00 rows=2000 width=44) (actual time=4.948..4.948 rows=1 loops=1)
         Output: public.test.id, public.test.info, public.test.crt_time
         ->  Append  (cost=0.00..0.00 rows=2000 width=44) (actual time=4.945..4.945 rows=1 loops=1)
               ->  Data Node Scan on test "_REMOTE_TABLE_QUERY_"  (cost=0.00..0.00 rows=1000 width=44) (actual time=4.943..4.943 row
s=1 loops=1)
                     Output: public.test.id, public.test.info, public.test.crt_time
                     Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5, datanode_6
                     Remote query: SELECT id, info, crt_time FROM ONLY test WHERE true
               ->  Data Node Scan on test1 "_REMOTE_TABLE_QUERY_"  (cost=0.00..0.00 rows=1000 width=44) (never executed)
                     Output: public.test.id, public.test.info, public.test.crt_time
                     Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5, datanode_6
                     Remote query: SELECT id, info, crt_time FROM ONLY test1 test WHERE true
 Total runtime: 19.123 ms
(14 rows)


# 加上only后, 只涉及父表本身的查询, limit会forward到datanode节点执行. good.

postgres=# explain analyze verbose select * from only test limit 1;
                                                            QUERY PLAN                                                            
----------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.00..0.00 rows=1 width=44) (actual time=1.817..1.818 rows=1 loops=1)
   Output: test.id, test.info, test.crt_time
   ->  Data Node Scan on "__REMOTE_LIMIT_QUERY__"  (cost=0.00..0.00 rows=1000 width=44) (actual time=1.812..1.812 rows=1 loops=1)
         Output: test.id, test.info, test.crt_time
         Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5, datanode_6
         Remote query: SELECT id, info, crt_time FROM ONLY test WHERE true LIMIT 1::bigint
 Total runtime: 1.860 ms
(7 rows)


# 直接查询没有子表的表, limit会forward到datanode节点执行. good.

postgres=# explain analyze verbose select * from test1 limit 1;
                                                            QUERY PLAN                                                            
----------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.00..0.00 rows=1 width=44) (actual time=1.359..1.360 rows=1 loops=1)
   Output: test1.id, test1.info, test1.crt_time
   ->  Data Node Scan on "__REMOTE_LIMIT_QUERY__"  (cost=0.00..0.00 rows=1000 width=44) (actual time=1.355..1.355 rows=1 loops=1)
         Output: test1.id, test1.info, test1.crt_time
         Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5, datanode_6
         Remote query: SELECT id, info, crt_time FROM ONLY test1 WHERE true LIMIT 1::bigint
 Total runtime: 1.411 ms
(7 rows)



group by, 聚合 : 
# 在父表上执行聚合函数, 会将所有数据收集到coordinator节点. 然后在coordinator节点执行聚合. not good.

postgres=# explain analyze verbose select count(*) from test;
                                                                   QUERY PLAN                                                       
            
------------------------------------------------------------------------------------------------------------------------------------
------------
 Aggregate  (cost=5.00..5.01 rows=1 width=0) (actual time=170.892..170.893 rows=1 loops=1)
   Output: count(*)
   ->  Append  (cost=0.00..0.00 rows=2000 width=0) (actual time=3.378..149.182 rows=20000 loops=1)
         ->  Data Node Scan on test "_REMOTE_TABLE_QUERY_"  (cost=0.00..0.00 rows=1000 width=0) (actual time=3.376..74.922 rows=1000
0 loops=1)
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5, datanode_6
               Remote query: SELECT * FROM ONLY test WHERE true
         ->  Data Node Scan on test1 "_REMOTE_TABLE_QUERY_"  (cost=0.00..0.00 rows=1000 width=0) (actual time=1.674..37.833 rows=100
00 loops=1)
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5, datanode_6
               Remote query: SELECT * FROM ONLY test1 test WHERE true
 Total runtime: 172.398 ms
(10 rows)

postgres=# explain analyze verbose select id,count(*) from test group by id;
                                                                   QUERY PLAN                                                       
            
------------------------------------------------------------------------------------------------------------------------------------
------------
 HashAggregate  (cost=10.00..10.20 rows=20 width=4) (actual time=75.885..83.446 rows=10000 loops=1)
   Output: public.test.id, count(*)
   ->  Append  (cost=0.00..0.00 rows=2000 width=4) (actual time=1.736..53.459 rows=20000 loops=1)
         ->  Data Node Scan on test "_REMOTE_TABLE_QUERY_"  (cost=0.00..0.00 rows=1000 width=4) (actual time=1.735..15.704 rows=1000
0 loops=1)
               Output: public.test.id
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5, datanode_6
               Remote query: SELECT id FROM ONLY test WHERE true
         ->  Data Node Scan on test1 "_REMOTE_TABLE_QUERY_"  (cost=0.00..0.00 rows=1000 width=4) (actual time=1.046..15.357 rows=100
00 loops=1)
               Output: public.test.id
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5, datanode_6
               Remote query: SELECT id FROM ONLY test1 test WHERE true
 Total runtime: 89.316 ms
(12 rows)


# 在父表加上only后, 执行聚合函数, 聚合函数将forward到子节点执行, 然后在coordinator节点计算聚合后的数据. good.
# 如果group by的不是分布列, 那么在coordinator节点还需要对datanode节点聚合后的数据再次聚合. 
# 例如这里的test表的分布列为id, 当group by info时需要对datanode节点聚合后的数据再次聚合. 

postgres=# explain analyze verbose select id,count(*) from only test group by id;
                                                        QUERY PLAN                                                         
---------------------------------------------------------------------------------------------------------------------------
 Data Node Scan on "__REMOTE_FQS_QUERY__"  (cost=0.00..0.00 rows=0 width=0) (actual time=3.309..17.280 rows=10000 loops=1)
   Output: test.id, (count(*))
   Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5, datanode_6
   Remote query: SELECT id, count(*) AS count FROM ONLY test GROUP BY id
 Total runtime: 23.205 ms
(5 rows)

postgres=# explain analyze verbose select count(*) from only test;
                                                           QUERY PLAN                                                            
---------------------------------------------------------------------------------------------------------------------------------
 Aggregate  (cost=2.50..2.51 rows=1 width=0) (actual time=2.096..2.096 rows=1 loops=1)
   Output: pg_catalog.count(*)
   ->  Data Node Scan on "__REMOTE_GROUP_QUERY__"  (cost=0.00..0.00 rows=1000 width=0) (actual time=2.053..2.062 rows=6 loops=1)
         Output: (count(*))
         Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5, datanode_6
         Remote query: SELECT count(*) FROM ONLY test WHERE true
 Total runtime: 2.153 ms
(7 rows)

postgres=# explain analyze verbose select id,avg(hashtext(info)) from only test group by id;
                                                        QUERY PLAN                                                         
---------------------------------------------------------------------------------------------------------------------------
 Data Node Scan on "__REMOTE_FQS_QUERY__"  (cost=0.00..0.00 rows=0 width=0) (actual time=9.025..29.709 rows=10000 loops=1)
   Output: test.id, (avg(hashtext(test.info)))
   Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5, datanode_6
   Remote query: SELECT id, pg_catalog.int8_avg(avg(hashtext(info))) AS avg FROM ONLY test GROUP BY id
 Total runtime: 35.809 ms
(5 rows)

postgres=# explain analyze verbose select info,avg(id) from only test group by info;
                                                              QUERY PLAN                                                            
   
------------------------------------------------------------------------------------------------------------------------------------
---
 HashAggregate  (cost=5.00..5.12 rows=10 width=36) (actual time=58.321..75.511 rows=10000 loops=1)
   Output: test.info, pg_catalog.avg((avg(test.id)))
   ->  Data Node Scan on "__REMOTE_GROUP_QUERY__"  (cost=0.00..0.00 rows=1000 width=36) (actual time=3.433..39.408 rows=10000 loops=
1)
         Output: test.info, (avg(test.id))
         Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5, datanode_6
         Remote query: SELECT info, avg(id) FROM ONLY test WHERE true GROUP BY 1
 Total runtime: 98.433 ms
(7 rows)



where条件 : 
# 在父表上执行SQL中包含where条件时, 可以forward到datanode节点. good.

postgres=# explain analyze verbose select * from test where id=1;
                                                                 QUERY PLAN                                                         
        
------------------------------------------------------------------------------------------------------------------------------------
--------
 Result  (cost=0.00..0.00 rows=2000 width=44) (actual time=3.211..4.404 rows=2 loops=1)
   Output: public.test.id, public.test.info, public.test.crt_time
   ->  Append  (cost=0.00..0.00 rows=2000 width=44) (actual time=3.208..4.398 rows=2 loops=1)
         ->  Data Node Scan on test "_REMOTE_TABLE_QUERY_"  (cost=0.00..0.00 rows=1000 width=44) (actual time=3.206..3.207 rows=1 lo
ops=1)
               Output: public.test.id, public.test.info, public.test.crt_time
               Node/s: datanode_3
               Remote query: SELECT id, info, crt_time FROM ONLY test WHERE (id = 1)
         ->  Data Node Scan on test1 "_REMOTE_TABLE_QUERY_"  (cost=0.00..0.00 rows=1000 width=44) (actual time=1.181..1.183 rows=1 l
oops=1)
               Output: public.test.id, public.test.info, public.test.crt_time
               Node/s: datanode_3
               Remote query: SELECT id, info, crt_time FROM ONLY test1 test WHERE (id = 1)
 Total runtime: 4.449 ms
(12 rows)

postgres=# explain analyze verbose select * from test where info='abc';
                                                                 QUERY PLAN                                                         
        
------------------------------------------------------------------------------------------------------------------------------------
--------
 Result  (cost=0.00..0.00 rows=2000 width=44) (actual time=5.822..5.822 rows=0 loops=1)
   Output: public.test.id, public.test.info, public.test.crt_time
   ->  Append  (cost=0.00..0.00 rows=2000 width=44) (actual time=5.819..5.819 rows=0 loops=1)
         ->  Data Node Scan on test "_REMOTE_TABLE_QUERY_"  (cost=0.00..0.00 rows=1000 width=44) (actual time=3.811..3.811 rows=0 lo
ops=1)
               Output: public.test.id, public.test.info, public.test.crt_time
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5, datanode_6
               Remote query: SELECT id, info, crt_time FROM ONLY test WHERE (info = 'abc'::text)
         ->  Data Node Scan on test1 "_REMOTE_TABLE_QUERY_"  (cost=0.00..0.00 rows=1000 width=44) (actual time=2.005..2.005 rows=0 l
oops=1)
               Output: public.test.id, public.test.info, public.test.crt_time
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5, datanode_6
               Remote query: SELECT id, info, crt_time FROM ONLY test1 test WHERE (info = 'abc'::text)
 Total runtime: 5.863 ms
(12 rows)



二, 1.0.2 : 

[postgres@db-172-16-19-13 ~]$ psql
psql (PGXC 1.0.2, based on PG 9.1.7)
Type "help" for help.
digoal=> create table test1(like test including all) inherits(test) distribute by hash(id) to group gp0;
NOTICE:  merging column "id" with inherited definition
NOTICE:  merging column "info" with inherited definition
NOTICE:  merging column "crt_time" with inherited definition
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index "test1_pkey" for table "test1"
CREATE TABLE
digoal=> insert into test1 select * from only test;
INSERT 0 10000


#在父表上使用limit, 无法forward limit到所有子表, 而是选择将所有数据收集到coordinator节点. not good.

digoal=> explain analyze verbose select * from test limit 1;
                                                        QUERY PLAN                                                        
--------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.00..0.00 rows=1 width=44) (actual time=0.934..0.935 rows=1 loops=1)
   Output: digoal.test.id, digoal.test.info, digoal.test.crt_time
   ->  Result  (cost=0.00..0.00 rows=2000 width=44) (actual time=0.933..0.933 rows=1 loops=1)
         Output: digoal.test.id, digoal.test.info, digoal.test.crt_time
         ->  Append  (cost=0.00..0.00 rows=2000 width=44) (actual time=0.931..0.931 rows=1 loops=1)
               ->  Data Node Scan on test  (cost=0.00..0.00 rows=1000 width=44) (actual time=0.931..0.931 rows=1 loops=1)
                     Output: digoal.test.id, digoal.test.info, digoal.test.crt_time
                     Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5
                     Remote query: SELECT id, info, crt_time FROM ONLY test WHERE true
               ->  Data Node Scan on test  (cost=0.00..0.00 rows=1000 width=44) (never executed)
                     Output: digoal.test.id, digoal.test.info, digoal.test.crt_time
                     Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5
                     Remote query: SELECT id, info, crt_time FROM ONLY test1 test WHERE true
 Total runtime: 11.654 ms
(14 rows)


# 加上only后, 只涉及父表本身的查询, 1.1devel 的话limit会forward到datanode节点执行. 但是1.0.2版本不会. 所以1.0.2 这里not good.
# 对于1.0.2 可以选择使用 execute direct on datanode_1 $$select * from only test limit 1$$;

digoal=> explain analyze verbose select * from only test limit 1;
                                                     QUERY PLAN                                                     
--------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.00..0.00 rows=1 width=44) (actual time=0.870..0.870 rows=1 loops=1)
   Output: id, info, crt_time
   ->  Result  (cost=0.00..0.00 rows=1000 width=44) (actual time=0.869..0.869 rows=1 loops=1)
         Output: id, info, crt_time
         ->  Data Node Scan on test  (cost=0.00..0.00 rows=1000 width=44) (actual time=0.868..0.868 rows=1 loops=1)
               Output: id, info, crt_time
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5
               Remote query: SELECT id, info, crt_time FROM ONLY test WHERE true
 Total runtime: 12.637 ms
(9 rows)

digoal=> explain analyze verbose select * from test1 limit 1;
                                                     QUERY PLAN                                                      
---------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.00..0.00 rows=1 width=44) (actual time=0.801..0.802 rows=1 loops=1)
   Output: id, info, crt_time
   ->  Result  (cost=0.00..0.00 rows=1000 width=44) (actual time=0.800..0.800 rows=1 loops=1)
         Output: id, info, crt_time
         ->  Data Node Scan on test1  (cost=0.00..0.00 rows=1000 width=44) (actual time=0.799..0.799 rows=1 loops=1)
               Output: id, info, crt_time
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5
               Remote query: SELECT id, info, crt_time FROM ONLY test1 WHERE true
 Total runtime: 12.472 ms
(9 rows)



group by, 聚合 : 
# 在父表上执行聚合函数, 会将所有数据收集到coordinator节点. 然后在coordinator节点执行聚合. not good.

digoal=> explain analyze verbose select count(*) from test;
                                                       QUERY PLAN                                                       
------------------------------------------------------------------------------------------------------------------------
 Aggregate  (cost=5.00..5.01 rows=1 width=0) (actual time=49.958..49.958 rows=1 loops=1)
   Output: count(*)
   ->  Append  (cost=0.00..0.00 rows=2000 width=0) (actual time=0.702..46.892 rows=20000 loops=1)
         ->  Data Node Scan on test  (cost=0.00..0.00 rows=1000 width=0) (actual time=0.702..22.739 rows=10000 loops=1)
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5
               Remote query: SELECT * FROM ONLY test WHERE true
         ->  Data Node Scan on test  (cost=0.00..0.00 rows=1000 width=0) (actual time=0.727..20.450 rows=10000 loops=1)
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5
               Remote query: SELECT * FROM ONLY test1 test WHERE true
 Total runtime: 50.465 ms
(10 rows)

digoal=> explain analyze verbose select id,count(*) from test group by id;
                                                      QUERY PLAN                                                       
-----------------------------------------------------------------------------------------------------------------------
 HashAggregate  (cost=10.00..10.02 rows=2 width=4) (actual time=29.463..31.808 rows=10000 loops=1)
   Output: digoal.test.id, count(*)
   ->  Append  (cost=0.00..0.00 rows=2000 width=4) (actual time=0.744..19.747 rows=20000 loops=1)
         ->  Data Node Scan on test  (cost=0.00..0.00 rows=1000 width=4) (actual time=0.743..8.637 rows=10000 loops=1)
               Output: digoal.test.id
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5
               Remote query: SELECT id FROM ONLY test WHERE true
         ->  Data Node Scan on test  (cost=0.00..0.00 rows=1000 width=4) (actual time=0.594..7.087 rows=10000 loops=1)
               Output: digoal.test.id
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5
               Remote query: SELECT id FROM ONLY test1 test WHERE true
 Total runtime: 32.980 ms
(12 rows)


# 在父表加上only后, 执行聚合函数, 聚合函数将forward到子节点执行, 然后在coordinator节点计算聚合后的数据. good.
# 如果group by的不是分布列, 那么在coordinator节点还需要对datanode节点聚合后的数据再次聚合. 
# 例如这里的test表的分布列为id, 当group by info时需要对datanode节点聚合后的数据再次聚合. 

digoal=> explain analyze verbose select id,count(*) from only test group by id;
                                                                 QUERY PLAN                                                         
        
------------------------------------------------------------------------------------------------------------------------------------
--------
 HashAggregate  (cost=5.00..5.01 rows=1 width=4) (actual time=26.008..28.199 rows=10000 loops=1)
   Output: test.id, pg_catalog.count(*)
   ->  Materialize  (cost=0.00..0.00 rows=0 width=0) (actual time=1.929..12.927 rows=10000 loops=1)
         Output: test.id, (count(*))
         ->  Data Node Scan on "__REMOTE_GROUP_QUERY__"  (cost=0.00..0.00 rows=1000 width=4) (actual time=1.929..10.610 rows=10000 l
oops=1)
               Output: test.id, count(*)
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5
               Remote query: SELECT group_1.id, count(*)  FROM (SELECT id, info, crt_time FROM ONLY test WHERE true) group_1 GROUP B
Y 1  
 Total runtime: 29.236 ms
(9 rows)

digoal=> explain analyze verbose select count(*) from only test;
                                                              QUERY PLAN                                                            
   
------------------------------------------------------------------------------------------------------------------------------------
---
 Aggregate  (cost=2.50..2.51 rows=1 width=0) (actual time=0.845..0.846 rows=1 loops=1)
   Output: pg_catalog.count(*)
   ->  Materialize  (cost=0.00..0.00 rows=0 width=0) (actual time=0.821..0.831 rows=5 loops=1)
         Output: (count(*))
         ->  Data Node Scan on "__REMOTE_GROUP_QUERY__"  (cost=0.00..0.00 rows=1000 width=0) (actual time=0.820..0.830 rows=5 loops=
1)
               Output: count(*)
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5
               Remote query: SELECT count(*)  FROM (SELECT id, info, crt_time FROM ONLY test WHERE true) group_1   
 Total runtime: 0.879 ms
(9 rows)

digoal=> explain analyze verbose select id,avg(hashtext(info)) from only test group by id;
                                                                         QUERY PLAN                                                 
                         
------------------------------------------------------------------------------------------------------------------------------------
-------------------------
 HashAggregate  (cost=7.50..7.51 rows=1 width=36) (actual time=61.675..70.284 rows=10000 loops=1)
   Output: test.id, pg_catalog.avg((avg(hashtext(test.info))))
   ->  Materialize  (cost=0.00..0.00 rows=0 width=0) (actual time=9.465..52.209 rows=10000 loops=1)
         Output: test.id, (avg(hashtext(test.info)))
         ->  Data Node Scan on "__REMOTE_GROUP_QUERY__"  (cost=0.00..0.00 rows=1000 width=36) (actual time=9.464..49.767 rows=10000 
loops=1)
               Output: test.id, avg(hashtext(test.info))
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5
               Remote query: SELECT group_1.id, avg(hashtext(group_1.info))  FROM (SELECT id, info, crt_time FROM ONLY test WHERE tr
ue) group_1 GROUP BY 1  
 Total runtime: 72.024 ms
(9 rows)

digoal=> explain analyze verbose select info,avg(id) from only test group by info;
                                                                    QUERY PLAN                                                      
               
------------------------------------------------------------------------------------------------------------------------------------
---------------
 HashAggregate  (cost=5.00..5.01 rows=1 width=36) (actual time=36.358..45.066 rows=10000 loops=1)
   Output: test.info, pg_catalog.avg((avg(test.id)))
   ->  Materialize  (cost=0.00..0.00 rows=0 width=0) (actual time=2.751..26.584 rows=10000 loops=1)
         Output: test.info, (avg(test.id))
         ->  Data Node Scan on "__REMOTE_GROUP_QUERY__"  (cost=0.00..0.00 rows=1000 width=36) (actual time=2.749..24.266 rows=10000 
loops=1)
               Output: test.info, avg(test.id)
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5
               Remote query: SELECT group_1.info, avg(group_1.id)  FROM (SELECT id, info, crt_time FROM ONLY test WHERE true) group_
1 GROUP BY 1  
 Total runtime: 46.274 ms
(9 rows)



where条件 : 
# 在父表上执行SQL中包含where条件时, 可以forward到datanode节点. good.

digoal=> explain analyze verbose select * from test where id=1;
                                                      QUERY PLAN                                                      
----------------------------------------------------------------------------------------------------------------------
 Result  (cost=0.00..0.00 rows=2000 width=44) (actual time=21.564..21.828 rows=2 loops=1)
   Output: digoal.test.id, digoal.test.info, digoal.test.crt_time
   ->  Append  (cost=0.00..0.00 rows=2000 width=44) (actual time=21.562..21.822 rows=2 loops=1)
         ->  Data Node Scan on test  (cost=0.00..0.00 rows=1000 width=44) (actual time=21.562..21.562 rows=1 loops=1)
               Output: digoal.test.id, digoal.test.info, digoal.test.crt_time
               Node/s: datanode_2
               Remote query: SELECT id, info, crt_time FROM ONLY test WHERE (id = 1)
         ->  Data Node Scan on test  (cost=0.00..0.00 rows=1000 width=44) (actual time=0.260..0.260 rows=1 loops=1)
               Output: digoal.test.id, digoal.test.info, digoal.test.crt_time
               Node/s: datanode_2
               Remote query: SELECT id, info, crt_time FROM ONLY test1 test WHERE (id = 1)
 Total runtime: 21.856 ms
(12 rows)

digoal=> explain analyze verbose select * from test where info='abc';
                                                      QUERY PLAN                                                      
----------------------------------------------------------------------------------------------------------------------
 Result  (cost=0.00..0.00 rows=2000 width=44) (actual time=31.395..31.395 rows=0 loops=1)
   Output: digoal.test.id, digoal.test.info, digoal.test.crt_time
   ->  Append  (cost=0.00..0.00 rows=2000 width=44) (actual time=31.395..31.395 rows=0 loops=1)
         ->  Data Node Scan on test  (cost=0.00..0.00 rows=1000 width=44) (actual time=30.584..30.584 rows=0 loops=1)
               Output: digoal.test.id, digoal.test.info, digoal.test.crt_time
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5
               Remote query: SELECT id, info, crt_time FROM ONLY test WHERE (info = 'abc'::text)
         ->  Data Node Scan on test  (cost=0.00..0.00 rows=1000 width=44) (actual time=0.809..0.809 rows=0 loops=1)
               Output: digoal.test.id, digoal.test.info, digoal.test.crt_time
               Node/s: datanode_1, datanode_2, datanode_3, datanode_4, datanode_5
               Remote query: SELECT id, info, crt_time FROM ONLY test1 test WHERE (info = 'abc'::text)
 Total runtime: 31.423 ms
(12 rows)



[小结]
1. 不要在父表上使用limit. 因为目前的Postgres-XC版本, 在父表上使用limit将导致查询所有数据汇总到coordinator后limit.
2. 不要在父表上使用聚合函数, 理由同上.
3. 1.0.2 的版本不要使用limit , 如果要使用, 请加上execute direct on datanode $$sql$$;

