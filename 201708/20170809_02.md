## 数据库metascan - 存储级、块级、batch级过滤与数据编排  
                     
### 作者                      
digoal                     
                       
### 日期                       
2017-08-09                 
                                
### 标签                
PostgreSQL , metascan , 块级过滤 , 块级统计信息 , BATCH级统计信息 , brin , 区间索引 , 块级索引 , batch级索引 , 数据编排 , 存储计算分离 , 混合编排 , 分段编排         
                
----                
                 
## 背景     
为了加速数据的检索效率，我们通常需要对数据创建索引，提高数据定位的精准性。例如查询某人某个月的通话流水数据，没有索引的话，我们需要搜索所有的数据，逐条匹配。通过索引，可以直接定位到需要查询的记录。  
  
特别是在存储和计算分离时，如果搜索量越大，网络中传输的数据量就越大。瓶颈很明显。  
  
另外，在OLAP领域，需要对大量的数据进行处理，如果都建索引，索引引入的开销还是蛮大的。  
  
那么有没有其他方法，不建索引降低扫描量呢？  
  
## 存储层统计和过滤下推  
相信大家一定已经想到了，统计信息，没错我们可以对存储的数据，按块进行数据统计，例如每个块内的数据范围。  
  
有几个非常常见的技术实现：  
  
1、PostgreSQL BRIN索引。  
  
[《PostgreSQL 物联网黑科技 - 瘦身几百倍的索引(BRIN index)》](../201604/20160414_01.md)    
  
https://www.postgresql.org/docs/10/static/brin-intro.html  
  
PostgreSQL brin索引就是块级索引，记录的是每个块、或者每一批连续的块的统计信息。  
  
在按这个列搜索时，通过元数据，过滤不相干的块。  
  
2、cstore_fdw列存储插件。实际上它也是按BATCH编排的列存储，每个BATCH的元数据（最大值、最小值）可以用于扫描时的过滤。  
  
https://github.com/citusdata/cstore_fdw  
  
Skip indexes: Stores min/max statistics for row groups, and uses them to skip over unrelated rows.  
  
**Using Skip Indexes**  
  
cstore_fdw partitions each column into multiple blocks. Skip indexes store minimum and maximum values for each of these blocks. While scanning the table, if min/max values of the block contradict the WHERE clause, then the block is completely skipped. This way, the query processes less data and hence finishes faster.  
  
To use skip indexes more efficiently, you should load the data after sorting it on a column that is commonly used in the WHERE clause. This ensures that there is a minimum overlap between blocks and the chance of them being skipped is higher.  
  
In practice, the data generally has an inherent dimension (for example a time field) on which it is naturally sorted. Usually, the queries also have a filter clause on that column (for example you want to query only the last week's data), and hence you don't need to sort the data in such cases.  
  
在按这个列搜索时，通过元数据，过滤不相干的块。  
  
例子  
  
```  
某个300GB的外部表，采样skip index扫描，加速扫描。耗时103毫秒。  
  
explain (analyze,verbose,timing,costs,buffers) select c400,sum(c2) from ft_tbl1 where c400=1 group by c400;  
  
         Filter: (ft_tbl1.c400 = 1)  
         Rows Removed by Filter: 89996    
         CStore File: /data01/digoal/pg_root1921/cstore_fdw/13146/41038  
         CStore File Size: 325166400400  
         Buffers: shared hit=8004  
 Planning time: 52.524 ms  
 Execution time: 103.555 ms  
(13 rows)  
  
不使用where c400=1，耗时89秒  
explain (analyze,verbose,timing,costs,buffers) select c400,sum(c2) from ft_tbl1  group by c400;  
  
         CStore File: /data01/digoal/pg_root1921/cstore_fdw/13146/41038  
         CStore File Size: 325166400400  
         Buffers: shared hit=8004  
 Planning time: 52.691 ms  
 Execution time: 89428.721 ms  
```  
  
需要提一下，目前cstore_fdw这个插件没有支持并行计算，而实际上PostgreSQL的fdw接口已经支持了并行计算，cstore_fdw只需要改造一下，即可支持并行计算。  
  
如下  
  
https://www.postgresql.org/docs/10/static/fdw-callbacks.html#fdw-callbacks-parallel  
  
## 过滤效率与线性相关性  
注意，由于数据存储的关系，并不是所有列的统计信息过滤性都很好。举个例子：  
  
某列的写入很随机，导致值的分布很随机，那么在一个数据块里面包含的数据范围可能比较大，这种列的存储元信息过滤性就很差。  
  
```  
create table a(id int, c1 int);  
insert into a select generate_series(1,1000000), random()*1000000;  
```  
  
数据的分布如下  
  
```  
postgres=# select substring(ctid::text, '(\d+),')::int8 blkid, min(c1) min_c1, max(c1) max_c1, min(id) min_id, max(id) max_id from a group by 1 order by 1;  
 blkid | min_c1 | max_c1 | min_id | max_id    
-------+--------+--------+--------+---------  
     0 |   2697 | 998322 |      1 |     909  
     1 |   1065 | 998817 |    910 |    1818  
     2 |    250 | 998025 |   1819 |    2727  
     3 |     62 | 997316 |   2728 |    3636  
     4 |   1556 | 998640 |   3637 |    4545  
     5 |    999 | 999536 |   4546 |    5454  
     6 |   1385 | 999196 |   5455 |    6363  
     7 |   1809 | 999042 |   6364 |    7272  
     8 |   3044 | 999606 |   7273 |    8181  
     9 |   1719 | 999186 |   8182 |    9090  
    10 |    618 | 997031 |   9091 |    9999  
    11 |     80 | 997581 |  10000 |   10908  
    12 |    781 | 997710 |  10909 |   11817  
    13 |   1539 | 998857 |  11818 |   12726  
    14 |   2097 | 999932 |  12727 |   13635  
    15 |    114 | 999913 |  13636 |   14544  
    16 |    136 | 999746 |  14545 |   15453  
    17 |   2047 | 997439 |  15454 |   16362  
    18 |   1955 | 996937 |  16363 |   17271  
    19 |   1487 | 999705 |  17272 |   18180  
    20 |     97 | 999549 |  18181 |   19089  
    21 |    375 | 999161 |  19090 |   19998  
    22 |    645 | 994457 |  19999 |   20907  
    23 |   4468 | 998612 |  20908 |   21816  
    24 |    865 | 996342 |  21817 |   22725  
    25 |    402 | 998151 |  22726 |   23634  
    26 |    429 | 998823 |  23635 |   24543  
    27 |   1305 | 999521 |  24544 |   25452  
    28 |    974 | 998874 |  25453 |   26361  
    29 |   1056 | 999271 |  26362 |   27270  
。。。。。。  
```  
  
对于ID列，分布非常清晰（线性相关性好），存储元数据的过滤性好。而C1列，分布非常散，存储元数据的过滤性差。  
  
例如我要查id=10000的数据，直接查11号数据块，跳过其他数据块的扫描。  
  
而如果我要查c1=10000的数据，那么要查很多个数据块，因为能跳过的数据块很少。  
  
## 如何提升每一列的过滤性 - 存储编排  
对于单列来说，提升过滤性的方法非常简单，按顺序存储即可。  
  
例如前面的测试表，我们要提高C1的过滤性，按C1重排一下即可实现。  
  
重排后，C1列与物理存储（行号）的相关性会变成1或-1，即线性相关，因此过滤性就特别好。  
  
```  
postgres=# create temp table tmp_a (like a);  
CREATE TABLE  
postgres=# insert into tmp_a select * from a order by c1;  
INSERT 0 1000000  
postgres=# truncate a;  
TRUNCATE TABLE  
postgres=# insert into a select * from tmp_a;  
INSERT 0 1000000  
postgres=# end;  
COMMIT  
postgres=# select substring(ctid::text, '(\d+),')::int8 blkid, min(c1) min_c1, max(c1) max_c1, min(id) min_id, max(id) max_id from a group by 1 order by 1;  
 blkid | min_c1 | max_c1 | min_id | max_id    
-------+--------+--------+--------+---------  
     0 |      0 |    923 |   2462 |  999519  
     1 |    923 |   1846 |   1487 |  997619  
     2 |   1847 |   2739 |    710 |  999912  
     3 |   2741 |   3657 |   1930 |  999053  
     4 |   3658 |   4577 |   1635 |  999579  
     5 |   4577 |   5449 |    852 |  999335  
     6 |   5450 |   6410 |    737 |  998277  
     7 |   6414 |   7310 |   3262 |  999024  
     8 |   7310 |   8245 |    927 |  997907  
     9 |   8246 |   9146 |    441 |  999209  
    10 |   9146 |  10015 |    617 |  999828  
    11 |  10016 |  10920 |   1226 |  998264  
    12 |  10923 |  11859 |   1512 |  997404  
    13 |  11862 |  12846 |    151 |  998737  
    14 |  12847 |  13737 |   1007 |  999250  
。。。。。。  
  
c1列和物理存储（行号）的线性相关性  
postgres=# select correlation from pg_stats where tablename='a' and attname='c1';  
 correlation   
-------------  
           1  
(1 row)  
```  
  
糟糕的是，这么编排后，ID这个字段的过滤性就变差了。  
  
这是为什么呢？  
  
### 全局/全表 两列相对线性相关性  
实际上是ID和C1列的相关性，它控制了按C1排序后ID列变离散的问题。  
  
ID和C1的相关性如何呢？  
  
```  
postgres=# select corr(c1,id) from (select row_number() over(order by c1) c1, row_number() over(order by id) id from a) t;  
         corr            
-----------------------  
 -0.000695987373950136  
(1 row)  
```  
  
c1和id的全局（全表）相关性极差，导致了这个问题。  
  
### 局部/部分记录 两列相对线性相关性  
如果全表按C1或ID排序，那么另一列的离散度就会变得很高。  
  
但是，某些情况下，可能存在这样的情况，某些记录A和B字段的相关性很好，而其他记录他们的相关性不好。  
  
例子  
  
在之前的记录基础上，再插入一批记录。  
  
```  
postgres=# insert into a select id, id*2 from generate_series(1,100000) t(id);  
INSERT 0 100000  
```  
  
这部分数据id, c1字段的相关性为1。(局部相关性)  
  
```  
postgres=# select ctid from a offset 1000000 limit 1;  
    ctid      
------------  
 (1113,877)  
(1 row)  
  
postgres=# select corr(c1,id) from (select row_number() over(order by c1) c1, row_number() over(order by id) id from a where ctid >'(1113,877)') t;  
 corr   
------  
    1  
(1 row)  
```  
  
全局相关性一下也提升了不少  
  
```  
postgres=# select corr(c1,id) from (select row_number() over(order by c1) c1, row_number() over(order by id) id from a) t;  
       corr          
-------------------  
 0.182542794451908  
(1 row)  
```  
  
### 如何提升每一列的过滤性 - 存储编排  
  
为了获得最好的过滤性（每个列都能很好的过滤），采用全局排序满足不了需求。  
  
实际上需要局部排序，例如前面的例子，前面100万行，按C1排序，后面10万行再按ID排序。  
  
这样的话有10万记录的ID的过滤性很好，有110万记录的C1的过滤性也很好。  
  
### 复合排序 多列相对线性相关性  
我记得以前写过一篇这样的文档：  
  
[《一个简单算法可以帮助物联网,金融 用户 节约98%的数据存储成本 (PostgreSQL,Greenplum帮你做到)》](../201604/20160404_01.md)    
  
这里讲的实际上也是存储编排的精髓，通过排列组合，计算每两列的线性相关性，根据这个找出最佳的多列排序组合，从而提高整体相关性（提高压缩比）。  
  
同样适用于本文提到的提高所有列的过滤性。  
  
## 精髓  
1、局部、全局 两列相对相关性。决定了按某列排序后，另一列的离散度。  
  
2、编排的目的是，可以尽可能的让更多的列有序的存储，从而可以过滤最多的行。  
  
3、全局相关性，决定了按某一列排序时，另一列的离散度。  
  
4、局部相关性，决定了在某些记录中，两列的线性相关性。  
  
5、按局部相关性编排，可以尽可能的让更多的列有序的存储，从而可以过滤最多的行。但是算法较复杂，需要算出什么样的行在一起，按什么排序存放才能获得最佳过滤性。     
  
6、通过排列组合，计算每两列的线性相关性，根据这个找出最佳的多列排序组合，从而提高整体相关性（提高压缩比）。  
  
7、编排后，与存储（行号）线性相关性差的列，如果选择性较好（DISTINCT VALUE较多）时，并且业务有过滤数据的需求，建议还是需要建索引。  
  
## 相关技术  
1、列存储插件 cstore  
  
https://github.com/citusdata/cstore_fdw  
  
https://www.postgresql.org/docs/10/static/fdw-callbacks.html#fdw-callbacks-parallel  
  
2、[《一个简单算法可以帮助物联网,金融 用户 节约98%的数据存储成本 (PostgreSQL,Greenplum帮你做到)》](../201604/20160404_01.md)    
  
3、[《PostgreSQL 物联网黑科技 - 瘦身几百倍的索引(BRIN index)》](../201604/20160414_01.md)    
  
https://www.postgresql.org/docs/10/static/brin-intro.html  
  
4、metascan是阿里云PostgreSQL内核团队研发的一个数据库功能，已用于RDS PostgreSQL和HybridDB for PostgreSQL，将来亦可整合到存储引擎层面，将数据的FILTER下推到存储层，根据用户提供的查询条件，在不建索引的情况下可以减少数据的扫描量，提高效率。   
   
我们已测试，查询性能有3到5倍的提升（相比不建索引）。同时写入性能有至少1倍的提升（相比建立索引）。   
     
## 云端产品    
[阿里云 RDS PostgreSQL](https://www.aliyun.com/product/rds/postgresql)          
        
[阿里云 HybridDB for PostgreSQL](https://www.aliyun.com/product/gpdb)          
  
  
