## PostgreSQL AWR报告   
                                                          
### 作者                                                         
digoal                                                          
                                                          
### 日期                                                         
2016-11-23                                                              
                                                          
### 标签                                                        
PostgreSQL , AWR , Oracle , 数据库诊断 , 性能报告 , snapshot , 快照                                                                                                                 
                                                          
----                                                        
                     
## 背景    
熟悉Oracle的童鞋一定对AWR不陌生，通常要分析一个数据库在某个时间段的性能，可以从数据库的动态视图等统计信息记录中生成一份该时段的统计分析报告。  
  
里面包含了常见的等待事件分析，TOP SQL, TOP event等。  
  
PostgreSQL是一个功能和Oracle几乎可以媲美的开源产品，分析报告的工具也非常多，例如pgstatsinfo, pgsnap, pgtop, pgfouine, ..... 非常的多。  
  
我不想介绍这么多的工具，而是自己根据对PG的经验写了一个非常简单易用的，不需要安装一堆的插件，周期性的打快照即可。  用法和AWR非常类似。  
  
本文主要是将之前写的一个比较完整的巡检脚本转换成SQL接口的AWR，易用性更强，不需要登陆数据库主机，即可获得报告。  
  
将来PG加入新的统计信息表，我会继续追加到这个简单的工具中。  
  
希望大家一起来使用和改进，有问题可以发给我。  
  
## 接口介绍
1\. 快照列表  
  
其实就是快照的清单，每打一个快照，就会新增一条记录。  
  
```
postgres=# select * from snap_list;
 id |          snap_ts           | snap_level 
----+----------------------------+------------
  1 | 2016-11-23 19:59:10.321282 | database
  3 | 2016-11-23 22:29:55.139357 | global
  4 | 2016-11-23 22:30:42.602292 | database
  5 | 2016-11-23 22:30:42.602292 | database
  6 | 2016-11-23 22:30:42.602292 | database
  7 | 2016-11-23 22:29:55.139357 | global
  8 | 2016-11-23 22:29:55.139357 | global
  9 | 2016-11-23 22:29:55.139357 | global
 10 | 2016-11-23 23:00:31.796333 | global
 11 | 2016-11-23 22:29:55.139357 | global
 12 | 2016-11-23 23:02:36.590308 | database
 13 | 2016-11-23 23:03:51.727333 | global
 14 | 2016-11-23 23:03:51.727333 | global
 15 | 2016-11-23 23:03:51.727333 | global
 16 | 2016-11-23 23:03:51.727333 | global
 17 | 2016-11-23 23:03:51.727333 | global
 18 | 2016-11-23 23:03:51.727333 | global
 19 | 2016-11-23 23:03:51.727333 | global
 20 | 2016-11-23 23:03:51.727333 | global
 21 | 2016-11-23 23:02:36.590308 | database
 22 | 2016-11-23 23:08:50.900675 | global
 23 | 2016-11-23 23:08:53.153526 | global
 24 | 2016-11-23 23:08:55.816379 | global
 25 | 2016-11-23 23:09:11.242692 | database
 26 | 2016-11-23 23:09:32.270733 | database
(25 rows)
```
  
2\. 快照历史数据表  
  
打快照时，会将系统的统计信息记录到这些历史表，后面根据时间段生成诊断报告就用到这里的数据。  
  
```
postgres=# \dt __pg_stats__.snap_*
                      List of relations
    Schema    |            Name            | Type  |  Owner   
--------------+----------------------------+-------+----------
 __pg_stats__ | snap_list                  | table | postgres
 __pg_stats__ | snap_pg_conn_stats         | table | postgres
 __pg_stats__ | snap_pg_cputime_topsql     | table | postgres
 __pg_stats__ | snap_pg_database_age       | table | postgres
 __pg_stats__ | snap_pg_db_conn_limit      | table | postgres
 __pg_stats__ | snap_pg_db_rel_size        | table | postgres
 __pg_stats__ | snap_pg_db_role_setting    | table | postgres
 __pg_stats__ | snap_pg_db_size            | table | postgres
 __pg_stats__ | snap_pg_dead_tup           | table | postgres
 __pg_stats__ | snap_pg_hash_idx           | table | postgres
 __pg_stats__ | snap_pg_index_bloat        | table | postgres
 __pg_stats__ | snap_pg_long_2pc           | table | postgres
 __pg_stats__ | snap_pg_long_xact          | table | postgres
 __pg_stats__ | snap_pg_many_indexes_rel   | table | postgres
 __pg_stats__ | snap_pg_notused_indexes    | table | postgres
 __pg_stats__ | snap_pg_rel_age            | table | postgres
 __pg_stats__ | snap_pg_rel_space_bucket   | table | postgres
 __pg_stats__ | snap_pg_role_conn_limit    | table | postgres
 __pg_stats__ | snap_pg_seq_deadline       | table | postgres
 __pg_stats__ | snap_pg_stat_activity      | table | postgres
 __pg_stats__ | snap_pg_stat_archiver      | table | postgres
 __pg_stats__ | snap_pg_stat_bgwriter      | table | postgres
 __pg_stats__ | snap_pg_stat_database      | table | postgres
 __pg_stats__ | snap_pg_stat_statements    | table | postgres
 __pg_stats__ | snap_pg_statio_all_indexes | table | postgres
 __pg_stats__ | snap_pg_statio_all_tables  | table | postgres
 __pg_stats__ | snap_pg_table_bloat        | table | postgres
 __pg_stats__ | snap_pg_tbs_size           | table | postgres
 __pg_stats__ | snap_pg_unlogged_table     | table | postgres
 __pg_stats__ | snap_pg_user_deadline      | table | postgres
 __pg_stats__ | snap_pg_vacuumlo           | table | postgres
 __pg_stats__ | snap_pg_waiting            | table | postgres
(32 rows)
```
  
3\. 创建快照  
  
顾名思义，就是创建快照，我这里分为两种快照，一种是全局的，一种是库级的。  
  
全局的在哪里创建都可以，但是只需要创建一次就够了，而库级的需要连接到需要分析库去创建快照。   
  
```
select __pg_stats__.snap_database();

select __pg_stats__.snap_database();
```
  
4\. 查询快照  
  
```
select * from __pg_stats__.snap_list;
```
  
5\. 删除快照  
  
删除指定snap_ID以前的快照。  
  
删除指定时间以前的快照。  
  
保留最近的几个快照，其他删除。  
  
```
select snap_delete(10::int8);  -- 删除指定SNAP ID以前的快照

select snap_delete(10::int4);  -- 保留最近的10个快照，其他删除。  

select snap_delete('2016-11-23 12:00:00');  -- 删除指定时间前的快照。
```
  
6\. 生成报告  
  
指定开始和结束snap_id, 生成报告.     
  
生成全局报告  
  
```
psql --pset=pager=off -q -h xxx.xxx.xxx.xxx -p xxxx -U superuser -d dbname -c "select * from snap_report_global(1,1)" > /tmp/global.md
```
  
生成当前数据库报告  
  
```
psql --pset=pager=off -q -h xxx.xxx.xxx.xxx -p xxxx -U superuser -d dbname -c "select * from snap_report_database(2,10)" > /tmp/db.md
```
  
## 部署快照功能
### 修改配置文件  
需要用到pg_stat_statements插件，统计TOP SQL。    
  
```
$ vi postgresql.conf 

shared_preload_libraries='pg_stat_statements' 

$ pg_ctl restart -m fast 
```
  
### 初始化
在需要打快照的库都装上这个SQL。  
  
[init.sql](20161123_01_sql_001.sql)  
    
### 创建打快照的function
在需要打快照的库都装上这个SQL。  
  
[snap_functions.sql](20161123_01_sql_002.sql)  
  
### 创建清理快照的function
在需要清理快照数据的库都装上这个SQL。  
  
[snap_delete_functions.sql](20161123_01_sql_003.sql)  
  
### 创建生成报告的function
在需要生成诊断报告的库都装上这个SQL。  
  
[snap_report_functions.sql](20161123_01_sql_004.sql)  
  
## 定时打快照
连接到对应的数据库执行  
  
```
select snap_database();  -- 每个库都要执行。

select snap_global();  --  只需要在一个库执行。
```
  
## 其他
目前还不支持从日志文件生成统计报告，这部分可以修改源码后实现，当然，如果你能访问数据库主机，那一切都简单了。  
  
我写本文的目的是，只要能连数据库，就能生成诊断报告。  
   
```
echo "|+++++++++++++++++++++++++++++++++++++++++++++++++++++++++|"
echo "|                   数据库错误日志分析                    |"
echo "|+++++++++++++++++++++++++++++++++++++++++++++++++++++++++|"
echo ""

echo "----->>>---->>>  获取错误日志信息: "
cat *.csv | grep -E "^[0-9]" | grep -E "WARNING|ERROR|FATAL|PANIC" | awk -F "," '{print $12" , "$13" , "$14}'|sort|uniq -c|sort -rn
echo "建议: "
echo "    参考 http://www.postgresql.org/docs/current/static/errcodes-appendix.html ."
echo -e "\n"

echo "----->>>---->>>  获取连接请求情况: "
find . -name "*.csv" -type f -mtime -28 -exec grep "connection authorized" {} +|awk -F "," '{print $2,$3,$5}'|sed 's/\:[0-9]*//g'|sort|uniq -c|sort -n -r
echo "建议: "
echo "    连接请求非常多时, 请考虑应用层使用连接池, 或者使用pgbouncer连接池. "
echo -e "\n"

echo "----->>>---->>>  获取认证失败情况: "
find . -name "*.csv" -type f -mtime -28 -exec grep "password authentication failed" {} +|awk -F "," '{print $2,$3,$5}'|sed 's/\:[0-9]*//g'|sort|uniq -c|sort -n -r
echo "建议: "
echo "    认证失败次数很多时, 可能是有用户在暴力破解, 建议使用auth_delay插件防止暴力破解. "
echo -e "\n"

echo "|+++++++++++++++++++++++++++++++++++++++++++++++++++++++++|"
echo "|                   数据库慢SQL日志分析                   |"
echo "|+++++++++++++++++++++++++++++++++++++++++++++++++++++++++|"
echo ""

echo "----->>>---->>>  慢查询统计: "
cat *.csv|awk -F "," '{print $1" "$2" "$3" "$8" "$14}' |grep "duration:"|grep -v "plan:"|awk '{print $1" "$4" "$5" "$6}'|sort|uniq -c|sort -rn
echo "建议: "
echo "    输出格式(条数,日期,用户,数据库,QUERY,耗时ms). "
echo "    慢查询反映执行时间超过log_min_duration_statement的SQL, 可以根据实际情况分析数据库或SQL语句是否有优化空间. "
echo ""
echo "----->>>---->>>  慢查询分布头10条的执行时间, ms: "
cat *.csv|awk -F "," '{print $1" "$2" "$3" "$8" "$14}' |grep "duration:"|grep -v "plan:"|awk '{print $1" "$4" "$5" "$6" "$7" "$8}'|sort -k 6 -n|head -n 10
echo ""
echo "----->>>---->>>  慢查询分布尾10条的执行时间, ms: "
cat *.csv|awk -F "," '{print $1" "$2" "$3" "$8" "$14}' |grep "duration:"|grep -v "plan:"|awk '{print $1" "$4" "$5" "$6" "$7" "$8}'|sort -k 6 -n|tail -n 10
echo -e "\n"

echo "----->>>---->>>  auto_explain 分析统计: "
cat *.csv|awk -F "," '{print $1" "$2" "$3" "$8" "$14}' |grep "plan:"|grep "duration:"|awk '{print $1" "$4" "$5" "$6}'|sort|uniq -c|sort -rn
echo "建议: "
echo "    输出格式(条数,日期,用户,数据库,QUERY). "
echo "    慢查询反映执行时间超过auto_explain.log_min_duration的SQL, 可以根据实际情况分析数据库或SQL语句是否有优化空间, 分析csvlog中auto_explain的输出可以了解语句超时时的执行计划详情. "
echo -e "\n"
```
  
修改源码要达到的目的，支持rotate table日志记录  
  
将审计日志，慢SQL，auto_explain日志，错误日志记录特殊的数据表，  
  
该表不记录redo，使用APPEND ONLY方式，  
  
该表保持一定记录条数，或大小限制，可以通过GUC配置记录数和SIZE.   
  
好处，方便用户查询，方便生成诊断报告。  
        
## 全局报告样本  
## 报告时间段: ```2016-11-23 19:59:10.321282``` ~ ```2016-11-23 22:29:55.139357```    
  
## 一、数据库定制参数信息
  
### 1. 用户或数据库级别定制参数
  
database | role | snap_ts | setconfig
---|---|---|---
  
#### 建议
  
定制参数需要关注, 优先级高于数据库的启动参数和配置文件中的参数, 特别是排错时需要关注.  
  
## 二、数据库空间使用分析
  
### 1. 表空间使用情况
  
tablespace | tbs_location | snap_ts | size
---|---|---|---
pg_default | ```-``` | ```2016-11-23 22:29:55.139357+08``` | 107 GB
pg_global | ```-``` | ```2016-11-23 22:29:55.139357+08``` | 521 kB
  
#### 建议
  
注意检查表空间所在文件系统的剩余空间, (默认表空间在$PGDATA/base目录下), IOPS分配是否均匀, OS的sysstat包可以观察IO使用率.  
  
### 2. 数据库使用情况
  
database | snap_ts | size
---|---|---
```db0``` | ```2016-11-23 22:29:55.139357+08``` | 69 MB
```postgres``` | ```2016-11-23 22:29:55.139357+08``` | 107 GB
```template0``` | ```2016-11-23 22:29:55.139357+08``` | 7225 kB
```template1``` | ```2016-11-23 22:29:55.139357+08``` | 7225 kB
  
#### 建议
  
注意检查数据库的大小, 是否需要清理历史数据.  
  
## 三、数据库连接分析
  
### 1. 活跃度
  
state | snap_ts | connections
---|---|---
active | ```2016-11-23 22:29:55.139357+08``` | 1
  
#### 建议
  
如果active状态很多, 说明数据库比较繁忙. 如果idle in transaction很多, 说明业务逻辑设计可能有问题. 如果idle很多, 可能使用了连接池, 并且可能没有自动回收连接到连接池的最小连接数.  
  
### 2. 剩余连接数
  
snap_ts | max_enabled_connections | used | res_for_super | res_for_normal
---|---|---|---|---
```2016-11-23 22:29:55.139357+08``` | 100 | 1 | 3 | 96
  
#### 建议
  
给超级用户和普通用户设置足够的连接, 以免不能登录数据库.  
  
### 3. 用户连接数限制
  
rolename | snap_ts | conn_limit | connects
---|---|---|---
```postgres``` | ```2016-11-23 22:29:55.139357+08``` | -1 | 1
  
#### 建议
  
给用户设置足够的连接数, alter role ... CONNECTION LIMIT .  
  
### 4. 数据库连接限制
  
database | snap_ts | conn_limit | connects
---|---|---|---
```postgres``` | ```2016-11-23 22:29:55.139357+08``` | -1 | 1
  
#### 建议
  
给数据库设置足够的连接数, alter database ... CONNECTION LIMIT .  
  
## 四、数据库性能分析
  
### 1. TOP 10 SQL : total_cpu_time
  
rolename | database | calls | total_ms | min_ms | max_ms | mean_ms | stddev_ms | rows | shared_blks_hit | shared_blks_read | shared_blks_dirtied | shared_blks_written | local_blks_hit | local_blks_read | local_blks_dirtied | shared_blks_written | temp_blks_read | temp_blks_written | blk_read_time | blk_write_time | query
---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---
```postgres``` | ```postgres``` | 1822041 | 32336.2049990667 | 0.006 | 292.108 | 0.0177472433386512 | 0.48189617968061 | 1822041 | 1884104 | 11715 | 12308 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |  ```INSERT INTO pgbench_history (tid, bid, aid, delta, mtime) VALUES ($1, $2, $3, $4, CURRENT_TIMESTAMP);```
```postgres``` | ```postgres``` | 1822041 | 30391.7759995177 | 0.008 | 17.405 | 0.0166800725120904 | 0.0409643958497072 | 1822041 | 7885406 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |  ```SELECT abalance FROM pgbench_accounts WHERE aid = $1;```
```postgres``` | ```postgres``` | 1822041 | 189252.379000017 | 0.023 | 479.599 | 0.103868342699208 | 3.4063774205776 | 1822041 | 12288766 | 36926 | 1072115 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |  ```UPDATE pgbench_accounts SET abalance = abalance + $1 WHERE aid = $2;```
```postgres``` | ```postgres``` | 1822041 | 450374.602999878 | 0.012 | 480.164 | 0.247181376818626 | 2.42196486548835 | 1822041 | 71283502 | 2596 | 4290 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |  ```UPDATE pgbench_branches SET bbalance = bbalance + $1 WHERE bid = $2;```
```postgres``` | ```postgres``` | 1822041 | 220270.93199979 | 0.012 | 482.988 | 0.120892412410036 | 1.78259941452006 | 1822041 | 62847181 | 3691 | 7137 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |  ```UPDATE pgbench_tellers SET tbalance = tbalance + $1 WHERE tid = $2;```
```postgres``` | ```postgres``` | 1 | 6686.644 | 6686.644 | 6686.644 | 6686.644 | 0 | 0 | 2217 | 161855 | 1 | 0 | 0 | 0 | 0 | 0 | 24438 | 24438 | 0 | 0 |  ```alter table pgbench_accounts add primary key (aid)```
```postgres``` | ```postgres``` | 1 | 13686.573 | 13686.573 | 13686.573 | 13686.573 | 0 | 10000000 | 8 | 163935 | 163935 | 158427 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |  ```copy pgbench_accounts from stdin```
```postgres``` | ```postgres``` | 3 | 12229.58 | 3918.771 | 4371.462 | 4076.52666666667 | 208.71987779531 | 0 | 2729076 | 2 | 4 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |  ```create table IF NOT EXISTS snap_pg_hash_idx as select 1::int8 snap_id, now() snap_ts, current_database(),pg_get_indexdef(oid) from pg_class where relkind=$$i$$ and pg_get_indexdef(oid) ~ $$USING hash$$;```
```postgres``` | ```postgres``` | 3 | 23013.05 | 7495.389 | 7991.163 | 7671.01666666667 | 226.733615402648 | 0 | 2450329 | 4 | 6 | 0 | 0 | 0 | 0 | 0 | 675 | 633 | 0 | 0 |  ```create table IF NOT EXISTS snap_pg_rel_space_bucket as select 1::int8 snap_id, now() snap_ts, current_database(), buk this_buk_no, cnt rels_in_this_buk, pg_size_pretty(min) buk_min, pg_size_pretty(max) buk_max from  (   select row_number() over (partition by buk order by tsize), tsize, buk, min(tsize) over (partition by buk),max(tsize) over (partition by buk), count(*) over (partition by buk) cnt from   (     select pg_relation_size(a.oid) tsize, width_bucket(pg_relation_size(a.oid),tmin-1,tmax+1,10) buk from     (       select min(pg_relation_size(a.oid)) tmin, max(pg_relation_size(a.oid)) tmax from pg_class a, pg_namespace c where a.relnamespace=c.oid and nspname !~ $$^pg_$$ and nspname<>$$information_schema$$     ) t, pg_class a, pg_namespace c where a.relnamespace=c.oid and nspname !~ $$^pg_$$ and nspname<>$$information_schema$$   ) t  ) t where row_number=1;```
```postgres``` | ```postgres``` | 3 | 6350.835 | 2003.815 | 2177.683 | 2116.945 | 80.0675198566811 | 0 | 512088 | 60 | 19 | 0 | 0 | 0 | 0 | 0 | 14038 | 13990 | 0 | 0 |  ```create table IF NOT EXISTS snap_pg_table_bloat as select 1::int8 snap_id, now() snap_ts,    current_database() AS db, schemaname, tablename, reltuples::bigint AS tups, relpages::bigint AS pages, otta,   ROUND(CASE WHEN otta=0 OR sml.relpages=0 OR sml.relpages=otta THEN 0.0 ELSE sml.relpages/otta::numeric END,1) AS tbloat,   CASE WHEN relpages < otta THEN 0 ELSE relpages::bigint - otta END AS wastedpages,   CASE WHEN relpages < otta THEN 0 ELSE bs*(sml.relpages-otta)::bigint END AS wastedbytes,   CASE WHEN relpages < otta THEN $$0 bytes$$::text ELSE (bs*(relpages-otta))::bigint &#124;&#124; $$ bytes$$ END AS wastedsize,   iname, ituples::bigint AS itups, ipages::bigint AS ipages, iotta,   ROUND(CASE WHEN iotta=0 OR ipages=0 OR ipages=iotta THEN 0.0 ELSE ipages/iotta::numeric END,1) AS ibloat,   CASE WHEN ipages < iotta THEN 0 ELSE ipages::bigint - iotta END AS wastedipages,   CASE WHEN ipages < iotta THEN 0 ELSE bs*(ipages-iotta) END AS wastedibytes,   CASE WHEN ipages < iotta THEN $$0 bytes$$ ELSE (bs*(ipages-iotta))::bigint &#124;&#124; $$ bytes$$ END AS wastedisize,   CASE WHEN relpages < otta THEN     CASE WHEN ipages < iotta THEN 0 ELSE bs*(ipages-iotta::bigint) END     ELSE CASE WHEN ipages < iotta THEN bs*(relpages-otta::bigint)       ELSE bs*(relpages-otta::bigint + ipages-iotta::bigint) END   END AS totalwastedbytes FROM (   SELECT     nn.nspname AS schemaname,     cc.relname AS tablename,     COALESCE(cc.reltuples,0) AS reltuples,     COALESCE(cc.relpages,0) AS relpages,     COALESCE(bs,0) AS bs,     COALESCE(CEIL((cc.reltuples*((datahdr+ma-       (CASE WHEN datahdr%ma=0 THEN ma ELSE datahdr%ma END))+nullhdr2+4))/(bs-20::float)),0) AS otta,     COALESCE(c2.relname,$$?$$) AS iname, COALESCE(c2.reltuples,0) AS ituples, COALESCE(c2.relpages,0) AS ipages,     COALESCE(CEIL((c2.reltuples*(datahdr-12))/(bs-20::float)),0) AS iotta    FROM      pg_class cc   JOIN pg_namespace nn ON cc.relnamespace = nn.oid AND nn.nspname <> $$information_schema$$   LEFT JOIN   (     SELECT       ma,bs,foo.nspname,foo.relname,       (datawidth+(hdr+ma-(case when hdr%ma=0 THEN ma ELSE hdr%ma END)))::numeric AS datahdr,       (maxfracsum*(nullhdr+ma-(case when nullhdr%ma=0 THEN ma ELSE nullhdr%ma END))) AS nullhdr2     FROM (       SELECT         ns.nspname, tbl.relname, hdr, ma, bs,         SUM((1-coalesce(null_frac,0))*coalesce(avg_width, 2048)) AS datawidth,         MAX(coalesce(null_frac,0)) AS maxfracsum,         hdr+(           SELECT 1+count(*)/8           FROM pg_stats s2           WHERE null_frac<>0 AND s2.schemaname = ns.nspname AND s2.tablename = tbl.relname         ) AS nullhdr       FROM pg_attribute att        JOIN pg_class tbl ON att.attrelid = tbl.oid       JOIN pg_namespace ns ON ns.oid = tbl.relnamespace        LEFT JOIN pg_stats s ON s.schemaname=ns.nspname       AND s.tablename = tbl.relname       AND s.inherited=false       AND s.attname=att.attname,       (         SELECT           (SELECT current_setting($$block_size$$)::numeric) AS bs,             CASE WHEN SUBSTRING(SPLIT_PART(v, $$ $$, 2) FROM $$#"[0-9]+.[0-9]+#"%$$ for $$#$$)               IN ($$8.0$$,$$8.1$$,$$8.2$$) THEN 27 ELSE 23 END AS hdr,           CASE WHEN v ~ $$mingw32$$ OR v ~ $$64-bit$$ THEN 8 ELSE 4 END AS ma         FROM (SELECT version() AS v) AS foo       ) AS constants       WHERE att.attnum > 0 AND tbl.relkind=$$r$$       GROUP BY 1,2,3,4,5     ) AS foo   ) AS rs   ON cc.relname = rs.relname AND nn.nspname = rs.nspname   LEFT JOIN pg_index i ON indrelid = cc.oid   LEFT JOIN pg_class c2 ON c2.oid = i.indexrelid ) AS sml order by wastedbytes desc limit 10;```
  
#### 建议
  
检查SQL是否有优化空间, 配合auto_explain插件在csvlog中观察LONG SQL的执行计划是否正确.  
  
### 2. 数据库统计信息, 回滚比例, 命中比例, 数据块读写时间, 死锁, 复制冲突
  
database | snap_ts | rollback_ratio | hit_ratio | blk_read_time | blk_write_time | conflicts | deadlocks
---|---|---|---|---|---|---|---
```db0``` | ```2016-11-23 22:29:55.139357+08``` | 0.00 % | 0.00 % | 0 | 0 | 0 | 0
```postgres``` | ```2016-11-23 22:29:55.139357+08``` | 0.00 % | 99.96 % | 0 | 0 | 0 | 0
```template0``` | ```2016-11-23 22:29:55.139357+08``` | 0.00 % | 0.00 % | 0 | 0 | 0 | 0
```template1``` | ```2016-11-23 22:29:55.139357+08``` | 0.00 % | 0.00 % | 0 | 0 | 0 | 0
  
#### 建议
  
回滚比例大说明业务逻辑可能有问题, 命中率小说明shared_buffer要加大, 数据块读写时间长说明块设备的IO性能要提升, 死锁次数多说明业务逻辑有问题, 复制冲突次数多说明备库可能在跑LONG SQL.  
  
### 3. 检查点, bgwriter 统计信息
  
checkpoints_timed | checkpoints_req | checkpoint_write_time | checkpoint_sync_time | buffers_checkpoint | buffers_clean | maxwritten_clean | buffers_backend | buffers_backend_fsync | buffers_alloc
---|---|---|---|---|---|---|---|---|---
11 | 15 | 90727 | 363 | 1132174 | 0 | 0 | 525227 | 0 | 234453
  
#### 说明
  
checkpoints_timed , 统计周期内, 发生了多少次调度检查点.  
  
checkpoints_req , 统计周期内, 发生了多少次人为执行检查点.  
  
checkpoint_write_time , 检查点过程中, write系统调用的耗时ms.  
  
checkpoint_sync_time , 检查点过程中, fsync系统调用的耗时ms.  
  
buffers_checkpoint , 检查点过程中, ckpt进程写出(write)了多少buffer pages.  
  
buffers_clean , 统计周期内, bgwriter进程写出(write)了多少buffer pages.  
  
maxwritten_clean , 统计周期内, bgwriter被打断了多少次(由于write的pages超过一个bgwriter调度周期内的阈值).  
  
buffers_backend , 统计周期内, 有多少pages是被backend process直接write out的.  
  
buffers_backend_fsync , 统计周期内, 有多少pages是被backend process直接fsync的.  
  
buffers_alloc , 统计周期内, 指派了多少个pages.  
  
#### 建议
  
checkpoint_write_time多说明检查点持续时间长, 检查点过程中产生了较多的脏页.  
  
checkpoint_sync_time代表检查点开始时的shared buffer中的脏页被同步到磁盘的时间, 如果时间过长, 并且数据库在检查点时性能较差, 考虑一下提升块设备的IOPS能力.  
  
buffers_backend_fsync太多说明需要加大shared buffer 或者 减小bgwriter_delay参数.  
  
maxwritten_clean太多说明需要减小调大bgwriter_lru_maxpages和bgwriter_lru_multiplier参数.  
  
### 4. 归档统计信息
  
archived_count | last_archived_wal | last_archived_time | failed_count | last_failed_wal | last_failed_time | now_insert_xlog_file
---|---|---|---|---|---|---

  
#### 建议
  
last_archived_wal和now_insert_xlog_file相差很多, 说明失败的归档很多.  
  
## 五、数据库年龄分析
  
### 1. 数据库年龄
  
database | snap_ts | age | age_remain
---|---|---|---
```db0``` | ```2016-11-23 22:29:55.139357+08``` | 63930093 | 2083553555
```postgres``` | ```2016-11-23 22:29:55.139357+08``` | 63930093 | 2083553555
```template0``` | ```2016-11-23 22:29:55.139357+08``` | 63930093 | 2083553555
```template1``` | ```2016-11-23 22:29:55.139357+08``` | 63930093 | 2083553555
  
#### 建议
  
数据库的年龄正常情况下应该小于vacuum_freeze_table_age, 如果剩余年龄小于2亿, 建议人为干预, 将LONG SQL或事务杀掉后, 执行vacuum freeze.  
  
### 2. 长事务, 2PC
  
snap_ts | database | user | query | xact_start | xact_duration | query_start | query_duration | state
---|---|---|---|---|---|---|---|---
  
snap_ts | name | statement | prepare_time | duration | parameter_types | from_sql
---|---|---|---|---|---|---|---|---
  
#### 建议
  
长事务过程中产生的垃圾, 无法回收, 建议不要在数据库中运行LONG SQL, 或者错开DML高峰时间去运行LONG SQL. 2PC事务一定要记得尽快结束掉, 否则可能会导致数据库膨胀.  
  
参考: http://blog.163.com/digoal@126/blog/static/1638770402015329115636287/   
  
## 六、数据库安全或潜在风险分析
  
### 1. 用户密码到期时间
  
snap_ts | rolname | rolvaliduntil
---|---|---|---








  
#### 建议
  
到期后, 用户将无法登陆, 记得修改密码, 同时将密码到期时间延长到某个时间或无限时间, alter role ... VALID UNTIL 'timestamp'.  
    
## 库级报告样本  
## 报告时间段: ```2016-11-23 22:30:42.602292``` ~ ```2016-11-23 22:30:42.602292```    
  
## 一、数据库性能分析
  
### 1. 当前数据库 TOP 10 SQL : total_cpu_time
  
calls | total_ms | min_ms | max_ms | mean_ms | stddev_ms | rows | shared_blks_hit | shared_blks_read | shared_blks_dirtied | shared_blks_written | local_blks_hit | local_blks_read | local_blks_dirtied | shared_blks_written | temp_blks_read | temp_blks_written | blk_read_time | blk_write_time | query
---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---
1769375 | 423916.014000022 | 0.014 | 476.127 | 0.239585172165316 | 2.81870301350584 | 1769375 | 57060460 | 0 | 7274 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ```UPDATE pgbench_branches SET bbalance = bbalance + $1 WHERE bid = $2;```
1769375 | 203088.22800013 | 0.023 | 488.756 | 0.114779641398797 | 4.24429566877362 | 1769375 | 9812996 | 2431 | 1358957 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ```UPDATE pgbench_accounts SET abalance = abalance + $1 WHERE aid = $2;```
1769375 | 189200.759000043 | 0.015 | 475.529 | 0.106930842246557 | 1.13013345420501 | 1769375 | 56403095 | 0 | 16872 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ```UPDATE pgbench_tellers SET tbalance = tbalance + $1 WHERE tid = $2;```
1769375 | 39874.252999695 | 0.006 | 465.971 | 0.0225357841045568 | 1.61234263936941 | 1769375 | 1827720 | 11187 | 12547 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ```INSERT INTO pgbench_history (tid, bid, aid, delta, mtime) VALUES ($1, $2, $3, $4, CURRENT_TIMESTAMP);```
1769375 | 30228.6699995451 | 0.008 | 24.36 | 0.0170843772518544 | 0.0401863153856261 | 1769375 | 7237131 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ```SELECT abalance FROM pgbench_accounts WHERE aid = $1;```
1 | 15333.882 | 15333.882 | 15333.882 | 15333.882 | 0 | 1 | 1608955 | 2070 | 2070 | 0 | 0 | 0 | 0 | 0 | 14165 | 14083 | 0 | 0 | ```select snap_database();```
1769375 | 1706.72599996778 | 0 | 1.636 | 0.000964592582126481 | 0.00262716797941176 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ```END;```
1769375 | 1561.886999971 | 0 | 1.858 | 0.000882733733662991 | 0.00261568333549411 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ```BEGIN;```
2 | 765.381 | 376.318 | 389.063 | 382.6905 | 6.3725 | 690 | 18156 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 6912 | 6912 | 0 | 0 | ```select * from snap_report_database(?,?);```
1 | 193.542 | 193.542 | 193.542 | 193.542 | 0 | 1 | 493 | 0 | 12 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ```select snap_global();```
  
#### 建议
  
检查SQL是否有优化空间, 配合auto_explain插件在csvlog中观察LONG SQL的执行计划是否正确.  
  
### 2. TOP 10 size 表统计信息
  
current_database | nspname | relname | relkind | pg_relation_size | seq_scan | seq_tup_read | idx_scan | idx_tup_fetch | n_tup_ins | n_tup_upd | n_tup_del | n_tup_hot_upd | n_live_tup | n_dead_tup
---|---|---|---|---|---|---|---|---|---|---|---|---|---|---
```postgres``` | ```public``` | ```rum_test``` | r | 15 GB | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.00000000000000000000 | 0.00000000000000000000
```postgres``` | ```public``` | ```gin_test``` | r | 15 GB | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.00000000000000000000 | 0.00000000000000000000
```postgres``` | ```public``` | ```arr_test``` | r | 4340 MB | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.00000000000000000000 | 0.00000000000000000000
```postgres``` | ```public``` | ```pgbench_accounts``` | r | 1374 MB | 0 | 0 | 3538750 | 3538750 | 0 | 1769375 | 0 | 1621232 | 10432854.000000000000 | 1048529.000000000000
```postgres``` | ```public``` | ```gist_test``` | r | 498 MB | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.00000000000000000000 | 0.00000000000000000000
```postgres``` | ```public``` | ```btree_test``` | r | 422 MB | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.00000000000000000000 | 0.00000000000000000000
```postgres``` | ```public``` | ```p1``` | r | 346 MB | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.00000000000000000000 | 0.00000000000000000000
```postgres``` | ```public``` | ```p2``` | r | 346 MB | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.00000000000000000000 | 0.00000000000000000000
```postgres``` | ```public``` | ```pgbench_history``` | r | 179 MB | 0 | 0 | 0 | 0 | 1769375 | 0 | 0 | 0 | 3391848.000000000000 | 0.00000000000000000000
```postgres``` | ```public``` | ```test_pg_part_single``` | r | 66 MB | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.00000000000000000000 | 0.00000000000000000000
  
#### 说明
  
seq_scan, 全表扫描次数  
  
seq_tup_read, 全表扫描实际一共读取了多少条记录, 如果平均每次读取的记录数不多, 可能是limit语句造成的  
  
idx_scan, 索引扫描次数  
  
idx_tup_fetch, 索引扫描实际获取的记录数, 如果平均每次读取记录数很多, 说明数据库倾向使用索引扫描, 建议观察随机IO的性能看情况调整  
  
n_tup_ins, 统计周期内, 插入了多少条记录  
  
n_tup_upd, 统计周期内, 更新了多少条记录  
  
n_tup_hot_upd, 统计周期内, HOT更新(指更新后的记录依旧在当前PAGE)了多少条记录  
  
n_live_tup, 该表有多少可用数据  
  
n_dead_tup, 该表有多少垃圾数据  
  
#### 建议
  
经验值: 单表超过10GB, 并且这个表需要频繁更新 或 删除+插入的话, 建议对表根据业务逻辑进行合理拆分后获得更好的性能, 以及便于对膨胀索引进行维护; 如果是只读的表, 建议适当结合SQL语句进行优化.  
  
### 3. 全表扫描统计 , 平均实际扫描记录数排名前10的表
  
current_database | nspname | relname | relkind | pg_relation_size | seq_scan | seq_tup_read | idx_scan | idx_tup_fetch | n_tup_ins | n_tup_upd | n_tup_del | n_tup_hot_upd | n_live_tup | n_dead_tup
---|---|---|---|---|---|---|---|---|---|---|---|---|---|---
```postgres``` | ```__pg_stats__``` | ```snap_pg_statio_all_indexes``` | r | 31 MB | 4 | 400916 | 0 | 0 | 50118 | 0 | 0 | 0 | 100229.000000000000 | 0.00000000000000000000
```postgres``` | ```pg_catalog``` | ```pg_constraint``` | r | 38 MB | 1 | 99956 | 7538 | 7888 | 0 | 0 | 0 | 0 | 0.00000000000000000000 | 0.00000000000000000000
```postgres``` | ```pg_catalog``` | ```pg_index``` | r | 9032 kB | 8 | 400944 | 2276 | 51517 | 0 | 0 | 0 | 0 | 0.00000000000000000000 | 0.00000000000000000000
```postgres``` | ```pg_catalog``` | ```pg_class``` | r | 17 MB | 562 | 21762766 | 113810 | 63446 | 0 | 0 | 0 | 0 | 0.00000000000000000000 | 0.00000000000000000000
```postgres``` | ```__pg_stats__``` | ```snap_pg_statio_all_tables``` | r | 464 kB | 4 | 6476 | 0 | 0 | 820 | 0 | 0 | 0 | 1619.0000000000000000 | 0.00000000000000000000
```postgres``` | ```__pg_stats__``` | ```snap_pg_db_rel_size``` | r | 496 kB | 4 | 5904 | 0 | 0 | 747 | 0 | 0 | 0 | 1476.0000000000000000 | 0.00000000000000000000
```postgres``` | ```pg_catalog``` | ```pg_statistic``` | r | 312 kB | 2 | 1134 | 113774 | 3190 | 0 | 132 | 0 | 95 | 0.00000000000000000000 | 74.0000000000000000
```postgres``` | ```__pg_stats__``` | ```snap_pg_rel_age``` | r | 64 kB | 2 | 400 | 0 | 0 | 100 | 0 | 0 | 0 | 200.0000000000000000 | 0.00000000000000000000
```postgres``` | ```__pg_stats__``` | ```snap_pg_stat_statements``` | r | 64 kB | 2 | 218 | 0 | 0 | 4 | 0 | 0 | 0 | 4.0000000000000000 | 0.00000000000000000000
```postgres``` | ```__pg_stats__``` | ```snap_pg_table_bloat``` | r | 16 kB | 2 | 40 | 0 | 0 | 10 | 0 | 0 | 0 | 10.0000000000000000 | 0.00000000000000000000
  
#### 说明
  
seq_scan, 全表扫描次数  
  
seq_tup_read, 全表扫描实际一共读取了多少条记录, 如果平均每次读取的记录数不多, 可能是limit语句造成的  
  
idx_scan, 索引扫描次数  
  
idx_tup_fetch, 索引扫描实际获取的记录数, 如果平均每次读取记录数很多, 说明数据库倾向使用索引扫描, 建议观察随机IO的性能看情况调整  
  
n_tup_ins, 统计周期内, 插入了多少条记录  
  
n_tup_upd, 统计周期内, 更新了多少条记录  
  
n_tup_hot_upd, 统计周期内, HOT更新(指更新后的记录依旧在当前PAGE)了多少条记录  
  
n_live_tup, 该表有多少可用数据  
  
n_dead_tup, 该表有多少垃圾数据  
  
#### 建议
  
平均扫描的记录数如果很多, 建议找到SQL, 并针对性的创建索引(统计分析需求除外).  
  
### 4. 未命中buffer , 热表统计
  
current_database | schemaname | relname | heap_blks_read | heap_blks_hit | idx_blks_read | idx_blks_hit | toast_blks_read | toast_blks_hit | tidx_blks_read | tidx_blks_hit
---|---|---|---|---|---|---|---|---|---|---










  
#### 建议
  
如果热表的命中率很低, 说明需要增加shared buffer, 添加内存.  
  
### 5. 未命中&命中buffer , 热表统计
  
current_database | schemaname | relname | heap_blks_read | heap_blks_hit | idx_blks_read | idx_blks_hit | toast_blks_read | toast_blks_hit | tidx_blks_read | tidx_blks_hit
---|---|---|---|---|---|---|---|---|---|---










  
#### 建议
  
如果热表的命中率很低, 说明需要增加shared buffer, 添加内存.  
  
### 6. 未命中 , 热索引统计
  
current_database | schemaname | relname | indexrelname | idx_blks_read | idx_blks_hit
---|---|---|---|---|---
```postgres``` | ```pg_catalog``` | ```pg_database``` | ```pg_database_datname_index``` | 8 | 511138
```postgres``` | ```pg_catalog``` | ```pg_authid``` | ```pg_authid_oid_index``` | 8 | 5711
```postgres``` | ```pg_catalog``` | ```pg_shdepend``` | ```pg_shdepend_reference_index``` | 8 | 3096
```postgres``` | ```pg_catalog``` | ```pg_tablespace``` | ```pg_tablespace_oid_index``` | 8 | 2756
```postgres``` | ```pg_catalog``` | ```pg_database``` | ```pg_database_oid_index``` | 8 | 1013858
```postgres``` | ```pg_catalog``` | ```pg_authid``` | ```pg_authid_rolname_index``` | 8 | 4795
```postgres``` | ```pg_catalog``` | ```pg_shdepend``` | ```pg_shdepend_depender_index``` | 6 | 19054
```postgres``` | ```pg_catalog``` | ```pg_db_role_setting``` | ```pg_db_role_setting_databaseid_rol_index``` | 4 | 1018992
```postgres``` | ```pg_catalog``` | ```pg_tablespace``` | ```pg_tablespace_spcname_index``` | 3 | 13
```postgres``` | ```pg_catalog``` | ```pg_shdescription``` | ```pg_shdescription_o_c_index``` | 3 | 10
  
#### 建议
  
如果热索引的命中率很低, 说明需要增加shared buffer, 添加内存.  
  
### 7. 未命中&命中buffer , 热索引统计
  
current_database | schemaname | relname | indexrelname | idx_blks_read | idx_blks_hit
---|---|---|---|---|---
```postgres``` | ```public``` | ```pgbench_accounts``` | ```pgbench_accounts_pkey``` | 0 | 11170449
```postgres``` | ```public``` | ```pgbench_tellers``` | ```pgbench_tellers_pkey``` | 0 | 7130729
```postgres``` | ```public``` | ```pgbench_branches``` | ```pgbench_branches_pkey``` | 0 | 4982020
```postgres``` | ```pg_catalog``` | ```pg_db_role_setting``` | ```pg_db_role_setting_databaseid_rol_index``` | 4 | 1018992
```postgres``` | ```pg_catalog``` | ```pg_database``` | ```pg_database_oid_index``` | 8 | 1013858
```postgres``` | ```pg_catalog``` | ```pg_database``` | ```pg_database_datname_index``` | 8 | 511138
```postgres``` | ```pg_catalog``` | ```pg_class``` | ```pg_class_oid_index``` | 0 | 333803
```postgres``` | ```pg_catalog``` | ```pg_statistic``` | ```pg_statistic_relid_att_inh_index``` | 0 | 227715
```postgres``` | ```pg_catalog``` | ```pg_opclass``` | ```pg_opclass_am_name_nsp_index``` | 0 | 50480
```postgres``` | ```pg_catalog``` | ```pg_attribute``` | ```pg_attribute_relid_attnum_index``` | 0 | 22926
  
#### 建议
  
如果热索引的命中率很低, 说明需要增加shared buffer, 添加内存.  
  
### 8. 上次巡检以来未使用，或者使用较少的索引
  
current_database | schemaname | relname | indexrelname | idx_scan | idx_tup_read | idx_tup_fetch | pg_size_pretty
---|---|---|---|---|---
```postgres``` | ```public``` | ```arr_test``` | ```idx_arr_test``` | 0 | 0 | 0 | 3910 MB
```postgres``` | ```public``` | ```btree_test``` | ```idx_btree``` | 0 | 0 | 0 | 214 MB
```postgres``` | ```public``` | ```btree_test``` | ```idx_btree_1``` | 0 | 0 | 0 | 214 MB
```postgres``` | ```public``` | ```btree_test``` | ```idx_btree_2``` | 0 | 0 | 0 | 214 MB
```postgres``` | ```public``` | ```gin_test``` | ```idx_gin_test``` | 0 | 0 | 0 | 3910 MB
```postgres``` | ```public``` | ```gist_test``` | ```idx_gist``` | 0 | 0 | 0 | 601 MB
```postgres``` | ```public``` | ```rum_test``` | ```rumidx``` | 0 | 0 | 0 | 7036 MB
  
#### 建议
  
建议和应用开发人员确认后, 删除不需要的索引.  
  
### 9. 索引数超过4并且SIZE大于10MB的表
  
current_database | schemaname | relname | pg_size_pretty | idx_cnt
---|---|---|---|---
  
#### 建议
  
索引数量太多, 影响表的增删改性能, 建议检查是否有不需要的索引.  
  
建议检查pg_stat_all_tables(n_tup_ins,n_tup_upd,n_tup_del,n_tup_hot_upd), 如果确实非常频繁, 建议检查哪些索引是不需要的.  
  
## 二、数据库空间使用分析
  
### 1. 用户对象占用空间的柱状图
  
snap_ts | current_database | this_buk_no | rels_in_this_buk | buk_min | buk_max
---|---|---|---|---|---
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | 1 | 50631 | 0 bytes | 1374 MB
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | 3 | 3 | 3910 MB | 4340 MB
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | 5 | 1 | 7036 MB | 7036 MB
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | 10 | 2 | 15 GB | 15 GB
  
#### 建议
  
纵览用户对象大小的柱状分布图, 单容量超过10GB的对象(指排除TOAST的空间还超过10GB)，建议分区, 目前建议使用pg_pathman插件.  
  
## 三、数据库垃圾分析
  
### 1. 表膨胀分析
  
snap_ts | db | schemaname | tablename | tups | pages | otta | tbloat | wastedpages | wastedbytes | wastedsize | iname | itups | ipages | iotta | ibloat | wastedipages | wastedibytes | wastedisize | totalwastedbytes
---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```public``` | ```gin_test``` | 10000000 | 2000001 | 1737641 | 1.2 | 262360 | 2149253120 | 2149253120 bytes | idx_gin_test | 999505408 | 500492 | 171109651 | 0.0 | 0 | 0 | 0 bytes | 2149253120
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```public``` | ```rum_test``` | 9800000 | 1960028 | 1702888 | 1.2 | 257140 | 2106490880 | 2106490880 bytes | rumidx | 979514496 | 823549 | 167687321 | 0.0 | 0 | 0 | 0 bytes | 2106490880
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```public``` | ```pgbench_accounts``` | 10432854 | 173971 | 168519 | 1.0 | 5452 | 44662784 | 44662784 bytes | pgbench_accounts_pkey | 10432854 | 27422 | 139156 | 0.2 | 0 | 0 | 0 bytes | 44662784
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```public``` | ```arr_test``` | 10000000 | 555557 | 553109 | 1.0 | 2448 | 20054016 | 20054016 bytes | idx_arr_test | 999504960 | 500492 | 53326501 | 0.0 | 0 | 0 | 0 bytes | 20054016
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```public``` | ```pgbench_tellers``` | 51587 | 2790 | 430 | 6.5 | 2360 | 19333120 | 19333120 bytes | pgbench_tellers_pkey | 1000 | 574 | 3 | 191.3 | 571 | 4677632 | 4677632 bytes | 24010752
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```public``` | ```pgbench_branches``` | 100 | 2288 | 1 | 2288.0 | 2287 | 18735104 | 18735104 bytes | pgbench_branches_pkey | 100 | 80 | 1 | 80.0 | 79 | 647168 | 647168 bytes | 19382272
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```pg_catalog``` | ```pg_class``` | 51056 | 2191 | 1175 | 1.9 | 1016 | 8323072 | 8323072 bytes | pg_class_tblspc_relfilenode_index | 51056 | 315 | 907 | 0.3 | 0 | 0 | 0 bytes | 8323072
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```pg_catalog``` | ```pg_class``` | 51056 | 2191 | 1175 | 1.9 | 1016 | 8323072 | 8323072 bytes | pg_class_oid_index | 51056 | 443 | 907 | 0.5 | 0 | 0 | 0 bytes | 8323072
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```pg_catalog``` | ```pg_class``` | 51056 | 2191 | 1175 | 1.9 | 1016 | 8323072 | 8323072 bytes | pg_class_relname_nsp_index | 51056 | 589 | 907 | 0.6 | 0 | 0 | 0 bytes | 8323072
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```pg_catalog``` | ```pg_attribute``` | 107789 | 2926 | 2164 | 1.4 | 762 | 6242304 | 6242304 bytes | pg_attribute_relid_attnum_index | 107789 | 662 | 1570 | 0.4 | 0 | 0 | 0 bytes | 6242304
  
#### 建议
  
根据浪费的字节数, 设置合适的autovacuum_vacuum_scale_factor, 大表如果频繁的有更新或删除和插入操作, 建议设置较小的autovacuum_vacuum_scale_factor来降低浪费空间.  
  
同时还需要打开autovacuum, 根据服务器的内存大小, CPU核数, 设置足够大的autovacuum_work_mem 或 autovacuum_max_workers 或 maintenance_work_mem, 以及足够小的 autovacuum_naptime.  
  
同时还需要分析是否对大数据库使用了逻辑备份pg_dump, 系统中是否经常有长SQL, 长事务. 这些都有可能导致膨胀.  
  
使用pg_reorg或者vacuum full可以回收膨胀的空间.  
  
参考: http://blog.163.com/digoal@126/blog/static/1638770402015329115636287/.  
  
otta评估出的表实际需要页数, iotta评估出的索引实际需要页数.  
  
bs数据库的块大小.  
  
tbloat表膨胀倍数, ibloat索引膨胀倍数, wastedpages表浪费了多少个数据块, wastedipages索引浪费了多少个数据块.  
  
wastedbytes表浪费了多少字节, wastedibytes索引浪费了多少字节.  
  
### 2. 索引膨胀分析
  
snap_ts | db | schemaname | tablename | tups | pages | otta | tbloat | wastedpages | wastedbytes | wastedsize | iname | itups | ipages | iotta | ibloat | wastedipages | wastedibytes | wastedisize | totalwastedbytes
---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```public``` | ```gist_test``` | 9999939 | 63695 | 63632 | 1.0 | 63 | 516096 | 516096 bytes | idx_gist | 9999939 | 76922 | 36711 | 2.1 | 40211 | 329408512 | 329408512 bytes | 329924608
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```public``` | ```test_pg_part_single``` | 999999 | 8389 | 8322 | 1.0 | 67 | 548864 | 548864 bytes | test_pg_part_single_pkey | 999999 | 5486 | 2570 | 2.1 | 2916 | 23887872 | 23887872 bytes | 24436736
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```pg_catalog``` | ```pg_depend``` | 209624 | 2280 | 1540 | 1.5 | 740 | 6062080 | 6062080 bytes | pg_depend_depender_index | 209624 | 2462 | 950 | 2.6 | 1512 | 12386304 | 12386304 bytes | 18448384
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```pg_catalog``` | ```pg_depend``` | 209624 | 2280 | 1540 | 1.5 | 740 | 6062080 | 6062080 bytes | pg_depend_reference_index | 209624 | 1875 | 950 | 2.0 | 925 | 7577600 | 7577600 bytes | 13639680
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```public``` | ```pgbench_tellers``` | 51587 | 2790 | 430 | 6.5 | 2360 | 19333120 | 19333120 bytes | pgbench_tellers_pkey | 1000 | 574 | 3 | 191.3 | 571 | 4677632 | 4677632 bytes | 24010752
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```public``` | ```test_pg_part_orig_3``` | 100014 | 737 | 833 | 0.9 | 0 | 0 | 0 bytes | test_pg_part_orig_3_pkey | 100014 | 551 | 257 | 2.1 | 294 | 2408448 | 2408448 bytes | 2408448
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```public``` | ```test_pg_part_pathman_4``` | 100000 | 761 | 833 | 0.9 | 0 | 0 | 0 bytes | test_pg_part_pathman_4_pkey | 100000 | 551 | 257 | 2.1 | 294 | 2408448 | 2408448 bytes | 2408448
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```public``` | ```test_pg_part_pathman_8``` | 100000 | 738 | 833 | 0.9 | 0 | 0 | 0 bytes | test_pg_part_pathman_8_pkey | 100000 | 551 | 257 | 2.1 | 294 | 2408448 | 2408448 bytes | 2408448
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```public``` | ```test_pg_part_pathman_3``` | 100000 | 732 | 833 | 0.9 | 0 | 0 | 0 bytes | test_pg_part_pathman_3_pkey | 100000 | 551 | 257 | 2.1 | 294 | 2408448 | 2408448 bytes | 2408448
```2016-11-23 22:53:52.210324+08``` | ```postgres``` | ```public``` | ```test_pg_part_orig_9``` | 100001 | 730 | 833 | 0.9 | 0 | 0 | 0 bytes | test_pg_part_orig_9_pkey | 100001 | 551 | 257 | 2.1 | 294 | 2408448 | 2408448 bytes | 2408448
  
#### 建议
  
如果索引膨胀太大, 会影响性能, 建议重建索引, create index CONCURRENTLY ... .  
  
### 3. 垃圾记录 TOP 10 表分析
  
snap_ts | database | schemaname | tablename | n_dead_tup
---|---|---|---|---
  
#### 建议
  
通常垃圾过多, 可能是因为无法回收垃圾, 或者回收垃圾的进程繁忙或没有及时唤醒, 或者没有开启autovacuum, 或在短时间内产生了大量的垃圾.  
  
可以等待autovacuum进行处理, 或者手工执行vacuum table.  
  
### 4. 未引用的大对象分析
  
snap_ts | database | pg_size_pretty
---|---|---|---|---
  
#### 建议
  
如果大对象没有被引用时, 建议删除, 否则就类似于内存泄露, 使用vacuumlo可以删除未被引用的大对象, 例如: vacuumlo -l 1000 $db -w或者我写的调用vacuumlo()函数.  
  
应用开发时, 注意及时删除不需要使用的大对象, 使用lo_unlink 或 驱动对应的API.  
  
参考 http://www.postgresql.org/docs/9.4/static/largeobjects.html  
  
## 四、数据库安全或潜在风险分析
  
### 1. 表年龄前100
  
snap_ts | database | rolname | nspname | relkind | relname | age | age_remain
---|---|---|---|---|---|---|---
  
#### 建议
  
表的年龄正常情况下应该小于vacuum_freeze_table_age, 如果剩余年龄小于2亿, 建议人为干预, 将LONG SQL或事务杀掉后, 执行vacuum freeze.  
  
### 2. unlogged table和hash index
  
snap_ts | database | rolname | nspname | relname
---|---|---|---|---
  
snap_ts | database | idx
---|---|---
  
#### 建议
  
unlogged table和hash index不记录XLOG, 无法使用流复制或者log shipping的方式复制到standby节点, 如果在standby节点执行某些SQL, 可能导致报错或查不到数据.  
  
在数据库CRASH后无法修复unlogged table和hash index, 不建议使用.  
  
PITR对unlogged table和hash index也不起作用.  
  
### 3. 剩余可使用次数不足1000万次的序列检查
  
snap_ts | database | rolname | nspname | relname | times_remain
---|---|---|---|---|---
  
#### 建议
  
序列剩余使用次数到了之后, 将无法使用, 报错, 请开发人员关注.  
  
### 4. 锁等待分析
  
snap_ts | locktype | r_mode | r_user | r_db | relation | r_pid | r_page | r_tuple | r_xact_start | r_query_start | r_locktime | r_query | w_mode | w_pid | w_page | w_tuple | w_xact_start | w_query_start | w_locktime | w_query
---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---
  
#### 建议
  
锁等待状态, 反映业务逻辑的问题或者SQL性能有问题, 建议深入排查持锁的SQL.  

           
[Count](http://info.flagcounter.com/h9V1)                                                      
                 
         
