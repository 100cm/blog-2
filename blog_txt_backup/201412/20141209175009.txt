PostgreSQL research

ceph - adding A monitor (MANUAL)

2014-12-09 17:50:09   查看原文>>

本文讲一下如何对一个已经存在的ceph storage cluster手工添加一个监控节点.
建议的监控节点数为奇数. 因为需要使用paxos算法确保监控节点健康(大于一半的节点健康表示健康).
大致步骤 : 
1. 环境准备
2. 安装软件
3. 添加节点

以docker为例演示一下如何添加monitor节点 : 
测试环境请参考 : 
http://blog.163.com/digoal@126/blog/static/163877040201410269169450/
已有3个monitor节点, 本文再添加2个monitor节点.

创建卷 : 

[root@localhost ~]# mkdir -p /data01/mon4
[root@localhost ~]# mkdir -p /data01/mon5



启动容器 : 

# docker run -d --net=none --dns=202.101.172.35 --name=mon4 --hostname=mon4 --privileged=true -v /data01/mon4:/data01 digoal/sshd_ceph:giant
# docker run -d --net=none --dns=202.101.172.35 --name=mon5 --hostname=mon5 --privileged=true -v /data01/mon5:/data01 digoal/sshd_ceph:giant



配置容器网络 : 

./pipework.sh docker0 -i eth0 mon4 172.17.0.9/16
./pipework.sh br0 -i eth1 mon4 172.18.0.9/16
./pipework.sh br1 -i eth2 mon4 172.19.0.9/16
./pipework.sh docker0 -i eth0 mon5 172.17.0.10/16
./pipework.sh br0 -i eth1 mon5 172.18.0.10/16
./pipework.sh br1 -i eth2 mon5 172.19.0.10/16

ssh 172.17.0.9
ip route add default via 172.17.42.1 dev eth0

ssh 172.17.0.10
ip route add default via 172.17.42.1 dev eth0



配置所有节点主机名(所有节点) : 

ssh to 172.17.0.2, 3, 4, 9, 10

vi /etc/hosts
172.17.0.1      deploy
172.17.0.2      mon1
172.17.0.3      mon2
172.17.0.4      mon3
172.17.0.9      mon4
172.17.0.10      mon5
172.17.0.5      osd1
172.17.0.6      osd2
172.17.0.7      osd3
172.17.0.8      osd4



配置yum仓库(mon4, mon5) : 
参考 : 
http://blog.163.com/digoal@126/blog/static/163877040201410269169450/

配置内核参数 : 
参考 : 
http://blog.163.com/digoal@126/blog/static/163877040201410269169450/

安装软件 : 
参考 : 
http://blog.163.com/digoal@126/blog/static/163877040201410269169450/
http://blog.163.com/digoal@126/blog/static/163877040201410274232276/

创建数据目录(两种方法) : 
默认目录 : 

[root@mon4 ~]# mkdir -p /var/lib/ceph/mon/ceph-4
[root@mon5 ~]# mkdir -p /var/lib/ceph/mon/ceph-5


或者你可以使用非默认目录, 使用非默认目录后, 不能使用/etc/init.d/ceph来启动mon : 

[root@mon4 ~]# mkdir -p /data01/ceph/mon/ceph-4
[root@mon5 ~]# mkdir -p /data01/ceph/mon/ceph-5



从现有监控节点生成新增节点的信息, (或者从网络接收KEY, 在新增节点本地生成)
并拷贝配置文件和key到新增节点 : 
在已有节点生成的方法 : 

[root@localhost ~]# ssh 172.17.0.2
root@172.17.0.2's password: 
Last login: Tue Dec  9 16:13:47 2014 from 172.17.42.1
[root@mon1 ~]# ceph-mon --mkfs -i mon4 --monmap /tmp/monmap --keyring /tmp/ceph.mon.keyring 
ceph-mon: set fsid to f649b128-963c-4802-ae17-5a76f36c4c76
ceph-mon: created monfs at /var/lib/ceph/mon/ceph-mon4 for mon.mon4
[root@mon1 ~]# ceph-mon --mkfs -i mon5 --monmap /tmp/monmap --keyring /tmp/ceph.mon.keyring 
ceph-mon: set fsid to f649b128-963c-4802-ae17-5a76f36c4c76
ceph-mon: created monfs at /var/lib/ceph/mon/ceph-mon5 for mon.mon5


创建完拷贝到新加节点的对应目录即可.

在本地生成的方法 : 
1. 首选要将配置拷贝到新节点 : 

[root@mon1 ~]# scp /etc/ceph/ceph.conf /etc/ceph/ceph.client.admin.keyring 172.17.0.9:/etc/ceph
[root@mon1 ~]# scp /etc/ceph/ceph.conf /etc/ceph/ceph.client.admin.keyring 172.17.0.10:/etc/ceph


2. 接收KEY

[root@mon4 ~]# ceph auth get mon. -o /tmp/key
exported keyring for mon.
[root@mon5 ~]# ceph auth get mon. -o /tmp/key
exported keyring for mon.


3. 接收cluster map信息

[root@mon4 ~]# ceph mon getmap -o /tmp/map
got monmap epoch 1
[root@mon5 ~]# ceph mon getmap -o /tmp/map
got monmap epoch 1


4. 生成数据目录文件

[root@mon4 ~]# ceph-mon -i mon4 --mkfs --monmap /tmp/map --keyring /tmp/key --mon-data /data01/ceph/mon/ceph-4
ceph-mon: set fsid to f649b128-963c-4802-ae17-5a76f36c4c76
ceph-mon: created monfs at /data01/ceph/mon/ceph-4 for mon.mon4
[root@mon5 ~]# ceph-mon -i mon5 --mkfs --monmap /tmp/map --keyring /tmp/key --mon-data /data01/ceph/mon/ceph-5
ceph-mon: set fsid to f649b128-963c-4802-ae17-5a76f36c4c76
ceph-mon: created monfs at /data01/ceph/mon/ceph-5 for mon.mon5

# ceph-mon --help
usage: ceph-mon -i monid [flags]
  --debug_mon n
        debug monitor level (e.g. 10)
  --mkfs
        build fresh monitor fs
  --force-sync
        force a sync from another mon by wiping local data (BE CAREFUL)
  --yes-i-really-mean-it
        mandatory safeguard for --force-sync
  --compact
        compact the monitor store
  --osdmap <filename>
        only used when --mkfs is provided: load the osdmap from <filename>
  --inject-monmap <filename>
        write the <filename> monmap to the local monitor store and exit
  --extract-monmap <filename>
        extract the monmap from the local monitor store and exit
  --mon-data <directory>
        where the mon store and keyring are located
  --conf/-c FILE    read configuration from the given configuration file
  --id/-i ID        set ID portion of my name
  --name/-n TYPE.ID set name
  --cluster NAME    set cluster name (default: ceph)
  --version         show version and quit

  -d                run in foreground, log to stderr.
  -f                run in foreground, log to usual location.
  --debug_ms N      set message debug level (e.g. 1)



5. 添加新增节点(在任意节点添加一次即可).

[root@mon4 ~]# ceph mon add mon4 172.17.0.9
port defaulted to 6789; added mon.mon4 at 172.17.0.9:6789/0
[root@mon4 ~]# ceph mon add mon5 172.17.0.10
port defaulted to 6789; added mon.mon5 at 172.17.0.10:6789/0



启动mon

[root@mon4 ~]# ceph-mon -i mon4 --public-addr 172.17.0.9 --mon-data /data01/ceph/mon/ceph-4
[root@mon4 ~]# ps -ewf|grep ceph
root         223       1  3 17:45 pts/0    00:00:00 ceph-mon -i mon4 --public-addr 172.17.0.9 --mon-data /data01/ceph/mon/ceph-4
root         254      27  0 17:45 pts/0    00:00:00 grep --color=auto ceph
[root@mon5 ~]# ceph-mon -i mon5 --public-addr 172.17.0.10 --mon-data /data01/ceph/mon/ceph-5
[root@mon5 ~]# ps -ewf|grep ceph
root         127       1  2 17:45 pts/0    00:00:00 ceph-mon -i mon5 --public-addr 172.17.0.10 --mon-data /data01/ceph/mon/ceph-5
root         160      28  0 17:45 pts/0    00:00:00 grep --color=auto ceph


启动加入/etc/rc.local (注意centos7需要添加文件的执行权限chmod +x /etc/rc.d/rc.local)

查看集群状态, 可以看到新增的mon节点信息 : 

[root@mon5 ~]# ceph -s
    cluster f649b128-963c-4802-ae17-5a76f36c4c76
     health HEALTH_OK
     monmap e3: 5 mons at {mon1=172.17.0.2:6789/0,mon2=172.17.0.3:6789/0,mon3=172.17.0.4:6789/0,mon4=172.17.0.9:6789/0,mon5=172.17.0.10:6789/0}, election epoch 14, quorum 0,1,2,3,4 mon1,mon2,mon3,mon4,mon5
     osdmap e29: 4 osds: 4 up, 4 in
      pgmap v265: 128 pgs, 1 pools, 0 bytes data, 0 objects
            39588 MB used, 1597 GB / 1636 GB avail
                 128 active+clean



最后, 建议修改所有mon节点的配置文件, 将新增的mon节点信息加进去.
(修改ceph.conf只是为了好看, 其实mon节点之间是通过monmap来发现其他mon节点的, 所以配置文件不是必须的)

[root@xxxxxxxxxxxx ~]# cat /etc/ceph/ceph.conf 
.... 如下 : 
mon initial members = mon1, mon2, mon3, mon4, mon5
mon host = 172.17.0.2, 172.17.0.3, 172.17.0.4, 172.17.0.9, 172.17.0.10



[参考]
1. http://docs.ceph.com/docs/master/rados/operations/add-or-rm-mons/
2. http://blog.163.com/digoal@126/blog/static/163877040201410269169450/
Flag Counter
