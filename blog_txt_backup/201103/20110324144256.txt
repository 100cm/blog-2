PostgreSQL research

GreenPlum startup timeout resoluation

2011-03-24 14:42:56   查看原文>>

昨天数据仓库的同事把GreenPlum停掉，并且重启了服务器。
非常悲剧的是存放数据文件的分区被写在了FSTAB文件里面，默认情况下，文件系统有一个时间和MOUNT次数的阀值，超过阀值在服务器重启时将强行检查分区。这下一搞就搞到临晨1点多，最后通过光盘引导进到系统的救援模式把那些分区从fstab移除才把服务器弄起来。
服务器起来之后该起GreenPlum了，非常不幸，数据库起不来了。
现在回想起来原因可能是这样的：
1。在数据库关闭的时候，主节点是关闭了，但是SEGMENT节点可能还没来得及关掉，这个时候服务器重启了。
2。服务器起来之后，数据库该做恢复。但是GP的启动参数中默认有一个-w 等待60秒，而60秒还不够恢复。
3。因此60秒未起来的节点都会被认为启动FAULT，导致自动关闭GREENPLUM数据库集群（包括主节点和子节点）。
这样的话再怎么起也起不来。
下面是详细的处理过程：
1. 现象
20110324:01:48:42:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Starting gpstart with args: ''
20110324:01:48:42:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Gathering information and validating the environment...
20110324:01:48:42:gpstart:dw-host33-master-if0:greenplum-[INFO]:-local Greenplum Version: 'postgres (Greenplum Database) 3.3.6.1 bui
ld 1'
20110324:01:48:42:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Starting Master instance in admin mode
20110324:01:48:43:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Obtaining Greenplum Master catalog information
20110324:01:48:43:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Obtaining Segment details from master...
20110324:01:48:43:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Master Started...
20110324:01:48:43:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Shutting down master
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:---------------------------
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Master instance parameters
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:---------------------------
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Database                 = template1
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Master Port              = 1921
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Master directory         = /database/gp_master_3_3_6_1/gp-1
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Master standby start     = On
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:---------------------------------------
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Segment instances that will be started
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:---------------------------------------
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Host           Datadir                    Port   Status
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host35-if2  /database/gp_dmdir_0/gp0   51001  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host37-if0  /database/gp_dmdir_2/gp0   51101  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host35-if3  /database/gp_dmdir_1/gp1   51002  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host37-if1  /database/gp_dmdir_3/gp1   51102  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host36-if2  /database/gp_dmdir_0/gp2   51001  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host38-if0  /database/gp_dmdir_2/gp2   51101  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host36-if3  /database/gp_dmdir_1/gp3   51002  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host38-if1  /database/gp_dmdir_3/gp3   51102  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host37-if2  /database/gp_dmdir_0/gp4   51001  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host35-if0  /database/gp_dmdir_2/gp4   51101  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host37-if3  /database/gp_dmdir_1/gp5   51002  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host35-if1  /database/gp_dmdir_3/gp5   51102  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host38-if2  /database/gp_dmdir_0/gp6   51001  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host36-if0  /database/gp_dmdir_2/gp6   51101  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host38-if3  /database/gp_dmdir_1/gp7   51002  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host36-if1  /database/gp_dmdir_3/gp7   51102  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host39-if2  /database/gp_dmdir_0/gp8   51001  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host43-if0  /database/gp_dmdir_2/gp8   51101  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host39-if3  /database/gp_dmdir_1/gp9   51002  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host43-if1  /database/gp_dmdir_3/gp9   51102  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host41-if2  /database/gp_dmdir_0/gp10  51001  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host44-if0  /database/gp_dmdir_2/gp10  51101  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host41-if3  /database/gp_dmdir_1/gp11  51002  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host44-if1  /database/gp_dmdir_3/gp11  51102  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host43-if2  /database/gp_dmdir_0/gp12  51001  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host39-if0  /database/gp_dmdir_2/gp12  51101  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host43-if3  /database/gp_dmdir_1/gp13  51002  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host39-if1  /database/gp_dmdir_3/gp13  51102  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host44-if2  /database/gp_dmdir_0/gp14  51001  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host41-if0  /database/gp_dmdir_2/gp14  51101  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host44-if3  /database/gp_dmdir_1/gp15  51002  Valid
20110324:01:48:45:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dw-host41-if1  /database/gp_dmdir_3/gp15  51102  Valid
20110324:01:48:46:gp.py:dw-host33-master-if0:greenplum-[INFO]:-Starting standby master
20110324:01:48:46:gp.py:dw-host33-master-if0:greenplum-[INFO]:-Checking if standby master is running on host: dw-host34-if3  in directory: /database/gp_master_3_3_6_1/gp-1
20110324:01:48:46:gp.py:dw-host33-master-if0:greenplum-[INFO]:-No db instance process, entering recovery startup mode
20110324:01:48:47:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Commencing parallel segment instance startup, please wait...
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Process results...
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-----------------------------------------------------
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:31  FAILED  host:'dw-host39-if1' datadir:'/database/gp_dmdir_3/gp13' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:11  FAILED  host:'dw-host39-if3' datadir:'/database/gp_dmdir_1/gp9' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:10  FAILED  host:'dw-host39-if2' datadir:'/database/gp_dmdir_0/gp8' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:26  FAILED  host:'dw-host43-if0' datadir:'/database/gp_dmdir_2/gp8' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:27  FAILED  host:'dw-host43-if1' datadir:'/database/gp_dmdir_3/gp9' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:15  FAILED  host:'dw-host43-if3' datadir:'/database/gp_dmdir_1/gp13' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:29  FAILED  host:'dw-host44-if1' datadir:'/database/gp_dmdir_3/gp11' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:16  FAILED  host:'dw-host44-if2' datadir:'/database/gp_dmdir_0/gp14' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:28  FAILED  host:'dw-host44-if0' datadir:'/database/gp_dmdir_2/gp10' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:17  FAILED  host:'dw-host44-if3' datadir:'/database/gp_dmdir_1/gp15' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:33  FAILED  host:'dw-host41-if1' datadir:'/database/gp_dmdir_3/gp15' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:13  FAILED  host:'dw-host41-if3' datadir:'/database/gp_dmdir_1/gp11' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:12  FAILED  host:'dw-host41-if2' datadir:'/database/gp_dmdir_0/gp10' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:32  FAILED  host:'dw-host41-if0' datadir:'/database/gp_dmdir_2/gp14' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:5  FAILED  host:'dw-host36-if3' datadir:'/database/gp_dmdir_1/gp3' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:4  FAILED  host:'dw-host36-if2' datadir:'/database/gp_dmdir_0/gp2' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:25  FAILED  host:'dw-host36-if1' datadir:'/database/gp_dmdir_3/gp7' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:24  FAILED  host:'dw-host36-if0' datadir:'/database/gp_dmdir_2/gp6' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:8  FAILED  host:'dw-host38-if2' datadir:'/database/gp_dmdir_0/gp6' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:9  FAILED  host:'dw-host38-if3' datadir:'/database/gp_dmdir_1/gp7' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:20  FAILED  host:'dw-host38-if0' datadir:'/database/gp_dmdir_2/gp2' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:21  FAILED  host:'dw-host38-if1' datadir:'/database/gp_dmdir_3/gp3' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:18  FAILED  host:'dw-host37-if0' datadir:'/database/gp_dmdir_2/gp0' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:19  FAILED  host:'dw-host37-if1' datadir:'/database/gp_dmdir_3/gp1' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:6  FAILED  host:'dw-host37-if2' datadir:'/database/gp_dmdir_0/gp4' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:7  FAILED  host:'dw-host37-if3' datadir:'/database/gp_dmdir_1/gp5' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:23  FAILED  host:'dw-host35-if1' datadir:'/database/gp_dmdir_3/gp5' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:22  FAILED  host:'dw-host35-if0' datadir:'/database/gp_dmdir_2/gp4' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:3  FAILED  host:'dw-host35-if3' datadir:'/database/gp_dmdir_1/gp1' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-DBID:2  FAILED  host:'dw-host35-if2' datadir:'/database/gp_dmdir_0/gp0' with reason:'PG_CTL failed.'
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-----------------------------------------------------


20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-----------------------------------------------------
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Total processes marked as completed             = 2
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Total processes marked as failed                = 30 <<<<<
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-----------------------------------------------------
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Total instances marked invalid and bypassed     = 0
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Successfully started 2 of 32 segment instances <<<<<
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-----------------------------------------------------
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[WARNING]:-Segment instance startup failures reported
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[WARNING]:-Failed start 30 of 32 segment instances <<<<<
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[WARNING]:-A total of 30 errors were encountered
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[WARNING]:-Review /home/greenplum/gpAdminLogs/gpstart_20110324.log
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[WARNING]:-For more details on segment startup failure(s)
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[WARNING]:-Run gpstate to review current segment instance status
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-----------------------------------------------------
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[ERROR]:-No segment started for content: 0.  curr_content=12
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dumping success segments: ['DBID:30  STARTED', 'DBID:14  STARTED']
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-dumping mapping: ['12: DBID:30  STARTED']
20110324:01:52:49:gpstart:dw-host33-master-if0:greenplum-[INFO]:-Commencing parallel segment instance shutdown, please wait...
20110324:01:52:54:gpstart:dw-host33-master-if0:greenplum-[CRITICAL]:-gpstart failed. (Reason='Do not have enough valid segments to start the array.') exiting...

只有两个节点起来了。

2。没有启动的节点的日志表明数据库在做恢复，CPU占用100%。
2011-03-24 01:51:49.539239 CST,,,p16689,th-507526368,,,,0,,,seg-1,,,,,"LOG","00000","database system was interrupted at 2011-03-23 18:35:06 CST",,,,,,,0,,"xlog.c",5623,
2011-03-24 01:51:49.627039 CST,,,p16689,th-507526368,,,,0,,,seg-1,,,,,"LOG","00000","checkpoint record is at 111/CFA98080",,,,,,,0,,"xlog.c",5700,
2011-03-24 01:51:49.627083 CST,,,p16689,th-507526368,,,,0,,,seg-1,,,,,"LOG","00000","redo record is at 111/CFA98080; undo record is at 0/0; shutdown FALSE",,,,,,,0,,"xlog.c",5739,
2011-03-24 01:51:49.627099 CST,,,p16689,th-507526368,,,,0,,,seg-1,,,,,"LOG","00000","next transaction ID: 0/21258188; next OID: 595602762",,,,,,,0,,"xlog.c",5743,
2011-03-24 01:51:49.627110 CST,,,p16689,th-507526368,,,,0,,,seg-1,,,,,"LOG","00000","next MultiXactId: 1; next MultiXactOffset: 0",,,,,,,0,,"xlog.c",5746,
2011-03-24 01:51:49.627142 CST,,,p16689,th-507526368,,,,0,,,seg-1,,,,,"LOG","00000","database system was not properly shut down; automatic recovery in progress",,,,,,,0,,"xlog.c",5829,
2011-03-24 01:51:49.627323 CST,,,p16689,th-507526368,,,,0,,,seg-1,,,,,"LOG","00000","redo starts at 111/CFA980D8",,,,,,,0,,"xlog.c",5893,
2011-03-24 01:51:49.729438 CST,"greenplum","postgres",p16690,th-507526368,"[local]",,2011-03-24 01:51:49 CST,0,,,seg-1,,,,,"FATAL","57P03","the database system is starting up",,,,,,,0,,"postmaster.c",1887,"Traceback 0: 0x98615e: /opt/greenplumdb/3.3.6.1/greenplum-db-3.3.6.1/bin/postgres errstart+0x3be
Traceback 1: 0x7c10e8: /opt/greenplumdb/3.3.6.1/greenplum-db-3.3.6.1/bin/postgres +0x7c10e8
Traceback 2: 0x7c2216: /opt/greenplumdb/3.3.6.1/greenplum-db-3.3.6.1/bin/postgres +0x7c2216
Traceback 3: 0x7c35e5: /opt/greenplumdb/3.3.6.1/greenplum-db-3.3.6.1/bin/postgres PostmasterMain+0x945
Traceback 4: 0x6e533b: /opt/greenplumdb/3.3.6.1/greenplum-db-3.3.6.1/bin/postgres main+0x48b
Traceback 5: 0x3f2501d994: /lib64/libc.so.6 __libc_start_main+0xf4
Traceback 6: 0x45c899: /opt/greenplumdb/3.3.6.1/greenplum-db-3.3.6.1/bin/postgres +0x45c899
"

3。正常启动的节点日志：
2011-03-24 13:33:01.047260 CST,,,p19004,th-1848986848,,,,0,,,seg-1,,,,,"LOG","00000","database system was shut down at 2011-03-24 13:31:38 CST",,,,,,,0,,"xlog.c",5603,
2011-03-24 13:33:01.047371 CST,,,p19004,th-1848986848,,,,0,,,seg-1,,,,,"LOG","00000","checkpoint record is at 111/DAC1F440",,,,,,,0,,"xlog.c",5700,
2011-03-24 13:33:01.047387 CST,,,p19004,th-1848986848,,,,0,,,seg-1,,,,,"LOG","00000","redo record is at 111/DAC1F440; undo record is at 0/0; shutdown TRUE",,,,,,,0,,"xlog.c",5739,
2011-03-24 13:33:01.047401 CST,,,p19004,th-1848986848,,,,0,,,seg-1,,,,,"LOG","00000","next transaction ID: 0/21260914; next OID: 595668298",,,,,,,0,,"xlog.c",5743,
2011-03-24 13:33:01.047414 CST,,,p19004,th-1848986848,,,,0,,,seg-1,,,,,"LOG","00000","next MultiXactId: 1; next MultiXactOffset: 0",,,,,,,0,,"xlog.c",5746,
2011-03-24 13:33:01.047426 CST,,,p19004,th-1848986848,,,,0,,,seg-1,,,,,"LOG","00000","end of transaction log location is 111/DAC1F498",,,,,,,0,,"xlog.c",5998,
2011-03-24 13:33:01.047439 CST,,,p19004,th-1848986848,,,,0,,,seg-1,,,,,"LOG","00000","database system is ready",,,,,,,0,,"xlog.c",6189,

正常启动的节点和正在启动的节点看到的进程也是不一样的。
正常启动是postgres: writer process
正在启动是postgres: startup process

4。现象前面已经说过了，因为超时所以数据库起不来。那么怎么解决超时的问题，让数据库可以做完恢复阶段呢？
使用gpstart -v获取到子节点启动的脚本: (期间尝试修改过greenplum的启动脚本python写的，还是不能将-W传达给子节点，这个不知道GreenPlum会不会在后面的版本改进)
如下 :
$GPHOME/bin/pg_ctl -D /database/gp_dmdir_2/gp0 -l /database/gp_dmdir_2/gp0/pg_log/startup.log -w start 2>&1
$GPHOME/bin/pg_ctl -D /database/gp_dmdir_3/gp1 -l /database/gp_dmdir_3/gp1/pg_log/startup.log -w start 2>&1

把-w 改成-W，然后在各个子节点手工执行,(在做这个操作之前，应该确保不会有任何人可以修改到子节点的数据,可以通过防火墙来做)
#export PATH
GPPERFMONHOME=/opt/greenplum_performance_monitor/greenplum-perfmon-2.0.0.3
GPHOME=/opt/greenplumdb/3.3.6.1/greenplum-db-3.3.6.1
# Replace with symlink path if it is present and correct
if [ -h ${GPHOME}/../greenplum-db ]; then
    GPHOME_BY_SYMLINK=`(cd ${GPHOME}/../greenplum-db/ && pwd -P)`
    if [ x"${GPHOME_BY_SYMLINK}" = x"${GPHOME}" ]; then
        GPHOME=`(cd ${GPHOME}/../greenplum-db/ && pwd -L)`/.
    fi
    unset GPHOME_BY_SYMLINK
fi
PATH=$GPPERFMONHOME/bin:$GPHOME/bin:$GPHOME/ext/python/bin:$PATH
LD_LIBRARY_PATH=$GPPERFMONHOME/lib:$GPHOME/lib:$GPHOME/ext/python/lib:$LD_LIBRARY_PATH
PYTHONPATH=$GPHOME/lib/python
PYTHONHOME=$GPHOME/ext/python
MASTER_DATA_DIRECTORY=/database/gp_master_3_3_6_1/gp-1
export MASTER_DATA_DIRECTORY
export GPPERFMONHOME
export GPHOME
export PGPORT=1921
export PATH
export LD_LIBRARY_PATH
export PYTHONPATH
export PYTHONHOME

$GPHOME/bin/pg_ctl -D /database/gp_dmdir_2/gp0 -l /database/gp_dmdir_2/gp0/pg_log/startup.log -W start 2>&1
$GPHOME/bin/pg_ctl -D /database/gp_dmdir_3/gp1 -l /database/gp_dmdir_3/gp1/pg_log/startup.log -W start 2>&1

大概过了半个小时，所有的节点全部恢复完成。

5。 gpstop -f -C
确保各节点完全关闭后 gpstart 数据库启动完成。


6。其他:
如何在主节点关闭之后去关闭没有关干净的子节点?
gpstart -m 启动主节点到管理模式,
gpstop -M fast|immediate
或者使用ipcclean  ipcrm去清除

评论

wrong1121 - 2012-02-23 17:53:51

前辈，我遇到了相似的问题。我在使用gpmapreduce之后，使用gpstop -r重启系统，出报错了。按照你的方法，解决不了。你帮着分析一下原因

Lee_chao - 2011-04-02 7:57:11

4.0.5以上版本已经可以在gpstart上添加参数-w，解决这个问题

