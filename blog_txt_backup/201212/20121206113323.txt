PostgreSQL research

SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6

2012-12-06 11:33:23   查看原文>>

本文介绍P570(POWER6 4.2GHZ 16核) 如何安装SUSE LINUX操作系统.
1. 下载ISO
https://www.suse.com/products/server/eval.html
2. 选择IBM POWER下载
3. 刻录成光盘(当然网络安装也是可以的,本例使用光盘安装)
4. 将光盘插入P570光驱中.
5. 登陆HMC
以P570(CPU POWER6)为例
6. 创建逻辑分区, 将资源全部分配给逻辑分区.
7. 选中逻辑分区, 选择激活分区并打开终端.
8. 选择光盘引导
9. 进入SUSE安装界面
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
在boot:后面输入install, 准备安装.

SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.

10. 在这个界面按下F9 Abort 安装. 使用TAB键选中Abort Installation. 将退到配置界面.
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
 
11. 在配置界面配置语言, VNC和SSH.
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
如果选择错误可以使用Ctrl+D退回上一层.
配置使用VNC安装
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
配置语言选择ENGLISH.
Ctrl+D退回顶层, 选择1开始安装
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
输入VNC密码等
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
配置网络信息, 注意网卡不要选择错误.
配置网关
配置域名
配置DNS
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
安装, 终端将停留在这个界面, 这时你应该使用VNC客户端连接到P570进行安装
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
启动VNC, 连接IP:1, 输入配置的VNCPASSWORD, 图形化安装 : 
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
VNC界面 : 
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.

不要激活multipathd, 原因本文见末尾.
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
进入专家模式, 配置分区
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
选择正确的本地硬盘, /dev/sda不一定是本地硬盘, 这里一定要注意.
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
定制分区配置, 注意/boot和PPC所在磁盘的分区表一定是MSDOS的, 如果是GPT将无法引导使用.
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
 
配置1GB PPC分区和4GB boot 分区 : 
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.

SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
根分区可放在RAID下面 : 
把/dev/sdi和/dev/sdj配置时不格式, 选择为RAID分区类型 : 
在RAID中配置RAID1 : 
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
配置软件包, 选择合适的软件, 编译环境请勾上.
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
 
配置启动级别(如果希望使用VNC, 请使用5级别)
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
开始安装, 安装完后自动重启再次进入VNC进行安装后的配置 : 
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.
其他配置略.
配置结束后再次自动重启, 进入shell安装其他软件包 : 
例如: sysstat
SUSE SLES-11-SP2-DVD-ppc64-GM-DVD1 installed on IBM PowerPC P570 POWER6 - 德哥@Digoal - The Heart,The World.

使用案例 : 
查看CPU信息和内存信息 : 

linux-8tov:~ # cat /proc/cpuinfo 
processor       : 0
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 1
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 2
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 3
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 4
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 5
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 6
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 7
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 8
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 9
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 10
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 11
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 12
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 13
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 14
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

processor       : 15
cpu             : POWER6 (architected), altivec supported
clock           : 4208.000000MHz
revision        : 4.0 (pvr 003e 0400)

timebase        : 512000000
platform        : pSeries
model           : IBM,9117-MMA
machine         : CHRP IBM,9117-MMA


linux-8tov:~ # cat /proc/meminfo 
MemTotal:       130020096 kB
MemFree:        108628416 kB
Buffers:            6848 kB
Cached:         20251840 kB
SwapCached:            0 kB
Active:         14395264 kB
Inactive:        5962432 kB
Active(anon):   13323776 kB
Inactive(anon):  4529472 kB
Active(file):    1071488 kB
Inactive(file):  1432960 kB
Unevictable:           0 kB
Mlocked:               0 kB
SwapTotal:             0 kB
SwapFree:              0 kB
Dirty:               448 kB
Writeback:             0 kB
AnonPages:        100800 kB
Mapped:          4343104 kB
Shmem:          17754240 kB
Slab:             228096 kB
SReclaimable:     118720 kB
SUnreclaim:       109376 kB
KernelStack:        4224 kB
PageTables:        12800 kB
NFS_Unstable:          0 kB
Bounce:                0 kB
WritebackTmp:          0 kB
CommitLimit:    65010048 kB
Committed_AS:   17960704 kB
VmallocTotal:   8589934592 kB
VmallocUsed:      230528 kB
VmallocChunk:   8589615424 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:      16384 kB


简单性能测试 : 
将$PGDATA数据目录放到/dev/shm中, 规避IO问题, 测试一下POWER6在SUSE下发挥如何?
使用测试模型如下 : 
http://blog.163.com/digoal@126/blog/static/163877040201210279569426/
安装PostgreSQL : 

mkdir /home/postgres
groupadd postgres
useradd -g postgres postgres
passwd postgres
mkdir -p /data01/postgres/pg_root
chown -R postgres:postgres /data01/postgres
chmod 700 /data01/postgres/pg_root


检查flex版本

linux-8tov:/opt/soft_bak # flex -V
flex 2.5.35


下载postgresql-9.2.1.tar.bz2

tar -jxvf postgresql-9.2.1.tar.bz2
chown -R postgres:postgres postgresql-9.2.1
su - postgres
vi .bash_profile
export PS1="$USER@`/bin/hostname -s`-> "
export PGPORT=1921
export PGUSER=postgres
export PGDATA=/data01/postgres/pg_root
export LANG=en_US.utf8
export PGHOME=/opt/pgsql9.2.1
export PGHOST=$PGDATA

export LD_LIBRARY_PATH=$PGHOME/lib:/lib64:/usr/lib64:/usr/local/lib64:/lib:/usr/lib:/usr/local/lib
export DATE=`date +"%Y%m%d%H%M"`
export PATH=$PGHOME/bin:$PATH:.
export MANPATH=$PGHOME/share/man:$MANPATH
alias rm='rm -i'
alias ll='ls -lh'


su - root

. /home/postgres/.bash_profile
cd postgresql-9.2.1/
./configure --prefix=/opt/pgsql9.2.1 --with-pgport=1921 --without-perl --without-python --without-tcl --without-openssl --without-pa
m --without-ldap --without-libxml --without-libxslt --enable-thread-safety --with-wal-blocksize=16 --without-readline --enable-debug
 --without-zlib && gmake world
gmake install-world



配置内核参数 : 

vi /etc/sysctl.conf
# Controls the maximum shared segment size, in bytes
kernel.shmmax = 68719476736
# Controls the maximum number of shared memory segments, in pages
kernel.shmall = 4294967296
kernel.shmmni = 4096
kernel.sem = 50100 64128000 50100 1280
fs.file-max = 7672460
net.ipv4.ip_local_port_range = 9000 65000
net.core.rmem_default = 1048576
net.core.rmem_max = 4194304
net.core.wmem_default = 262144
net.core.wmem_max = 1048576
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_max_syn_backlog = 4096
net.core.netdev_max_backlog = 10000
net.ipv4.ip_conntrack_max = 655360
fs.aio-max-nr = 1048576
net.ipv4.tcp_timestamps = 0
vm.overcommit_memory = 0

sysctl -p



vi /etc/security/limits.conf 
* soft    nofile  131072
* hard    nofile  131072
* soft    nproc   131072
* hard    nproc   131072
* soft    core    unlimited
* hard    core    unlimited
* soft    memlock 50000000
* hard    memlock 50000000



初始化数据库

su - postgres
initdb -D $PGDATA -E UTF8 --locale=C -W



修改参数 : 

postgres@linux-8tov-> cat postgresql.conf |grep "^[a-Z]"
listen_addresses = '0.0.0.0'            # what IP address(es) to listen on;
port = 1921                             # (change requires restart)
max_connections = 100                   # (change requires restart)
unix_socket_directory = '.'             # (change requires restart)
unix_socket_permissions = 0777          # begin with 0 to use octal notation
shared_buffers = 4096MB                 # min 128kB
maintenance_work_mem = 1024MB           # min 1MB
max_stack_depth = 6MB                   # min 100kB
fsync = on                              # turns forced synchronization on or off
synchronous_commit = on                # synchronization level;
wal_sync_method = fsync         # the default is the first option
full_page_writes = on                   # recover from partial page writes
wal_buffers = -1                        # min 32kB, -1 sets based on shared_buffers
checkpoint_segments = 128               # in logfile segments, min 1, 16MB each
random_page_cost = 1.0                  # same scale as above
effective_cache_size = 128000MB
log_destination = 'csvlog'              # Valid values are combinations of
logging_collector = on          # Enable capturing of stderr and csvlog
log_directory = 'pg_log'                # directory where log files are written,
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log' # log file name pattern,
log_file_mode = 0600                    # creation mode for log files,
log_truncate_on_rotation = on           # If on, an existing log file with the
log_rotation_age = 1d                   # Automatic rotation of logfiles will
log_rotation_size = 10MB                # Automatic rotation of logfiles will
log_checkpoints = on
log_error_verbosity = verbose    # terse, default, or verbose messages
log_timezone = 'PRC'
datestyle = 'iso, mdy'
timezone = 'PRC'
lc_messages = 'C'                       # locale for system error message
lc_monetary = 'C'                       # locale for monetary formatting
lc_numeric = 'C'                        # locale for number formatting
lc_time = 'C'                           # locale for time formatting
default_text_search_config = 'pg_catalog.english'


启动数据库

pg_ctl start


测试P570: pgbench -M prepared -n -f ./ocz_test.sql -r -c 8 -j 8 -T 60 -U digoal digoal

postgres@linux-8tov-> pgbench -M prepared -n -f ./ocz_test.sql -r -c 8 -j 8 -T 60 -U digoal digoal
transaction type: Custom query
scaling factor: 1
query mode: prepared
number of clients: 8
number of threads: 8
duration: 60 s
number of transactions actually processed: 2044453
tps = 34073.725437 (including connections establishing)
tps = 34076.355739 (excluding connections establishing)
statement latencies in milliseconds:
        0.002345        \setrandom id 1 100000000
        0.230169        select f_ocz_test(:id);


测试DELL R610 (Intel(R) Xeon(R) CPU           E5504  @ 2.00GHz): 

pgbench -M prepared -n -f ./ocz_test.sql -r -c 8 -j 8 -T 60 -U digoal digoal
ocz@db-172-16-3-150-> pgbench -M prepared -n -f ./ocz_test.sql -r -c 8 -j 8 -T 60 -U digoal digoal
transaction type: Custom query
scaling factor: 1
query mode: prepared
number of clients: 8
number of threads: 8
duration: 60 s
number of transactions actually processed: 872040
tps = 14531.464744 (including connections establishing)
tps = 14532.889839 (excluding connections establishing)
statement latencies in milliseconds:
        0.002503        \setrandom id 1 200000000
        0.545474        select f_ocz_test(:id);


从测试结果来看, 4.2GHZ的CPU比INTEL的至强2.0GB(降频到1.6GHZ)强悍1倍多.
但是至强CPU显然没有完全发挥, 从以往经验来看16个(CPU核数*2)连接的时候才是它的最大发挥. 
16个连接的测试如下, 现在就相差无几了.

ocz@db-172-16-3-150-> pgbench -M prepared -n -f ./ocz_test.sql -r -c 16 -j 4 -T 60 -U digoal digoal
transaction type: Custom query
scaling factor: 1
query mode: prepared
number of clients: 16
number of threads: 4
duration: 60 s
number of transactions actually processed: 1977694
tps = 32950.854344 (including connections establishing)
tps = 32960.524839 (excluding connections establishing)
statement latencies in milliseconds:
        0.002050        \setrandom id 1 100000000
        0.481313        select f_ocz_test(:id);


在P570上使用同样的连接进行测试, 结果如下, 反而比不过X86的1.6GHZ至强了 : 

postgres@linux-8tov-> pgbench -M prepared -n -f ./ocz_test.sql -r -c 16 -j 4 -T 60 -U digoal digoal
transaction type: Custom query
scaling factor: 1
query mode: prepared
number of clients: 16
number of threads: 4
duration: 60 s
number of transactions actually processed: 1896552
tps = 31589.410287 (including connections establishing)
tps = 31595.576777 (excluding connections establishing)
statement latencies in milliseconds:
        0.002599        \setrandom id 1 100000000
        0.501256        select f_ocz_test(:id);



测试P570 pg_test_fsync : 
普通硬盘中测试 : 

postgres@linux-8tov-> pg_test_fsync 
2 seconds per test
O_DIRECT supported on this platform for open_datasync and open_sync.

Compare file sync methods using one 16kB write:
(in wal_sync_method preference order, except fdatasync
is Linux's default)
        open_datasync                                 n/a
        fdatasync                         134.321 ops/sec
        fsync                              81.323 ops/sec
        fsync_writethrough                            n/a
        open_sync                         134.287 ops/sec

Compare file sync methods using two 16kB writes:
(in wal_sync_method preference order, except fdatasync
is Linux's default)
        open_datasync                                 n/a
        fdatasync                         144.923 ops/sec
        fsync                              87.392 ops/sec
        fsync_writethrough                            n/a
        open_sync                          52.988 ops/sec

Compare open_sync with different write sizes:
(This is designed to compare the cost of writing 16kB
in different write open_sync sizes.)
         1 * 16kB open_sync write         147.943 ops/sec
         2 *  8kB open_sync writes         64.352 ops/sec
         4 *  4kB open_sync writes         33.420 ops/sec
         8 *  2kB open_sync writes         13.343 ops/sec
        16 *  1kB open_sync writes          8.251 ops/sec

Test if fsync on non-write file descriptor is honored:
(If the times are similar, fsync() can sync data written
on a different descriptor.)
        write, fsync, close               116.095 ops/sec
        write, close, fsync               109.310 ops/sec

Non-Sync'ed 16kB writes:
        write                           132190.476 ops/sec


P570 /dev/shm中测试 : 

postgres@linux-8tov-> pg_test_fsync 
2 seconds per test
O_DIRECT supported on this platform for open_datasync and open_sync.

Compare file sync methods using one 16kB write:
(in wal_sync_method preference order, except fdatasync
is Linux's default)
        open_datasync                                 n/a
        fdatasync                       325731.238 ops/sec
        fsync                           327595.203 ops/sec
        fsync_writethrough                            n/a
        open_sync                                    n/a*
* This file system and its mount options do not support direct
I/O, e.g. ext4 in journaled mode.

Compare file sync methods using two 16kB writes:
(in wal_sync_method preference order, except fdatasync
is Linux's default)
        open_datasync                                 n/a
        fdatasync                       190201.193 ops/sec
        fsync                           191306.352 ops/sec
        fsync_writethrough                            n/a
        open_sync                                    n/a*
* This file system and its mount options do not support direct
I/O, e.g. ext4 in journaled mode.

Compare open_sync with different write sizes:
(This is designed to compare the cost of writing 16kB
in different write open_sync sizes.)
         1 * 16kB open_sync write                    n/a*
         2 *  8kB open_sync writes                   n/a*
         4 *  4kB open_sync writes                   n/a*
         8 *  2kB open_sync writes                   n/a*
        16 *  1kB open_sync writes                   n/a*

Test if fsync on non-write file descriptor is honored:
(If the times are similar, fsync() can sync data written
on a different descriptor.)
        write, fsync, close             111022.447 ops/sec
        write, close, fsync             110380.913 ops/sec

Non-Sync'ed 16kB writes:
        write                           182141.988 ops/sec



DELL R610 (Intel(R) Xeon(R) CPU           E5504  @ 2.00GHz) /dev/shm中的测试 : 

ocz@db-172-16-3-150-> pg_test_fsync 
2 seconds per test
O_DIRECT supported on this platform for open_datasync and open_sync.

Compare file sync methods using one 16kB write:
(in wal_sync_method preference order, except fdatasync
is Linux's default)
        open_datasync                                 n/a
        fdatasync                       271407.153 ops/sec
        fsync                           272099.550 ops/sec
        fsync_writethrough                            n/a
        open_sync                                    n/a*
* This file system and its mount options do not support direct
I/O, e.g. ext4 in journaled mode.

Compare file sync methods using two 16kB writes:
(in wal_sync_method preference order, except fdatasync
is Linux's default)
        open_datasync                                 n/a
        fdatasync                       150862.830 ops/sec
        fsync                           149515.375 ops/sec
        fsync_writethrough                            n/a
        open_sync                                    n/a*
* This file system and its mount options do not support direct
I/O, e.g. ext4 in journaled mode.

Compare open_sync with different write sizes:
(This is designed to compare the cost of writing 16kB
in different write open_sync sizes.)
         1 * 16kB open_sync write                    n/a*
         2 *  8kB open_sync writes                   n/a*
         4 *  4kB open_sync writes                   n/a*
         8 *  2kB open_sync writes                   n/a*
        16 *  1kB open_sync writes                   n/a*

Test if fsync on non-write file descriptor is honored:
(If the times are similar, fsync() can sync data written
on a different descriptor.)
        write, fsync, close             140258.073 ops/sec
        write, close, fsync             140829.814 ops/sec

Non-Sync'ed 16kB writes:
        write                           203436.554 ops/sec


测试P570的 pg_test_timing

linux-8tov:~ # cat /sys/devices/system/clocksource/clocksource0/current_clocksource 
timebase
linux-8tov:~ # cat /sys/devices/system/clocksource/clocksource0/available_clocksource 
timebase 
postgres@linux-8tov-> pg_test_timing 
Testing timing overhead for 3 seconds.
Per loop time including overhead: 118.81 nsec
Histogram of timing durations:
   < usec:      count   percent
      256:          1  0.00000%
      128:          0  0.00000%
       64:          0  0.00000%
       32:          4  0.00002%
       16:          6  0.00002%
        8:        122  0.00048%
        4:        248  0.00098%
        2:    2998424 11.87444%
        1:   22252273 88.12405%


DELL R610 (Intel(R) Xeon(R) CPU           E5504  @ 2.00GHz) 测试的pg_test_timing

[root@db-172-16-3-150 data05]# cat /sys/devices/system/clocksource/clocksource0/current_clocksource
jiffies 
[root@db-172-16-3-150 data05]# cat /sys/devices/system/clocksource/clocksource0/available_clocksource 
jiffies 
ocz@db-172-16-3-150-> pg_test_timing 
Testing timing overhead for 3 seconds.
Per loop time including overhead: 80.17 nsec
Histogram of timing durations:
   < usec:      count   percent
      128:          3  0.00001%
       64:          0  0.00000%
       32:         14  0.00004%
       16:       3004  0.00803%
        8:        294  0.00079%
        4:        220  0.00059%
        2:    2971082  7.93924%
        1:   34448131 92.05131%


从测试结果来看, P570取时间的损耗要大一点.

【注意】
1. 本例中P570连接了存储, 所以在安装SUSE时会提示检测到多路径设备, 是否需要激活.
安装时不要激活, 因为多路径设备激活后没有配置multipathd.conf的情况下, 会把所有盘都加到多路径中.
而操作系统不能安装在多路径设备中, 因为系统还没有加载时根本认不到多路径设备.
所以安装时请选择不激活多路径设备.
将操作系统安装到本地硬盘中.
2. 必须有PPC分区和 boot分区. boot分区不要使用lvm或者RAID, 否则无法引导.
3. 其他分区可以使用RAID或者LVM.
4. http://blog.163.com/digoal@126/blog/static/1638770402012315112954240/
Flag Counter
