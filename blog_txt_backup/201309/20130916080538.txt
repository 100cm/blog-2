PostgreSQL research

PostgreSQL pending patch : MAP_HUGETLB for shared memory

2013-09-16 8:05:38   查看原文>>

The attached patch adds the MAP_HUGETLB flag to mmap() for shared memory
on systems that support it. It's based on Christian Kruse's patch from
last year, incorporating suggestions from Andres Freund.

On a system with 4GB shared_buffers, doing pgbench runs long enough for
each backend to touch most of the buffers, this patch saves nearly 8MB of
memory per backend and improves performances by just over 2% on average.

It is still WIP as there are a couple of points that Andres has pointed
out to me that haven't been addressed yet; also, the documentation is
incomplete.

Richard

-- 
Richard Poole                 http://www.2ndQuadrant.com/
PostgreSQL Development, 24x7 Support, Training & Services


MAP_HUGETLB是内核2.6.32引入的一个mmap flags, 用于使用huge pages分配共享内存.
使用大页面的好处是在大内存的管理上减少CPU的开销, 意见减少页表的大小. 从而提高性能.
PostgreSQL 9.3开始共享内存的分配使用mmap的方式.  所以这个补丁需用到9.3以及以上版本.
同时需要操作系统的支持, 内核需要2.6.32以及以上版本才行.
huge page在操作系统层面的配置, 详细参考Documentation/vm/hugetlbpage.txt

root@digoal-PowerEdge-R610:~# sysctl -w vm.nr_hugepages=10240
vm.nr_hugepages = 10240
root@digoal-PowerEdge-R610:~# cat /proc/meminfo 
HugePages_Total:   10240
HugePages_Free:    10240
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB


配置为系统配置 : 

root@digoal-PowerEdge-R610:~# vi /etc/sysctl.conf
# add
vm.nr_hugepages = 10240



[参考]

1. https://commitfest.postgresql.org/action/patch_view?id=1222

2. man mmap

flag


MAP_HUGETLB (since Linux 2.6.32)


Allocate the mapping using "huge pages."  See the Linux kernel


source file Documentation/vm/hugetlbpage.txt for further


information.


3. http://www.man7.org/linux/man-pages/man2/mmap.2.html

4. Documentation/vm/hugetlbpage.txt

The kernel built with hugepage support should show the number of configured


hugepages in the system by running the "cat /proc/meminfo" command.



/proc/meminfo also provides information about the total number of hugetlb


pages configured in the kernel.  It also displays information about the


number of free hugetlb pages at any time.  It also displays information about


the configured hugepage size - this is needed for generating the proper


alignment and size of the arguments to the above system calls.



The output of "cat /proc/meminfo" will have lines like:



.....


HugePages_Total: xxx


HugePages_Free:  yyy


HugePages_Rsvd:  www


Hugepagesize:    zzz kB


where:


HugePages_Total is the size of the pool of hugepages.


HugePages_Free is the number of hugepages in the pool that are not yet


allocated.


HugePages_Rsvd is short for "reserved," and is the number of hugepages


for which a commitment to allocate from the pool has been made, but no


allocation has yet been made. It's vaguely analogous to overcommit.



/proc/filesystems should also show a filesystem of type "hugetlbfs" configured


in the kernel.



/proc/sys/vm/nr_hugepages indicates the current number of configured hugetlb


pages in the kernel.  Super user can dynamically request more (or free some


pre-configured) hugepages.


The allocation (or deallocation) of hugetlb pages is possible only if there are


enough physically contiguous free pages in system (freeing of hugepages is


possible only if there are enough hugetlb pages free that can be transferred


back to regular memory pool).



Pages that are used as hugetlb pages are reserved inside the kernel and cannot


be used for other purposes.



Once the kernel with Hugetlb page support is built and running, a user can


use either the mmap system call or shared memory system calls to start using


the huge pages.  It is required that the system administrator preallocate


enough memory for huge page purposes.



Use the following command to dynamically allocate/deallocate hugepages:



        echo 20 > /proc/sys/vm/nr_hugepages



This command will try to configure 20 hugepages in the system.  The success


or failure of allocation depends on the amount of physically contiguous


memory that is preset in system at this time.  System administrators may want


to put this command in one of the local rc init files.  This will enable the


kernel to request huge pages early in the boot process (when the possibility


of getting physical contiguous pages is still very high).


If the user applications are going to request hugepages using mmap system


call, then it is required that system administrator mount a file system of


type hugetlbfs:



        mount none /mnt/huge -t hugetlbfs <uid=value> <gid=value> <mode=value>


                 <size=value> <nr_inodes=value>



This command mounts a (pseudo) filesystem of type hugetlbfs on the directory


/mnt/huge.  Any files created on /mnt/huge uses hugepages.  The uid and gid


options sets the owner and group of the root of the file system.  By default


the uid and gid of the current process are taken.  The mode option sets the


mode of root of file system to value & 0777.  This value is given in octal.


By default the value 0755 is picked. The size option sets the maximum value of


memory (huge pages) allowed for that filesystem (/mnt/huge). The size is


rounded down to HPAGE_SIZE.  The option nr_inodes sets the maximum number of


inodes that /mnt/huge can use.  If the size or nr_inodes options are not


provided on command line then no limits are set.  For size and nr_inodes


options, you can use [G|g]/[M|m]/[K|k] to represent giga/mega/kilo. For


example, size=2K has the same meaning as size=2048. An example is given at


the end of this document.



read and write system calls are not supported on files that reside on hugetlb


file systems.



Regular chown, chgrp, and chmod commands (with right permissions) could be


used to change the file attributes on hugetlbfs.



Also, it is important to note that no such mount command is required if the


applications are going to use only shmat/shmget system calls.  Users who


wish to use hugetlb page via shared memory segment should be a member of


a supplementary group and system admin needs to configure that gid into


/proc/sys/vm/hugetlb_shm_group.  It is possible for same or different


applications to use any combination of mmaps and shm* calls, though the


mount of filesystem will be required for using mmap calls.


5. patch 增加的一个参数

+     <varlistentry id="guc-huge-tlb-pages" xreflabel="huge_tlb_pages">


+      <term><varname>huge_tlb_pages</varname> (<type>enum</type>)</term>


+      <indexterm>


+       <primary><varname>huge_tlb_pages</> configuration parameter</primary>


+      </indexterm>


+      <listitem>


+       <para>


+        Enables/disables the use of huge tlb pages. Valid values are


+        <literal>on</literal>, <literal>off</literal> and <literal>try</literal>.


+        The default value is <literal>try</literal>.


+       </para>


+


+          <para>


+          Use of huge tlb pages reduces the cpu time spent on memory management and


+          the amount of memory used for page tables and therefore improves performance.


+          </para>


+


+       <para>


+        With <varname>huge_tlb_pages</varname> set to <literal>on</literal>


+        <symbol>mmap()</symbol> will be called with <symbol>MAP_HUGETLB</symbol>.


+        If the call fails the server will fail fatally.


+       </para>


+


+       <para>


+        With <varname>huge_tlb_pages</varname> set to <literal>off</literal> we


+        will not use <symbol>MAP_HUGETLB</symbol> at all.


+       </para>


+


+       <para>


+        With <varname>huge_tlb_pages</varname> set to <literal>try</literal>


+        we will try to use <symbol>MAP_HUGETLB</symbol> and fall back to


+        <symbol>mmap()</symbol> without <symbol>MAP_HUGETLB</symbol>.


+       </para>


+      </listitem>


+     </varlistentry>


其他详见

http://www.postgresql.org/message-id/attachment/30126/hugepages-v1.patch

