PostgreSQL research

a case for work_mem tuning in partition tables HashAggregate & GroupAggregate

2014-10-29 17:01:58   查看原文>>

群里的一位朋友问到的一个问题, 当他使用主表查询, 对一批数据进行分组排序输出时, 与直接对多个要查询的子表进行查询并分组输出时间要慢很多.
例如, 按天分区的表.

select id,count(*) from a where crt_time>='2014-01-01 and crt_time <'2014-01-08' group by id; -- 100秒
与
select id,count(*) from a_1 group by id 
union 
select id,count(*) from a_2 group by id
union 
select id,count(*) from a_3 group by id
union 
select id,count(*) from a_4 group by id
union 
select id,count(*) from a_5 group by id
union 
select id,count(*) from a_6 group by id
union 
select id,count(*) from a_7 group by id;  -- 5秒
首先排除第一条SQL主表a有数据的可能, 然后排除扫描所有子表的可能.
以上两种可能都不存在, 那么就看执行计划了.



这是直接使用子表查询的执行计划 : 
a case for work_mem tuning in partition tables HashAggregate GroupAggregate - 德哥@Digoal - PostgreSQL research

这是使用主表查询的执行计划.
a case for work_mem tuning in partition tables HashAggregate GroupAggregate - 德哥@Digoal - PostgreSQL research
两个执行计划的区别在于, 一个使用了hash聚合(快的那个), 另一个使用了排序以及分组聚合(慢的那个).
接下来看看使用分组聚合的详细执行计划 : 
explain (analyze,verbose,costs,buffers,timing) SQL的输出如下 : 
我们可以看到最耗的位置在排序处, 从append 3.8秒到排序输出第一行150秒的耗时约146.2秒. 排序方法是external merge.
用到的磁盘空间215MB.
为什么直接查子表不需要额外排序, 而查总表则出现了外部排序呢? 原因可能是单个子表的数据量较小, 选择了较优的hashagg , 而查总表的话, 所有数据聚合后, hashagg需要的内存不够, 所以选择了较差的分组聚合.
有兴趣的朋友可以阅读 :  src/backend/executor/nodeAgg.c

a case for work_mem tuning in partition tables HashAggregate GroupAggregate - 德哥@Digoal - PostgreSQL research
为了消除这个外部排序的影响, 可以加大work_mem. 
将work_mem调到1GB后, 查总表也使用hashagg, 问题消除.

下面在测试环境模拟一下, 使用上一篇文章的例子
http://blog.163.com/digoal@126/blog/static/163877040201492911252135/

digoal=# create table c(id int, crt_time date);
CREATE TABLE
digoal=# create table c1(like c including all) inherits(c);
NOTICE:  merging column "id" with inherited definition
NOTICE:  merging column "crt_time" with inherited definition
CREATE TABLE
digoal=# create table c2(like c including all) inherits(c);
NOTICE:  merging column "id" with inherited definition
NOTICE:  merging column "crt_time" with inherited definition
CREATE TABLE
digoal=# create table c3(like c including all) inherits(c);
NOTICE:  merging column "id" with inherited definition
NOTICE:  merging column "crt_time" with inherited definition
CREATE TABLE
digoal=# create table c4(like c including all) inherits(c);
NOTICE:  merging column "id" with inherited definition
NOTICE:  merging column "crt_time" with inherited definition
CREATE TABLE
digoal=# create table c5(like c including all) inherits(c);
NOTICE:  merging column "id" with inherited definition
NOTICE:  merging column "crt_time" with inherited definition
CREATE TABLE
digoal=# create table c6(like c including all) inherits(c);
NOTICE:  merging column "id" with inherited definition
NOTICE:  merging column "crt_time" with inherited definition
CREATE TABLE
digoal=# alter table c1 add constraint ck check(crt_time='2014-01-01');
ALTER TABLE
digoal=# alter table c2 add constraint ck check(crt_time='2014-01-02');
ALTER TABLE
digoal=# alter table c3 add constraint ck check(crt_time='2014-01-03');
ALTER TABLE
digoal=# alter table c4 add constraint ck check(crt_time='2014-01-04');
ALTER TABLE
digoal=# alter table c5 add constraint ck check(crt_time='2014-01-05');
ALTER TABLE
digoal=# alter table c6 add constraint ck check(crt_time='2014-01-06');
ALTER TABLE
digoal=# show constraint_exclusion;
 constraint_exclusion 
----------------------
 partition
(1 row)



插入测试数据

digoal=# insert into c1 select generate_series(1,1000000),'2014-01-01';
INSERT 0 1000000
digoal=# insert into c2 select generate_series(1,1000000),'2014-01-02';
INSERT 0 1000000
digoal=# insert into c3 select generate_series(1,1000000),'2014-01-03';
INSERT 0 1000000
digoal=# insert into c4 select generate_series(1,1000000),'2014-01-04';
INSERT 0 1000000
digoal=# insert into c5 select generate_series(1,1000000),'2014-01-05';
INSERT 0 1000000
digoal=# insert into c6 select generate_series(1,1000000),'2014-01-06';
INSERT 0 1000000



当前的work_mem : 

digoal=# show work_mem;
 work_mem 
----------
 128MB
(1 row)



查总表外部排序 : 

digoal=# explain (analyze,verbose,costs,buffers,timing) select id,count(*) from c where crt_time>='2014-01-01' and crt_time <'2014-01-07' group by id;
                                                              QUERY PLAN                                                            
   
------------------------------------------------------------------------------------------------------------------------------------
---
 GroupAggregate  (cost=792612.05..857909.28 rows=2029722 width=4) (actual time=9810.286..13421.311 rows=1000000 loops=1)
   Output: c.id, count(*)
   Buffers: shared hit=3996 read=2610, temp read=2565 written=2565
   ->  Sort  (cost=792612.05..807612.05 rows=6000001 width=4) (actual time=9810.267..12040.295 rows=6000000 loops=1)
         Output: c.id
         Sort Key: c.id
         Sort Method: external merge  Disk: 82016kB
         Buffers: shared hit=3996 read=2610, temp read=2565 written=2565
         ->  Append  (cost=0.00..96606.00 rows=6000001 width=4) (actual time=0.082..2979.715 rows=6000000 loops=1)
               Buffers: shared hit=3996 read=2610
               ->  Seq Scan on public.c  (cost=0.00..0.00 rows=1 width=4) (actual time=0.002..0.002 rows=0 loops=1)
                     Output: c.id
                     Filter: ((c.crt_time >= '2014-01-01'::date) AND (c.crt_time < '2014-01-07'::date))
               ->  Seq Scan on public.c1  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.078..329.924 rows=1000000 loops=
1)
                     Output: c1.id
                     Filter: ((c1.crt_time >= '2014-01-01'::date) AND (c1.crt_time < '2014-01-07'::date))
                     Buffers: shared hit=32 read=1069
               ->  Seq Scan on public.c2  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.061..328.645 rows=1000000 loops=
1)
                     Output: c2.id
                     Filter: ((c2.crt_time >= '2014-01-01'::date) AND (c2.crt_time < '2014-01-07'::date))
                     Buffers: shared hit=214 read=887
               ->  Seq Scan on public.c3  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.065..330.881 rows=1000000 loops=
1)
                     Output: c3.id
                     Filter: ((c3.crt_time >= '2014-01-01'::date) AND (c3.crt_time < '2014-01-07'::date))
                     Buffers: shared hit=913 read=188
               ->  Seq Scan on public.c4  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.080..336.704 rows=1000000 loops=
1)
                     Output: c4.id
                     Filter: ((c4.crt_time >= '2014-01-01'::date) AND (c4.crt_time < '2014-01-07'::date))
                     Buffers: shared hit=650 read=451
               ->  Seq Scan on public.c5  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.043..333.758 rows=1000000 loops=
1)
                     Output: c5.id
                     Filter: ((c5.crt_time >= '2014-01-01'::date) AND (c5.crt_time < '2014-01-07'::date))
                     Buffers: shared hit=1101
               ->  Seq Scan on public.c6  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.043..332.370 rows=1000000 loops=
1)
                     Output: c6.id
                     Filter: ((c6.crt_time >= '2014-01-01'::date) AND (c6.crt_time < '2014-01-07'::date))
                     Buffers: shared hit=1086 read=15
 Total runtime: 13525.762 ms
(38 rows)



本例查子表也用到了外部排序, 因为数据分散的问题.

digoal=# explain (analyze,verbose,costs,buffers,timing) select id,count(*) from c1 where crt_time>='2014-01-01' and crt_time <'2014-01-02' group by id union select id,count(*) from c2 where crt_time>='2014-01-02' and crt_time <'2014-01-03' group by id union select id,count(*) from c3 where crt_time>='2014-01-03' and crt_time <'2014-01-04' group by id union select id,count(*) from c4 where crt_time>='2014-01-04' and crt_time <'2014-01-05' group by id union select id,count(*) from c5 where crt_time>='2014-01-05' and crt_time <'2014-01-06' group by id union select id,count(*) from c6 where crt_time>='2014-01-06' and crt_time <'2014-01-07' group by id;
                                                                 QUERY PLAN                                                         
         
------------------------------------------------------------------------------------------------------------------------------------
---------
 Unique  (cost=942611.93..987611.93 rows=6000000 width=4) (actual time=19002.061..23284.741 rows=1000000 loops=1)
   Output: c1.id, (count(*))
   Buffers: shared hit=3993 read=2613, temp read=4763 written=4763
   ->  Sort  (cost=942611.93..957611.93 rows=6000000 width=4) (actual time=19002.057..22088.342 rows=6000000 loops=1)
         Output: c1.id, (count(*))
         Sort Key: c1.id, (count(*))
         Sort Method: external merge  Disk: 152352kB
         Buffers: shared hit=3993 read=2613, temp read=4763 written=4763
         ->  Append  (cost=21101.00..246606.00 rows=6000000 width=4) (actual time=845.864..9184.473 rows=6000000 loops=1)
               Buffers: shared hit=3993 read=2613
               ->  HashAggregate  (cost=21101.00..31101.00 rows=1000000 width=4) (actual time=845.862..1368.280 rows=1000000 loops=1
)
                     Output: c1.id, count(*)
                     Buffers: shared hit=24 read=1077
                     ->  Seq Scan on public.c1  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.100..307.566 rows=1000000 
loops=1)
                           Output: c1.id, c1.crt_time
                           Filter: ((c1.crt_time >= '2014-01-01'::date) AND (c1.crt_time < '2014-01-02'::date))
                           Buffers: shared hit=24 read=1077
               ->  HashAggregate  (cost=21101.00..31101.00 rows=1000000 width=4) (actual time=822.011..1350.118 rows=1000000 loops=1
)
                     Output: c2.id, count(*)
                     Buffers: shared hit=219 read=882
                     ->  Seq Scan on public.c2  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.097..300.078 rows=1000000 
loops=1)
                           Output: c2.id, c2.crt_time
                           Filter: ((c2.crt_time >= '2014-01-02'::date) AND (c2.crt_time < '2014-01-03'::date))
                           Buffers: shared hit=219 read=882
               ->  HashAggregate  (cost=21101.00..31101.00 rows=1000000 width=4) (actual time=822.433..1372.078 rows=1000000 loops=1
)
                     Output: c3.id, count(*)
                     Buffers: shared hit=913 read=188
                     ->  Seq Scan on public.c3  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.086..295.581 rows=1000000 
loops=1)
                           Output: c3.id, c3.crt_time
                           Filter: ((c3.crt_time >= '2014-01-03'::date) AND (c3.crt_time < '2014-01-04'::date))
                           Buffers: shared hit=913 read=188
               ->  HashAggregate  (cost=21101.00..31101.00 rows=1000000 width=4) (actual time=843.288..1396.913 rows=1000000 loops=1
)
                     Output: c4.id, count(*)
                     Buffers: shared hit=650 read=451
                     ->  Seq Scan on public.c4  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.100..305.916 rows=1000000 
loops=1)
                           Output: c4.id, c4.crt_time
                           Filter: ((c4.crt_time >= '2014-01-04'::date) AND (c4.crt_time < '2014-01-05'::date))
                           Buffers: shared hit=650 read=451
               ->  HashAggregate  (cost=21101.00..31101.00 rows=1000000 width=4) (actual time=825.540..1380.924 rows=1000000 loops=1
)
                     Output: c5.id, count(*)
                     Buffers: shared hit=1101
                     ->  Seq Scan on public.c5  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.057..295.092 rows=1000000 
loops=1)
                           Output: c5.id, c5.crt_time
                           Filter: ((c5.crt_time >= '2014-01-05'::date) AND (c5.crt_time < '2014-01-06'::date))
                           Buffers: shared hit=1101
               ->  HashAggregate  (cost=21101.00..31101.00 rows=1000000 width=4) (actual time=813.685..1357.617 rows=1000000 loops=1
)
                     Output: c6.id, count(*)
                     Buffers: shared hit=1086 read=15
                     ->  Seq Scan on public.c6  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.056..288.254 rows=1000000 
loops=1)
                           Output: c6.id, c6.crt_time
                           Filter: ((c6.crt_time >= '2014-01-06'::date) AND (c6.crt_time < '2014-01-07'::date))
                           Buffers: shared hit=1086 read=15
 Total runtime: 23437.343 ms
(53 rows)



将work_mem调整为1G, 可以看到都用了hash agg.

digoal=# set work_mem='1024MB';
SET
digoal=# explain (analyze,verbose,costs,buffers,timing) select id,count(*) from c where crt_time>='2014-01-01' and crt_time <'2014-01-07' group by id;
                                                           QUERY PLAN                                                            
---------------------------------------------------------------------------------------------------------------------------------
 HashAggregate  (cost=126606.01..146903.23 rows=2029722 width=4) (actual time=5675.413..6155.421 rows=1000000 loops=1)
   Output: c.id, count(*)
   Buffers: shared hit=3998 read=2608
   ->  Append  (cost=0.00..96606.00 rows=6000001 width=4) (actual time=0.129..2918.016 rows=6000000 loops=1)
         Buffers: shared hit=3998 read=2608
         ->  Seq Scan on public.c  (cost=0.00..0.00 rows=1 width=4) (actual time=0.003..0.003 rows=0 loops=1)
               Output: c.id
               Filter: ((c.crt_time >= '2014-01-01'::date) AND (c.crt_time < '2014-01-07'::date))
         ->  Seq Scan on public.c1  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.124..333.355 rows=1000000 loops=1)
               Output: c1.id
               Filter: ((c1.crt_time >= '2014-01-01'::date) AND (c1.crt_time < '2014-01-07'::date))
               Buffers: shared hit=40 read=1061
         ->  Seq Scan on public.c2  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.062..330.987 rows=1000000 loops=1)
               Output: c2.id
               Filter: ((c2.crt_time >= '2014-01-01'::date) AND (c2.crt_time < '2014-01-07'::date))
               Buffers: shared hit=208 read=893
         ->  Seq Scan on public.c3  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.062..328.088 rows=1000000 loops=1)
               Output: c3.id
               Filter: ((c3.crt_time >= '2014-01-01'::date) AND (c3.crt_time < '2014-01-07'::date))
               Buffers: shared hit=913 read=188
         ->  Seq Scan on public.c4  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.088..327.046 rows=1000000 loops=1)
               Output: c4.id
               Filter: ((c4.crt_time >= '2014-01-01'::date) AND (c4.crt_time < '2014-01-07'::date))
               Buffers: shared hit=650 read=451
         ->  Seq Scan on public.c5  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.042..324.955 rows=1000000 loops=1)
               Output: c5.id
               Filter: ((c5.crt_time >= '2014-01-01'::date) AND (c5.crt_time < '2014-01-07'::date))
               Buffers: shared hit=1101
         ->  Seq Scan on public.c6  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.040..327.222 rows=1000000 loops=1)
               Output: c6.id
               Filter: ((c6.crt_time >= '2014-01-01'::date) AND (c6.crt_time < '2014-01-07'::date))
               Buffers: shared hit=1086 read=15
 Total runtime: 6242.880 ms
(33 rows)

digoal=# explain (analyze,verbose,costs,buffers,timing) select id,count(*) from c1 where crt_time>='2014-01-01' and crt_time <'2014-01-02' group by id union select id,count(*) from c2 where crt_time>='2014-01-02' and crt_time <'2014-01-03' group by id union select id,count(*) from c3 where crt_time>='2014-01-03' and crt_time <'2014-01-04' group by id union select id,count(*) from c4 where crt_time>='2014-01-04' and crt_time <'2014-01-05' group by id union select id,count(*) from c5 where crt_time>='2014-01-05' and crt_time <'2014-01-06' group by id union select id,count(*) from c6 where crt_time>='2014-01-06' and crt_time <'2014-01-07' group by id;
                                                              QUERY PLAN                                                            
   
------------------------------------------------------------------------------------------------------------------------------------
 HashAggregate  (cost=276606.00..336606.00 rows=6000000 width=4) (actual time=11468.509..11781.540 rows=1000000 loops=1)
   Output: c1.id, (count(*))
   Buffers: shared hit=4025 read=2581
   ->  Append  (cost=21101.00..246606.00 rows=6000000 width=4) (actual time=850.063..9035.397 rows=6000000 loops=1)
         Buffers: shared hit=4025 read=2581
         ->  HashAggregate  (cost=21101.00..31101.00 rows=1000000 width=4) (actual time=850.061..1368.469 rows=1000000 loops=1)
               Output: c1.id, count(*)
               Buffers: shared hit=48 read=1053
               ->  Seq Scan on public.c1  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.114..307.451 rows=1000000 loops=1)
                     Output: c1.id, c1.crt_time
                     Filter: ((c1.crt_time >= '2014-01-01'::date) AND (c1.crt_time < '2014-01-02'::date))
                     Buffers: shared hit=48 read=1053
         ->  HashAggregate  (cost=21101.00..31101.00 rows=1000000 width=4) (actual time=836.154..1349.903 rows=1000000 loops=1)
               Output: c2.id, count(*)
               Buffers: shared hit=216 read=885
               ->  Seq Scan on public.c2  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.087..303.089 rows=1000000 loops=1)
                     Output: c2.id, c2.crt_time
                     Filter: ((c2.crt_time >= '2014-01-02'::date) AND (c2.crt_time < '2014-01-03'::date))
                     Buffers: shared hit=216 read=885
         ->  HashAggregate  (cost=21101.00..31101.00 rows=1000000 width=4) (actual time=828.630..1348.352 rows=1000000 loops=1)
               Output: c3.id, count(*)
               Buffers: shared hit=921 read=180
               ->  Seq Scan on public.c3  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.091..297.766 rows=1000000 loops=1)
                     Output: c3.id, c3.crt_time
                     Filter: ((c3.crt_time >= '2014-01-03'::date) AND (c3.crt_time < '2014-01-04'::date))
                     Buffers: shared hit=921 read=180
         ->  HashAggregate  (cost=21101.00..31101.00 rows=1000000 width=4) (actual time=842.887..1354.458 rows=1000000 loops=1)
               Output: c4.id, count(*)
               Buffers: shared hit=653 read=448
               ->  Seq Scan on public.c4  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.097..303.056 rows=1000000 loops=1)
                     Output: c4.id, c4.crt_time
                     Filter: ((c4.crt_time >= '2014-01-04'::date) AND (c4.crt_time < '2014-01-05'::date))
                     Buffers: shared hit=653 read=448
         ->  HashAggregate  (cost=21101.00..31101.00 rows=1000000 width=4) (actual time=828.422..1341.230 rows=1000000 loops=1)
               Output: c5.id, count(*)
               Buffers: shared hit=1101
               ->  Seq Scan on public.c5  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.056..297.737 rows=1000000 loops=1)
                     Output: c5.id, c5.crt_time
                     Filter: ((c5.crt_time >= '2014-01-05'::date) AND (c5.crt_time < '2014-01-06'::date))
                     Buffers: shared hit=1101
         ->  HashAggregate  (cost=21101.00..31101.00 rows=1000000 width=4) (actual time=827.476..1338.545 rows=1000000 loops=1)
               Output: c6.id, count(*)
               Buffers: shared hit=1086 read=15
               ->  Seq Scan on public.c6  (cost=0.00..16101.00 rows=1000000 width=4) (actual time=0.056..296.118 rows=1000000 loops=1)
                     Output: c6.id, c6.crt_time
                     Filter: ((c6.crt_time >= '2014-01-06'::date) AND (c6.crt_time < '2014-01-07'::date))
                     Buffers: shared hit=1086 read=15
 Total runtime: 11931.280 ms
(48 rows)



至于work_mem该怎样设置, 设置多大, 需要结合应用场景来设置, 可以在会话中临时设置当前会话的值, 也可以在postgresql.conf中设置默认在, 也可以设置数据库或角色的优先值. 
一般OLTP的话, 如果没有需要用到work_mem的查询(如排序,分组), 那么默认值就可以了.
如果有用到WORK_MEM的需求, 可以根据需要调大.
对于OLAP系统, 也是根据时间情况来调整, 可以比OLTP略大.

[参考]
1. http://blog.163.com/digoal@126/blog/static/16387704020141229159715/

Flag Counter
