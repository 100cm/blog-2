PostgreSQL research

PostgreSQL why not DirectIO for datafile?

2015-05-03 10:26:03   查看原文>>

PostgreSQL目前仅仅支持xlog使用DirectIO，对于数据文件不支持DirectIO，这么多年了，为什么PG社区不加入这块的支持呢？
DirectIO是直接写块设备的，可以旁路kernel cache，这对于XLOG来说，有好处也有坏处，如果你的文件在写入后要立即读取，那么无疑是写缓存更好。因此建议有流复制的主节点或上游节点不要使用DirectIO。同样对于standby节点来说，XLOG也是需要立即读取用来恢复的，因此standby节点也不需要开启DirectIO。这一点在代码中有体现。
src/backend/access/transam/xlog.c

/*
 * Return the (possible) sync flag used for opening a file, depending on the
 * value of the GUC wal_sync_method.
 */
static int
get_sync_bit(int method)
{
        int                     o_direct_flag = 0;

        /* If fsync is disabled, never open in sync mode */
        if (!enableFsync)
                return 0;

        /*
         * Optimize writes by bypassing kernel cache with O_DIRECT when using
         * O_SYNC/O_FSYNC and O_DSYNC.  But only if archiving and streaming are
         * disabled, otherwise the archive command or walsender process will read
         * the WAL soon after writing it, which is guaranteed to cause a physical
         * read if we bypassed the kernel cache. We also skip the
         * posix_fadvise(POSIX_FADV_DONTNEED) call in XLogFileClose() for the same
         * reason.
         *
         * Never use O_DIRECT in walreceiver process for similar reasons; the WAL
         * written by walreceiver is normally read by the startup process soon
         * after its written. Also, walreceiver performs unaligned writes, which
         * don't work with O_DIRECT, so it is required for correctness too.
         */
        if (!XLogIsNeeded() && !AmWalReceiverProcess())   // 对于standby节点,不使用O_DIRECT
                o_direct_flag = PG_O_DIRECT;

        switch (method)
        {
                        /*
                         * enum values for all sync options are defined even if they are
                         * not supported on the current platform.  But if not, they are
                         * not included in the enum option array, and therefore will never
                         * be seen here.
                         */
                case SYNC_METHOD_FSYNC:
                case SYNC_METHOD_FSYNC_WRITETHROUGH:
                case SYNC_METHOD_FDATASYNC:
                        return 0;
#ifdef OPEN_SYNC_FLAG
                case SYNC_METHOD_OPEN:
                        return OPEN_SYNC_FLAG | o_direct_flag;
#endif
#ifdef OPEN_DATASYNC_FLAG
                case SYNC_METHOD_OPEN_DSYNC:
                        return OPEN_DATASYNC_FLAG | o_direct_flag;
#endif
                default:
                        /* can't happen (unless we are out of sync with option array) */
                        elog(ERROR, "unrecognized wal_sync_method: %d", method);
                        return 0;                       /* silence warning */
        }
}



那么对于数据文件来说，DirectIO有什么好处呢？
首先，PostgreSQL管理了自己的基于LRU算法的SHARED BUFFER，数据块在读写时会用到SHARED BUFFER，同时还会产生kernel cache。那么问题来了，数据块可能同时在数据库和系统的两处缓存中存在，出现了双重缓存的情况。这不仅仅浪费内存空间，而且降低了使用效率。
使用DirectIO可以避免出现双重缓存，但是对应用程序来说会增加文件操作的复杂度，例如open手册中提到的：

The O_DIRECT flag may impose alignment restrictions on the length and address of userspace buffers and the file
       offset of I/Os.  In Linux alignment restrictions vary by file system and kernel version  and  might  be  absent
       entirely.  However there is currently no file system-independent interface for an application to discover these
       restrictions for a given file or file system.  Some file systems provide their own interfaces for doing so, for
       example the XFS_IOC_DIOINFO operation in xfsctl(3).
       Under Linux 2.4, transfer sizes, and the alignment of the user buffer and the file offset must all be multiples
       of the logical block size of the file system.  Under Linux 2.6, alignment to 512-byte boundaries suffices.


使用O_DIRECT 后需要考虑BUFFER对齐，打开文件的OFFSET必须为文件系统逻辑块大小的倍数。
某些文件系统提供了O_direct的接口。
根据Greg Smith提供的一些信息，使用O_DIRECT并不一定能带来性能的提升。这也许是PG社区目前并未考虑使用O_DIRECT的原因。

As Tom already mentioned this isn't working because of alignment 
issues.  I'm not sure what you expect to achieve though.  You should be 
warned that other than the WAL, every experiment I've ever seen that 
tries to add more direct I/O to the database has failed to improve 
anything; the result is neither barely noticeable, or a major 
performance drop.  This is particularly futile if you're doing your 
research on Linux/ext3, where even if your code works delivers a speed 
up no one will trust it enough to ever merge and deploy it, due to the 
generally poor quality of that area of the kernel so far.

This particular area is magnetic for drawing developer attention as it 
seems like there's a big win just under the surface if things were 
improved a bit.  There isn't.  On operating systems like Solaris where 
it's possible to prototype here by use mounting options to silently 
covert parts of the database to direct I/O, experiments in that area 
have all been disappointing.  One of the presentations from Jignesh Shah 
at Sun covered his experiments in this area, can't seem to find it at 
the moment but I remember the results were not positive in any way.

-- 
Greg Smith  2ndQuadrant US  Baltimore, MD
PostgreSQL Training, Services and Support
greg(at)2ndQuadrant(dot)com   www.2ndQuadrant.us


所以不要指望简单的修改PostgreSQL里面的md.c,  fd.c的一些打开数据文件的接口，就可以实现O_DIRECT。

[参考]
1. http://www.postgresql.org/message-id/flat/011c01c7249a$4fa27980$19527c0a@OPERAO
2. http://www.postgresql.org/message-id/flat/AANLkTilt3jl5V7-8QHEuryWNWoyfKA6VRRwDbyW3BYIB@mail.gmail.com#AANLkTilt3jl5V7-8QHEuryWNWoyfKA6VRRwDbyW3BYIB@mail.gmail.com
3. man 8 raw
4. man 3 xfsctl

       XFS_IOC_DIOINFO
              Get information required to perform direct I/O on the specified file descriptor.   Direct  I/O  is  per-
              formed  directly to and from a user’s data buffer.  Since the kernel’s buffer cache is no longer between
              the two, the user’s data buffer must conform to the same type of constraints as required for accessing a
              raw  disk partition.  The final argument points to a variable of type struct dioattr, which contains the
              following members: d_mem is the memory alignment requirement of the user’s data buffer.  d_miniosz spec-
              ifies  block  size, minimum I/O request size, and I/O alignment.  The size of all I/O requests must be a
              multiple of this amount and the value of the seek pointer at the time of the I/O request must also be an
              integer  multiple  of  this amount.  d_maxiosz is the maximum I/O request size which can be performed on
              the file descriptor.  If an I/O request does not meet these constraints, the read(2)  or  write(2)  will
              fail  with  EINVAL.   All  I/O requests are kept consistent with any data brought into the cache with an
              access through a non-direct I/O file descriptor.


5. man 2 open

       #include <sys/types.h>
       #include <sys/stat.h>
       #include <fcntl.h>
       int open(const char *pathname, int flags);
       int open(const char *pathname, int flags, mode_t mode);

The full list of file creation flags  and  file  status
       flags is as follows:
       O_DIRECT (Since Linux 2.4.10)
              Try  to  minimize  cache effects of the I/O to and from this file.  In general this will degrade perfor-
              mance, but it is useful in special situations, such as when applications do their own caching.  File I/O
              is  done  directly  to/from user space buffers.  The I/O is synchronous, that is, at the completion of a
              read(2) or write(2), data is guaranteed to have been transferred.  See NOTES below for  further  discus-
              sion.
              A semantically similar (but deprecated) interface for block devices is described in raw(8).
NOTE
   O_DIRECT
       The O_DIRECT flag may impose alignment restrictions on the length and address of userspace buffers and the file
       offset of I/Os.  In Linux alignment restrictions vary by file system and kernel version  and  might  be  absent
       entirely.  However there is currently no file system-independent interface for an application to discover these
       restrictions for a given file or file system.  Some file systems provide their own interfaces for doing so, for
       example the XFS_IOC_DIOINFO operation in xfsctl(3).

       Under Linux 2.4, transfer sizes, and the alignment of the user buffer and the file offset must all be multiples
       of the logical block size of the file system.  Under Linux 2.6, alignment to 512-byte boundaries suffices.

       O_DIRECT I/Os should never be run concurrently with the fork(2) system call, if the memory buffer is a  private
       mapping  (i.e.,  any  mapping  created with the mmap(2) MAP_PRIVATE flag; this includes memory allocated on the
       heap and statically allocated buffers).  Any such I/Os, whether submitted via an asynchronous I/O interface  or
       from  another thread in the process, should be completed before fork(2) is called.  Failure to do so can result
       in data corruption and undefined behavior in parent and child processes.  This restriction does not apply  when
       the  memory  buffer  for the O_DIRECT I/Os was created using shmat(2) or mmap(2) with the MAP_SHARED flag.  Nor
       does this restriction apply when the memory buffer has been advised as MADV_DONTFORK with madvise(2),  ensuring
       that it will not be available to the child after fork(2).

       The  O_DIRECT  flag  was  introduced in SGI IRIX, where it has alignment restrictions similar to those of Linux
       2.4.  IRIX has also a fcntl(2) call to query appropriate alignments, and sizes.  FreeBSD 4.x introduced a  flag
       of the same name, but without alignment restrictions.

       O_DIRECT  support was added under Linux in kernel version 2.4.10.  Older Linux kernels simply ignore this flag.
       Some file systems may not implement the flag and open() will fail with EINVAL if it is used.

       Applications should avoid mixing O_DIRECT and normal I/O to the same file, and especially to  overlapping  byte
       regions  in the same file.  Even when the file system correctly handles the coherency issues in this situation,
       overall I/O throughput is likely to be slower than using either  mode  alone.   Likewise,  applications  should
       avoid mixing mmap(2) of files with direct I/O to the same files.

       The  behaviour  of O_DIRECT with NFS will differ from local file systems.  Older kernels, or kernels configured
       in certain ways, may not support this combination.  The NFS protocol does not support passing the flag  to  the
       server, so O_DIRECT I/O will only bypass the page cache on the client; the server may still cache the I/O.  The
       client asks the server to make the I/O synchronous to preserve the synchronous  semantics  of  O_DIRECT.   Some
       servers  will  perform poorly under these circumstances, especially if the I/O size is small.  Some servers may
       also be configured to lie to clients about the I/O having reached stable storage; this will avoid  the  perfor-
       mance penalty at some risk to data integrity in the event of server power failure.  The Linux NFS client places
       no alignment restrictions on O_DIRECT I/O.

       In summary, O_DIRECT is a potentially powerful tool that should be used with caution.  It is  recommended  that
       applications treat use of O_DIRECT as a performance option which is disabled by default.

              "The  thing  that has always disturbed me about O_DIRECT is that the whole interface is just stupid, and
              was probably designed by a deranged monkey on some serious mind-controlling substances." — Linus


Flag Counter
