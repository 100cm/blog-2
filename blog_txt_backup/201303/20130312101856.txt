PostgreSQL research

PostgreSQL remove duplicated data in Table

2013-03-12 10:18:56   查看原文>>

昨天一位兄弟遇到创建唯一索引失败的问题, 原因是有重复数据.
例如 : 

digoal=> create table test (uk1 int, uk2 text, info text, crt_time timestamp);
CREATE TABLE
digoal=> insert into test select generate_series(1,100),'digoal','test',clock_timestamp();
INSERT 0 100
digoal=> insert into test select generate_series(1,100),'digoal','test',clock_timestamp();
INSERT 0 100
digoal=> create unique index uk_test on test(uk1,uk2);
ERROR:  23505: could not create unique index "uk_test"
DETAIL:  Key (uk1, uk2)=(26, digoal) is duplicated.
SCHEMA NAME:  digoal
TABLE NAME:  test
CONSTRAINT NAME:  uk_test
LOCATION:  comparetup_index_btree, tuplesort.c:3181


上面的例子要创建的是uk1和uk2的联合唯一索引, 显然有重复数据无法创建下去.
要去除uk1和uk2联合重复的数据, 如果遇到重复只保留1条.
[方法一] : 
如果这个表有PK的话, 可以通过PK来区分该删除哪些, 该保留哪些?
例如 : 

-- 给上面的表添加PK, 如下 : 
digoal=> create sequence seq_test ;
CREATE SEQUENCE
digoal=> alter table test add column pk int default nextval('seq_test'::regclass);
ALTER TABLE
digoal=> alter table test add constraint pk_test primary key (pk);
ALTER TABLE
-- 删除uk1+uk2的重复数据, 保留PK值最小的那条.
digoal=> delete from test where pk in (select pk from (select row_number() over (partition by uk1,uk2 order by pk) rn,pk from test)AS t where rn>1);
DELETE 100
-- 删除重复数据后的记录如下 : 
digoal=> select * from test;
 uk1 |  uk2   | info |          crt_time          | pk  
-----+--------+------+----------------------------+-----
   1 | digoal | test | 2013-03-12 08:38:42.028668 |   1
   2 | digoal | test | 2013-03-12 08:38:42.028852 |   2
   3 | digoal | test | 2013-03-12 08:38:42.02886  |   3
   4 | digoal | test | 2013-03-12 08:38:42.028864 |   4
   5 | digoal | test | 2013-03-12 08:38:42.028866 |   5
   6 | digoal | test | 2013-03-12 08:38:42.028869 |   6
   7 | digoal | test | 2013-03-12 08:38:42.028872 |   7
   8 | digoal | test | 2013-03-12 08:38:42.028875 |   8
   9 | digoal | test | 2013-03-12 08:38:42.028877 |   9
  10 | digoal | test | 2013-03-12 08:38:42.02888  |  10
  11 | digoal | test | 2013-03-12 08:38:42.028883 |  11
  12 | digoal | test | 2013-03-12 08:38:42.028886 |  12
  13 | digoal | test | 2013-03-12 08:38:42.028888 |  13
  14 | digoal | test | 2013-03-12 08:38:42.028891 |  14
  15 | digoal | test | 2013-03-12 08:38:42.028893 |  15
  16 | digoal | test | 2013-03-12 08:38:42.028896 |  16
  17 | digoal | test | 2013-03-12 08:38:42.028899 |  17
  18 | digoal | test | 2013-03-12 08:38:42.028901 |  18
  19 | digoal | test | 2013-03-12 08:38:42.028904 |  19
  20 | digoal | test | 2013-03-12 08:38:42.028907 |  20
  21 | digoal | test | 2013-03-12 08:38:42.028909 |  21
  22 | digoal | test | 2013-03-12 08:38:42.028912 |  22
  23 | digoal | test | 2013-03-12 08:38:42.028914 |  23
  24 | digoal | test | 2013-03-12 08:38:42.028917 |  24
  25 | digoal | test | 2013-03-12 08:38:42.02892  |  25
  26 | digoal | test | 2013-03-12 08:38:42.028922 |  26
  27 | digoal | test | 2013-03-12 08:38:42.028925 |  27
  28 | digoal | test | 2013-03-12 08:38:42.028927 |  28
  29 | digoal | test | 2013-03-12 08:38:42.02893  |  29
  30 | digoal | test | 2013-03-12 08:38:42.028933 |  30
  31 | digoal | test | 2013-03-12 08:38:42.028935 |  31
  32 | digoal | test | 2013-03-12 08:38:42.028938 |  32
  33 | digoal | test | 2013-03-12 08:38:42.028941 |  33
  34 | digoal | test | 2013-03-12 08:38:42.028944 |  34
  35 | digoal | test | 2013-03-12 08:38:42.028946 |  35
  36 | digoal | test | 2013-03-12 08:38:42.028949 |  36
  37 | digoal | test | 2013-03-12 08:38:42.028952 |  37
  38 | digoal | test | 2013-03-12 08:38:42.028955 |  38
  39 | digoal | test | 2013-03-12 08:38:42.028957 |  39
  40 | digoal | test | 2013-03-12 08:38:42.02896  |  40
  41 | digoal | test | 2013-03-12 08:38:42.028963 |  41
  42 | digoal | test | 2013-03-12 08:38:42.028965 |  42
  43 | digoal | test | 2013-03-12 08:38:42.028968 |  43
  44 | digoal | test | 2013-03-12 08:38:42.02897  |  44
  45 | digoal | test | 2013-03-12 08:38:42.028973 |  45
  46 | digoal | test | 2013-03-12 08:38:42.028975 |  46
  47 | digoal | test | 2013-03-12 08:38:42.028978 |  47
  48 | digoal | test | 2013-03-12 08:38:42.028981 |  48
  49 | digoal | test | 2013-03-12 08:38:42.028983 |  49
  50 | digoal | test | 2013-03-12 08:38:42.028994 |  50
  51 | digoal | test | 2013-03-12 08:38:42.028997 |  51
  52 | digoal | test | 2013-03-12 08:38:42.028999 |  52
  53 | digoal | test | 2013-03-12 08:38:42.029002 |  53
  54 | digoal | test | 2013-03-12 08:38:42.029004 |  54
  55 | digoal | test | 2013-03-12 08:38:42.029007 |  55
  56 | digoal | test | 2013-03-12 08:38:42.02901  |  56
  57 | digoal | test | 2013-03-12 08:38:42.029012 |  57
  58 | digoal | test | 2013-03-12 08:38:42.029015 |  58
  59 | digoal | test | 2013-03-12 08:38:42.029017 |  59
  60 | digoal | test | 2013-03-12 08:38:42.02902  |  60
  61 | digoal | test | 2013-03-12 08:38:42.029022 |  61
  62 | digoal | test | 2013-03-12 08:38:42.029025 |  62
  63 | digoal | test | 2013-03-12 08:38:42.029028 |  63
  64 | digoal | test | 2013-03-12 08:38:42.02903  |  64
  65 | digoal | test | 2013-03-12 08:38:42.029033 |  65
  66 | digoal | test | 2013-03-12 08:38:42.029035 |  66
  67 | digoal | test | 2013-03-12 08:38:42.029038 |  67
  68 | digoal | test | 2013-03-12 08:38:42.029041 |  68
  69 | digoal | test | 2013-03-12 08:38:42.029043 |  69
  70 | digoal | test | 2013-03-12 08:38:42.029046 |  70
  71 | digoal | test | 2013-03-12 08:38:42.029048 |  71
  72 | digoal | test | 2013-03-12 08:38:42.029051 |  72
  73 | digoal | test | 2013-03-12 08:38:42.029053 |  73
  74 | digoal | test | 2013-03-12 08:38:42.029056 |  74
  75 | digoal | test | 2013-03-12 08:38:42.029059 |  75
  76 | digoal | test | 2013-03-12 08:38:42.029061 |  76
  77 | digoal | test | 2013-03-12 08:38:42.029064 |  77
  78 | digoal | test | 2013-03-12 08:38:42.029066 |  78
  79 | digoal | test | 2013-03-12 08:38:42.029085 |  79
  80 | digoal | test | 2013-03-12 08:38:42.029089 |  80
  81 | digoal | test | 2013-03-12 08:38:42.029091 |  81
  82 | digoal | test | 2013-03-12 08:38:42.029094 |  82
  83 | digoal | test | 2013-03-12 08:38:42.029097 |  83
  84 | digoal | test | 2013-03-12 08:38:42.029099 |  84
  85 | digoal | test | 2013-03-12 08:38:42.029102 |  85
  86 | digoal | test | 2013-03-12 08:38:42.029104 |  86
  87 | digoal | test | 2013-03-12 08:38:42.029107 |  87
  88 | digoal | test | 2013-03-12 08:38:42.02911  |  88
  89 | digoal | test | 2013-03-12 08:38:42.029112 |  89
  90 | digoal | test | 2013-03-12 08:38:42.029115 |  90
  91 | digoal | test | 2013-03-12 08:38:42.029118 |  91
  92 | digoal | test | 2013-03-12 08:38:42.02912  |  92
  93 | digoal | test | 2013-03-12 08:38:42.029123 |  93
  94 | digoal | test | 2013-03-12 08:38:42.029125 |  94
  95 | digoal | test | 2013-03-12 08:38:42.029128 |  95
  96 | digoal | test | 2013-03-12 08:38:42.029131 |  96
  97 | digoal | test | 2013-03-12 08:38:42.029133 |  97
  98 | digoal | test | 2013-03-12 08:38:42.029136 |  98
  99 | digoal | test | 2013-03-12 08:38:42.029138 |  99
 100 | digoal | test | 2013-03-12 08:38:42.029141 | 100
(100 rows)
-- 现在可以创建uk1+uk2的唯一约束了.
digoal=> create unique index uk_test on test(uk1,uk2);
CREATE INDEX



[方法二] : 
如果这个表没有PK, 也没关系, PostgreSQL 定位每一行使用的是ctid字段, 包含了这行记录所在的数据块以及数据块内的itemid信息. 
例如 : 

digoal=> drop table test;
DROP TABLE
digoal=> create table test (uk1 int, uk2 text, info text, crt_time timestamp);
CREATE TABLE
digoal=> insert into test select generate_series(1,10),'digoal','test',clock_timestamp();
INSERT 0 10
digoal=> insert into test select generate_series(1,10),'digoal','test',clock_timestamp();
INSERT 0 10
-- 删除uk1+uk2重复的数据, 保留ctid最小的那条. (如果要保留时间最早的那条, 改成order by crt_time即可)
digoal=> delete from test where ctid in (select ctid from (select row_number() over (partition by uk1,uk2 order by ctid) rn,ctid from test)AS t where rn>1) returning *;
 uk1 |  uk2   | info |          crt_time          
-----+--------+------+----------------------------
   1 | digoal | test | 2013-03-12 08:55:06.478993
   2 | digoal | test | 2013-03-12 08:55:06.479017
   3 | digoal | test | 2013-03-12 08:55:06.479022
   4 | digoal | test | 2013-03-12 08:55:06.479025
   5 | digoal | test | 2013-03-12 08:55:06.479028
   6 | digoal | test | 2013-03-12 08:55:06.47903
   7 | digoal | test | 2013-03-12 08:55:06.479033
   8 | digoal | test | 2013-03-12 08:55:06.479036
   9 | digoal | test | 2013-03-12 08:55:06.479038
  10 | digoal | test | 2013-03-12 08:55:06.479041
(10 rows)
DELETE 10
-- 保留的数据如下,ctid是最小的数据 : 
digoal=> select ctid,* from test;
  ctid  | uk1 |  uk2   | info |          crt_time          
--------+-----+--------+------+----------------------------
 (0,1)  |   1 | digoal | test | 2013-03-12 08:55:05.232498
 (0,2)  |   2 | digoal | test | 2013-03-12 08:55:05.235077
 (0,3)  |   3 | digoal | test | 2013-03-12 08:55:05.235086
 (0,4)  |   4 | digoal | test | 2013-03-12 08:55:05.235089
 (0,5)  |   5 | digoal | test | 2013-03-12 08:55:05.235092
 (0,6)  |   6 | digoal | test | 2013-03-12 08:55:05.235095
 (0,7)  |   7 | digoal | test | 2013-03-12 08:55:05.235098
 (0,8)  |   8 | digoal | test | 2013-03-12 08:55:05.235101
 (0,9)  |   9 | digoal | test | 2013-03-12 08:55:05.235103
 (0,10) |  10 | digoal | test | 2013-03-12 08:55:05.235106
(10 rows)



[方法三] : 
不需要PK或者ctid唯一定位到1行记录的值, 通过中间表来做. 在一个事务中完成. 
如果test表在去除重复记录期间有DML操作, 应该先锁表, 禁止DML. 否则又可能有重复记录插入.

digoal=> drop table test;
DROP TABLE
digoal=> create table test (uk1 int, uk2 text, info text, crt_time timestamp);
CREATE TABLE
digoal=> insert into test select generate_series(1,10),'digoal','test',clock_timestamp();
INSERT 0 10
digoal=> insert into test select generate_series(1,10),'digoal','test',clock_timestamp();
INSERT 0 10
digoal=> begin;
BEGIN
digoal=> create local temp table tmp_test (like test);
CREATE TABLE
digoal=> lock table test in exclusive mode;
LOCK TABLE
-- uk1,uk2重复的情况下, 只保留crt_time最小的一条
digoal=> insert into tmp_test select uk1,uk2,info,crt_time from 
digoal->   (select row_number() over (partition by uk1,uk2 order by crt_time) rn,* from test) AS t 
digoal-> where rn=1;
INSERT 0 10
digoal=> truncate table test;
TRUNCATE TABLE
digoal=> insert into test select * from tmp_test;
INSERT 0 10
digoal=> create unique index uk_test on test(uk1,uk2);
CREATE INDEX
digoal=> drop table tmp_test;
DROP TABLE
digoal=> end;
COMMIT



[方法四] : 
不支持窗口函数的话, 还是有办法的, 例如使用游标.
函数处理 : 

digoal=> drop table test;
DROP TABLE
digoal=> create table test (uk1 int, uk2 text, info text, crt_time timestamp);
CREATE TABLE
digoal=> insert into test select generate_series(1,10),'digoal','test',clock_timestamp();
INSERT 0 10
digoal=> insert into test select generate_series(1,10),'digoal','test',clock_timestamp();
INSERT 0 10
digoal=> insert into test values (1,null,'digoal',clock_timestamp());
INSERT 0 1
digoal=> insert into test values (1,null,'digoal',clock_timestamp());
INSERT 0 1
digoal=> insert into test values (1,null,'digoal',clock_timestamp());
INSERT 0 1
digoal=> insert into test values (null,null,'digoal',clock_timestamp());
INSERT 0 1
digoal=> insert into test values (null,null,'digoal',clock_timestamp());
INSERT 0 1
digoal=> insert into test values (null,null,'digoal',clock_timestamp());
INSERT 0 1
digoal=> insert into test values (null,'test','digoal',clock_timestamp());
INSERT 0 1
digoal=> insert into test values (null,'test','digoal',clock_timestamp());
INSERT 0 1
digoal=> insert into test values (null,'test','digoal',clock_timestamp());
INSERT 0 1
-- uk1和uk2重复的数据, 只保留crt_time最小的一条.
do language plpgsql $$
declare
  ref cursor for select * from test;
begin
  lock table test in exclusive mode;
  create temp table tmp_test(like test);
  create index idx1 on tmp_test(uk1);
  create index idx2 on tmp_test(uk2);
  for rec in ref loop
    perform 1 from tmp_test t where rec.uk1=t.uk1 and rec.uk2=t.uk2;
    if found then
      perform 1 from tmp_test t where rec.uk1=t.uk1 and rec.uk2=t.uk2 and rec.crt_time<t.crt_time;
      if found then
        delete from tmp_test where rec.uk1=t.uk1 and rec.uk2=t.uk2;
        insert into tmp_test values(rec.uk1, rec.uk2, rec.info, rec.crt_time);
      end if;
    else
      insert into tmp_test values(rec.uk1, rec.uk2, rec.info, rec.crt_time);
    end if;
  end loop;
  truncate table test;
  insert into test select * from tmp_test;
  drop table tmp_test;
end;
$$;

digoal=> select * from test;
 uk1 |  uk2   |  info  |          crt_time          
-----+--------+--------+----------------------------
   1 | digoal | test   | 2013-03-12 10:10:07.0416
   2 | digoal | test   | 2013-03-12 10:10:07.041726
   3 | digoal | test   | 2013-03-12 10:10:07.041733
   4 | digoal | test   | 2013-03-12 10:10:07.041737
   5 | digoal | test   | 2013-03-12 10:10:07.04174
   6 | digoal | test   | 2013-03-12 10:10:07.041742
   7 | digoal | test   | 2013-03-12 10:10:07.041745
   8 | digoal | test   | 2013-03-12 10:10:07.041748
   9 | digoal | test   | 2013-03-12 10:10:07.041751
  10 | digoal | test   | 2013-03-12 10:10:07.041753
   1 |        | digoal | 2013-03-12 10:10:22.217691
   1 |        | digoal | 2013-03-12 10:10:22.741411
   1 |        | digoal | 2013-03-12 10:10:23.138676
     |        | digoal | 2013-03-12 10:10:28.359152
     |        | digoal | 2013-03-12 10:10:28.893596
     |        | digoal | 2013-03-12 10:10:29.304329
     | test   | digoal | 2013-03-12 10:10:36.24248
     | test   | digoal | 2013-03-12 10:10:36.916402
     | test   | digoal | 2013-03-12 10:10:37.318659
(19 rows)

digoal=> create unique index uk_test on test(uk1,uk2);
CREATE INDEX


【小结】
1. 根据数据表的大小以及重复数据的占比, 选择合适的方法.
delete大量数据后建议马上执行analyze.
如果重复数据占比较大, 并且是使用delete的方法删除重复数据的, 那么9.0以上的系统建议vacuum full. 老的系统建议使用pg_reorg来删除碎片.
重复数据占比较小的表建议使用delete的方法删除重复数据.
重复数据占比较大的表, 建议使用重组表的方法删除重复数据. 
当然还要考虑未来这个表是否会有DML操作, 如果未来会有大量的DML, 新增数据等操作, 那么即使重复数据较多的表也没必要使用重组的方法去除重复数据, 因为vacuum后这些空间还是可用的。
