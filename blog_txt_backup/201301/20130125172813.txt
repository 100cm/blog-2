PostgreSQL research

waiting PostgreSQL Parallel Query Execution

2013-01-25 17:28:13   查看原文>>

说到并行查询, 比较常见的有Oracle的parallel HINT, 如下 : 

16.1.2.6 Hints for Parallel Execution

The hints that follow instruct the optimizer about how statements are parallelized or not parallelized when using parallel execution:

  • PARALLEL

  • PQ_DISTRIBUTE

  • PARALLEL_INDEX

  • NO_PARALLEL_INDEX

其他的如GreenPlum, Postgres-XC, plproxy, VoltDB, mongoDB等分布式数据库就不谈了, 这里只谈一下单节点数据库的并行处理.
PostgreSQL 客户端并行支持已经比较完善, 可以通过打开多个数据库连接, 并行管理来实现.
但是服务端并行目前还不是很完善, 像Oracle这样的HINT目前不支持. 大家可以关注一下PostgreSQL 的roadmap和TODO list.

目前PostgreSQL 已经实现的服务端并行处理有 : 

  • effective_io_concurrency allows table page prefetch requests to the kernel, for bitmap joins

  • Helper processes like background writer and wal writer offload I/O requirements from the main query execution process

  • Server-side languages can potentially do parallel operations

1. 通过调整effective_io_concurrency参数, 允许表数据的预取, 这个设置尽量和存储的阵列保持一致(raid 0/1和盘数相同, raid5去除校验盘).
详细的设置参考末尾部分.
2. 当bgwriter或walwriter进程非常繁忙的时候, 与客户端进程交互的backend process也可参与bgwriter和walwrite的工作, 即flush dirty block和写xlog信息.
3. 服务端过程语言, 是潜在的并行支持. 例如用C写并行处理函数.

服务端并行的好处 : 

  • Using multiple CPUs

  • Using multiple I/O channels (for sequential and random I/O)

  • Using multiple CPUs and I/O channels

1. 合理利用CPU多核。
2. 合理利用多IO通道。
3. 合理利用CPU多核以及多IO通道。

并行实现方法 : 

  • Use fork (or a thread on Windows) and only call libc and parallel-specific functions to do parallel computation or I/O. This avoids the problem of trying to make the existing backend code thread-safe. Do we need to wait until we can share a transaction among back-end processes?

  • Same as above, but modify some existing backend modules to be fork/thread-safe, with or without shared memory access; this might allow entire executor node trees to be run in parallel

  • Create full backends that can execute parts of a query in parallel and return results

  • Create a pool of backends waiting for parallel requests

  • An initial approach might start by modifying individual plan nodes to run in parallel in the executor. Eventually we'd need to educate the planner and optimizer about how to model parallelizing queries.

1. 使用fork的方式, 但是如果不想改动当前的backend代码, 那就得等待PostgreSQL支持多个backend process共享事务信息.
2. 与第一条相同, 但是需要修改backend模块, 并保证线程安全. 支持共享内存访问, 这个方法允许节点数完全并行执行.
3. 创建全新的backend process来并行执行SQL的各个部分, 并返回结果
4. 预先创建进程池, 等待并行请求.
5. 最初应该从修改执行计划节点开始入手, 同时需要修改执行计划器以及优化器的代码以便构建并行查询的模型.

挑战 : 

Finding Appropriate Tasks: For parallelism to be added to a single-threaded task, the task must be able to be broken into sufficiently-large parts and executed independently. (If the sub-parts are too small, the overhead of doing parallelism overwhelms the benefits of parallelism.) Unfortunately, unlike a GUI
application, the Postgres backend executes a query by performing many small tasks that must be executed in sequence, e.g. parser, planner, executor.

This means that databases allow parallelism only in limited situations, mostly for large queries that can become CPU or I/O bound. For example, it is unlikely that selecting a row based on a primary key would benefit from parallelism. In contrast, large queries can often benefit from parallelism.

Returning Data: Another challenge is returning data from the helper process/thread. For something like SUM(), it is easy, but passing a large volume of data back can be complex.

Avoiding Overhead: Parallelism has its own costs so there will need to be a way to control when parallel execution is used.

Limiting Excessive Parallelism: There also needs to be some mechnism that detects parallelism by other sessions so CPU and I/O resources are not exceeded.

1. 并行查询并不是所有的场景都适合, 对于OLTP系统, 大部分任务是小任务, 并行查询在构建并行任务方面的开销可能以及超越了它的意义, 因为小任务根本就不需要并行执行. 所以找对场景很重要.
2. 返回结果也是一个挑战, 对于简单的结果返回比较容易, 但是从并行进程或线程返回大数据集, 就比较复杂.
3. 并行查询本身的耗费, 包括执行计划, 生成进程, 生成内存资源,锁等的耗费. 如何将这些耗费正确的评估出来, 选择是并行还是非并行也是比较大的挑战.
4. 并行查询的资源限制, 不能无节制的使用CPU和IO资源, 这样可能导致不良后果.

并行运用场景 : 

  • Sorting

  • Tablespaces

  • Partitions

  • Multi-table access

  • Joins (e.g. nested loop), CTEs

  • Sequential scans on 1GB segment files

  • I/O and row processing

  • Aggregates

  • Data export

  • COPY (to reduce the CPU overhead of parsing)

  • Index builds

  • Constraint checking

  • Expensive functions, e.g. PostGIS



【参考】
1. https://wiki.postgresql.org/wiki/Parallel_Query_Execution
2. http://www.postgresql.org/message-id/flat/CAGTBQpbRYp9GNe2JjbXXCAO1-OsYXdh2fUyZVka+GXY22dj+iQ@mail.gmail.com#CAGTBQpbRYp9GNe2JjbXXCAO1-OsYXdh2fUyZVka+GXY22dj+iQ@mail.gmail.com
3. http://www.postgresql.org/message-id/flat/CAEYLb_VeZpKDX54VEx3X30oy_UOTh89XoejJW6aucjjiUjskXw@mail.gmail.com
4. 
effective_io_concurrency (integer)


    Sets the number of concurrent disk I/O operations that PostgreSQL expects can be executed simultaneously. Raising this value will increase the number of I/O operations that any individual PostgreSQL session attempts to initiate in parallel. The allowed range is 1 to 1000, or zero to disable issuance of asynchronous I/O requests. Currently, this setting only affects bitmap heap scans.


    A good starting point for this setting is the number of separate drives comprising a RAID 0 stripe or RAID 1 mirror being used for the database. (For RAID 5 the parity drive should not be counted.) However, if the database is often busy with multiple queries issued in concurrent sessions, lower values may be sufficient to keep the disk array busy. A value higher than needed to keep the disks busy will only result in extra CPU overhead.


    For more exotic systems, such as memory-based storage or a RAID array that is limited by bus bandwidth, the correct value might be the number of I/O paths available. Some experimentation may be needed to find the best value.


    Asynchronous I/O depends on an effective posix_fadvise function, which some operating systems lack. If the function is not present then setting this parameter to anything but zero will result in an error. On some operating systems (e.g., Solaris), the function is present but does not actually do anything.


    5. http://wiki.postgresql.org/wiki/Todo
    6. http://wiki.postgresql.org/wiki/Development_information
