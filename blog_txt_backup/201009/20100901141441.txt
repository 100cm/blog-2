PostgreSQL research

RHEL Cache release behaviors WHEN using GFS lock_dlm

2010-09-01 14:14:41   查看原文>>

在PostgreSQL上有一个非常好的利用OS Cache获取良好的IO性能的工具pgfincore.
使用pgfadv_willneed将表加载到OS cache。在单节点的PostgreSQL上使用非常好。
在执行pgfadv_willneed之前的内存状态：
postgres@db_192_168_173_60_skyurs4-> cat /proc/meminfo 
MemTotal:     24682828 kB
MemFree:      24080936 kB
Buffers:        104540 kB
Cached:         354204 kB
SwapCached:          0 kB
Active:         169704 kB
Inactive:       337488 kB
HighTotal:           0 kB
HighFree:            0 kB
LowTotal:     24682828 kB
LowFree:      24080936 kB
SwapTotal:    16779884 kB
SwapFree:     16779884 kB
Dirty:             116 kB
Writeback:           0 kB
AnonPages:       48416 kB
Mapped:          98348 kB
Slab:            45332 kB
PageTables:       6236 kB
NFS_Unstable:        0 kB
Bounce:              0 kB
CommitLimit:  29121296 kB
Committed_AS:  1415476 kB
VmallocTotal: 34359738367 kB
VmallocUsed:    275648 kB
VmallocChunk: 34359461743 kB
HugePages_Total:     0
HugePages_Free:      0
HugePages_Rsvd:      0
Hugepagesize:     2048 kB
执行pgfadv_willneed之后的MEMINFO：
postgres@db_192_168_173_60_skyurs4-> cat /proc/meminfo 
MemTotal:     24682828 kB
MemFree:      11525464 kB
Buffers:        104560 kB
Cached:       12878800 kB
SwapCached:          0 kB
Active:         172692 kB
Inactive:     12859280 kB
HighTotal:           0 kB
HighFree:            0 kB
LowTotal:     24682828 kB
LowFree:      11525464 kB
SwapTotal:    16779884 kB
SwapFree:     16779884 kB
Dirty:             244 kB
Writeback:           0 kB
AnonPages:       48568 kB
Mapped:          98356 kB
Slab:            74700 kB
PageTables:       6236 kB
NFS_Unstable:        0 kB
Bounce:              0 kB
CommitLimit:  29121296 kB
Committed_AS:  1413192 kB
VmallocTotal: 34359738367 kB
VmallocUsed:    275648 kB
VmallocChunk: 34359461743 kB
HugePages_Total:     0
HugePages_Free:      0
HugePages_Rsvd:      0
Hugepagesize:     2048 kB
数据文件被放在OS PAGE CACHE的INACTIVE中了。下次去取这部分数据的时候被被置换到ACTIVE状态。（长时间不取的话可能会内核被FREE掉）

最近把pgfincore部署另一个PostgreSQL上，效果好像不太好，从/proc/meminfo看到OS的缓存很容易被释放掉。
加载pgfincore前
 
MemTotal:     24682828 kB
MemFree:      23881664 kB
Buffers:         85640 kB
Cached:         551104 kB
SwapCached:          0 kB
Active:         115700 kB
Inactive:       573188 kB
HighTotal:           0 kB
HighFree:            0 kB
LowTotal:     24682828 kB
LowFree:      23881664 kB
SwapTotal:    16779884 kB
SwapFree:     16779884 kB
Dirty:             544 kB
Writeback:           0 kB
AnonPages:       52172 kB
Mapped:         190560 kB
Slab:            57628 kB
PageTables:       5900 kB
NFS_Unstable:        0 kB
Bounce:              0 kB
CommitLimit:  29121296 kB
Committed_AS:  1494116 kB
VmallocTotal: 34359738367 kB
VmallocUsed:    278564 kB
VmallocChunk: 34359459759 kB
HugePages_Total:     0
HugePages_Free:      0
HugePages_Rsvd:      0
Hugepagesize:     2048 kB
加载pgfincore后
 
MemTotal:     24682828 kB
MemFree:      13830172 kB
Buffers:         85744 kB
Cached:       10577900 kB
SwapCached:          0 kB
Active:         123852 kB
Inactive:     10592604 kB
HighTotal:           0 kB
HighFree:            0 kB
LowTotal:     24682828 kB
LowFree:      13830172 kB
SwapTotal:    16779884 kB
SwapFree:     16779884 kB
Dirty:             316 kB
Writeback:           0 kB
AnonPages:       53304 kB
Mapped:         190792 kB
Slab:            79788 kB
PageTables:       6516 kB
NFS_Unstable:        0 kB
Bounce:              0 kB
CommitLimit:  29121296 kB
Committed_AS:  1492540 kB
VmallocTotal: 34359738367 kB
VmallocUsed:    278564 kB
VmallocChunk: 34359459759 kB
HugePages_Total:     0
HugePages_Free:      0
HugePages_Rsvd:      0
Hugepagesize:     2048 kB
 
从/proc/meminfo上看，与前面那个系统无异。但是很快inactive下的CACHE会被清除掉。
约5分钟后再看
MemTotal:     24682828 kB
MemFree:      23878196 kB
Buffers:         86072 kB
Cached:         553624 kB
SwapCached:          0 kB
Active:         126848 kB
Inactive:       565692 kB
HighTotal:           0 kB
HighFree:            0 kB
LowTotal:     24682828 kB
LowFree:      23878196 kB
SwapTotal:    16779884 kB
SwapFree:     16779884 kB
Dirty:             100 kB
Writeback:           0 kB
AnonPages:       53212 kB
Mapped:         190616 kB
Slab:            56344 kB
PageTables:       6496 kB
NFS_Unstable:        0 kB
Bounce:              0 kB
CommitLimit:  29121296 kB
Committed_AS:  1490960 kB
VmallocTotal: 34359738367 kB
VmallocUsed:    278564 kB
VmallocChunk: 34359459759 kB
HugePages_Total:     0
HugePages_Free:      0
HugePages_Rsvd:      0
Hugepagesize:     2048 kB
就好像pgfincore没有起到作用。
经过多方面分析，终于找到了问题的根源，是gfs文件系统的cache机制产生的问题。
gfs使用dlm_lock挂载时，大多数的块缓存优化特性将不起作用，而且GFS会强制一段时间后清除GFS文件缓存。(根据红帽技术支持所言：这么做的目的是提高GFS多节点同时操作一个GFS文件系统时性能，避免另一个节点在申请块的时候需要所有其他节点的该块是CLEAR的)
经过查询，GFS提供了一个参数，可以打开本地文件缓存优化特性，加载为lock_nolock模式。也就是单节点文件系统模式。这样的话问题就解决了。
参考man gfs_mount
localcaching
              This flag tells GFS that it is running as a local (not clustered) filesystem, so it  can  turn  on  some
              block caching optimizations that can’t be used when running in cluster mode.
              This  is  turned  on  automatically  by  the  lock_nolock  module,  but  can  be overridden by using the
              ignore_local_fs option.
ignore_local_fs
              By  default,  using the nolock lock module automatically turns on the localcaching and localflocks opti-
              mizations.  ignore_local_fs forces GFS to treat the filesystem as if it  were  a  multihost  (clustered)
              filesystem, with localcaching and localflocks optimizations turned off.
 找到问题后，把集群调用的数据库启动脚步稍加改动，使用lock_nolock锁模式，同一时间只有一个节点挂载该文件系统。问题得到解决。
