PostgreSQL research

key size limited with PostgreSQL btree index access method

2011-09-08 15:06:57   查看原文>>

今天在看mongoDB的文档时发现mongoDB对索引列的SIZE也有限制。如下

Keys Too Large To Index

Index entries have a limitation on their maximum size (the sum of the values), currently approximately 800 bytes. Documents which fields have values (key size in index terminology) greater than this size can not be indexed. You will see log messages similar to:

...Btree::insert: key too large to index, skipping...

Queries against this index will not return the unindexed documents. You can force a query to use another index, or really no index, using this special index hint:

db.myCollection.find({<key>: <value too large to index>}).hint({$natural: 1})

This will cause the document to be used for comparison of that field (or fields), rather than the index.

NOTE:  This limitation will eventually be removed (see SERVER-3372 ).

虽然size > 800 bytes不会被索引，但是能被插进去。这和PostgreSQL有所不同，PostgreSQL不能被索引的话记录是不能被插进表去的。
下面分几个方面来测试一下PostgreSQL的索引SIZE限制.
引用源码里面的一段btree相关comment : 
# src/backend/access/nbtree/nbtinsert.c  

      /*
         * Check whether the item can fit on a btree page at all. (Eventually, we
         * ought to try to apply TOAST methods if not.) We actually need to be
         * able to fit three items on every page, so restrict any one item to 1/3
         * the per-page available space. Note that at this point, itupsz doesn't
         * include the ItemId.
         *
         * NOTE: similar code appears in _bt_insertonpg() to defend against
         * oversize items being inserted into an already-existing index. But
         * during creation of an index, we don't go through there.
         */
        if (itupsz > BTMaxItemSize(npage))
                ereport(ERROR,
                                (errcode(ERRCODE_PROGRAM_LIMIT_EXCEEDED),
                        errmsg("index row size %lu exceeds maximum %lu for index \"%s\"",
                                   (unsigned long) itupsz,
                                   (unsigned long) BTMaxItemSize(npage),
                                   RelationGetRelationName(wstate->index)),
                errhint("Values larger than 1/3 of a buffer page cannot be indexed.\n"
                                "Consider a function index of an MD5 hash of the value, "
                                "or use full text indexing.")));



# include/access/nbtree.h 

/*
 * Maximum size of a btree index entry, including its tuple header.
 *
 * We actually need to be able to fit three items on every page,
 * so restrict any one item to 1/3 the per-page available space.
 */
#define BTMaxItemSize(page) \
        MAXALIGN_DOWN((PageGetPageSize(page) - \
                                   MAXALIGN(SizeOfPageHeaderData + 3*sizeof(ItemIdData)) - \
                                   MAXALIGN(sizeof(BTPageOpaqueData))) / 3)


从上面的代码和解释大概可以看出索引KEY的SIZE需要受到PAGE SIZE的限制，计算方法如上。

限制和索引access method有关，下面着重测试btree索引的限制.
测试表结构:

digoal=# \d index_test 
 Table "public.index_test"
 Column | Type | Modifiers 
--------+------+-----------
 info   | text | 



测试环境:

PostgreSQL9.1beta2
RHEL5 64位
UTF8字符集
BLOCK=8KB



测试项 : 
1. 索引方法

btree , hash



2. 字段存储类型,以下4种存储类型的解释可以参考我之前写过的BLOG或者PostgreSQL手册.

plain
main
external 不压缩,直接存到TOAST。
extended 先压缩,大于1/3则完全存储到TOAST,否则存储到HEAP表本地。



3. 数据量

index_key < 1/3BLOCK_SIZE
1/3BLOCK_SIZE < index_key < BLOCK_SIZE
index_key > BLOCK_SIZE



4. 混合测试
目的,
1. 索引建立时是否有个标记来记录KEY的存储类型的。
2. 索引存储的值是和表一致？或是根据索引记录的存储类型来压缩？

下面开始正式的测试过程。
text 类型默认是extended 格式存储,如下

digoal=# \d+ index_test 
             Table "public.index_test"
 Column | Type | Modifiers | Storage  | Description 
--------+------+-----------+----------+-------------
 info   | text |           | extended | 


先测试plain,因此要改一下,为了测试比较清晰,先清数据,

digoal=# truncate table index_test ;
TRUNCATE TABLE
digoal=# alter table index_test alter column info set storage plain;
ALTER TABLE
digoal=# \d+ index_test 
             Table "public.index_test"
 Column | Type | Modifiers | Storage | Description 
--------+------+-----------+---------+-------------
 info   | text |           | plain   | 
Has OIDs: no


现在就是plain存储了.
暂时不往里面建索引，试试插入几条和前面数据量匹配的数据。
2000个中文字.

digoal=# copy index_test from '/home/postgres/index_test/uncompress_2000';
COPY 1


5000个中文字.

digoal=# copy index_test from '/home/postgres/index_test/uncompress_5000';
ERROR:  row is too big: size 15032, maximum size 8160
CONTEXT:  COPY index_test, line 1: "索引测试索引测试索引测试索引测试索引测试索引测试索引测试索引测试索..."


10000个中文字.

digoal=# copy index_test from '/home/postgres/index_test/uncompress_10000';
ERROR:  row is too big: size 30032, maximum size 8160
CONTEXT:  COPY index_test, line 1: "索引测试索引测试索引测试索引测试索引测试索引测试索引测试索引测试索..."


显然，PLAIN存储不能存储超过8160个字节（这里测试的是8KB的BLOCK）

下面修改为main测试

digoal=# truncate table index_test ;
TRUNCATE TABLE
digoal=# alter table index_test alter column info set storage main;
ALTER TABLE
digoal=# copy index_test from '/home/postgres/index_test/uncompress_2000';
COPY 1
digoal=# copy index_test from '/home/postgres/index_test/uncompress_5000';
COPY 1
digoal=# copy index_test from '/home/postgres/index_test/uncompress_10000';
COPY 1
digoal=# select pg_column_size(info) from index_test ;
 pg_column_size 
----------------
             91
            194
            366
(3 rows)


数据压缩后可以插入.

下面修改为external测试

digoal=# truncate table index_test ;
TRUNCATE TABLE
digoal=# alter table index_test alter column info set storage external;
ALTER TABLE
digoal=# copy index_test from '/home/postgres/index_test/uncompress_2000';
COPY 1
digoal=# copy index_test from '/home/postgres/index_test/uncompress_5000';
COPY 1
digoal=# copy index_test from '/home/postgres/index_test/uncompress_10000';
COPY 1
digoal=# select pg_column_size(info) from index_test ;
 pg_column_size 
----------------
           6000
          15000
          30000
(3 rows)


注意到数据插入到TOAST表了, 因此HEAP表只用到了一个PAGE 8KB , HEAP表里面该列的位置存放的是一个指向TOAST表的对象。
TOAST的内部结构可以参考源码或者我之前写过一篇关于TOAST的BLOG。
另外需要注意的是，即使有多个列是extended存储的，也都存储到一个TOAST表里面。

digoal=# select pg_relation_size('index_test');
 pg_relation_size 
------------------
             8192
(1 row)
digoal=# select relname from pg_class where oid in (select reltoastrelid from pg_class where relname='index_test');
     relname      
------------------
 pg_toast_2129400
(1 row)
digoal=# alter table index_test add column info1 text;
ALTER TABLE
digoal=# insert into index_test (info1) select info from index_test ;
INSERT 0 10240
digoal=# select relname from pg_class where oid in (select reltoastrelid from pg_class where relname='index_test');
     relname      
------------------
 pg_toast_2129400
(1 row)



下面修改为extended测试

digoal=# alter table index_test alter column info set storage extended;
ALTER TABLE
digoal=# truncate table index_test ;
TRUNCATE TABLE
插入5W中文字
digoal=# copy index_test from '/home/postgres/index_test/compress_2000';
COPY 1
插入15W中文字
digoal=# copy index_test from '/home/postgres/index_test/compress_5000';
COPY 1
插入30W中文字
digoal=# copy index_test from '/home/postgres/index_test/compress_10000';
COPY 1
digoal=# select pg_column_size(info),octet_length(info)/3 from index_test ;
 pg_column_size | ?column? 
----------------+----------
           1741 |    50000  (完全存储在heap 表) 注意没有超出1/3PAGE的大小.
           5171 |   150000 (完全存储在TOAST 表) 注意已经超出1/3PAGE的大小.
          10321 |   300000 (完全存储在TOAST 表) 注意已经超出一个PAGE的大小.
(3 rows)


如下:

digoal=# truncate table index_test ;
TRUNCATE TABLE
digoal=# copy index_test from '/home/postgres/index_test/compress_2000';
COPY 1
digoal=# select pg_column_size(info),octet_length(info)/3 from index_test ;
 pg_column_size | ?column? 
----------------+----------
           1741 |    50000
(1 row)

digoal=# insert into index_test select * from index_test ;
INSERT 0 1
digoal=# insert into index_test select * from index_test ;
INSERT 0 2
digoal=# insert into index_test select * from index_test ;
INSERT 0 4
digoal=# insert into index_test select * from index_test ;
INSERT 0 8
digoal=# insert into index_test select * from index_test ;
INSERT 0 16
digoal=# insert into index_test select * from index_test ;
INSERT 0 32
digoal=# insert into index_test select * from index_test ;
INSERT 0 64
digoal=# insert into index_test select * from index_test ;
INSERT 0 128
digoal=# insert into index_test select * from index_test ;
INSERT 0 256
digoal=# insert into index_test select * from index_test ;
INSERT 0 512
digoal=# insert into index_test select * from index_test ;
INSERT 0 1024
digoal=# insert into index_test select * from index_test ;
INSERT 0 2048
digoal=# select pg_relation_size('index_test');
 pg_relation_size 
------------------
          8388608
(1 row)

digoal=# select pg_total_relation_size('index_test');
 pg_total_relation_size 
------------------------
                8421376
(1 row)

digoal=# truncate table index_test ;
TRUNCATE TABLE
digoal=# copy index_test from '/home/postgres/index_test/compress_5000';
COPY 1
digoal=# insert into index_test select * from index_test ;
INSERT 0 1
digoal=# insert into index_test select * from index_test ;
INSERT 0 2
digoal=# insert into index_test select * from index_test ;
INSERT 0 4
digoal=# insert into index_test select * from index_test ;
INSERT 0 8
digoal=# insert into index_test select * from index_test ;
INSERT 0 16
digoal=# insert into index_test select * from index_test ;
INSERT 0 32
digoal=# insert into index_test select * from index_test ;
INSERT 0 64
digoal=# insert into index_test select * from index_test ;
INSERT 0 128
digoal=# insert into index_test select * from index_test ;
INSERT 0 256
digoal=# insert into index_test select * from index_test ;
INSERT 0 512
digoal=# insert into index_test select * from index_test ;
INSERT 0 1024
digoal=# insert into index_test select * from index_test ;
INSERT 0 2048
digoal=# select pg_relation_size('index_test');
 pg_relation_size 
------------------
           221184
(1 row)

digoal=# select pg_total_relation_size('index_test');
 pg_total_relation_size 
------------------------
               24535040
(1 row)



接下来要测试索引了:

digoal=# truncate table index_test ;
TRUNCATE TABLE
digoal=# alter table index_test alter column info set storage plain;
ALTER TABLE
digoal=# copy index_test from '/home/postgres/index_test/uncompress_2000';
COPY 1
digoal=# create index idx_test on index_test using btree (info);
ERROR:  index row size 6016 exceeds maximum 2712 for index "idx_test"
HINT:  Values larger than 1/3 of a buffer page cannot be indexed.
Consider a function index of an MD5 hash of the value, or use full text indexing.
digoal=# select pg_column_size(info) from index_test ;
 pg_column_size 
----------------
           6004
(1 row)


未压缩存储2000个中文字加上列的头部信息需要6004字节，超出索引了。下面把存储改为MAIN的存储。

digoal=# alter table index_test alter column info set storage main;
ALTER TABLE


注意，修改只对修改之后插入的数据生效，以前的数据不会变化。占用空间还是6004字节。

digoal=# select pg_column_size(info) from index_test ;
 pg_column_size 
----------------
           6004
(1 row)


但是，索引可以建立了。说明建立索引时需要读取表字段的存储格式，并且按照这个存储格式来存储到索引里面,所以第一条记录6004字节在索引里面会被压缩,而不是原样复制。

digoal=# create index idx_test on index_test using btree (info);
CREATE INDEX


再插入同样的数据，压缩后只有91字节。

digoal=# copy index_test from '/home/postgres/index_test/uncompress_2000';
COPY 1
digoal=# select pg_column_size(info) from index_test ;
 pg_column_size 
----------------
           6004
             91
(2 rows)



而且索引的存储格式一旦索引建立以后就不会变更了，即使表的变更了。索引的也不会变更。来看如下例子.

digoal=# TRUNCATE table index_test ;
TRUNCATE TABLE
digoal=# drop index idx_test ;
DROP INDEX
digoal=# alter table index_test alter column info set storage plain;
ALTER TABLE
digoal=# create index idx_test on index_test using btree (info);
CREATE INDEX


这里建立的索引使用的存储格式是PLAIN。
然后我把表的存储格式变成main.然后插入2000个中文字看看什么情况？

digoal=# alter table index_test alter column info set storage main;
ALTER TABLE
digoal=# copy index_test from '/home/postgres/index_test/uncompress_2000';
ERROR:  index row size 6016 exceeds maximum 2712 for index "idx_test"
HINT:  Values larger than 1/3 of a buffer page cannot be indexed.
Consider a function index of an MD5 hash of the value, or use full text indexing.


CONTEXT:  COPY index_test, line 1: "索引测试索引测试索引测试索引测试索引测试索引测试索引测试索引测试索..."


这里报错了，报的是索引的错误。正好说明即使被索引的字段的存储方式变更了。索引的也不会变更。
为什么会这样设计，其实是可以改进的。

接下来看看索引会不会使用TOAST表,答案是9.1beta2这个版本不使用，如下.
9.2不存在这个问题 . 

digoal=# drop index idx_test;
DROP INDEX
digoal=# TRUNCATE table index_test ;
TRUNCATE TABLE
digoal=# alter table index_test alter column info set storage external;
ALTER TABLE
digoal=# create index idx_test on index_test using btree (info);
CREATE INDEX
digoal=# copy index_test from '/home/postgres/index_test/uncompress_2000';
ERROR:  index row size 6016 exceeds maximum 2712 for index "idx_test"
HINT:  Values larger than 1/3 of a buffer page cannot be indexed.
Consider a function index of an MD5 hash of the value, or use full text indexing.
CONTEXT:  COPY index_test, line 1: "索引测试索引测试索引测试索引测试索引测试索引测试索引测试索引测试索..."


digoal=# drop index idx_test;
DROP INDEX
digoal=# alter table index_test alter column info set storage extended;
ALTER TABLE
digoal=# create index idx_test on index_test using btree (info);
CREATE INDEX
digoal=# copy index_test from '/home/postgres/index_test/uncompress_2000';
COPY 1
digoal=# copy index_test from '/home/postgres/index_test/compress_2000';
COPY 1
digoal=# copy index_test from '/home/postgres/index_test/compress_5000';
ERROR:  index row size 5184 exceeds maximum 2712 for index "idx_test"
HINT:  Values larger than 1/3 of a buffer page cannot be indexed.
Consider a function index of an MD5 hash of the value, or use full text indexing.
CONTEXT:  COPY index_test, line 1: "索引测试索引测试索引测试索引测试索引测试索引测试索引测试索引测试索..."


显然索引是没有使用TOAST的，因为代码里有这段话,可能以后会尝试TOAST.

         * Check whether the item can fit on a btree page at all. (Eventually, we
         * ought to try to apply TOAST methods if not.) We actually need to be
         * able to fit three items on every page, so restrict any one item to 1/3
         * the per-page available space. Note that at this point, itupsz doesn't
         * include the ItemId.


最后来一个HASH的索引。

digoal=# drop index idx_test ;
DROP INDEX
digoal=# create index idx_test on index_test using hash (info);
CREATE INDEX
digoal=# copy index_test from '/home/postgres/index_test/compress_5000';
COPY 1
digoal=# copy index_test from '/home/postgres/index_test/compress_10000';
COPY 1
digoal=# select pg_column_size(info),octet_length(info) from index_test ;
 pg_column_size | octet_length 
----------------+--------------
             91 |         6000
           1741 |       150000
           5171 |       450000
          10321 |       900000
(4 rows)


压缩后10321字节的字段允许存储，但是不要被这个误导，因为HASH索引里面存储的不是字段内容。

digoal=# insert into index_test select * from index_test ;
INSERT 0 2560
digoal=# select pg_total_relation_size('index_test'::regclass);
 pg_total_relation_size 
------------------------
               64389120
(1 row)

digoal=# select pg_relation_size('index_test'::regclass);
 pg_relation_size 
------------------
           270336
(1 row)

digoal=# select pg_relation_size('idx_test'::regclass);
 pg_relation_size 
------------------
           442368
(1 row)
digoal=# select count(*) from index_test ;
 count 
-------
  5120
(1 row)


5120条记录，64M内容，HASH索引只用了400多KB（和字段内容有关系,因为我这里用的是4个中文字重复几千次）。

另一个与btree索引不同的是,虽然主表是extended存储的,但是HASH索引是plain存储的.

digoal=# \d+ idx_test 
                Index "public.idx_test"
 Column |  Type   | Definition | Storage | Description 
--------+---------+------------+---------+-------------
 info   | integer | info       | plain   | 
hash, for table "public.index_test"



【参考】
1. http://www.postgresql.org/docs/9.1/static/indexes-types.html
2. src/backend/access/common/indextuple.c
3. src/backend/access/nbtree/nbtinsert.c
4. src/backend/access/nbtree/nbtsort.c
5. src/backend/access/hash,gin,gist....
6. 修改TOAST阈值
http://blog.163.com/digoal@126/blog/static/16387704020130108132117/
