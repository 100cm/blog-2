PostgreSQL research

gfs I/O error 引发 rhcs 服务切换

2011-12-09 8:21:49   查看原文>>

主机A：
运行orasrv服务, GFS设备为sdc, cluster_orapg:oradata
Dec  8 20:50:36 db1 kernel: mptbase: ioc0: LogInfo(0x31170000): Originator={PL}, Code={IO Device Missing Delay Retry}, SubCode(0x000
0)
Dec  8 20:51:09 db1 last message repeated 9 times
Dec  8 20:51:17 db1 last message repeated 3 times
Dec  8 20:51:17 db1 kernel: sd 1:0:0:2: SCSI error: return code = 0x00020000
Dec  8 20:51:17 db1 kernel: end_request: I/O error, dev sdc, sector 494973040
Dec  8 20:51:17 db1 kernel: sd 1:0:0:2: SCSI error: return code = 0x00020000
Dec  8 20:51:17 db1 kernel: end_request: I/O error, dev sdc, sector 583010568
Dec  8 20:51:17 db1 kernel: GFS: fsid=cluster_orapg:oradata.1: fatal: I/O error
Dec  8 20:51:17 db1 kernel: GFS: fsid=cluster_orapg:oradata.1:   block = 72876323
Dec  8 20:51:17 db1 kernel: GFS: fsid=cluster_orapg:oradata.1:   function = gfs_logbh_wait
Dec  8 20:51:17 db1 kernel: GFS: fsid=cluster_orapg:oradata.1:   file = /builddir/build/BUILD/gfs-kmod-0.1.23/_kmod_build_/src/gfs/d
io.c, line = 925
Dec  8 20:51:17 db1 kernel: GFS: fsid=cluster_orapg:oradata.1:   time = 1323348677
Dec  8 20:51:17 db1 kernel: GFS: fsid=cluster_orapg:oradata.1: about to withdraw from the cluster
Dec  8 20:51:17 db1 kernel: GFS: fsid=cluster_orapg:oradata.1: telling LM to withdraw
Dec  8 20:51:19 db1 kernel: dlm: oradata: group leave failed -512 0
Dec  8 20:51:19 db1 kernel: GFS: fsid=cluster_orapg:oradata.1: withdrawn
Dec  8 20:51:19 db1 kernel: 
Dec  8 20:51:19 db1 kernel: Call Trace:
Dec  8 20:51:19 db1 kernel:  [<ffffffff885e30a4>] :gfs:gfs_lm_withdraw+0xc4/0xd3
Dec  8 20:51:19 db1 kernel:  [<ffffffff800b9da9>] delayacct_end+0x5d/0x86
Dec  8 20:51:19 db1 kernel:  [<ffffffff8006398e>] __wait_on_bit+0x60/0x6e
Dec  8 20:51:19 db1 kernel:  [<ffffffff80014eec>] sync_buffer+0x0/0x3f
Dec  8 20:51:19 db1 kernel:  [<ffffffff80063a08>] out_of_line_wait_on_bit+0x6c/0x78
Dec  8 20:51:19 db1 kernel:  [<ffffffff885f88a3>] :gfs:gfs_io_error_bh_i+0x32/0x37
Dec  8 20:51:19 db1 kernel:  [<ffffffff885d0ed1>] :gfs:gfs_logbh_wait+0x51/0x70
Dec  8 20:51:19 db1 kernel:  [<ffffffff885e3f26>] :gfs:disk_commit+0x2eb/0x44b
Dec  8 20:51:19 db1 kernel:  [<ffffffff885e49bd>] :gfs:log_flush_internal+0x18a/0x26f
Dec  8 20:51:19 db1 kernel:  [<ffffffff885ea89b>] :gfs:do_write_buf+0x52b/0x67e
Dec  8 20:51:19 db1 kernel:  [<ffffffff885e9fc8>] :gfs:walk_vm+0x10e/0x311
Dec  8 20:51:19 db1 kernel:  [<ffffffff885ea370>] :gfs:do_write_buf+0x0/0x67e
Dec  8 20:51:19 db1 kernel:  [<ffffffff885ea277>] :gfs:__gfs_write+0xac/0xc6
Dec  8 20:51:19 db1 kernel:  [<ffffffff80016433>] vfs_write+0xce/0x174
Dec  8 20:51:19 db1 kernel:  [<ffffffff8004379f>] sys_pwrite64+0x50/0x70
Dec  8 20:51:19 db1 kernel:  [<ffffffff8005d229>] tracesys+0x71/0xe0
Dec  8 20:51:19 db1 kernel:  [<ffffffff8005d28d>] tracesys+0xd5/0xe0
Dec  8 20:51:19 db1 kernel: 
被主机B fence
Dec  8 20:56:26 db1 syslogd 1.4.1: restart.

主机B：
运行pgsrv服务, GFS设备为sdb, cluster_orapg:database.
Dec  8 20:50:36 db2 kernel: mptbase: ioc0: LogInfo(0x31170000): Originator={PL}, Code={IO Device Missing Delay Retry}, SubCode(0x000
0)
Dec  8 20:51:09 db2 last message repeated 23 times
Dec  8 20:51:09 db2 kernel: mptbase: ioc0: LogInfo(0x31170000): Originator={PL}, Code={IO Device Missing Delay Retry}, SubCode(0x000
0)
Dec  8 20:51:09 db2 kernel: sd 1:0:0:1: SCSI error: return code = 0x00020000
Dec  8 20:51:09 db2 kernel: end_request: I/O error, dev sdb, sector 1917040512
Dec  8 20:51:09 db2 kernel: mptbase: ioc0: LogInfo(0x31170000): Originator={PL}, Code={IO Device Missing Delay Retry}, SubCode(0x000
0)
Dec  8 20:51:09 db2 last message repeated 4 times
Dec  8 20:51:09 db2 kernel: GFS: fsid=cluster_orapg:database.0: fatal: I/O error
Dec  8 20:51:09 db2 kernel: GFS: fsid=cluster_orapg:database.0:   block = 239630064
Dec  8 20:51:09 db2 kernel: GFS: fsid=cluster_orapg:database.0:   function = gfs_dreread
Dec  8 20:51:09 db2 kernel: GFS: fsid=cluster_orapg:database.0:   file = /builddir/build/BUILD/gfs-kmod-0.1.23/_kmod_build_/src/gfs/
dio.c, line = 576
Dec  8 20:51:09 db2 kernel: GFS: fsid=cluster_orapg:database.0:   time = 1323348669
Dec  8 20:51:09 db2 kernel: sd 1:0:0:1: SCSI error: return code = 0x00020000
Dec  8 20:51:09 db2 kernel: end_request: I/O error, dev sdb, sector 398263568
Dec  8 20:51:09 db2 kernel: Buffer I/O error on device sdb, logical block 49782946
Dec  8 20:51:09 db2 kernel: lost page write due to I/O error on sdb
Dec  8 20:51:09 db2 kernel: Buffer I/O error on device sdb, logical block 49782947
Dec  8 20:51:09 db2 kernel: lost page write due to I/O error on sdb
Dec  8 20:51:09 db2 kernel: GFS: fsid=cluster_orapg:database.0: about to withdraw from the cluster
Dec  8 20:51:09 db2 kernel: GFS: fsid=cluster_orapg:database.0: telling LM to withdraw
Dec  8 20:51:09 db2 kernel: dlm: database: group leave failed -512 0
Dec  8 20:51:09 db2 kernel: GFS: fsid=cluster_orapg:database.0: withdrawn
Dec  8 20:51:09 db2 kernel: 
Dec  8 20:51:09 db2 kernel: Call Trace:
Dec  8 20:51:09 db2 kernel:  [<ffffffff886560a4>] :gfs:gfs_lm_withdraw+0xc4/0xd3
Dec  8 20:51:09 db2 kernel:  [<ffffffff800b9da9>] delayacct_end+0x5d/0x86
Dec  8 20:51:09 db2 kernel:  [<ffffffff8006398e>] __wait_on_bit+0x60/0x6e
Dec  8 20:51:09 db2 kernel:  [<ffffffff80014eec>] sync_buffer+0x0/0x3f
Dec  8 20:51:09 db2 kernel:  [<ffffffff80063a08>] out_of_line_wait_on_bit+0x6c/0x78
Dec  8 20:51:09 db2 kernel:  [<ffffffff8866b8a3>] :gfs:gfs_io_error_bh_i+0x32/0x37
Dec  8 20:51:09 db2 kernel:  [<ffffffff88642b38>] :gfs:gfs_dreread+0xad/0xc7
Dec  8 20:51:09 db2 kernel:  [<ffffffff88642b7a>] :gfs:gfs_dread+0x28/0x43
Dec  8 20:51:09 db2 kernel:  [<ffffffff8864f2b2>] :gfs:make_dinode+0x46/0x288
Dec  8 20:51:09 db2 kernel:  [<ffffffff8866a60b>] :gfs:gfs_trans_add_bh+0xc7/0xd9
Dec  8 20:51:09 db2 kernel:  [<ffffffff88644e23>] :gfs:gfs_dirent_alloc+0x1d7/0x239
Dec  8 20:51:09 db2 kernel:  [<ffffffff8865b604>] :gfs:gfs_dinode_out+0x17c/0x1a9
Dec  8 20:51:09 db2 kernel:  [<ffffffff88646db8>] :gfs:gfs_dir_add+0x3e1/0x3f3
Dec  8 20:51:09 db2 kernel:  [<ffffffff88650f9f>] :gfs:gfs_createi+0x46a/0x600
Dec  8 20:51:09 db2 kernel:  [<ffffffff8008a387>] complete+0x38/0x4b
Dec  8 20:51:10 db2 kernel:  [<ffffffff886612b8>] :gfs:gfs_create+0x78/0x1c3
Dec  8 20:51:10 db2 kernel:  [<ffffffff8003a196>] vfs_create+0xe6/0x158
Dec  8 20:51:10 db2 kernel:  [<ffffffff8001aa7e>] open_namei+0x19d/0x6d5
Dec  8 20:51:10 db2 kernel:  [<ffffffff8002732a>] do_filp_open+0x1c/0x38
Dec  8 20:51:10 db2 kernel:  [<ffffffff80019720>] do_sys_open+0x44/0xbe
Dec  8 20:51:10 db2 kernel:  [<ffffffff8005d28d>] tracesys+0xd5/0xe0
Dec  8 20:51:10 db2 kernel: 
Dec  8 20:51:17 db2 kernel: mptbase: ioc0: LogInfo(0x31170000): Originator={PL}, Code={IO Device Missing Delay Retry}, SubCode(0x000
0)
Dec  8 20:51:25 db2 last message repeated 6 times
Dec  8 20:51:25 db2 kernel: sd 1:0:0:1: SCSI error: return code = 0x00020000
Dec  8 20:51:25 db2 kernel: end_request: I/O error, dev sdb, sector 1165922184
Dec  8 20:51:25 db2 kernel: mptbase: ioc0: LogInfo(0x31170000): Originator={PL}, Code={IO Device Missing Delay Retry}, SubCode(0x000
0)
Dec  8 20:51:25 db2 last message repeated 2 times
Dec  8 20:51:25 db2 kernel: sd 1:0:0:1: SCSI error: return code = 0x00020000
Dec  8 20:51:25 db2 kernel: end_request: I/O error, dev sdb, sector 1183923672
Dec  8 20:51:25 db2 kernel: Buffer I/O error on device sdb, logical block 147990459
Dec  8 20:51:25 db2 kernel: lost page write due to I/O error on sdb
Dec  8 20:51:25 db2 kernel: sd 1:0:0:1: SCSI error: return code = 0x00020000
Dec  8 20:51:25 db2 kernel: end_request: I/O error, dev sdb, sector 416
Dec  8 20:51:25 db2 kernel: Buffer I/O error on device sdb, logical block 52
Dec  8 20:51:25 db2 kernel: lost page write due to I/O error on sdb
Dec  8 20:51:25 db2 kernel: sd 1:0:0:1: SCSI error: return code = 0x00020000
Dec  8 20:51:25 db2 kernel: end_request: I/O error, dev sdb, sector 1132207488
Dec  8 20:51:30 db2 openais[8564]: [TOTEM] The token was lost in the OPERATIONAL state. 
Dec  8 20:51:30 db2 openais[8564]: [TOTEM] Receive multicast socket recv buffer size (288000 bytes). 
Dec  8 20:51:30 db2 openais[8564]: [TOTEM] Transmit multicast socket send buffer size (288000 bytes). 
Dec  8 20:51:30 db2 openais[8564]: [TOTEM] entering GATHER state from 2. 
Dec  8 20:51:33 db2 kernel: mptbase: ioc0: LogInfo(0x31170000): Originator={PL}, Code={IO Device Missing Delay Retry}, SubCode(0x000
0)
Dec  8 20:51:33 db2 last message repeated 63 times
Dec  8 20:51:35 db2 openais[8564]: [TOTEM] entering GATHER state from 0. 
Dec  8 20:51:35 db2 openais[8564]: [TOTEM] Creating commit token because I am the rep. 
Dec  8 20:51:35 db2 openais[8564]: [TOTEM] Saving state aru ca8ac high seq received ca8ac 
Dec  8 20:51:35 db2 openais[8564]: [TOTEM] Storing new sequence id for ring fc 
Dec  8 20:51:35 db2 openais[8564]: [TOTEM] entering COMMIT state. 
Dec  8 20:51:35 db2 openais[8564]: [TOTEM] entering RECOVERY state. 
Dec  8 20:51:35 db2 openais[8564]: [TOTEM] position [0] member 192.168.1.24: 
Dec  8 20:51:35 db2 openais[8564]: [TOTEM] previous ring seq 248 rep 192.168.1.22 
Dec  8 20:51:35 db2 openais[8564]: [TOTEM] aru ca8ac high delivered ca8ac received flag 1 
Dec  8 20:51:35 db2 openais[8564]: [TOTEM] Did not need to originate any messages in recovery. 
Dec  8 20:51:35 db2 openais[8564]: [TOTEM] Sending initial ORF token 
Dec  8 20:51:35 db2 openais[8564]: [CLM  ] CLM CONFIGURATION CHANGE 
Dec  8 20:51:35 db2 openais[8564]: [CLM  ] New Configuration: 
Dec  8 20:51:35 db2 kernel: dlm: closing connection to node 1
Dec  8 20:51:35 db2 openais[8564]: [CLM  ]      r(0) ip(192.168.1.24)  
Dec  8 20:51:35 db2 openais[8564]: [CLM  ] Members Left: 
Dec  8 20:51:35 db2 openais[8564]: [CLM  ]      r(0) ip(192.168.1.22)  
Dec  8 20:51:35 db2 openais[8564]: [CLM  ] Members Joined: 
Dec  8 20:51:35 db2 openais[8564]: [CLM  ] CLM CONFIGURATION CHANGE 
Dec  8 20:51:35 db2 openais[8564]: [CLM  ] New Configuration: 
Dec  8 20:51:35 db2 openais[8564]: [CLM  ]      r(0) ip(192.168.1.24)  
Dec  8 20:51:35 db2 openais[8564]: [CLM  ] Members Left: 
Dec  8 20:51:35 db2 openais[8564]: [CLM  ] Members Joined: 
Dec  8 20:51:35 db2 openais[8564]: [SYNC ] This node is within the primary component and will provide service. 
Dec  8 20:51:35 db2 openais[8564]: [TOTEM] entering OPERATIONAL state. 
Dec  8 20:51:35 db2 openais[8564]: [CLM  ] got nodejoin message 192.168.1.24 
Dec  8 20:51:35 db2 openais[8564]: [CPG  ] got joinlist message from node 2 
Dec  8 20:51:41 db2 kernel: mptbase: ioc0: LogInfo(0x31170000): Originator={PL}, Code={IO Device Missing Delay Retry}, SubCode(0x000
0)
Dec  8 20:51:46 db2 last message repeated 64 times
Dec  8 20:51:46 db2 kernel: sd 1:0:0:1: SCSI error: return code = 0x00020000
Dec  8 20:51:46 db2 kernel: end_request: I/O error, dev sdb, sector 394900640
Dec  8 20:51:46 db2 kernel: mptbase: ioc0: LogInfo(0x31170000): Originator={PL}, Code={IO Device Missing Delay Retry}, SubCode(0x000
0)
Dec  8 20:51:46 db2 last message repeated 62 times
Dec  8 20:52:35 db2 fenced[8581]: db1 not a cluster member after 60 sec post_fail_delay
Dec  8 20:52:35 db2 fenced[8581]: fencing node "db1"
Dec  8 20:52:38 db2 fenced[8581]: fence "db1" success
Dec  8 20:52:38 db2 gfs_controld[8593]: database finish: needs recovery jid 1 nodeid 1 status 1
Dec  8 20:52:38 db2 kernel: GFS: fsid=cluster_orapg:oradata.0: jid=1: Trying to acquire journal lock...
Dec  8 20:52:38 db2 kernel: GFS: fsid=cluster_orapg:oradata.0: jid=1: Looking at journal...
Dec  8 20:52:38 db2 kernel: GFS: fsid=cluster_orapg:oradata.0: jid=1: Acquiring the transaction lock...
Dec  8 20:52:39 db2 kernel: GFS: fsid=cluster_orapg:oradata.0: jid=1: Replaying journal...
Dec  8 20:52:39 db2 kernel: GFS: fsid=cluster_orapg:oradata.0: jid=1: Replayed 38 of 38 blocks
Dec  8 20:52:39 db2 kernel: GFS: fsid=cluster_orapg:oradata.0: jid=1: replays = 38, skips = 0, sames = 0
Dec  8 20:52:39 db2 kernel: GFS: fsid=cluster_orapg:oradata.0: jid=1: Journal replayed in 1s
Dec  8 20:52:39 db2 kernel: GFS: fsid=cluster_orapg:oradata.0: jid=1: Done
Dec  8 20:52:40 db2 clurgmgrd[8629]: <notice> Taking over service service:orasrv from down member db1 
Dec  8 20:52:40 db2 avahi-daemon[6402]: Registering new address record for 192.168.1.26 on bond0.
Dec  8 20:52:52 db2 clurgmgrd[8629]: <notice> Service service:orasrv started 

cluster_orapg:oradata恢复正常, cluster_orapg:database文件系统依然异常,


