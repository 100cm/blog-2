PostgreSQL research

PostgreSQL 9.4 New Feature - Auto-resize the catalog cache

2014-05-06 16:41:44   查看原文>>

PostgreSQL 9.4 对catalog元数据的缓存改进, 动态加载使得catalog不需要一次性加载至内存哈希表, 一方面减少了内存需求, 一方面也提高了访问效率. 对于catalog比较大但是活跃数据较少的数据库应用场景尤为有用.
例如堆积了很多历史表的数据库, 或者数据仓库. 存在大量函数的数据库. 等.


Make catalog cache hash tables resizeable.
author  Heikki Linnakangas <heikki.linnakangas@iki.fi>
Thu, 5 Sep 2013 16:47:56 +0000 (19:47 +0300)
committer       Heikki Linnakangas <heikki.linnakangas@iki.fi>
Thu, 5 Sep 2013 17:20:03 +0000 (20:20 +0300)
commit  20cb18db4668b016748fbb5fcb1422bc3e0d52d1
tree    82ee53ee378c3fc6fde586f7e3a628421eae7bf6        tree | snapshot
parent  b1892aaeaaf34d8d1637221fc1cbda82ac3fcd71        commit | diff
Make catalog cache hash tables resizeable.

If the hash table backing a catalog cache becomes too full (fillfactor > 2),
enlarge it. A new buckets array, double the size of the old, is allocated,
and all entries in the old hash are moved to the right bucket in the new
hash.

This has two benefits. First, cache lookups don't get so expensive when
there are lots of entries in a cache, like if you access hundreds of
thousands of tables. Second, we can make the (initial) sizes of the caches
much smaller, which saves memory.

This patch dials down the initial sizes of the catcaches. The new sizes are
chosen so that a backend that only runs a few basic queries still won't need
to enlarge any of them.


当catalog哈希表快满时, 使用RehashCatCache进行扩展, 详见末尾.

[参考]
1. http://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=20cb18db4668b016748fbb5fcb1422bc3e0d52d1
2. src/backend/utils/cache/catcache.c

+ * Enlarge a catcache, doubling the number of buckets.
+ */
+static void
+RehashCatCache(CatCache *cp)
+{
+   dlist_head *newbucket;
+   int         newnbuckets;
+   int         i;
+
+   elog(DEBUG1, "rehashing catalog cache id %d for %s; %d tups, %d buckets",
+        cp->id, cp->cc_relname, cp->cc_ntup, cp->cc_nbuckets);
+
+   /* Allocate a new, larger, hash table. */
+   newnbuckets = cp->cc_nbuckets * 2;
+   newbucket = (dlist_head *) MemoryContextAllocZero(CacheMemoryContext, newnbuckets * sizeof(dlist_head));
+
+   /* Move all entries from old hash table to new. */
+   for (i = 0; i < cp->cc_nbuckets; i++)
+   {
+       dlist_mutable_iter iter;
+       dlist_foreach_modify(iter, &cp->cc_bucket[i])
+       {
+           CatCTup    *ct = dlist_container(CatCTup, cache_elem, iter.cur);
+           int         hashIndex = HASH_INDEX(ct->hash_value, newnbuckets);
+
+           dlist_delete(iter.cur);
+           dlist_push_head(&newbucket[hashIndex], &ct->cache_elem);
+       }
+   }
+
+   /* Switch to the new array. */
+   pfree(cp->cc_bucket);
+   cp->cc_nbuckets = newnbuckets;
+   cp->cc_bucket = newbucket;
+}

...

+   /*
+    * If the hash table has become too full, enlarge the buckets array.
+    * Quite arbitrarily, we enlarge when fill factor > 2.
+    */
+   if (cache->cc_ntup > cache->cc_nbuckets * 2)
+       RehashCatCache(cache);
+


Flag Counter
