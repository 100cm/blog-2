PostgreSQL research

PostgreSQL seqscan performance affected by blockdev's readahead

2012-06-07 17:13:05   查看原文>>

昨天一位群里的兄弟在问怎么优化大表全表扫描的性能, 刚好昨天做了一下这方面的测试.
目标是测试块设备的预读的大小和读取速度的关系.
大表全表扫描和读取速度息息相关.
测试环境 : 

PostgreSQL 9.2 beta2
CentOS 5.x 64位
DELL R610
6块2.5寸 SAS146G RAID5
RAID bus controller: LSI Logic / Symbios Logic MegaRAID SAS 1078



测试表 : 

postgres@172_16_3_52-> psql digoal digoal
psql (9.2beta2)
Type "help" for help.
digoal=> drop table user_info;
creaDROP TABLE
digoal=> create table read_ahead_test (id int,info text);
CREATE TABLE
digoal=> alter table read_ahead_test alter column info set storage plain;
ALTER TABLE
\c digoal postgres
digoal=# insert into digoal.read_ahead_test select generate_series(1,50000000),repeat('digoal',100);
digoal=# select * from pgfadvise_dontneed('digoal.read_ahead_test');
digoal=# checkpoint;



测试SQL : 

date +%F%T
psql digoal digoal -c "copy digoal.read_ahead_test to stdout" >/dev/null
date +%F%T


计算耗时.

一、测试Linux的blockdev设置的预读和设备读取速度的关系.
1. 测试前, 关闭RAID卡读写缓存 (这个一般在RAID卡的BIOS中配置), 以免给测试带来干扰.
no read ahead
write through
2. 测试过程中记得刷掉OS cache以免影响测试结果

接下来开始测试, 默认的块设备的readahead是256个扇区.
分别测试一下增加readahead后, 读取速度和全表扫描的速度.
测试的表的表空间放在/dev/sda的分区上.

-- ra=256的测试和结果 : 

# blockdev --getra /dev/sda
256

$ pg_ctl stop -m fast
# echo 3 > /proc/sys/vm/drop_caches
$ pg_ctl start
$ date +%F%T
$ psql digoal digoal -c "copy digoal.read_ahead_test to stdout" >/dev/null
$ date +%F%T
全表扫描时间 : 26秒
$ vmstat -n 3
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0    188 2930180   1528 1011088    0    0 102016   104 1830 24390  6  2 88  4  0
 0  1    188 2587740   1536 1353056    0    0 113920     5 1905 26957  7  2 87  3  0
 1  0    188 2174068   1536 1765536    0    0 137557     0 2083 32173  8  3 88  2  0
 1  0    188 1840024   1544 2098788    0    0 111104     4 1890 26290  7  2 87  4  0
 0  1    188 1496740   1548 2441304    0    0 114177     0 1904 26963  7  2 88  3  0
 0  1    188 1085888   1556 2851280    0    0 136619     5 2082 31962  8  3 87  2  0


-- ra=512的测试和结果 : 

# blockdev --setra 512 /dev/sda

$ pg_ctl stop -m fast
# echo 3 > /proc/sys/vm/drop_caches
$ pg_ctl start
$ date +%F%T
$ psql digoal digoal -c "copy digoal.read_ahead_test to stdout" >/dev/null
$ date +%F%T
全表扫描时间 : 24秒
vmstat -n 3
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0    188 2708512   1048 1232908    0    0 127404     0 1522 29901  8  2 88  3  0
 1  0    188 2306600   1064 1634088    0    0 133632    16 1548 31367  8  2 88  2  0
 1  0    188 1890836   1064 2048856    0    0 138325     0 1560 32336  8  3 87  2  0
 1  0    188 1510464   1076 2428276    0    0 126465     4 1524 29733  8  2 88  3  0
 1  0    188 1062712   1084 2875064    0    0 148907     5 1597 34697  9  3 88  1  0


-- ra=1024的测试和结果 : 

blockdev --setra 1024 /dev/sda

$ pg_ctl stop -m fast
# echo 3 > /proc/sys/vm/drop_caches
$ pg_ctl start
$ date +%F%T
$ psql digoal digoal -c "copy digoal.read_ahead_test to stdout" >/dev/null
$ date +%F%T
全表扫描时间 : 22秒
vmstat -n 3
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0    188 2875852   1644 1066280    0    0 143531    69 1584 33914  8  3 88  2  0
 1  0    188 2456600   1648 1484564    0    0 139436    81 1572 32986  8  2 88  2  0
 1  0    188 1991844   1656 1948576    0    0 154624     5 1622 36508  9  3 87  1  0
 0  1    188 1613096   1672 2326372    0    0 125953     7 1505 29894  7  2 88  3  0
 2  0    188 1152740   1676 2785708    0    0 153088     1 1614 36147  9  3 88  1  0


-- ra=2048的测试和结果 : 

# blockdev --setra 2048 /dev/sda

$ pg_ctl stop -m fast
# echo 3 > /proc/sys/vm/drop_caches
$ pg_ctl start
$ date +%F%T
$ psql digoal digoal -c "copy digoal.read_ahead_test to stdout" >/dev/null
$ date +%F%T
全表扫描时间 : 20秒
# vmstat -n 3
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 3  0    188 2589292   1540 1352444    0    0 161111    71 1617 37631  9  3 88  1  0
 1  0    188 2082192   1548 1858148    0    0 168619     5 1653 39399  9  3 88  1  0
 1  0    188 1600960   1552 2338564    0    0 160087     0 1605 37485  9  3 88  1  0
 1  0    188 1112444   1560 2825988    0    0 162475    64 1637 37953  9  3 88  1  0


-- ra=4096的测试和结果 : 

# blockdev --setra 4096 /dev/sda

$ pg_ctl stop -m fast
# echo 3 > /proc/sys/vm/drop_caches
$ pg_ctl start
$ date +%F%T
$ psql digoal digoal -c "copy digoal.read_ahead_test to stdout" >/dev/null
$ date +%F%T
全表扫描时间 : 19秒
# vmstat -n 3
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0    188 2818292   1524 1122932    0    0 171349    68 1602 39751  9  3 88  0  0
 1  0    188 2288724   1524 1651320    0    0 176115     0 1608 40758 10  3 88  0  0
 1  0    188 1769508   1536 2169420    0    0 172716     5 1606 40037 10  3 88  0  0
 1  0    188 1254188   1544 2683504    0    0 171349    64 1592 39532  9  3 88  0  0


-- ra=8192的测试和结果 : 

# blockdev --setra 8192 /dev/sda

$ pg_ctl stop -m fast
# echo 3 > /proc/sys/vm/drop_caches
$ pg_ctl start
$ date +%F%T
$ psql digoal digoal -c "copy digoal.read_ahead_test to stdout" >/dev/null
$ date +%F%T
全表扫描时间 : 18秒
# vmstat -n 3
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0    188 2548572   1492 1393008    0    0 185687    69 1496 42820 11  5 84  0  0
 1  0    188 1982132   1500 1958180    0    0 188416     5 1588 43314 13  2 85  0  0
 1  0    188 1415632   1504 2523504    0    0 188417     0 1598 43302 12  2 85  0  0


-- ra=16384的测试和结果 : 

# blockdev --setra 16384 /dev/sda

$ pg_ctl stop -m fast
# echo 3 > /proc/sys/vm/drop_caches
$ pg_ctl start
$ date +%F%T
$ psql digoal digoal -c "copy digoal.read_ahead_test to stdout" >/dev/null
$ date +%F%T
全表扫描时间 : 19秒
# vmstat -n 3
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 2  0    188 2463192   1484 1478880    0    0 180223     0 1439 41479 10  3 87  0  0
 2  0    188 1896940   1492 2044388    0    0 188416     5 1346 43339 13  2 85  0  0
 1  0    188 1338660   1496 2601364    0    0 185687    73 1457 43175 13  2 85  0  0


-- ra=32768的测试和结果 : 

# blockdev --setra 32768 /dev/sda

$ pg_ctl stop -m fast
# echo 3 > /proc/sys/vm/drop_caches
$ pg_ctl start
$ date +%F%T
$ psql digoal digoal -c "copy digoal.read_ahead_test to stdout" >/dev/null
$ date +%F%T
全表扫描时间 : 18秒
# vmstat -n 3
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0    188 2569472   1476 1371568    0    0 185687   124 1412 42899  9  3 87  0  0
 1  0    188 2044076   1484 1895808    0    0 174763     5 1385 40608 10  3 87  0  0
 1  0    188 1518680   1492 2420132    0    0 174764     1 1388 40599 10  3 88  0  0


-- ra=327680的测试和结果 : 

# blockdev --setra 327680 /dev/sda

$ pg_ctl stop -m fast
# echo 3 > /proc/sys/vm/drop_caches
$ pg_ctl start
$ date +%F%T
$ psql digoal digoal -c "copy digoal.read_ahead_test to stdout" >/dev/null
$ date +%F%T
全表扫描时间 : 24秒
# vmstat -n 3
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi       bo   in   cs us sy id wa st
 0  1    188 2983212   1444 906140     0    0 146656     0 1360 32821  8  2 88  3  0
 1  0    188 2829776   1460 1110860    0    0 68160     68 1245 36021  8  2 88  2  0
 3  0    188 2260452   1472 1678712    0    0 189324     5 1506 29839  7  2 88  3  0
 1  0    188 1778992   1472 2159408    0    0 160203     3 1442 30208  7  2 88  3  0
 2  0    188 1373900   1488 2563432    0    0 134711     5 1338 32042  8  2 88  3  0
 1  0    188 881388    1488 2944896    0    0 128165    13 1329 34959  8  2 87  2  0
 1  0    188 727952    1496 3207964    0    0 86656     24 1294 36210  9  2 88  2  0
 0  0    188 541092    1508 3395564    0    0 62537      8 1170 16217  4  1 94  1  0



二、RAID卡或存储控制器上的readahead和Linux下设置的readahead有同样效果. 
测试略.

【小结】
1. 当RAID通道的速度不是瓶颈的时候,readahead加大是可以提升RAID的读取速度的. 但是当达到RAID通道的瓶颈后, 提升就不明显了.
2. readahead持续增加到达一定量的时候性能会出现拐点, 继续加大则会导致性能下降.
3. 本例选择COPY TO STDOUT重定向到/dev/null目的为降低OS CACHE对性能测试的影响.
4. OLTP系统不适合使用大的readahead, 更适合数据仓库系统. OLTP的特点是请求密集型, 每次IO的数据量是比较小的, 且离散的. 如果设置大的readahead 虽然读速度(每秒读取数据量MB)提高了, 但是必将影响OLTP系统的单次IO请求时间. 
