PostgreSQL research

PostgreSQL custom aggregate function(hash agg) improve performance for count distince

2014-08-21 9:52:22   查看原文>>

之前写过关于定制PostgreSQL和Postgres-XC聚合函数的文章, 感兴趣的朋友可参考如下, 对自定义聚合函数有个了解.
1. http://blog.163.com/digoal@126/blog/static/16387704020134222140958/
2. http://blog.163.com/digoal@126/blog/static/16387704020121118112533410/
本文说的是通过自定义聚合函数来提升count(distinct x)的性能.
我们先看一下PostgreSQL是如何处理这个操作的 : 

digoal=# CREATE TABLE test_table (id INT, val INT);
CREATE TABLE
digoal=# INSERT INTO test_table
digoal-#      SELECT mod(i, 1000), (1000 * random())::int
digoal-#        FROM generate_series(1,10000000) s(i);
INSERT 0 10000000
digoal=# ANALYZE test_table;
ANALYZE
digoal=# explain analyze SELECT id, COUNT(DISTINCT val) FROM test_table GROUP BY 1;
                                                              QUERY PLAN                                                            
  
------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate  (cost=1376219.83..1451229.83 rows=1000 width=8) (actual time=18734.990..24936.301 rows=1000 loops=1)
   ->  Sort  (cost=1376219.83..1401219.83 rows=10000000 width=8) (actual time=18728.432..21178.936 rows=10000000 loops=1)
         Sort Key: id
         Sort Method: external merge  Disk: 175872kB
         ->  Seq Scan on test_table  (cost=0.00..111002.00 rows=10000000 width=8) (actual time=0.033..1218.911 rows=10000000 loops=1)
 Total runtime: 24984.937 ms
(6 rows)


总共耗时大概25秒, 其中全表扫描耗时1.2秒, 排序耗时19秒, 排序后输出到下一节点(聚合)耗时2秒, 聚合耗时4秒.
显然, 排序占了大部分时间. 这里有较大的优化空间.
tvondra贡献了一个插件来提高count distinct的性能, 确切的应该说提供了一个聚合函数.
https://github.com/tvondra/count_distinct
当前版本9.3.5, count distinct的处理原理 : 

With the previous implementation (based on hash tables), memory consumption was a big problem. For example when counting 80M unique 32-bit integers, it was common to see more than 5GB of RAM allocated (which is way more than the 320MB necessary for the values, and ~1.6GB when including some hash table related overhead (buckets, pointers, ...). This was mostly due to clashing with MemoryContext internals, etc.


tvondra的聚合函数可以降低内存的使用, 但是依旧有可能导致内存溢出(超出WORK_MEM使用disk). 所以, 如果有很多的唯一值, 那么需要更大的内存. 

With the new implementation significantly improves this, and the memory consumption is a fraction (usually less than 10-20% of what it used to be).

Still, it may happen that you run out of memory. It's not very likely because for large number of groups planner will switch to GroupAggregate (effectively keeping a single group in memory), but it's possible.


9.5以后可能会通过哈希聚合(也就是本文提到的插件)来解决性能问题.

Sadly, that is not something the extension could handle internally in a reasonable way. The only actual solution is to implement this into HashAggregate itself (some people are working on this, but don't hold your breath - it won't happen before 9.5).

So in short - if you're dealing with a lot of distinct values, you need a lot of RAM in the machine.


前面我们的work_mem较小, 所以没有使用qsort, 加大work_mem后可以看到memory的开销是860MB, 我们后面观察一下使用自定义的聚合函数后会不会下降.

digoal=# set work_mem='2048MB';
SET
digoal=# explain (analyze,verbose,buffers) SELECT id, COUNT(DISTINCT val) FROM test_table GROUP BY 1;
                                                                 QUERY PLAN                                                         
         
------------------------------------------------------------------------------------------------------------------------------------
---------
 GroupAggregate  (cost=10001273676.83..10001348686.83 rows=1000 width=8) (actual time=10853.080..17148.746 rows=1000 loops=1)
   Output: id, count(DISTINCT val)
   Buffers: shared hit=11002
   ->  Sort  (cost=10001273676.83..10001298676.83 rows=10000000 width=8) (actual time=10844.455..12902.849 rows=10000000 loops=1)
         Output: id, val
         Sort Key: test_table.id
         Sort Method: quicksort  Memory: 861967kB
         Buffers: shared hit=11002
         ->  Seq Scan on public.test_table  (cost=0.00..111002.00 rows=10000000 width=8) (actual time=0.037..1258.655 rows=10000000 
loops=1)
               Output: id, val
               Buffers: shared hit=11002
 Total runtime: 17240.958 ms
(12 rows)



下载并安装count distinct插件.

[root@db-172-16-3-221 soft_bak]# cd /opt/soft_bak/
[root@db-172-16-3-221 soft_bak]# git clone https://github.com/tvondra/count_distinct
[root@db-172-16-3-221 soft_bak]# cd count_distinct/
[root@db-172-16-3-221 count_distinct]# export PATH=/opt/pgsql/bin:$PATH
[root@db-172-16-3-221 count_distinct]# which pg_config
/opt/pgsql/bin/pg_config
[root@db-172-16-3-221 count_distinct]# gmake clean
[root@db-172-16-3-221 count_distinct]# gmake && gmake install
[root@db-172-16-3-221 count_distinct]# su - postgres
postgres@db-172-16-3-221-> psql
psql (9.3.5)
Type "help" for help.
digoal=# create extension count_distinct;
CREATE EXTENSION
digoal=# explain (analyze,verbose,buffers) select id,count_distinct(val) from test_table group by 1;
                                                                 QUERY PLAN                                                         
         
------------------------------------------------------------------------------------------------------------------------------------
---------
 GroupAggregate  (cost=1376219.83..1451232.33 rows=1000 width=8) (actual time=18885.591..27492.614 rows=1000 loops=1)
   Output: id, count_distinct(val)
   Buffers: shared hit=11002, temp read=37391 written=37391
   ->  Sort  (cost=1376219.83..1401219.83 rows=10000000 width=8) (actual time=18876.824..21338.226 rows=10000000 loops=1)
         Output: id, val
         Sort Key: test_table.id
         Sort Method: external merge  Disk: 175872kB
         Buffers: shared hit=11002, temp read=37391 written=37391
         ->  Seq Scan on public.test_table  (cost=0.00..111002.00 rows=10000000 width=8) (actual time=0.041..1250.068 rows=10000000 
loops=1)
               Output: id, val
               Buffers: shared hit=11002
 Total runtime: 27550.719 ms
(12 rows)


我们看到, 如果work memory不够的话, 还是会用到排序和分组聚合, 所以时间没有比传统的快.
加大work_mem后, 没有使用排序了, 而是使用了哈希聚合, 数据全命中的情况下, 时间从17秒缩短到了8.8秒

digoal=# set work_mem='2048MB';
SET
digoal=# explain (analyze,verbose,buffers) select id,count_distinct(val) from test_table group by 1;
                                                              QUERY PLAN                                                            
   
------------------------------------------------------------------------------------------------------------------------------------
---
 HashAggregate  (cost=161002.00..161014.50 rows=1000 width=8) (actual time=8570.713..8820.665 rows=1000 loops=1)
   Output: id, count_distinct(val)
   Buffers: shared hit=11002
   ->  Seq Scan on public.test_table  (cost=0.00..111002.00 rows=10000000 width=8) (actual time=0.038..1319.931 rows=10000000 loops=
1)
         Output: id, val
         Buffers: shared hit=11002
 Total runtime: 8822.011 ms
(7 rows)


使用哈希聚合效率比分组聚合要高, 少了排序的过程.

[参考]
1. http://blog.163.com/digoal@126/blog/static/16387704020134222140958/
2. http://blog.163.com/digoal@126/blog/static/16387704020121118112533410/
3. http://www.postgresql.org/docs/9.4/static/xaggr.html
4. http://blog.pgaddict.com/posts/count-distinct-improvements

Flag Counter
