<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">thinking in Dump data from PostgreSQL's table which have few bad blocks</h2>
	<h5 id="">2011-03-22 11:33:00&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/1638770402011222113040830/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;">今天在群里有位兄弟遇到PostgreSQL坏块的表无法读取的问题，版本是8.2的。当涉及到全表扫描是会遇到错误块的提示。<br>以前我在GreenPlum中也遇到过类似问题。当时是使用COPY的方法把可以导出的数据导出。遇到坏块之后的数据都无法导出。<br>今天再来看这个问题，可能还有更好的解决办法：不过已经没有场景可以验证了，以后遇到的时候一定要试一试。<br>参考方法1 ： <br>COPY bad_table to csv<br>参考方法2 : <br>删除坏块的所有记录,可行性不高，因为删除记录是需要改动TUPLE的HEAD的xmax的，而扫描到PAGE都有问题，这样肯定还是不行。<br>参考方法3 :<br>采用指针,跳过出错的块，这样的好处是可以导出更多的正常数据。<br>参考方法4 : <br>来自互连网,<br>Below is the entry quoted from the online manual for 7.3:<br><br>ZERO_DAMAGED_PAGES (boolean)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Detection&nbsp;of&nbsp;a&nbsp;damaged&nbsp;page&nbsp;header&nbsp;normally&nbsp;causes&nbsp;PostgreSQL&nbsp;to<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;report&nbsp;an&nbsp;error,&nbsp;aborting&nbsp;the&nbsp;current&nbsp;transaction.&nbsp;Setting<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;zero_damaged_pages&nbsp;to&nbsp;true&nbsp;causes&nbsp;the&nbsp;system&nbsp;to&nbsp;instead&nbsp;report&nbsp;a<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;warning,&nbsp;zero&nbsp;out&nbsp;the&nbsp;damaged&nbsp;page,&nbsp;and&nbsp;continue&nbsp;processing.<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;behavior&nbsp;will&nbsp;destroy&nbsp;data,&nbsp;namely&nbsp;all&nbsp;the&nbsp;rows&nbsp;on&nbsp;the<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;damaged&nbsp;page.&nbsp;But&nbsp;it&nbsp;allows&nbsp;you&nbsp;to&nbsp;get&nbsp;past&nbsp;the&nbsp;error&nbsp;and<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;retrieve&nbsp;rows&nbsp;from&nbsp;any&nbsp;undamaged&nbsp;pages&nbsp;that&nbsp;may&nbsp;be&nbsp;present&nbsp;in<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;table.&nbsp;So&nbsp;it&nbsp;is&nbsp;useful&nbsp;for&nbsp;recovering&nbsp;data&nbsp;if&nbsp;corruption&nbsp;has<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;occurred&nbsp;due&nbsp;to&nbsp;hardware&nbsp;or&nbsp;software&nbsp;error.&nbsp;You&nbsp;should&nbsp;generally<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;not&nbsp;set&nbsp;this&nbsp;true&nbsp;until&nbsp;you&nbsp;have&nbsp;given&nbsp;up&nbsp;hope&nbsp;of&nbsp;recovering<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data&nbsp;from&nbsp;the&nbsp;damaged&nbsp;page(s)&nbsp;of&nbsp;a&nbsp;table.&nbsp;The&nbsp;default&nbsp;setting&nbsp;is<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;off,&nbsp;and&nbsp;it&nbsp;can&nbsp;only&nbsp;be&nbsp;changed&nbsp;by&nbsp;a&nbsp;superuser.<span><br><br></span>修复过程 : <br>Please note - <br>Note: vacuum is a time-consuming procedure; it may take up to several hours to complete! This procedure requires a lot of system resources and creates a high server load. <br>Be careful: if the server gets down during this process, some data may be lost! <br>We recommend you to backup HS database before you follow the steps below. <br>So, to fix the issue, you should do the following : <br>1. Stop H-Sphere and postgres : <br>Login into CP box under root user and run : <br>Linux : <br># /etc/rc.d/init.d/httpcp stop <br># /etc/rc.d/init.d/postgresql stop <br>FreeBSD : <br># /usr/local/etc/rc.d/apachecp.sh stop <br># /usr/local/etc/rc.d/010.pgsql.sh stop <br>2. Please edit the postgresql.conf ( Linux - ~postgres/data/postgresql.conf , FreeBSD - ~pgsql/data/postgresql.conf ) file and add the following line : zero_damaged_pages=on <br>3. Start postgresql service : <br>Linux : <br># /etc/rc.d/init.d/postgresql start <br>FreeBSD : <br># /usr/local/etc/rc.d/010.pgsql.sh start <br>4. Log into H-Sphere database and run the "vacuum analyze" command. E.g. : <br>[root@cp ~]# su -l cpanel <br>-bash-3.00$ psql hsphere <br>Welcome to psql 7.4.13, the PostgreSQL interactive terminal. <br>Type: <br>\copyright for distribution terms <br>\h for help with SQL commands <br>\? for help on internal slash commands <br>\g or terminate with semicolon to execute query <br>\q to quit <br>hsphere=# vacuum analyze <br>hsphere-# ; WARNING: relation "bill_entry" page 31516 is uninitialized --- fixing VACUUM <br>hsphere=# <br>5. Comment the "zero_damaged_pages=on" line in the postgresql.conf file and restart postgres/H-Sphere.</div>
	</div>
</div>
</body>
</html>