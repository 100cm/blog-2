<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">ZFS snapshot used with PostgreSQL PITR or FAST degrade or PG-XC GreenPlum plproxy MPP DB's consistent backup</h2>
	<h5 id="">2014-05-18 0:11:06&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/163877040201441723450443/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;"><div>上一篇BLOG介绍了一下ZFS的使用, 以及zfs的log和l2arc机制带来的读写性能提升.</div><div>本文将介绍一下ZFS的另一大功能, snapshot和clone. 结合PostgreSQL的PITR来使用, snapshot可以替换基础备份. 从而提高PostgreSQL恢复到过往时间点的速度(就近选择snapshot).</div><div>同时还可以作为&nbsp;PG-XC GreenPlum plproxy 等并行数据库解决方案的全局一致性备份, 对于pg-xc有冻结事务的功能, 所以可以不停库实现一致性备份, 对于greenplum和plproxy, 可以停库后做snapshot, 因为snapshot还是挺快的, 所以停库不需要多长时间. 这些快照可以在数据库起来后随时传输到备份环境, 不影响数据库运行, 当然传输过程会带来这个快照对应的数据块的读操作.</div><div><br></div><div>首先回到上一篇创建的pool的地方.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 ssd4]# /opt/zfs0.6.2/sbin/zpool create zptest /opt/zfs.disk1 /opt/zfs.disk2 /opt/zfs.disk3 /opt/zfs.disk4 log mirror /ssd4/zfs.log1 /ssd4/zfs.log2 cache /dev/disk/by-id/scsi-SATA_OCZ-REVODRIVE3_OCZ-Z2134R0TLQBNE659-part1</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# /opt/zfs0.6.2/sbin/zpool status zptest</font></div><div><font size="2"   >&nbsp; pool: zptest</font></div><div><font size="2"   >&nbsp;state: ONLINE</font></div><div><font size="2"   >&nbsp; scan: none requested</font></div><div><font size="2"   >config:</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; NAME &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;STATE &nbsp; &nbsp; READ WRITE CKSUM</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; zptest &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /opt/zfs.disk1 &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /opt/zfs.disk2 &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /opt/zfs.disk3 &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /opt/zfs.disk4 &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; logs</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mirror-4 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /ssd4/zfs.log1 &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /ssd4/zfs.log2 &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; cache</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sda1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >errors: No known data errors</font></div><p></p></pre></div><div>我们在上一篇是直接使用的pool, 这里要说一下, 在pool中创建dataset.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@db-172-16-3-150 ~]# /opt/zfs0.6.2/sbin/zfs create zptest/dir1</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# /opt/zfs0.6.2/sbin/zfs list</font></div><div><font size="2"   >NAME &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;USED &nbsp;AVAIL &nbsp;REFER &nbsp;MOUNTPOINT</font></div><div><font size="2"   >zptest &nbsp; &nbsp; &nbsp; &nbsp;316K &nbsp;3.81G &nbsp; &nbsp;30K &nbsp;/zptest</font></div><div><font size="2"   >zptest/dir1 &nbsp; &nbsp;30K &nbsp;3.81G &nbsp; &nbsp;30K &nbsp;/zptest/dir1</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# df -h</font></div><div><font size="2"   >zptest/dir1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 3.9G &nbsp; &nbsp; 0 &nbsp;3.9G &nbsp; 0% /zptest/dir1</font></div><p></p></pre></div><div><br></div><div>创建整个pool的snapshot或dataset的snapshot, snapshot格式如下 :&nbsp;</div><div><ul style="color: rgb(34, 34, 34); font-family: verdana, geneva, sans-serif; font-size: 12px; line-height: 18px;"   ><li style="list-style: square;"   ><i>pool/dataset@snapshot-name</i></li><li style="list-style: square;"   ><i>pool@snapshot-name</i></li></ul></div><div>例如, 我这里创建一个dataset的snapshot, 以时间命名.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 ~]# /opt/zfs0.6.2/sbin/zfs snapshot zptest/dir1@`date +%F%T`</font></div><div><span style="line-height: 28px;"   ><font size="2"   >[root@db-172-16-3-150 ~]# /opt/zfs0.6.2/sbin/zfs list -t snapshot</font></span></div><div><font size="2"   >NAME &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; USED &nbsp;AVAIL &nbsp;REFER &nbsp;MOUNTPOINT</font></div><div><font size="2"   >zptest/dir1@2014-05-1716:09:20 &nbsp; &nbsp; &nbsp;0 &nbsp; &nbsp; &nbsp;- &nbsp; &nbsp;30K &nbsp;-</font></div><p></p></pre></div><div>创建一个pool的snapshot.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 ~]# /opt/zfs0.6.2/sbin/zfs snapshot zptest@`date +%F%T`</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# /opt/zfs0.6.2/sbin/zfs list -t snapshot</font></div><div><font size="2"   >NAME &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; USED &nbsp;AVAIL &nbsp;REFER &nbsp;MOUNTPOINT</font></div><div><font size="2"   >zptest@2014-05-1716:12:49 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; &nbsp;- &nbsp; &nbsp;30K &nbsp;-</font></div><div><font size="2"   >zptest/dir1@2014-05-1716:09:20 &nbsp; &nbsp; &nbsp;0 &nbsp; &nbsp; &nbsp;- &nbsp; &nbsp;30K &nbsp;-</font></div><p></p></pre></div><div>删除snapshot.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 ~]# /opt/zfs0.6.2/sbin/zfs destroy zptest@2014-05-1716:12:49</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# /opt/zfs0.6.2/sbin/zfs destroy zptest/dir1@2014-05-1716:09:20</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# /opt/zfs0.6.2/sbin/zfs list -t snapshot</font></div><div><font size="2"   >no datasets available</font></div><p></p></pre></div><div>回滚到指定的snapshot.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@db-172-16-3-150 ~]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/sdc1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;29G &nbsp;9.3G &nbsp; 19G &nbsp;34% /</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;48G &nbsp; &nbsp; 0 &nbsp; 48G &nbsp; 0% /dev/shm</font></div><div><font size="2"   >/dev/sdc3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;98G &nbsp; 34G &nbsp; 59G &nbsp;37% /opt</font></div><div><font size="2"   >/dev/sdd1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 183G &nbsp; 33G &nbsp;142G &nbsp;19% /ssd1</font></div><div><font size="2"   >/dev/sdb1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 221G &nbsp; 43G &nbsp;167G &nbsp;21% /ssd4</font></div><div><font size="2"   >/ssd4/test.img &nbsp; &nbsp; &nbsp; 1008M &nbsp;207M &nbsp;751M &nbsp;22% /mnt</font></div><div><font size="2"   >zptest/dir1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 3.9G &nbsp; &nbsp; 0 &nbsp;3.9G &nbsp; 0% /zptest/dir1</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# cd /zptest/dir1/</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1]# ll</font></div><div><font size="2"   >total 0</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1]# dd if=/dev/zero of=./1 bs=1k count=1024</font></div></div><div><div><font size="2"   >1024+0 records in</font></div><div><font size="2"   >1024+0 records out</font></div><div><font size="2"   >1048576 bytes (1.0 MB) copied, 0.0228468 s, 45.9 MB/s</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1]# /opt/zfs0.6.2/sbin/zfs snapshot zptest/dir1@`date +%F%T`</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1]# dd if=/dev/zero of=./2 bs=1k count=1024</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1]# /opt/zfs0.6.2/sbin/zfs snapshot zptest/dir1@`date +%F%T`</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1]# dd if=/dev/zero of=./3 bs=1k count=1024</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1]# /opt/zfs0.6.2/sbin/zfs snapshot zptest/dir1@`date +%F%T`</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1]# dd if=/dev/zero of=./4 bs=1k count=1024</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1]# /opt/zfs0.6.2/sbin/zfs snapshot zptest/dir1@`date +%F%T`</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1]# rm -f *</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1]# ll</font></div><div><font size="2"   >total 0</font></div></div><div><div><font size="2"   >[root@db-172-16-3-150 dir1]# /opt/zfs0.6.2/sbin/zfs list -t snapshot</font></div><div><font size="2"   >NAME &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; USED &nbsp;AVAIL &nbsp;REFER &nbsp;MOUNTPOINT</font></div><div><font size="2"   >zptest/dir1@2014-05-1716:23:12 &nbsp; &nbsp;19K &nbsp; &nbsp; &nbsp;- &nbsp;1.03M &nbsp;-</font></div><div><font size="2"   >zptest/dir1@2014-05-1716:23:19 &nbsp; &nbsp;19K &nbsp; &nbsp; &nbsp;- &nbsp;2.03M &nbsp;-</font></div><div><font size="2"   >zptest/dir1@2014-05-1716:23:25 &nbsp; &nbsp;19K &nbsp; &nbsp; &nbsp;- &nbsp;3.04M &nbsp;-</font></div><div><font size="2"   >zptest/dir1@2014-05-1716:23:30 &nbsp;1.02M &nbsp; &nbsp; &nbsp;- &nbsp;4.04M &nbsp;-</font></div></div><p></p></pre></div><div>回滚前必须卸载对应的dataset或zpool, 并且只能回滚到最近的一个snapshot, 或者说, 要回滚到过去的snapshot, 必须删掉这个snapshot和当前之间的所有snapshot.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 ~]# /opt/zfs0.6.2/sbin/zfs umount zptest/dir1</font></div><div><div><font size="2"   >[root@db-172-16-3-150 ~]# /opt/zfs0.6.2/sbin/zfs rollback zptest/dir1@2014-05-1716:23:25</font></div><div><font size="2"   >cannot rollback to 'zptest/dir1@2014-05-1716:23:25': more recent snapshots exist</font></div><div><font size="2"   >use '-r' to force deletion of the following snapshots:</font></div><div><font size="2"   >zptest/dir1@2014-05-1716:23:30</font></div></div><p></p></pre></div><div>这里提示删除1个snapshot, 因为这个snapshot是在回滚点后面创建的.</div><div>使用-r自动删除.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 ~]# /opt/zfs0.6.2/sbin/zfs rollback -r zptest/dir1@2014-05-1716:23:25</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# /opt/zfs0.6.2/sbin/zfs mount zptest/dir1</font></div><div><div><font size="2"   >[root@db-172-16-3-150 ~]# cd /zptest/dir1</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1]# ll</font></div><div><font size="2"   >total 3080</font></div><div><font size="2"   >-rw-r--r-- 1 root root 1048576 May 17 16:22 1</font></div><div><font size="2"   >-rw-r--r-- 1 root root 1048576 May 17 16:23 2</font></div><div><font size="2"   >-rw-r--r-- 1 root root 1048576 May 17 16:23 3</font></div></div><p></p></pre></div><div>已经回到这个snapshot了.&nbsp;</div><div>接下来要说的是clone, 因为snapshot一旦回滚后将丢失回滚点后面的所有文件系统的变更. 但是如果只想先看看这个snapshot是不是想要的, 那么可使用clone将一个snapshot克隆出来, 进行读写操作. 不是的话删掉clone即可.</div><div>克隆必须在当前pool, 不能把克隆的集合放到其他pool里面. 例如我只创建了zptest这个pool, 可以把克隆后的目标放到同一个pool里面也就是zptest, 但是不能放到其他的pool, 例如zpool1.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 dir1]# /opt/zfs0.6.2/sbin/zfs list -t snapshot</font></div><div><font size="2"   >NAME &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; USED &nbsp;AVAIL &nbsp;REFER &nbsp;MOUNTPOINT</font></div><div><font size="2"   >zptest/dir1@2014-05-1716:23:12 &nbsp; &nbsp;19K &nbsp; &nbsp; &nbsp;- &nbsp;1.03M &nbsp;-</font></div><div><font size="2"   >zptest/dir1@2014-05-1716:23:19 &nbsp; &nbsp;19K &nbsp; &nbsp; &nbsp;- &nbsp;2.03M &nbsp;-</font></div><div><font size="2"   >zptest/dir1@2014-05-1716:23:25 &nbsp; &nbsp;18K &nbsp; &nbsp; &nbsp;- &nbsp;3.04M &nbsp;-</font></div><p></p></pre></div><div>克隆必须基于snapshot, 不能直接克隆dataset. 克隆后, 相当于新建了一个dataset.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@db-172-16-3-150 dir1]# /opt/zfs0.6.2/sbin/zfs clone zptest/dir1 zptest/dir1_c1</font></div><div><font size="2"   >cannot open 'zptest/dir1': operation not applicable to datasets of this type</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1]# /opt/zfs0.6.2/sbin/zfs clone zptest/dir1@2014-05-1716:23:12 zptest/dir1_c1</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1]# df -h</font></div><div><font size="2"   >zptest/dir1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 3.9G &nbsp;3.0M &nbsp;3.9G &nbsp; 1% /zptest/dir1</font></div><div><font size="2"   >zptest/dir1_c1 &nbsp; &nbsp; &nbsp; &nbsp;3.9G &nbsp;1.0M &nbsp;3.9G &nbsp; 1% /zptest/dir1_c1</font></div></div><div><div><font size="2"   >[root@db-172-16-3-150 dir1_c1]# /opt/zfs0.6.2/sbin/zfs list</font></div><div><font size="2"   >NAME &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; USED &nbsp;AVAIL &nbsp;REFER &nbsp;MOUNTPOINT</font></div><div><font size="2"   >zptest &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3.56M &nbsp;3.81G &nbsp; &nbsp;30K &nbsp;/zptest</font></div><div><font size="2"   >zptest/dir1 &nbsp; &nbsp; 3.09M &nbsp;3.81G &nbsp;3.04M &nbsp;/zptest/dir1</font></div><div><font size="2"   >zptest/dir1_c1 &nbsp; &nbsp;18K &nbsp;3.81G &nbsp;1.03M &nbsp;/zptest/dir1_c1</font></div></div><div><div><font size="2"   >[root@db-172-16-3-150 zptest]# cd /zptest/dir1_c1</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1_c1]# ll</font></div><div><font size="2"   >total 1027</font></div><div><font size="2"   >-rw-r--r-- 1 root root 1048576 May 17 16:22 1</font></div></div><p></p></pre></div><div>你可以对这个clone出来的dataset进行读写.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 dir1_c1]# cd /zptest/dir1_c1</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1_c1]# cp 1 2</font></div><div><font size="2"   >[root@db-172-16-3-150 dir1_c1]# ll</font></div><div><font size="2"   >total 2053</font></div><div><font size="2"   >-rw-r--r-- 1 root root 1048576 May 17 16:22 1</font></div><div><font size="2"   >-rw-r--r-- 1 root root 1048576 May 17 16:57 2</font></div><p></p></pre></div><div><br></div><div>结合PostgreSQL的PITR来使用, 例如把$PGDATA放在dataset中, 对$PGDATA做基础备份可以通过对这个dataset做snapshot来达到目的, 但是建议在standby上这么做, 因为cow也是会带来额外的开销并且容易带来碎片的.</div><div>另外一个建议在standby上做snapshot的原因是standby上的shared buffer中没有影响数据一致性的脏数据. 所以不需要执行pg_start_backup()直接创建snapshot即可, 如果在主库创建snapshot的话, 创建sanpshot前必须先执行pg_start_backup(), 在创建完snapshot后再执行pg_stop_backup().</div><div>在standby上同时还需要使用archive_command将xlog归档, 这样的话在使用snapshot做PITR时可以用上需要的xlog.</div><div>接下来我将演示一下使用场景.</div><div><div><div><img title="ZFS snapshot used with PostgreSQL PITR - 德哥@Digoal - PostgreSQL"   alt="ZFS snapshot used with PostgreSQL PITR - 德哥@Digoal - PostgreSQL"   style="margin:0 10px 0 0;"   src="http://img0.ph.126.net/BEVSJIQYE3Iwb0rTdCO2wQ==/6608764172329062474.png"   ></div>使用这种方法终于让PG可以和ORACLE一样有基于块增量备份了.&nbsp;</div><div><br></div>注意, 使用clonerecovery时, 需要注意修改对应的archive command, 不要覆盖原有的wal.&nbsp;</div><div><div style="line-height: 28px;"   >在普通目录初始化主库</div><div style="line-height: 28px;"   ><pre class="prettyprint"   ><p></p><div style="line-height: 28px;"   ><font size="2"   >pg93@db-172-16-3-150-&gt; initdb -D /ssd4/pg93/pg_root -E UTF8 --locale=C -U postgres -W</font></div><div style="line-height: 28px;"   ><font size="2"   >pg93@db-172-16-3-150-&gt; cd /ssd4/pg93/pg_root</font></div><div style="line-height: 28px;"   ><font size="2"   >pg93@db-172-16-3-150-&gt; cp /home/pg93/pgsql/share/recovery.conf.sample ./</font></div><div style="line-height: 28px;"   ><font size="2"   >pg93@db-172-16-3-150-&gt; mv recovery.conf.sample recovery.done</font></div><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; vi pg_hba.conf</font></div><div><font size="2"   >host all all 0.0.0.0/0 md5</font></div><div><font size="2"   >host replication postgres 127.0.0.1/32 trust</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; vi postgresql.conf</font></div><div><font size="2"   >listen_addresses = '0.0.0.0' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# what IP address(es) to listen on;</font></div><div><font size="2"   >port = 1921 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # (change requires restart)</font></div><div><font size="2"   >max_connections = 100 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # (change requires restart)</font></div><div><font size="2"   >superuser_reserved_connections = 13 &nbsp; &nbsp; # (change requires restart)</font></div><div><font size="2"   >unix_socket_directories = '.' &nbsp; # comma-separated list of directories</font></div><div><font size="2"   >tcp_keepalives_idle = 60 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# TCP_KEEPIDLE, in seconds;</font></div><div><font size="2"   >tcp_keepalives_interval = 10 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# TCP_KEEPINTVL, in seconds;</font></div><div><font size="2"   >tcp_keepalives_count = 10 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # TCP_KEEPCNT;</font></div><div><font size="2"   >shared_buffers = 1024MB &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # min 128kB</font></div><div><font size="2"   >maintenance_work_mem = 512MB &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# min 1MB</font></div><div><font size="2"   >vacuum_cost_delay = 10 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 0-100 milliseconds</font></div><div><font size="2"   >vacuum_cost_limit = 10000 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # 1-10000 credits</font></div><div><font size="2"   >bgwriter_delay = 10ms &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # 10-10000ms between rounds</font></div><div><font size="2"   >wal_level = hot_standby &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # minimal, archive, or hot_standby</font></div><div><font size="2"   >synchronous_commit = off &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# synchronization level;</font></div><div><font size="2"   >wal_writer_delay = 10ms &nbsp; &nbsp; &nbsp; &nbsp; # 1-10000 milliseconds</font></div><div><font size="2"   >checkpoint_segments = 64 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# in logfile segments, min 1, 16MB each</font></div><div><font size="2"   >archive_mode = on &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # allows archiving to be done</font></div><div><font size="2"   >archive_command = '/usr/bin/test ! -f /ssd1/pg93/arch/%f &amp;&amp; /bin/cp %p /ssd1/pg93/arch/%f'</font></div><div><font size="2"   >max_wal_senders = 32 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# max number of walsender processes</font></div><div><font size="2"   >wal_keep_segments = 128 &nbsp; &nbsp; &nbsp; &nbsp; # in logfile segments, 16MB each; 0 disables</font></div><div><font size="2"   >hot_standby = on &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# "on" allows queries during recovery</font></div><div><font size="2"   >max_standby_archive_delay = 300s &nbsp; &nbsp; &nbsp; &nbsp;# max delay before canceling queries</font></div><div><font size="2"   >max_standby_streaming_delay = 300s &nbsp; &nbsp; &nbsp;# max delay before canceling queries</font></div><div><font size="2"   >wal_receiver_status_interval = 1s &nbsp; &nbsp; &nbsp; # send replies at least this often</font></div><div><font size="2"   >hot_standby_feedback = on &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # send info from standby to prevent</font></div><div><font size="2"   >effective_cache_size = 96000MB</font></div><div><font size="2"   >log_destination = 'csvlog' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Valid values are combinations of</font></div><div><font size="2"   >logging_collector = on &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Enable capturing of stderr and csvlog</font></div><div><font size="2"   >log_truncate_on_rotation = on &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # If on, an existing log file with the</font></div><div><font size="2"   >log_checkpoints = on</font></div><div><font size="2"   >log_connections = on</font></div><div><font size="2"   >log_disconnections = on</font></div><div><font size="2"   >log_error_verbosity = verbose &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # terse, default, or verbose messages</font></div><div><font size="2"   >log_statement = 'ddl' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # none, ddl, mod, all</font></div><div><font size="2"   >log_timezone = 'PRC'</font></div><div><font size="2"   >log_autovacuum_min_duration = 0 # -1 disables, 0 logs all actions and</font></div><div><font size="2"   >datestyle = 'iso, mdy'</font></div><div><font size="2"   >timezone = 'PRC'</font></div><div><font size="2"   >lc_messages = 'C' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # locale for system error message</font></div><div><font size="2"   >lc_monetary = 'C' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # locale for monetary formatting</font></div><div><font size="2"   >lc_numeric = 'C' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# locale for number formatting</font></div><div><font size="2"   >lc_time = 'C' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # locale for time formatting</font></div><div><font size="2"   >default_text_search_config = 'pg_catalog.english'</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; vi recovery.done</font></div><div><font size="2"   >recovery_target_timeline = 'latest'</font></div><div><font size="2"   >standby_mode = on</font></div><div><font size="2"   >primary_conninfo = 'host=127.0.0.1 port=1922 user=postgres keepalives_idle=60'</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pg_ctl start -D /ssd4/pg93/pg_root</font></div></div><p></p></pre></div><div style="line-height: 28px;"   ><br></div><div style="line-height: 28px;"   >创建归档目录</div><div style="line-height: 28px;"   ><pre class="prettyprint"   ><p></p><div style="line-height: 28px;"   ><font size="2"   >[root@db-172-16-3-150 pg93]# mkdir -p /ssd1/pg93/arch</font></div><div style="line-height: 28px;"   ><font size="2"   >[root@db-172-16-3-150 pg93]# chown pg93:pg93 /ssd1/pg93/arch</font></div><p></p></pre></div></div><div style="line-height: 28px;"   ><br></div><div>创建zpool, dataset. 准备给standby使用.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@db-172-16-3-150 ssd1]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/sdc1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;29G &nbsp;9.3G &nbsp; 19G &nbsp;34% /</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;48G &nbsp; &nbsp; 0 &nbsp; 48G &nbsp; 0% /dev/shm</font></div><div><font size="2"   >/dev/sdc3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;98G &nbsp; 30G &nbsp; 63G &nbsp;33% /opt</font></div><div><font size="2"   >/dev/sdd1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 183G &nbsp;5.4G &nbsp;169G &nbsp; 4% /ssd1</font></div><div><font size="2"   >/dev/sdb1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 221G &nbsp; 42G &nbsp;168G &nbsp;20% /ssd4</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@db-172-16-3-150 ssd1]# cd /ssd1</font></div><div><font size="2"   >[root@db-172-16-3-150 ssd1]# dd if=/dev/zero of=./zfs.disk1 bs=1024k count=8192&nbsp;</font></div><div><font size="2"   >8192+0 records in</font></div><div><font size="2"   >8192+0 records out</font></div><div><font size="2"   >8589934592 bytes (8.6 GB) copied, 10.1841 s, 843 MB/s</font></div><div><font size="2"   >[root@db-172-16-3-150 ssd1]# cp zfs.disk1 zfs.disk2</font></div><div><font size="2"   >[root@db-172-16-3-150 ssd1]# cp zfs.disk1 zfs.disk3</font></div><div><font size="2"   >[root@db-172-16-3-150 ssd1]# cp zfs.disk1 zfs.disk4</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@db-172-16-3-150 ssd1]# cd /ssd4</font></div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# dd if=/dev/zero of=./zfs.log1 bs=1024k count=8192</font></div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# cp zfs.log1 zfs.log2</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# ll /dev/disk/by-id/|grep sda</font></div><div><font size="2"   >lrwxrwxrwx 1 root root &nbsp;9 May 16 21:48 ata-OCZ-REVODRIVE3_OCZ-Z2134R0TLQBNE659 -&gt; ../../sda</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 May 16 21:48 ata-OCZ-REVODRIVE3_OCZ-Z2134R0TLQBNE659-part1 -&gt; ../../sda1</font></div><div><font size="2"   >lrwxrwxrwx 1 root root &nbsp;9 May 16 21:48 scsi-SATA_OCZ-REVODRIVE3_OCZ-Z2134R0TLQBNE659 -&gt; ../../sda</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 May 16 21:48 scsi-SATA_OCZ-REVODRIVE3_OCZ-Z2134R0TLQBNE659-part1 -&gt; ../../sda1</font></div><div><font size="2"   >lrwxrwxrwx 1 root root &nbsp;9 May 16 21:48 wwn-0x5e83a97e827c316e -&gt; ../../sda</font></div><div><font size="2"   >lrwxrwxrwx 1 root root 10 May 16 21:48 wwn-0x5e83a97e827c316e-part1 -&gt; ../../sda1</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# zpool create zptest /ssd1/zfs.disk1 /ssd1/zfs.disk2 /ssd1/zfs.disk3 /ssd1/zfs.disk4 log mirror /ssd4/zfs.log1 /ssd4/zfs.log2 cache /dev/disk/by-id/wwn-0x5e83a97e827c316e-part1</font></div><div><font size="2"   ><br></font></div></div><div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# zfs create zptest/pg93</font></div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/sdc1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;29G &nbsp;9.3G &nbsp; 19G &nbsp;34% /</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;48G &nbsp; &nbsp; 0 &nbsp; 48G &nbsp; 0% /dev/shm</font></div><div><font size="2"   >/dev/sdc3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;98G &nbsp; 30G &nbsp; 63G &nbsp;33% /opt</font></div><div><font size="2"   >/dev/sdd1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 183G &nbsp; 38G &nbsp;137G &nbsp;22% /ssd1</font></div><div><font size="2"   >/dev/sdb1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 221G &nbsp; 56G &nbsp;154G &nbsp;27% /ssd4</font></div><div><font size="2"   >zptest &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 32G &nbsp;128K &nbsp; 32G &nbsp; 1% /zptest</font></div><div><font size="2"   >zptest/pg93 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;32G &nbsp;128K &nbsp; 32G &nbsp; 1% /zptest/pg93</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@db-172-16-3-150 ssd4]# chown -R pg93:pg93 /zptest/pg93</font></div></div><p></p></pre></div><div><br></div><div>在dataset中创建备库, 配置归档.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; psql -h 127.0.0.1 -p 1921 -U postgres postgres</font></div><div><font size="2"   >psql (9.3.3)</font></div><div><font size="2"   >Type "help" for help.</font></div><div><font size="2"   >postgres=# select pg_start_backup(now()::text);</font></div><div><font size="2"   >&nbsp;pg_start_backup&nbsp;</font></div><div><font size="2"   >-----------------</font></div><div><font size="2"   >&nbsp;0/2000028</font></div><div><font size="2"   >(1 row)</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >postgres=# \q</font></div><div><font size="2"   >&nbsp;&nbsp;</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; cp -r /ssd4/pg93/pg_root /zptest/pg93/</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; psql -h 127.0.0.1 -p 1921 -U postgres postgres</font></div><div><font size="2"   >psql (9.3.3)</font></div><div><font size="2"   >Type "help" for help.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >postgres=# select pg_stop_backup();</font></div><div><font size="2"   >NOTICE: &nbsp;pg_stop_backup complete, all required WAL segments have been archived</font></div><div><font size="2"   >&nbsp;pg_stop_backup&nbsp;</font></div><div><font size="2"   >----------------</font></div><div><font size="2"   >&nbsp;0/20000F0</font></div><div><font size="2"   >(1 row)</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; cd /zptest/pg93/pg_root/</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; vi postgresql.conf&nbsp;</font></div><div><font size="2"   >port = 1922</font></div><div><font size="2"   ># archive_command = '/usr/bin/test ! -f /ssd1/pg93/arch/%f &amp;&amp; /bin/cp %p /ssd1/pg93/arch/%f' &nbsp;# 不注释也没有关系, standby不会触发archive主进程</font></div></div><p></p></pre></div><div><div>原因如下, 只有数据库是RUN状态时才能触发pgarch_start() , 或者加上PM_HOT_STANDBY, PM_RECOVERY状态, 那么在hot<span style="line-height: 21px; font-size: small;"   >standby中也可以执行归档:&nbsp;</span></div><pre class="prettyprint"   ><p></p><div><font size="2"   >src/backend/postmaster/postmaster.c</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* If we have lost the archiver, try to start a new one */</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (XLogArchivingActive() &amp;&amp; PgArchPID == 0 &amp;&amp; pmState == PM_RUN)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PgArchPID = pgarch_start();</font></div><p></p></pre><div>数据库的几种状态 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >typedef enum</font></div><div><font size="2"   >{</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; PM_INIT, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/* postmaster starting */</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; PM_STARTUP, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* waiting for startup subprocess */</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; PM_RECOVERY, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/* in archive recovery mode */</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; PM_HOT_STANDBY, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* in hot standby mode */</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; PM_RUN, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* normal "database is alive" state */</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; PM_WAIT_BACKUP, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* waiting for online backup mode to end */</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; PM_WAIT_READONLY, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* waiting for read only backends to exit */</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; PM_WAIT_BACKENDS, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* waiting for live backends to exit */</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; PM_SHUTDOWN, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/* waiting for checkpointer to do shutdown</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* ckpt */</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; PM_SHUTDOWN_2, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/* waiting for archiver and walsenders to</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* finish */</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; PM_WAIT_DEAD_END, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* waiting for dead_end children to exit */</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; PM_NO_CHILDREN &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/* all important children have exited */</font></div><div><font size="2"   >} PMState;</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ><br></font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; mv recovery.done recovery.conf</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; vi recovery.conf</font></div><div><font size="2"   >primary_conninfo = 'host=127.0.0.1 port=1921 user=postgres keepalives_idle=60'</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; rm -f postmaster.pid</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pg_ctl start -D /zptest/pg93/pg_root</font></div><p></p></pre></div></div><div><br></div><div>使用pgbench给主库施加读写测试</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; psql -h 127.0.0.1 -p 1921 -U postgres postgres</font></div><div><font size="2"   >psql (9.3.3)</font></div><div><font size="2"   >Type "help" for help.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >postgres=# create table test(id int primary key, info text, crt_time timestamp);</font></div><div><font size="2"   >CREATE TABLE</font></div><div><font size="2"   >postgres=# create or replace function f_test(v_id int) returns void as $$</font></div><div><font size="2"   >declare</font></div><div><font size="2"   >begin</font></div><div><font size="2"   >&nbsp; update test set info=md5(random()::text),crt_time=now() where id=v_id;</font></div><div><font size="2"   >&nbsp; if not found then&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; insert into test values (v_id, md5(random()::text), now());</font></div><div><font size="2"   >&nbsp; end if;</font></div><div><font size="2"   >&nbsp; exception when SQLSTATE '23505' then</font></div><div><font size="2"   >&nbsp; &nbsp; return;</font></div><div><font size="2"   >end;</font></div><div><font size="2"   >$$ language plpgsql strict;</font></div><div><font size="2"   >CREATE FUNCTION</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; cd ~</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; vi test.sql</font></div><div><font size="2"   >\setrandom id 1 500000</font></div><div><font size="2"   >select f_test(:id);</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pgbench -M prepared -n -r -f ./test.sql -h 127.0.0.1 -p 1921 -U postgres -c 16 -j 8 -T 3000 postgres</font></div><p></p></pre></div><div><br></div><div>周期性的创建snapshot, snapshot并不会占用太多空间, 而且一个pool可以有2^64个snapshot, 足够用了, 所以可以多建立一些,</div><div>例如每半个小时创建一个. (根据情况而定)</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># zfs snapshot zptest/pg93@`date +%F%T`</font></div><div></div><p></p></pre></div><div>查看snapshot空间占用情况.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 ~]# zfs list -t snapshot</font></div><div><font size="2"   >NAME &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; USED &nbsp;AVAIL &nbsp;REFER &nbsp;MOUNTPOINT</font></div><div><font size="2"   >zptest/pg93@2014-05-1721:54:55 &nbsp; 143M &nbsp; &nbsp; &nbsp;- &nbsp; 185M &nbsp;-</font></div><div><font size="2"   >zptest/pg93@2014-05-1723:17:23 &nbsp;99.0M &nbsp; &nbsp; &nbsp;- &nbsp;3.65G &nbsp;-</font></div><div><font size="2"   >zptest/pg93@2014-05-1723:18:11 &nbsp;5.10M &nbsp; &nbsp; &nbsp;- &nbsp;3.65G &nbsp;-</font></div><div><font size="2"   >zptest/pg93@2014-05-1723:35:32 &nbsp; 214M &nbsp; &nbsp; &nbsp;- &nbsp;3.65G &nbsp;-</font></div><p></p></pre></div><div><br></div><div>使用snapshot创建克隆, 并结合PostgreSQL PITR, 将数据库恢复到一个指定的状态.</div><div>例如使用倒数第二个snapshot来克隆.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-172-16-3-150 ~]# zfs clone zptest/pg93@2014-05-1723:18:11 zptest/pg93_clone1</font></div><div><div><font size="2"   >[root@db-172-16-3-150 ~]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/sdc1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;29G &nbsp;9.3G &nbsp; 19G &nbsp;34% /</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;48G &nbsp; &nbsp; 0 &nbsp; 48G &nbsp; 0% /dev/shm</font></div><div><font size="2"   >/dev/sdc3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;98G &nbsp; 30G &nbsp; 63G &nbsp;33% /opt</font></div><div><font size="2"   >/dev/sdd1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 183G &nbsp; 41G &nbsp;133G &nbsp;24% /ssd1</font></div><div><font size="2"   >/dev/sdb1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 221G &nbsp; 39G &nbsp;171G &nbsp;19% /ssd4</font></div><div><font size="2"   >zptest &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 24G &nbsp;128K &nbsp; 24G &nbsp; 1% /zptest</font></div><div><font size="2"   >zptest/pg93 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;28G &nbsp;3.7G &nbsp; 24G &nbsp;14% /zptest/pg93</font></div><div><font size="2"   >zptest/pg93_clone1 &nbsp; &nbsp; 28G &nbsp;3.7G &nbsp; 24G &nbsp;14% /zptest/pg93_clone1</font></div></div><p></p></pre></div><div>修改必要的配置文件</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@db-172-16-3-150 ~]# su - pg93</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; cd /zptest/pg93_clone1/pg_root</font></div></div><div><font size="2"   >port = 1923</font></div><div><font size="2"   ># archive_command &nbsp;#注释</font></div><p></p></pre></div><div>选择一个合适的还原点, 以时间为还原点最好确认 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><span style="line-height: 28px;"   ><font size="2"   >pg93@db-172-16-3-150-&gt; vi recovery.conf</font></span></div><div><div><font size="2"   >restore_command = 'cp /ssd1/pg93/arch/%f %p' &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# e.g. 'cp /mnt/server/archivedir/%f %p'</font></div><div><font size="2"   >recovery_target_time = '2014-05-17 23:19:00.203219+08'</font></div><div><font size="2"   >recovery_target_timeline = 'latest'</font></div><div><font size="2"   >pause_at_recovery_target = true</font></div><div><font size="2"   >standby_mode = on</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; rm -f postmaster.pid</font></div></div><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; pg_ctl start -D /zptest/pg93_clone1/pg_root</font></div><div><font size="2"   >server starting</font></div><div><font size="2"   >pg93@db-172-16-3-150-&gt; LOG: &nbsp;00000: redirecting log output to logging collector process</font></div><div><font size="2"   >HINT: &nbsp;Future log output will appear in directory "pg_log".</font></div><div><font size="2"   >LOCATION: &nbsp;SysLogger_Start, syslogger.c:649</font></div></div><p></p></pre></div><div><br></div><div>一段时间后查看是否恢复到指定时间点.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >pg93@db-172-16-3-150-&gt; psql -h 127.0.0.1 -p 1923 -U postgres postgres</font></div><div><font size="2"   >psql (9.3.3)</font></div><div><font size="2"   >Type "help" for help.</font></div></div><div><div><font size="2"   >postgres=# select max(crt_time) from test;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; max &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</font></div><div><font size="2"   >---------------------------</font></div><div><font size="2"   >&nbsp;2014-05-17 23:19:00.20281</font></div><div><font size="2"   >(1 row)</font></div></div><p></p></pre></div><div><br></div><div>如果觉得这个快照不合适, 可以关闭数据库后删掉它.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >pg93@db-172-16-3-150-&gt; pg_ctl stop -m fast -D /zptest/pg93_clone1/pg_root</font></div><div><font size="2"   >[root@db-172-16-3-150 ~]# zfs destroy zptest/pg93_clone1</font></div><p></p></pre></div><div><br></div><div>最后说一下zpool的扩容, 增加磁盘即可. 最好选择和POOL中已存在磁盘容量大小, 性能一致的磁盘.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@db-172-16-3-150 ssd1]# cd /ssd1</font></div><div><font size="2"   >[root@db-172-16-3-150 ssd1]# dd if=/dev/zero of=./zfs.disk5 bs=1024k count=8192</font></div></div><div><div><font size="2"   >[root@db-172-16-3-150 ssd1]# zpool add zptest /ssd1/zfs.disk5</font></div><div><font size="2"   >[root@db-172-16-3-150 ssd1]# zpool status zptest</font></div><div><font size="2"   >&nbsp; pool: zptest</font></div><div><font size="2"   >&nbsp;state: ONLINE</font></div><div><font size="2"   >&nbsp; scan: none requested</font></div><div><font size="2"   >config:</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; NAME &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;STATE &nbsp; &nbsp; READ WRITE CKSUM</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; zptest &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /ssd1/zfs.disk1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /ssd1/zfs.disk2 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /ssd1/zfs.disk3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /ssd1/zfs.disk4 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /ssd1/zfs.disk5 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; logs</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mirror-4 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /ssd4/zfs.log1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /ssd4/zfs.log2 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; cache</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; wwn-0x5e83a97e827c316e-part1 &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >errors: No known data errors</font></div></div><div><div><font size="2"   >[root@db-172-16-3-150 ssd1]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/sdc1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;29G &nbsp;9.3G &nbsp; 19G &nbsp;34% /</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;48G &nbsp; &nbsp; 0 &nbsp; 48G &nbsp; 0% /dev/shm</font></div><div><font size="2"   >/dev/sdc3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;98G &nbsp; 30G &nbsp; 63G &nbsp;33% /opt</font></div><div><font size="2"   >/dev/sdd1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 183G &nbsp; 53G &nbsp;122G &nbsp;30% /ssd1</font></div><div><font size="2"   >/dev/sdb1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 221G &nbsp; 39G &nbsp;171G &nbsp;19% /ssd4</font></div><div><font size="2"   >zptest &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 29G &nbsp;128K &nbsp; 29G &nbsp; 1% /zptest</font></div><div><font size="2"   >zptest/pg93 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;33G &nbsp;3.7G &nbsp; 29G &nbsp;12% /zptest/pg93</font></div><div><font size="2"   >zptest/pg93_clone1 &nbsp; &nbsp; 33G &nbsp;3.7G &nbsp; 29G &nbsp;12% /zptest/pg93_clone1</font></div></div><p></p></pre></div><div>[其他]</div><div>1. 其实zfs的快照在数据库版本升级, 做重大调整时用作快速回滚也是很有用的. 例如greenplum的版本升级, 可以在停库后对所有节点的dataset创建快照, 再升级, 如果升级失败, 全部回滚到快照即可.</div><div><br></div>[参考]<wbr><div>1.&nbsp;<a style="line-height: 28px;" target="_blank" href="http://blog.163.com/digoal@126/blog/static/163877040201441694022110/"   >http://blog.163.com/digoal@126/blog/static/163877040201441694022110/</a></div>
<a rel="nofollow" href="http://info.flagcounter.com/h9V1"   ><img title="ZFS snapshot used with PostgreSQL PITR - 德哥@Digoal - PostgreSQL"   src="http://s03.flagcounter.com/count/h9V1/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_12/viewers_0/labels_0/pageviews_0/flags_0/"   alt="Flag Counter"   border="0"   ></a></div>
	</div>
	<h3>评论</h3>
	<div class="" id="" style="padding:0 20px;">
			<div id="">
				<h5 id="">xmarker - 2014-05-19 17:07:44</h5>
				<div>用zfs做数据库增量备份功能确实挺好的，另外每个snapshot的大小是增量的吧，如果原来的基础数据是100g，每个snapshot是在100g的基础上增量的对吧，如果基础数据的那个zfs pool磁盘坏掉了是不是snapshot也就不能用了？</div>
			</div>
			<div style="padding-left:40px;">
				<h5 id="">德哥@Digoal 回复 xmarker - 2014-05-19 17:07:44</h5>
				<div style="width:600px;">是增量的. 所以snapshot很小.<div>pool的磁盘坏掉了, snapshot也就没有了, 所以建议使用raid.</div><div>如果底层硬件没有RAID那么可以创建raidz pool, 来确保冗余.</div></div>
			</div>
	</div>
</div>
</body>
</html>