<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">CentOS 7 lvm cache dev VS zfs VS flashcache VS bcache VS direct SSD</h2>
	<h5 id="">2014-07-09 14:33:49&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/163877040201469111426772/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;"><div>本文测试结果仅供参考, rhel 7.0的lvm cache也只是一个预览性质的特性, 从测试结果来看, 用在生产环境也尚早.</div><div><br></div><div>前段时间对比了Linux下ZFS和FreeBSD下ZFS的性能, 在fsync接口上存在较大的性能差异, 这个问题已经提交给zfsonlinux的开发组员.&nbsp;</div><div><a target="_blank" href="http://blog.163.com/digoal@126/blog/static/1638770402014526992910/"   >http://blog.163.com/digoal@126/blog/static/1638770402014526992910/</a></div><div><a target="_blank" rel="nofollow" href="https://github.com/zfsonlinux/zfs/issues/2431"   >https://github.com/zfsonlinux/zfs/issues/2431</a></div><div>ZFS从功能和性能来讲, 确实是一个非常强大的文件系统, 包括块设备的管理.</div><div>Linux下如果要达到ZFS的部分功能, 需要软RAID管理, lvm, filesystem的软件组合.</div><div><span style="line-height: 28px;"   >RHEL 7开始, lvm针对SSD加入了类似flashcache, bcache的缓存功能. 支持writeback, writethrough模式.&nbsp;</span></div><div><span style="line-height: 28px;"   >本文将介绍一下lvm cache的使用, 同时对比一下它和zfs, flashcache, bcache以及直接使用ssd的性能差别.</span></div><div>理论上讲lvm cache 和bcache, flashcache的writeback模式, 相比直接使用ssd性能应该差不多(但是实际测试下来lvm的cache性能很不理想, 比zfs略好, 但是有大量的读, SSD iostat利用率很高, 并且lvm的条带使用不均匀, 不如zfs). ZFS使用ZIL后, 理论性能应该和前者也差不多, 但是zfsonlinux这块有我前面提到的性能问题, 所以就另当别论了.</div><div>另一方面, lvm cache的cache是独享的, 所以一个lv cache卷只能给一个lv orig卷使用. 这点和ZFS差别较大 . 但是zfs l2arc又不支持回写, 也是个缺陷.</div><div><br></div><div>本文测试环境 :&nbsp;</div><div>DELL R720xd</div><div>12 * 4TB SATA, 2*300G SAS(安装OS)</div><div>宝存 1.2T PCI-E SSD</div><div>CentOS 7 x64</div><div><div><img title="CentOS 7 lvm cache dev VS zfs VS flashcache VS bcache VS direct SSD - 德哥@Digoal - PostgreSQL research"   alt="CentOS 7 lvm cache dev VS zfs VS flashcache VS bcache VS direct SSD - 德哥@Digoal - PostgreSQL research"   style="margin:0 10px 0 0;"   src="http://img2.ph.126.net/2q6UzEL4Fg_pP8THlpBE_Q==/2151313247100192779.png"   ></div>测试工具, dd, pg_test_fsync.</div><div>测试fsync数据块大小8KB.</div><div><br></div><div>宝存SSD驱动安装.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@localhost soft_bak]# tar -zxvf release2.6.9.tar.gz&nbsp;</font></div><div><font size="2"   >release2.6.9/</font></div><div><font size="2"   >release2.6.9/shannon-2.6.18-274.el5.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.32-358.23.2.el6.x86_64.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.32-279.1.1.el6.x86_64.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/uninstall</font></div><div><font size="2"   >release2.6.9/shannon-2.6.32-279.el6.x86_64.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.32-220.el6.x86_64.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-v2.6-9.src.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.18-92.el5.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.32-131.0.15.el6.x86_64.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.18-8.el5.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.18-238.el5.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/install</font></div><div><font size="2"   >release2.6.9/shannon-2.6.32-431.5.1.el6.x86_64.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.18-128.el5.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.18-371.el5.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.18-308.el5.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.18-53.el5.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.32-71.el6.x86_64.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.32-431.el6.x86_64.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.32-358.el6.x86_64.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.18-194.el5.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.18-164.el5.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.32-358.6.2.el6.x86_64.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >release2.6.9/shannon-2.6.32-279.22.1.el6.x86_64.x86_64-v2.6-9.x86_64.rpm</font></div></div><div><div><font size="2"   >[root@localhost soft_bak]# rpm -ivh release2.6.9/shannon-v2.6-9.src.rpm</font></div><div><font size="2"   >Updating / installing...</font></div><div><font size="2"   >&nbsp; &nbsp;1:shannon-2.6.18-v2.6-9 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;################################# [100%]</font></div><div><font size="2"   >warning: user spike does not exist - using root</font></div><div><font size="2"   >warning: group spike does not exist - using root</font></div><div><font size="2"   >warning: user spike does not exist - using root</font></div><div><font size="2"   >warning: group spike does not exist - using root</font></div><div><font size="2"   >warning: user spike does not exist - using root</font></div><div><font size="2"   >warning: group spike does not exist - using root</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   ># uname -r</font></div><div><font size="2"   >3.10.0-123.el7.x86_64</font></div></div><div><font size="2"   ># yum install -y kernel-devel-3.10.0-123.el7.x86_64<span style="line-height: 28px;"   >&nbsp;</span><span style="line-height: 28px;"   >rpm-build gcc make&nbsp;</span>ncurses-devel</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ># cd ~/rpmbuild/SPECS/</font></div><div><div><font size="2"   >[root@localhost SPECS]# ll</font></div><div><font size="2"   >total 8</font></div><div><font size="2"   >-rw-rw-r--. 1 root root 7183 May 21 17:10 shannon-driver.spec</font></div></div><div><font size="2"   >[root@localhost SPECS]# rpmbuild -bb shannon-driver.spec</font></div><div><div><font size="2"   >[root@localhost SPECS]# cd ..</font></div><div><font size="2"   >[root@localhost rpmbuild]# ll</font></div><div><font size="2"   >total 0</font></div><div><font size="2"   >drwxr-xr-x. 3 root root 32 Jul &nbsp;9 19:56 BUILD</font></div><div><font size="2"   >drwxr-xr-x. 2 root root &nbsp;6 Jul &nbsp;9 19:56 BUILDROOT</font></div><div><font size="2"   >drwxr-xr-x. 3 root root 19 Jul &nbsp;9 19:56 RPMS</font></div><div><font size="2"   >drwxr-xr-x. 2 root root 61 Jul &nbsp;9 19:48 SOURCES</font></div><div><font size="2"   >drwxr-xr-x. 2 root root 32 Jul &nbsp;9 19:48 SPECS</font></div><div><font size="2"   >drwxr-xr-x. 2 root root &nbsp;6 Jul &nbsp;9 19:50 SRPMS</font></div><div><font size="2"   >[root@localhost rpmbuild]# cd RPMS</font></div><div><font size="2"   >[root@localhost RPMS]# ll</font></div><div><font size="2"   >total 0</font></div><div><font size="2"   >drwxr-xr-x. 2 root root 67 Jul &nbsp;9 19:56 x86_64</font></div><div><font size="2"   >[root@localhost RPMS]# cd x86_64/</font></div><div><font size="2"   >[root@localhost x86_64]# ll</font></div><div><font size="2"   >total 404</font></div><div><font size="2"   >-rw-r--r--. 1 root root 412100 Jul &nbsp;9 19:56 shannon-3.10.0-123.el7.x86_64.x86_64-v2.6-9.x86_64.rpm</font></div><div><font size="2"   >[root@localhost x86_64]# rpm -ivh shannon-3.10.0-123.el7.x86_64.x86_64-v2.6-9.x86_64.rpm</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   >Disk /dev/dfa: 1200.0 GB, 1200000860160 bytes, 2343751680 sectors<br>Units = sectors of 1 * 512 = 512 bytes<br>Sector size (logical/physical): 512 bytes / 4096 bytes<br>I/O size (minimum/optimal): 4096 bytes / 65536 bytes<br>Disk label type: dos<br>Disk identifier: 0x7e462b44</font></div><p></p></pre></div><div><br></div><div>PostgreSQL安装</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >yum -y install lrzsz sysstat e4fsprogs ntp readline-devel zlib zlib-devel openssl openssl-devel pam-devel libxml2-devel libxslt-devel python-devel tcl-devel gcc make smartmontools flex bison perl perl-devel perl-ExtUtils* OpenIPMI-tools openldap-devel</font></div></div><div><font size="2"   >wget&nbsp;http://ftp.postgresql.org/pub/source/v9.3.4/postgresql-9.3.4.tar.bz2</font></div><div><font size="2"   >tar -jxvf&nbsp;<span style="line-height: 28px;"   >postgresql-9.3.4.tar.bz2</span></font></div><div><font size="2"   ><span style="line-height: 28px;"   >cd&nbsp;</span><span style="line-height: 28px;"   >postgresql-9.3.4</span></font></div><div><font size="2"   >./configure --prefix=/opt/pgsql9.3.4 --with-pgport=1921 --with-perl --with-tcl --with-python --with-openssl --with-pam --with-ldap --with-libxml --with-libxslt --enable-thread-safety --enable-debug --enable-cassert</font></div><div><font size="2"   >gmake world &amp;&amp; gmake install-world</font></div><div><font size="2"   >ln -s /opt/pgsql9.3.4 /opt/pgsql</font></div><p></p></pre></div><div><br></div><div>测试iops</div><div><span style="line-height: 28px;"   >1. 直接使用SSD</span></div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   ># mkfs.xfs -f /dev/dfa1</font></div><div><font size="2"   >meta-data=/dev/dfa1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;isize=256 &nbsp; &nbsp;agcount=32, agsize=6553592 blks</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sectsz=4096 &nbsp;attr=2, projid32bit=1</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; crc=0</font></div><div><font size="2"   >data &nbsp; &nbsp; = &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bsize=4096 &nbsp; blocks=209714944, imaxpct=25</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sunit=0 &nbsp; &nbsp; &nbsp;swidth=0 blks</font></div><div><font size="2"   >naming &nbsp; =version 2 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;bsize=4096 &nbsp; ascii-ci=0 ftype=0</font></div><div><font size="2"   >log &nbsp; &nbsp; &nbsp;=internal log &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bsize=4096 &nbsp; blocks=102399, version=2</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sectsz=4096 &nbsp;sunit=1 blks, lazy-count=1</font></div><div><font size="2"   >realtime =none &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; extsz=4096 &nbsp; blocks=0, rtextents=0</font></div></div><div><div><font size="2"   >[root@localhost postgresql-9.3.4]# mount -t xfs /dev/dfa1 /mnt</font></div><div><font size="2"   >[root@localhost postgresql-9.3.4]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/mapper/centos-root &nbsp; 50G &nbsp;1.5G &nbsp; 49G &nbsp; 3% /</font></div><div><font size="2"   >devtmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;16G &nbsp; &nbsp; 0 &nbsp; 16G &nbsp; 0% /dev</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 16G &nbsp; &nbsp; 0 &nbsp; 16G &nbsp; 0% /dev/shm</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 16G &nbsp;8.9M &nbsp; 16G &nbsp; 1% /run</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 16G &nbsp; &nbsp; 0 &nbsp; 16G &nbsp; 0% /sys/fs/cgroup</font></div><div><font size="2"   >/dev/sda3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;497M &nbsp; 96M &nbsp;401M &nbsp;20% /boot</font></div><div><font size="2"   >/dev/mapper/centos-home &nbsp;173G &nbsp; 33M &nbsp;173G &nbsp; 1% /home</font></div><div><font size="2"   >/dev/dfa1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;800G &nbsp; 34M &nbsp;800G &nbsp; 1% /mnt</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@localhost postgresql-9.3.4]# /opt/pgsql/bin/pg_test_fsync -f /mnt/1</font></div><div><font size="2"   >5 seconds per test</font></div><div><font size="2"   >O_DIRECT supported on this platform for open_datasync and open_sync.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare file sync methods using one 8kB write:</font></div><div><font size="2"   >(in wal_sync_method preference order, except fdatasync</font></div><div><font size="2"   >is Linux's default)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_datasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 56805.093 ops/sec &nbsp; &nbsp; &nbsp;18 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fdatasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 45160.147 ops/sec &nbsp; &nbsp; &nbsp;22 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 45507.091 ops/sec &nbsp; &nbsp; &nbsp;22 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync_writethrough &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_sync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 57602.016 ops/sec &nbsp; &nbsp; &nbsp;17 usecs/op</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare file sync methods using two 8kB writes:</font></div><div><font size="2"   >(in wal_sync_method preference order, except fdatasync</font></div><div><font size="2"   >is Linux's default)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_datasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 28568.840 ops/sec &nbsp; &nbsp; &nbsp;35 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fdatasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 32591.457 ops/sec &nbsp; &nbsp; &nbsp;31 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 32736.908 ops/sec &nbsp; &nbsp; &nbsp;31 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync_writethrough &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_sync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 29071.443 ops/sec &nbsp; &nbsp; &nbsp;34 usecs/op</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare open_sync with different write sizes:</font></div><div><font size="2"   >(This is designed to compare the cost of writing 16kB</font></div><div><font size="2"   >in different write open_sync sizes.)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1 * 16kB open_sync write &nbsp; &nbsp; &nbsp; 40968.787 ops/sec &nbsp; &nbsp; &nbsp;24 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2 * &nbsp;8kB open_sync writes &nbsp; &nbsp; &nbsp;28805.187 ops/sec &nbsp; &nbsp; &nbsp;35 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4 * &nbsp;4kB open_sync writes &nbsp; &nbsp; &nbsp;18107.673 ops/sec &nbsp; &nbsp; &nbsp;55 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;8 * &nbsp;2kB open_sync writes &nbsp; &nbsp; &nbsp; &nbsp;834.181 ops/sec &nbsp; &nbsp;1199 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; 16 * &nbsp;1kB open_sync writes &nbsp; &nbsp; &nbsp; &nbsp;417.767 ops/sec &nbsp; &nbsp;2394 usecs/op</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Test if fsync on non-write file descriptor is honored:</font></div><div><font size="2"   >(If the times are similar, fsync() can sync data written</font></div><div><font size="2"   >on a different descriptor.)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write, fsync, close &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 35905.678 ops/sec &nbsp; &nbsp; &nbsp;28 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write, close, fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 35702.972 ops/sec &nbsp; &nbsp; &nbsp;28 usecs/op</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Non-Sync'ed 8kB writes:</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 314143.606 ops/sec &nbsp; &nbsp; &nbsp; 3 usecs/op</font></div></div><p></p></pre></div><div>iostat SSD使用率59%</div><div><br></div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@localhost postgresql-9.3.4]# dd if=/dev/zero of=/mnt/1 obs=4K oflag=sync,nonblock,noatime,nocache count=1024000</font></div><div><font size="2"   >1024000+0 records in</font></div><div><font size="2"   >128000+0 records out</font></div><div><font size="2"   >524288000 bytes (524 MB) copied, 6.95128 s, 75.4 MB/s</font></div><p></p></pre></div><div><span style="line-height: 28px;"   >iostat SSD</span><span style="line-height: 28px;"   >使用率</span><span style="line-height: 28px;"   >27.60</span></div><div><span style="line-height: 28px;"   ><br></span></div><div><span style="line-height: 28px;"   >2. 使用lvm cache</span></div><pre class="prettyprint"   ><p></p><div><font size="2"   ># umount /mnt</font></div><div></div><p></p></pre><div><span style="line-height: 28px;"   >清除设备信息(注意, 将丢失数据)</span></div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># dd if=/dev/urandom bs=512 count=64 of=/dev/dfa</font></div><div><span style="line-height: 28px;"   ><font size="2"   ># dd if=/dev/urandom bs=512 count=64 of=/dev/sdb</font></span></div><div><span style="line-height: 28px;"   ><font size="2"   >...</font></span></div><div><span style="line-height: 28px;"   ><font size="2"   ># dd if=/dev/urandom bs=512 count=64 of=/dev/sdm</font></span></div><p></p></pre></div><div><span style="line-height: 28px;"   >创建pv</span></div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># pvcreate /dev/sdb</font></div><div><font size="2"   >...</font></div><div><span style="line-height: 28px;"   ><font size="2"   ># pvcreate /dev/sdm</font></span></div><p></p></pre></div><div>注意, 创建dfa的pv时报错, 跟踪后发现是需要修改lvm.conf</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@localhost ~]# pvcreate /dev/dfa</font></div><div><font size="2"   >&nbsp; Physical volume /dev/dfa not found</font></div><div><font size="2"   >&nbsp; Device /dev/dfa not found (or ignored by filtering).</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@localhost ~]# pvcreate -vvvv /dev/dfa 2&gt;&amp;1|less</font></div><div><font size="2"   >#filters/filter-type.c:27 &nbsp; &nbsp; &nbsp; &nbsp; /dev/dfa: Skipping: Unrecognised LVM device type 252</font></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@localhost ~]# ll /dev/dfa</font></div><div><font size="2"   >brw-rw----. 1 root disk 252, 0 Jul &nbsp;9 21:19 /dev/dfa</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@localhost ~]# ll /dev/sdb</font></div><div><font size="2"   >brw-rw----. 1 root disk 8, 16 Jul &nbsp;9 21:03 /dev/sdb</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@localhost ~]# cat /proc/devices&nbsp;</font></div><div><font size="2"   >Character devices:</font></div><div><font size="2"   >&nbsp; 1 mem</font></div><div><font size="2"   >&nbsp; 4 /dev/vc/0</font></div><div><font size="2"   >&nbsp; 4 tty</font></div><div><font size="2"   >&nbsp; 4 ttyS</font></div><div><font size="2"   >&nbsp; 5 /dev/tty</font></div><div><font size="2"   >&nbsp; 5 /dev/console</font></div><div><font size="2"   >&nbsp; 5 /dev/ptmx</font></div><div><font size="2"   >&nbsp; 7 vcs</font></div><div><font size="2"   >&nbsp;10 misc</font></div><div><font size="2"   >&nbsp;13 input</font></div><div><font size="2"   >&nbsp;21 sg</font></div><div><font size="2"   >&nbsp;29 fb</font></div><div><font size="2"   >128 ptm</font></div><div><font size="2"   >136 pts</font></div><div><font size="2"   >162 raw</font></div><div><font size="2"   >180 usb</font></div><div><font size="2"   >188 ttyUSB</font></div><div><font size="2"   >189 usb_device</font></div><div><font size="2"   >202 cpu/msr</font></div><div><font size="2"   >203 cpu/cpuid</font></div><div><font size="2"   >226 drm</font></div><div><font size="2"   >245 shannon_ctrl_cdev</font></div><div><font size="2"   >246 ipmidev</font></div><div><font size="2"   >247 ptp</font></div><div><font size="2"   >248 pps</font></div><div><font size="2"   >249 megaraid_sas_ioctl</font></div><div><font size="2"   >250 hidraw</font></div><div><font size="2"   >251 usbmon</font></div><div><font size="2"   >252 bsg</font></div><div><font size="2"   >253 watchdog</font></div><div><font size="2"   >254 rtc</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Block devices:</font></div><div><font size="2"   >259 blkext</font></div><div><font size="2"   >&nbsp; 8 sd</font></div><div><font size="2"   >&nbsp; 9 md</font></div><div><font size="2"   >&nbsp;65 sd</font></div><div><font size="2"   >&nbsp;66 sd</font></div><div><font size="2"   >&nbsp;67 sd</font></div><div><font size="2"   >&nbsp;68 sd</font></div><div><font size="2"   >&nbsp;69 sd</font></div><div><font size="2"   >&nbsp;70 sd</font></div><div><font size="2"   >&nbsp;71 sd</font></div><div><font size="2"   >128 sd</font></div><div><font size="2"   >129 sd</font></div><div><font size="2"   >130 sd</font></div><div><font size="2"   >131 sd</font></div><div><font size="2"   >132 sd</font></div><div><font size="2"   >133 sd</font></div><div><font size="2"   >134 sd</font></div><div><font size="2"   >135 sd</font></div><div><font size="2"   >252 shannon</font></div><div><font size="2"   >253 device-mapper</font></div><div><font size="2"   >254 mdp</font></div></div><p></p></pre></div><div><br></div><div>修改/etc/lvm/lvm.conf, 添加宝存的type</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@localhost ~]# vi /etc/lvm/lvm.conf</font></div><div><div><font size="2"   >&nbsp; &nbsp; # types = [ "fd", 16 ]</font></div><div><font size="2"   >&nbsp; &nbsp; types = [ "shannon", 252 ]</font></div></div><p></p></pre></div><div>可以创建pv了.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@localhost ~]# pvcreate /dev/dfa</font></div><div><font size="2"   >&nbsp; Physical volume "/dev/dfa" successfully created</font></div><p></p></pre></div><div><br></div><div>创建新的vg</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@localhost ~]# pvs</font></div><div><font size="2"   >&nbsp; PV &nbsp; &nbsp; &nbsp; &nbsp; VG &nbsp; &nbsp; Fmt &nbsp;Attr PSize &nbsp; PFree</font></div><div><font size="2"   >&nbsp; /dev/dfa &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;lvm2 a-- &nbsp; &nbsp;1.09t 1.09t</font></div><div><font size="2"   >&nbsp; /dev/sda5 &nbsp;centos lvm2 a-- &nbsp;238.38g &nbsp; &nbsp;0&nbsp;</font></div><div><font size="2"   >&nbsp; /dev/sdb &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;lvm2 a-- &nbsp; &nbsp;3.64t 3.64t</font></div><div><font size="2"   >&nbsp; /dev/sdc &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;lvm2 a-- &nbsp; &nbsp;3.64t 3.64t</font></div><div><font size="2"   >&nbsp; /dev/sdd &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;lvm2 a-- &nbsp; &nbsp;3.64t 3.64t</font></div><div><font size="2"   >&nbsp; /dev/sde &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;lvm2 a-- &nbsp; &nbsp;3.64t 3.64t</font></div><div><font size="2"   >&nbsp; /dev/sdf &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;lvm2 a-- &nbsp; &nbsp;3.64t 3.64t</font></div><div><font size="2"   >&nbsp; /dev/sdg &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;lvm2 a-- &nbsp; &nbsp;3.64t 3.64t</font></div><div><font size="2"   >&nbsp; /dev/sdh &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;lvm2 a-- &nbsp; &nbsp;3.64t 3.64t</font></div><div><font size="2"   >&nbsp; /dev/sdi &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;lvm2 a-- &nbsp; &nbsp;3.64t 3.64t</font></div><div><font size="2"   >&nbsp; /dev/sdj &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;lvm2 a-- &nbsp; &nbsp;3.64t 3.64t</font></div><div><font size="2"   >&nbsp; /dev/sdk &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;lvm2 a-- &nbsp; &nbsp;3.64t 3.64t</font></div><div><font size="2"   >&nbsp; /dev/sdl &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;lvm2 a-- &nbsp; &nbsp;3.64t 3.64t</font></div><div><font size="2"   >&nbsp; /dev/sdm &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;lvm2 a-- &nbsp; &nbsp;3.64t 3.64t</font></div><p></p></pre></div><div><br></div><div>创建机械盘和SSD盘2个VG</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@localhost ~]# vgcreate vgdata01 /dev/sdb /dev/sdc /dev/sdd /dev/sde /dev/sdf /dev/sdg /dev/sdh /dev/sdi /dev/sdj /dev/sdk /dev/sdl /dev/sdm</font></div><div><font size="2"   >&nbsp; Volume group "vgdata01" successfully created</font></div><div><font size="2"   >[root@localhost ~]# vgcreate vgdata02 /dev/dfa</font></div><div><font size="2"   >&nbsp; Volume group "vgdata02" successfully created</font></div><p></p></pre></div><div><br></div><div>在机械盘的vg上创建lv</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@localhost ~]# lvcreate -L 100G -i 12 -n lv01 vgdata01</font></div><div><font size="2"   >&nbsp; Using default stripesize 64.00 KiB</font></div><div><font size="2"   >&nbsp; Rounding size (25600 extents) up to stripe boundary size (25608 extents).</font></div><div><font size="2"   >&nbsp; Logical volume "lv01" created</font></div><div><font size="2"   >[root@localhost ~]# lvs</font></div><div><font size="2"   >&nbsp; LV &nbsp; VG &nbsp; &nbsp; &nbsp; Attr &nbsp; &nbsp; &nbsp; LSize &nbsp; Pool Origin Data% &nbsp;Move Log Cpy%Sync Convert</font></div><div><font size="2"   >&nbsp; home centos &nbsp; -wi-ao---- 172.69g &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp; root centos &nbsp; -wi-ao---- &nbsp;50.00g &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp; swap centos &nbsp; -wi-ao---- &nbsp;15.70g &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp; lv01 vgdata01 -wi-a----- 100.03g&nbsp;</font></div><p></p></pre></div><div>在SSD VG上创建cache data和cache meta lv.</div><div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@localhost ~]# lvcreate -L 100G -n lv_cdata vgdata02</font></div><div><font size="2"   >&nbsp; Logical volume "lv_cdata" created</font></div><div><font size="2"   >[root@localhost ~]# lvcreate -L 100M -n lv_cmeta vgdata02</font></div><div><font size="2"   >&nbsp; Logical volume "lv_cmeta" created</font></div><p></p></pre></div><div><span style="line-height: 28px;"   >将cache data和cache meta lv转换成cache pool</span></div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@localhost ~]# lvconvert --type cache-pool --poolmetadata vgdata02/lv_cmeta vgdata02/lv_cdata</font></div><div><font size="2"   >&nbsp; Logical volume "lvol0" created</font></div><div><font size="2"   >&nbsp; Converted vgdata02/lv_cdata to cache pool.</font></div><div><div><font size="2"   >[root@localhost ~]# lvs</font></div><div><font size="2"   >&nbsp; LV &nbsp; &nbsp; &nbsp; VG &nbsp; &nbsp; &nbsp; Attr &nbsp; &nbsp; &nbsp; LSize &nbsp; Pool Origin Data% &nbsp;Move Log Cpy%Sync Convert</font></div><div><font size="2"   >&nbsp; home &nbsp; &nbsp; centos &nbsp; -wi-ao---- 172.69g &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp; root &nbsp; &nbsp; centos &nbsp; -wi-ao---- &nbsp;50.00g &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp; swap &nbsp; &nbsp; centos &nbsp; -wi-ao---- &nbsp;15.70g &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp; lv01 &nbsp; &nbsp; vgdata01 -wi-a----- 100.03g &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp; lv_cdata vgdata02 Cwi-a-C--- 100.00g&nbsp;</font></div></div><p></p></pre></div></div><div>将机械盘LV转换成CACHE lv.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@localhost ~]# lvconvert --type cache --cachepool vgdata02/lv_cdata vgdata01/lv01</font></div><div><font size="2"   >&nbsp; Unable to find cache pool LV, vgdata02/lv_cdata</font></div><p></p></pre></div><div>报错, 目前不支持跨VG创建cache lv.</div><div>本地VG则支持.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@localhost ~]# lvcreate -L 100G -n lv01 vgdata02</font></div><div><font size="2"   >&nbsp; Logical volume "lv01" created</font></div><div><font size="2"   >[root@localhost ~]# lvconvert --type cache --cachepool vgdata02/lv_cdata vgdata02/lv01</font></div><div><font size="2"   >&nbsp; vgdata02/lv01 is now cached.</font></div><p></p></pre></div><div><br></div><div>所以需要调整一下, 把ssd加入vgdata01, 同时创建lvm条带时需要制定一下块设备.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@localhost ~]# lvremove /dev/mapper/vgdata02-lv01</font></div><div><font size="2"   >Do you really want to remove active logical volume lv01? [y/n]: y</font></div><div><font size="2"   >&nbsp; Logical volume "lv01" successfully removed</font></div></div><div><div><font size="2"   >[root@localhost ~]# lvremove /dev/mapper/vgdata01-lv01&nbsp;</font></div><div><font size="2"   >Do you really want to remove active logical volume lv01? [y/n]: y</font></div><div><font size="2"   >&nbsp; Logical volume "lv01" successfully removed</font></div></div><div><font size="2"   >[root@localhost ~]# lvchange -a y vgdata02/lv_cdata</font></div><div><div><font size="2"   >[root@localhost ~]# lvremove /dev/mapper/vgdata02-lv_cdata</font></div><div><font size="2"   >Do you really want to remove active logical volume lv_cdata? [y/n]: y</font></div><div><font size="2"   >&nbsp; Logical volume "lv_cdata" successfully removed</font></div></div><div><div><font size="2"   >[root@localhost ~]# vgremove vgdata02</font></div><div><font size="2"   >&nbsp; Volume group "vgdata02" successfully removed</font></div></div><p></p></pre></div><div>扩展vgdata01</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@localhost ~]# vgextend vgdata01 /dev/dfa</font></div><div><font size="2"   >&nbsp; Volume group "vgdata01" successfully extended</font></div><p></p></pre></div><div><br></div><div>创建条带lvm, 同时指定机械盘(指定4K大小的条带).</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@localhost ~]# lvcreate -L 100G -i 12 -I4 -n lv01 vgdata01 /dev/sdb /dev/sdc /dev/sdd /dev/sde /dev/sdf /dev/sdg /dev/sdh /dev/sdi /dev/sdj /dev/sdk /dev/sdl /dev/sdm</font></div><div><font size="2"   >&nbsp; Rounding size (25600 extents) up to stripe boundary size (25608 extents).</font></div><div><font size="2"   >&nbsp; Logical volume "lv01" created</font></div><p></p></pre></div><div>创建cache lvm , 指定SSD.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@localhost ~]# lvcreate -L 100G -n lv_cdata vgdata01 /dev/dfa</font></div><div><font size="2"   >&nbsp; Logical volume "lv_cdata" created</font></div><div><font size="2"   >[root@localhost ~]# lvcreate -L 100M -n lv_cmeta vgdata01 /dev/dfa</font></div><div><font size="2"   >&nbsp; Logical volume "lv_cmeta" created</font></div><p></p></pre></div><div>转换cache lv</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@localhost ~]# lvconvert --type cache-pool --poolmetadata vgdata01/lv_cmeta --cachemode writeback vgdata01/lv_cdata</font></div><div><font size="2"   >&nbsp; Logical volume "lvol0" created</font></div><div><font size="2"   >&nbsp; Converted vgdata01/lv_cdata to cache pool.</font></div><div><font size="2"   >[root@localhost ~]# lvconvert --type cache --cachepool vgdata01/lv_cdata vgdata01/lv01</font></div><div><font size="2"   >&nbsp; vgdata01/lv01 is now cached.</font></div></div><div><div><font size="2"   >[root@localhost ~]# lvs</font></div><div><font size="2"   >&nbsp; LV &nbsp; &nbsp; &nbsp; VG &nbsp; &nbsp; &nbsp; Attr &nbsp; &nbsp; &nbsp; LSize &nbsp; Pool &nbsp; &nbsp; Origin &nbsp; &nbsp; &nbsp; Data% &nbsp;Move Log Cpy%Sync Convert</font></div><div><font size="2"   >&nbsp; home &nbsp; &nbsp; centos &nbsp; -wi-ao---- 172.69g &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp; root &nbsp; &nbsp; centos &nbsp; -wi-ao---- &nbsp;50.00g &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp; swap &nbsp; &nbsp; centos &nbsp; -wi-ao---- &nbsp;15.70g &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp; lv01 &nbsp; &nbsp; vgdata01 Cwi-a-C--- 100.03g lv_cdata [lv01_corig] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp; lv_cdata vgdata01 Cwi-a-C--- 100.00g &nbsp;</font></div></div><p></p></pre></div><div>在合并后的lv01上创建文件系统.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@localhost ~]# mkfs.xfs /dev/mapper/vgdata01-lv01</font></div><div><font size="2"   >meta-data=/dev/mapper/vgdata01-lv01 isize=256 &nbsp; &nbsp;agcount=16, agsize=1638912 blks</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sectsz=4096 &nbsp;attr=2, projid32bit=1</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; crc=0</font></div><div><font size="2"   >data &nbsp; &nbsp; = &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bsize=4096 &nbsp; blocks=26222592, imaxpct=25</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sunit=0 &nbsp; &nbsp; &nbsp;swidth=0 blks</font></div><div><font size="2"   >naming &nbsp; =version 2 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;bsize=4096 &nbsp; ascii-ci=0 ftype=0</font></div><div><font size="2"   >log &nbsp; &nbsp; &nbsp;=internal log &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bsize=4096 &nbsp; blocks=12804, version=2</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sectsz=4096 &nbsp;sunit=1 blks, lazy-count=1</font></div><div><font size="2"   >realtime =none &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; extsz=4096 &nbsp; blocks=0, rtextents=0</font></div></div><div><font size="2"   >[root@localhost ~]# mount /dev/mapper/vgdata01-lv01 /mnt</font></div><div><div><font size="2"   >[root@localhost ~]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/mapper/vgdata01-lv01 &nbsp;100G &nbsp; 33M &nbsp;100G &nbsp; 1% /mnt</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@localhost ~]# /opt/pgsql/bin/pg_test_fsync -f /mnt/1</font></div><div><font size="2"   >5 seconds per test</font></div><div><font size="2"   >O_DIRECT supported on this platform for open_datasync and open_sync.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare file sync methods using one 8kB write:</font></div><div><font size="2"   >(in wal_sync_method preference order, except fdatasync</font></div><div><font size="2"   >is Linux's default)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_datasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;8124.408 ops/sec &nbsp; &nbsp; 123 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fdatasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;8178.149 ops/sec &nbsp; &nbsp; 122 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;8113.938 ops/sec &nbsp; &nbsp; 123 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync_writethrough &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_sync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;8300.755 ops/sec &nbsp; &nbsp; 120 usecs/op</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare file sync methods using two 8kB writes:</font></div><div><font size="2"   >(in wal_sync_method preference order, except fdatasync</font></div><div><font size="2"   >is Linux's default)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_datasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4178.896 ops/sec &nbsp; &nbsp; 239 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fdatasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;6963.270 ops/sec &nbsp; &nbsp; 144 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;6930.345 ops/sec &nbsp; &nbsp; 144 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync_writethrough &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_sync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4205.576 ops/sec &nbsp; &nbsp; 238 usecs/op</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare open_sync with different write sizes:</font></div><div><font size="2"   >(This is designed to compare the cost of writing 16kB</font></div><div><font size="2"   >in different write open_sync sizes.)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1 * 16kB open_sync write &nbsp; &nbsp; &nbsp; &nbsp;7062.249 ops/sec &nbsp; &nbsp; 142 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2 * &nbsp;8kB open_sync writes &nbsp; &nbsp; &nbsp; 4229.181 ops/sec &nbsp; &nbsp; 236 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4 * &nbsp;4kB open_sync writes &nbsp; &nbsp; &nbsp; 2281.264 ops/sec &nbsp; &nbsp; 438 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;8 * &nbsp;2kB open_sync writes &nbsp; &nbsp; &nbsp; &nbsp;583.685 ops/sec &nbsp; &nbsp;1713 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; 16 * &nbsp;1kB open_sync writes &nbsp; &nbsp; &nbsp; &nbsp;285.534 ops/sec &nbsp; &nbsp;3502 usecs/op</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Test if fsync on non-write file descriptor is honored:</font></div><div><font size="2"   >(If the times are similar, fsync() can sync data written</font></div><div><font size="2"   >on a different descriptor.)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write, fsync, close &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;7494.674 ops/sec &nbsp; &nbsp; 133 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write, close, fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;7481.698 ops/sec &nbsp; &nbsp; 134 usecs/op</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Non-Sync'ed 8kB writes:</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 307025.095 ops/sec &nbsp; &nbsp; &nbsp; 3 usecs/op</font></div><p></p></pre></div><div>iostat SSD 使用率55%</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >Device: &nbsp; &nbsp; &nbsp; &nbsp; rrqm/s &nbsp; wrqm/s &nbsp; &nbsp; r/s &nbsp; &nbsp; w/s &nbsp; &nbsp;rkB/s &nbsp; &nbsp;wkB/s avgrq-sz avgqu-sz &nbsp; await r_await w_await &nbsp;svctm &nbsp;%util</font></div><div><font size="2"   >dfa &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp;878.00 15828.00 56192.00 63312.00 &nbsp; &nbsp;14.31 &nbsp; &nbsp; 0.63 &nbsp; &nbsp;0.04 &nbsp; &nbsp;0.51 &nbsp; &nbsp;0.01 &nbsp; 0.03 &nbsp;52.80</font></div><div><div><font size="2"   >sdc &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; 288.00 &nbsp; &nbsp;0.00 8350.00 &nbsp; &nbsp; 0.00 &nbsp;4664.00 &nbsp; &nbsp; 1.12 &nbsp; &nbsp; 0.14 &nbsp; &nbsp;0.02 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.02 &nbsp; 0.02 &nbsp;14.00</font></div><div><font size="2"   >sdb &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; 288.00 &nbsp; &nbsp;0.00 8350.00 &nbsp; &nbsp; 0.00 &nbsp;4664.00 &nbsp; &nbsp; 1.12 &nbsp; &nbsp; 0.12 &nbsp; &nbsp;0.01 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.01 &nbsp; 0.01 &nbsp;11.90</font></div><div><font size="2"   >sdd &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; 288.00 &nbsp; &nbsp;0.00 8350.00 &nbsp; &nbsp; 0.00 &nbsp;4664.00 &nbsp; &nbsp; 1.12 &nbsp; &nbsp; 0.12 &nbsp; &nbsp;0.01 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.01 &nbsp; 0.01 &nbsp;11.90</font></div><div><font size="2"   >sdh &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; 299.00 &nbsp; &nbsp;0.00 8350.00 &nbsp; &nbsp; 0.00 &nbsp;4708.00 &nbsp; &nbsp; 1.13 &nbsp; &nbsp; 0.14 &nbsp; &nbsp;0.02 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.02 &nbsp; 0.02 &nbsp;14.10</font></div><div><font size="2"   >sdf &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; 299.00 &nbsp; &nbsp;0.00 8350.00 &nbsp; &nbsp; 0.00 &nbsp;4708.00 &nbsp; &nbsp; 1.13 &nbsp; &nbsp; 0.12 &nbsp; &nbsp;0.01 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.01 &nbsp; 0.01 &nbsp;11.40</font></div><div><font size="2"   >sdi &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; 299.00 &nbsp; &nbsp;0.00 8350.00 &nbsp; &nbsp; 0.00 &nbsp;4708.00 &nbsp; &nbsp; 1.13 &nbsp; &nbsp; 0.15 &nbsp; &nbsp;0.02 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.02 &nbsp; 0.02 &nbsp;14.30</font></div><div><font size="2"   >sdg &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; 299.00 &nbsp; &nbsp;0.00 8350.00 &nbsp; &nbsp; 0.00 &nbsp;4708.00 &nbsp; &nbsp; 1.13 &nbsp; &nbsp; 0.14 &nbsp; &nbsp;0.02 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.02 &nbsp; 0.02 &nbsp;13.30</font></div><div><font size="2"   >sde &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; 288.00 &nbsp; &nbsp;0.00 8350.00 &nbsp; &nbsp; 0.00 &nbsp;4664.00 &nbsp; &nbsp; 1.12 &nbsp; &nbsp; 0.12 &nbsp; &nbsp;0.01 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.01 &nbsp; 0.01 &nbsp;12.00</font></div><div><font size="2"   >sdl &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; 291.00 &nbsp; &nbsp;0.00 8350.00 &nbsp; &nbsp; 0.00 &nbsp;4676.00 &nbsp; &nbsp; 1.12 &nbsp; &nbsp; 0.14 &nbsp; &nbsp;0.02 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.02 &nbsp; 0.02 &nbsp;14.00</font></div><div><font size="2"   >sdk &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; 291.00 &nbsp; &nbsp;0.00 8352.00 &nbsp; &nbsp; 0.00 &nbsp;4676.00 &nbsp; &nbsp; 1.12 &nbsp; &nbsp; 0.14 &nbsp; &nbsp;0.02 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.02 &nbsp; 0.02 &nbsp;13.60</font></div><div><font size="2"   >sdm &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; 291.00 &nbsp; &nbsp;0.00 8352.00 &nbsp; &nbsp; 0.00 &nbsp;4676.00 &nbsp; &nbsp; 1.12 &nbsp; &nbsp; 0.14 &nbsp; &nbsp;0.02 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.02 &nbsp; 0.02 &nbsp;13.60</font></div><div><font size="2"   >sdj &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; 291.00 &nbsp; &nbsp;0.00 8352.00 &nbsp; &nbsp; 0.00 &nbsp;4676.00 &nbsp; &nbsp; 1.12 &nbsp; &nbsp; 0.14 &nbsp; &nbsp;0.02 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.02 &nbsp; 0.02 &nbsp;14.10</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@localhost ~]# dd if=/dev/zero of=/mnt/1 obs=4K oflag=sync,nonblock,noatime,nocache count=1024000</font></div><div><font size="2"   >1024000+0 records in</font></div><div><font size="2"   >128000+0 records out</font></div><div><font size="2"   >524288000 bytes (524 MB) copied, 90.1487 s, 5.8 MB/s</font></div></div><p></p></pre></div><div><br></div><div>直接使用机械盘条带的测试结果 (指定4KiB条带大小)</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@localhost ~]# lvcreate -L 100G -i 12 -I4 -n lv02 vgdata01 /dev/sdb /dev/sdc /dev/sdd /dev/sde /dev/sdf /dev/sdg /dev/sdh /dev/sdi /dev/sdj /dev/sdk /dev/sdl /dev/sdm</font></div><div><div><font size="2"   >[root@localhost ~]# mkfs.xfs /dev/mapper/vgdata01-lv02</font></div><div><font size="2"   >meta-data=/dev/mapper/vgdata01-lv02 isize=256 &nbsp; &nbsp;agcount=16, agsize=1638911 blks</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sectsz=512 &nbsp; attr=2, projid32bit=1</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; crc=0</font></div><div><font size="2"   >data &nbsp; &nbsp; = &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bsize=4096 &nbsp; blocks=26222576, imaxpct=25</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sunit=1 &nbsp; &nbsp; &nbsp;swidth=12 blks</font></div><div><font size="2"   >naming &nbsp; =version 2 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;bsize=4096 &nbsp; ascii-ci=0 ftype=0</font></div><div><font size="2"   >log &nbsp; &nbsp; &nbsp;=internal log &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bsize=4096 &nbsp; blocks=12803, version=2</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sectsz=512 &nbsp; sunit=1 blks, lazy-count=1</font></div><div><font size="2"   >realtime =none &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; extsz=4096 &nbsp; blocks=0, rtextents=0</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   ># mount /dev/mapper/vgdata01-lv02 /mnt</font></div><div><div><font size="2"   >[root@localhost ~]# /opt/pgsql/bin/pg_test_fsync -f /mnt/1</font></div><div><font size="2"   >5 seconds per test</font></div><div><font size="2"   >O_DIRECT supported on this platform for open_datasync and open_sync.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare file sync methods using one 8kB write:</font></div><div><font size="2"   >(in wal_sync_method preference order, except fdatasync</font></div><div><font size="2"   >is Linux's default)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_datasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;5724.374 ops/sec &nbsp; &nbsp; 175 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fdatasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;5143.975 ops/sec &nbsp; &nbsp; 194 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;5248.552 ops/sec &nbsp; &nbsp; 191 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync_writethrough &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_sync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;5636.435 ops/sec &nbsp; &nbsp; 177 usecs/op</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare file sync methods using two 8kB writes:</font></div><div><font size="2"   >(in wal_sync_method preference order, except fdatasync</font></div><div><font size="2"   >is Linux's default)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_datasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2763.554 ops/sec &nbsp; &nbsp; 362 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fdatasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4121.941 ops/sec &nbsp; &nbsp; 243 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4060.660 ops/sec &nbsp; &nbsp; 246 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync_writethrough &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_sync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2701.105 ops/sec &nbsp; &nbsp; 370 usecs/op</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare open_sync with different write sizes:</font></div><div><font size="2"   >(This is designed to compare the cost of writing 16kB</font></div><div><font size="2"   >in different write open_sync sizes.)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1 * 16kB open_sync write &nbsp; &nbsp; &nbsp; &nbsp;5019.091 ops/sec &nbsp; &nbsp; 199 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2 * &nbsp;8kB open_sync writes &nbsp; &nbsp; &nbsp; 3055.081 ops/sec &nbsp; &nbsp; 327 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4 * &nbsp;4kB open_sync writes &nbsp; &nbsp; &nbsp; 1715.343 ops/sec &nbsp; &nbsp; 583 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;8 * &nbsp;2kB open_sync writes &nbsp; &nbsp; &nbsp; &nbsp;786.708 ops/sec &nbsp; &nbsp;1271 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; 16 * &nbsp;1kB open_sync writes &nbsp; &nbsp; &nbsp; &nbsp;469.455 ops/sec &nbsp; &nbsp;2130 usecs/op</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Test if fsync on non-write file descriptor is honored:</font></div><div><font size="2"   >(If the times are similar, fsync() can sync data written</font></div><div><font size="2"   >on a different descriptor.)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write, fsync, close &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4490.716 ops/sec &nbsp; &nbsp; 223 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write, close, fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4566.385 ops/sec &nbsp; &nbsp; 219 usecs/op</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Non-Sync'ed 8kB writes:</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 294268.753 ops/sec &nbsp; &nbsp; &nbsp; 3 usecs/op</font></div></div><p></p></pre></div><div><br></div><div>条带利用率显然没有ZFS使用均匀.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >sdc &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 14413.00 &nbsp; &nbsp; 0.00 28988.00 &nbsp; &nbsp; 4.02 &nbsp; &nbsp; 0.40 &nbsp; &nbsp;0.03 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.03 &nbsp; 0.03 &nbsp;39.90</font></div><div><font size="2"   >sdb &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 14413.00 &nbsp; &nbsp; 0.00 28988.00 &nbsp; &nbsp; 4.02 &nbsp; &nbsp; 0.39 &nbsp; &nbsp;0.03 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.03 &nbsp; 0.03 &nbsp;38.90</font></div><div><font size="2"   >sdd &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 7248.00 &nbsp; &nbsp; 0.00 &nbsp; 328.00 &nbsp; &nbsp; 0.09 &nbsp; &nbsp; 0.01 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; 0.00 &nbsp; 0.90</font></div><div><font size="2"   >sdh &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 7248.00 &nbsp; &nbsp; 0.00 &nbsp; 328.00 &nbsp; &nbsp; 0.09 &nbsp; &nbsp; 0.01 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; 0.00 &nbsp; 0.90</font></div><div><font size="2"   >sdf &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 7248.00 &nbsp; &nbsp; 0.00 &nbsp; 328.00 &nbsp; &nbsp; 0.09 &nbsp; &nbsp; 0.01 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; 0.00 &nbsp; 1.40</font></div><div><font size="2"   >sdi &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 7248.00 &nbsp; &nbsp; 0.00 &nbsp; 328.00 &nbsp; &nbsp; 0.09 &nbsp; &nbsp; 0.01 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; 0.00 &nbsp; 0.70</font></div><div><font size="2"   >sdg &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 7248.00 &nbsp; &nbsp; 0.00 &nbsp; 328.00 &nbsp; &nbsp; 0.09 &nbsp; &nbsp; 0.02 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; 0.00 &nbsp; 1.90</font></div><div><font size="2"   >sde &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 7248.00 &nbsp; &nbsp; 0.00 &nbsp; 328.00 &nbsp; &nbsp; 0.09 &nbsp; &nbsp; 0.01 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; 0.00 &nbsp; 0.90</font></div><div><font size="2"   >sdl &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 7248.00 &nbsp; &nbsp; 0.00 &nbsp; 328.00 &nbsp; &nbsp; 0.09 &nbsp; &nbsp; 0.02 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; 0.00 &nbsp; 2.00</font></div><div><font size="2"   >sdk &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 7248.00 &nbsp; &nbsp; 0.00 &nbsp; 328.00 &nbsp; &nbsp; 0.09 &nbsp; &nbsp; 0.01 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; 0.00 &nbsp; 1.40</font></div><div><font size="2"   >sdm &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 7248.00 &nbsp; &nbsp; 0.00 &nbsp; 328.00 &nbsp; &nbsp; 0.09 &nbsp; &nbsp; 0.02 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; 0.00 &nbsp; 1.70</font></div><div><font size="2"   >sdj &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 7248.00 &nbsp; &nbsp; 0.00 &nbsp; 328.00 &nbsp; &nbsp; 0.09 &nbsp; &nbsp; 0.01 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.00 &nbsp; 0.00 &nbsp; 1.00</font></div><p></p></pre></div><div><br></div><div>删除设备</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># umount /mnt</font></div><div><div><font size="2"   >[root@localhost ~]# lvremove vgdata01/lv_cdata</font></div><div><font size="2"   >&nbsp; Flushing cache for lv01</font></div><div><font size="2"   >&nbsp; 970 blocks must still be flushed.</font></div><div><font size="2"   >&nbsp; 0 blocks must still be flushed.</font></div><div><font size="2"   >Do you really want to remove active logical volume lv_cdata? [y/n]: y</font></div><div><font size="2"   >&nbsp; Logical volume "lv_cdata" successfully removed</font></div></div><div><div><font size="2"   >[root@localhost ~]# lvremove vgdata01/lv01</font></div><div><font size="2"   >Do you really want to remove active logical volume lv01? [y/n]: y</font></div><div><font size="2"   >&nbsp; Logical volume "lv01" successfully removed</font></div><div><font size="2"   >[root@localhost ~]# lvremove vgdata01/lv02</font></div><div><font size="2"   >Do you really want to remove active logical volume lv02? [y/n]: y</font></div><div><font size="2"   >&nbsp; Logical volume "lv02" successfully removed</font></div></div><div><div><font size="2"   >[root@localhost ~]# pvremove /dev/dfa</font></div><div><font size="2"   >&nbsp; PV /dev/dfa belongs to Volume Group vgdata01 so please use vgreduce first.</font></div><div><font size="2"   >&nbsp; (If you are certain you need pvremove, then confirm by using --force twice.)</font></div><div><font size="2"   >[root@localhost ~]# vgremove vgdata01</font></div><div><font size="2"   >&nbsp; Volume group "vgdata01" successfully removed</font></div><div><font size="2"   >[root@localhost ~]# pvremove /dev/dfa</font></div><div><font size="2"   >&nbsp; Labels on physical volume "/dev/dfa" successfully wiped</font></div><div><font size="2"   >[root@localhost ~]# pvremove /dev/sdb</font></div><div><font size="2"   >&nbsp; Labels on physical volume "/dev/sdb" successfully wiped</font></div><div><font size="2"   >[root@localhost ~]# pvremove /dev/sdc</font></div><div><font size="2"   >&nbsp; Labels on physical volume "/dev/sdc" successfully wiped</font></div><div><font size="2"   >[root@localhost ~]# pvremove /dev/sdd</font></div><div><font size="2"   >&nbsp; Labels on physical volume "/dev/sdd" successfully wiped</font></div><div><font size="2"   >[root@localhost ~]# pvremove /dev/sde</font></div><div><font size="2"   >&nbsp; Labels on physical volume "/dev/sde" successfully wiped</font></div><div><font size="2"   >[root@localhost ~]# pvremove /dev/sdf</font></div><div><font size="2"   >&nbsp; Labels on physical volume "/dev/sdf" successfully wiped</font></div><div><font size="2"   >[root@localhost ~]# pvremove /dev/sdg</font></div><div><font size="2"   >&nbsp; Labels on physical volume "/dev/sdg" successfully wiped</font></div><div><font size="2"   >[root@localhost ~]# pvremove /dev/sdh</font></div><div><font size="2"   >&nbsp; Labels on physical volume "/dev/sdh" successfully wiped</font></div><div><font size="2"   >[root@localhost ~]# pvremove /dev/sdi</font></div><div><font size="2"   >&nbsp; Labels on physical volume "/dev/sdi" successfully wiped</font></div><div><font size="2"   >[root@localhost ~]# pvremove /dev/sdj</font></div><div><font size="2"   >&nbsp; Labels on physical volume "/dev/sdj" successfully wiped</font></div><div><font size="2"   >[root@localhost ~]# pvremove /dev/sdk</font></div><div><font size="2"   >&nbsp; Labels on physical volume "/dev/sdk" successfully wiped</font></div><div><font size="2"   >[root@localhost ~]# pvremove /dev/sdl</font></div><div><font size="2"   >&nbsp; Labels on physical volume "/dev/sdl" successfully wiped</font></div><div><font size="2"   >[root@localhost ~]# pvremove /dev/sdm</font></div><div><font size="2"   >&nbsp; Labels on physical volume "/dev/sdm" successfully wiped</font></div><div><font size="2"   >[root@localhost ~]# pvs</font></div><div><font size="2"   >&nbsp; PV &nbsp; &nbsp; &nbsp; &nbsp; VG &nbsp; &nbsp; Fmt &nbsp;Attr PSize &nbsp; PFree</font></div><div><font size="2"   >&nbsp; /dev/sda5 &nbsp;centos lvm2 a-- &nbsp;238.38g &nbsp; &nbsp;0&nbsp;</font></div></div><p></p></pre></div><div><br></div><div>以下测试可参照, 其中flashcache性能损失极少(甚至比直接使用SSD性能更高).</div><div>zfs和lvm性能差不多, lvm略高, 但是LVM的fsync带来了大量的cache设备的读操作, 使得ssd的util比zfs高很多, 相当于浪费了较多的io. 不知原因, ZFSonLinux 则没有这个问题.</div><div><a target="_blank" href="http://blog.163.com/digoal@126/blog/static/1638770402014528115551323/"   >http://blog.163.com/digoal@126/blog/static/1638770402014528115551323/</a></div><div>3. 使用flashcache</div><div>4. 使用bcache</div><div>5. 使用zfs</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># yum install -y libtoolize&nbsp;autoconf automake</font></div><div><font size="2"   ># tar -zxvf spl-0.6.3.tar.gz&nbsp;</font></div><div><font size="2"   ># tar -zxvf zfs-0.6.3.tar.gz</font></div><div><font size="2"   ># cd&nbsp;<span style="line-height: 28px;"   >spl-0.6.3</span></font></div><div><font size="2"   ># ./autogen.sh&nbsp;</font></div><div><font size="2"   ># ./configure --prefix=/opt/spl0.6.3</font></div><div><font size="2"   ># make &amp;&amp; make install</font></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@localhost spl-0.6.3]# cd ..</font></div><div><font size="2"   >[root@localhost soft_bak]# cd zfs-0.6.3</font></div><div><font size="2"   >[root@localhost zfs-0.6.3]# yum install -y libuuid-devel</font></div></div><div><font size="2"   ><span style="line-height: 28px;"   >[root@localhost zfs-0.6.3]</span># ./configure --prefix=/opt/zfs0.6.3</font></div><div><font size="2"   ><span style="line-height: 28px;"   >[root@localhost zfs-0.6.3]</span># make &amp;&amp; make install</font></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@localhost ~]# modprobe splat</font></div><div><font size="2"   >[root@localhost ~]# /opt/spl0.6.3/sbin/splat -a</font></div></div><div><div><font size="2"   >------------------------------ Running SPLAT Tests ------------------------------</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:kmem_alloc &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:kmem_zalloc &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:vmem_alloc &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:vmem_zalloc &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:slab_small &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:slab_large &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:slab_align &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:slab_reap &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:slab_age &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:slab_lock &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:vmem_size &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kmem:slab_reclaim &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:single &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:multiple &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:system &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:wait &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:order &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:front &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:recurse &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:contention &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:delay &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;taskq:cancel &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; krng:freq &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mutex:tryenter &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mutex:race &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mutex:owned &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mutex:owner &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;condvar:signal1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;condvar:broadcast1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;condvar:signal2 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;condvar:broadcast2 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;condvar:timeout &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; thread:create &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; thread:exit &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; thread:tsd &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rwlock:N-rd/1-wr &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rwlock:0-rd/N-wr &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rwlock:held &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rwlock:tryenter &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rwlock:rw_downgrade &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rwlock:rw_tryupgrade &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; time:time1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; time:time2 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;vnode:vn_open &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;vnode:vn_openat &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;vnode:vn_rdwr &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;vnode:vn_rename &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;vnode:vn_getattr &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;vnode:vn_sync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kobj:open &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kobj:size/read &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; atomic:64-bit &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list:create/destroy &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list:ins/rm head &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list:ins/rm tail &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list:insert_after &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list:insert_before &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list:remove &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list:active &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;generic:ddi_strtoul &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;generic:ddi_strtol &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;generic:ddi_strtoull &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;generic:ddi_strtoll &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;generic:udivdi3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;generic:divdi3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cred:cred &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cred:kcred &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cred:groupmember &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; zlib:compress/uncompress &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;linux:shrink_dcache &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;linux:shrink_icache &nbsp; &nbsp; &nbsp; &nbsp;Pass &nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;linux:shrinker &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pass &nbsp;</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@localhost zfs-0.6.3]# /opt/zfs0.6.3/sbin/zpool create -f -o ashift=12 zp1 sdb sdc sdd sde sdf sdg sdh sdi sdj sdk sdl sdm</font></div><div><font size="2"   >[root@localhost zfs-0.6.3]# export PATH=/opt/zfs0.6.3/sbin:$PATH</font></div><div><font size="2"   >[root@localhost zfs-0.6.3]# zpool status</font></div><div><font size="2"   >&nbsp; pool: zp1</font></div><div><font size="2"   >&nbsp;state: ONLINE</font></div><div><font size="2"   >&nbsp; scan: none requested</font></div><div><font size="2"   >config:</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; NAME &nbsp; &nbsp; &nbsp; &nbsp;STATE &nbsp; &nbsp; READ WRITE CKSUM</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; zp1 &nbsp; &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdb &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdc &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdd &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sde &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdf &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdg &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdh &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdi &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdj &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdk &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdl &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdm &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@localhost zfs-0.6.3]# fdisk -c -u /dev/dfa</font></div><div><font size="2"   >Welcome to fdisk (util-linux 2.23.2).</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Changes will remain in memory only, until you decide to write them.</font></div><div><font size="2"   >Be careful before using the write command.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Device does not contain a recognized partition table</font></div><div><font size="2"   >Building a new DOS disklabel with disk identifier 0x2dd27e66.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >The device presents a logical sector size that is smaller than</font></div><div><font size="2"   >the physical sector size. Aligning to a physical sector (or optimal</font></div><div><font size="2"   >I/O) size boundary is recommended, or performance may be impacted.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Command (m for help): n</font></div><div><font size="2"   >Partition type:</font></div><div><font size="2"   >&nbsp; &nbsp;p &nbsp; primary (0 primary, 0 extended, 4 free)</font></div><div><font size="2"   >&nbsp; &nbsp;e &nbsp; extended</font></div><div><font size="2"   >Select (default p): p</font></div><div><font size="2"   >Partition number (1-4, default 1):&nbsp;</font></div><div><font size="2"   >First sector (2048-2343751679, default 2048):&nbsp;</font></div><div><font size="2"   >Using default value 2048</font></div><div><font size="2"   >Last sector, +sectors or +size{K,M,G} (2048-2343751679, default 2343751679): +16777216 &nbsp; &nbsp;</font></div><div><font size="2"   >Partition 1 of type Linux and of size 8 GiB is set</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Command (m for help): n</font></div><div><font size="2"   >Partition type:</font></div><div><font size="2"   >&nbsp; &nbsp;p &nbsp; primary (1 primary, 0 extended, 3 free)</font></div><div><font size="2"   >&nbsp; &nbsp;e &nbsp; extended</font></div><div><font size="2"   >Select (default p): p</font></div><div><font size="2"   >Partition number (2-4, default 2):&nbsp;</font></div><div><font size="2"   >First sector (16779265-2343751679, default 16781312):&nbsp;</font></div><div><font size="2"   >Using default value 16781312</font></div><div><font size="2"   >Last sector, +sectors or +size{K,M,G} (16781312-2343751679, default 2343751679): +209715200</font></div><div><font size="2"   >Partition 2 of type Linux and of size 100 GiB is set</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Command (m for help): w</font></div><div><font size="2"   >The partition table has been altered!</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Calling ioctl() to re-read partition table.</font></div><div><font size="2"   >Syncing disks.</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   >添加zil</font></div><div><font size="2"   >[root@localhost zfs-0.6.3]# zpool add zp1 log /dev/dfa1</font></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@localhost zfs-0.6.3]# zpool status</font></div><div><font size="2"   >&nbsp; pool: zp1</font></div><div><font size="2"   >&nbsp;state: ONLINE</font></div><div><font size="2"   >&nbsp; scan: none requested</font></div><div><font size="2"   >config:</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; NAME &nbsp; &nbsp; &nbsp; &nbsp;STATE &nbsp; &nbsp; READ WRITE CKSUM</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; zp1 &nbsp; &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdb &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdc &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdd &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sde &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdf &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdg &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdh &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdi &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdj &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdk &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdl &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdm &nbsp; &nbsp; &nbsp; ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; logs</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dfa1 &nbsp; &nbsp; &nbsp;ONLINE &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; 0 &nbsp; &nbsp; 0</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   >新增zfs</font></div><div><div><font size="2"   >[root@localhost zfs-0.6.3]# zfs create -o atime=off -o mountpoint=/data01 zp1/data01</font></div><div><font size="2"   >[root@localhost zfs-0.6.3]# df -h</font></div><div><font size="2"   >Filesystem &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Size &nbsp;Used Avail Use% Mounted on</font></div><div><font size="2"   >/dev/mapper/centos-root &nbsp; 50G &nbsp;1.7G &nbsp; 49G &nbsp; 4% /</font></div><div><font size="2"   >devtmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;16G &nbsp; &nbsp; 0 &nbsp; 16G &nbsp; 0% /dev</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 16G &nbsp; &nbsp; 0 &nbsp; 16G &nbsp; 0% /dev/shm</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 16G &nbsp;8.9M &nbsp; 16G &nbsp; 1% /run</font></div><div><font size="2"   >tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 16G &nbsp; &nbsp; 0 &nbsp; 16G &nbsp; 0% /sys/fs/cgroup</font></div><div><font size="2"   >/dev/mapper/centos-home &nbsp;173G &nbsp; 33M &nbsp;173G &nbsp; 1% /home</font></div><div><font size="2"   >/dev/sda3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;497M &nbsp; 96M &nbsp;401M &nbsp;20% /boot</font></div><div><font size="2"   >zp1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 43T &nbsp;128K &nbsp; 43T &nbsp; 1% /zp1</font></div><div><font size="2"   >zp1/data01 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;43T &nbsp;128K &nbsp; 43T &nbsp; 1% /data01</font></div></div><div><font size="2"   ><br></font></div><div><font size="2"   >测试</font></div><div><div><font size="2"   >[root@localhost zfs-0.6.3]# /opt/pgsql/bin/pg_test_fsync -f /data01/1</font></div><div><font size="2"   >5 seconds per test</font></div><div><font size="2"   >O_DIRECT supported on this platform for open_datasync and open_sync.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare file sync methods using one 8kB write:</font></div><div><font size="2"   >(in wal_sync_method preference order, except fdatasync</font></div><div><font size="2"   >is Linux's default)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_datasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a*</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fdatasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;6107.726 ops/sec &nbsp; &nbsp; 164 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;7016.477 ops/sec &nbsp; &nbsp; 143 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync_writethrough &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_sync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a*</font></div><div><font size="2"   >* This file system and its mount options do not support direct</font></div><div><font size="2"   >I/O, e.g. ext4 in journaled mode.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare file sync methods using two 8kB writes:</font></div><div><font size="2"   >(in wal_sync_method preference order, except fdatasync</font></div><div><font size="2"   >is Linux's default)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_datasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a*</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fdatasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;5602.343 ops/sec &nbsp; &nbsp; 178 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;8100.693 ops/sec &nbsp; &nbsp; 123 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync_writethrough &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_sync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a*</font></div><div><font size="2"   >* This file system and its mount options do not support direct</font></div><div><font size="2"   >I/O, e.g. ext4 in journaled mode.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare open_sync with different write sizes:</font></div><div><font size="2"   >(This is designed to compare the cost of writing 16kB</font></div><div><font size="2"   >in different write open_sync sizes.)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1 * 16kB open_sync write &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a*</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2 * &nbsp;8kB open_sync writes &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; n/a*</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4 * &nbsp;4kB open_sync writes &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; n/a*</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;8 * &nbsp;2kB open_sync writes &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; n/a*</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; 16 * &nbsp;1kB open_sync writes &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; n/a*</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Test if fsync on non-write file descriptor is honored:</font></div><div><font size="2"   >(If the times are similar, fsync() can sync data written</font></div><div><font size="2"   >on a different descriptor.)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write, fsync, close &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;6521.974 ops/sec &nbsp; &nbsp; 153 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write, close, fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;6672.833 ops/sec &nbsp; &nbsp; 150 usecs/op</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Non-Sync'ed 8kB writes:</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; write &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 82646.970 ops/sec &nbsp; &nbsp; &nbsp;12 usecs/op</font></div></div><div><font size="2"   ><br></font></div><div><div><font size="2"   >[root@localhost zfs-0.6.3]# dd if=/dev/zero of=/data01/1 obs=4K oflag=sync,nonblock,noatime,nocache count=1024000</font></div><div><font size="2"   >1024000+0 records in</font></div><div><font size="2"   >128000+0 records out</font></div><div><font size="2"   >524288000 bytes (524 MB) copied, 12.9542 s, 40.5 MB/s</font></div></div><p></p></pre></div><div>zfs直接使用机械盘测试, IOPS分布非常均匀.</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   >[root@localhost ~]# zpool remove zp1 /dev/dfa1</font></div><div><font size="2"   >[root@localhost ~]# /opt/pgsql/bin/pg_test_fsync -f /data01/1</font></div><div><font size="2"   >5 seconds per test</font></div><div><font size="2"   >O_DIRECT supported on this platform for open_datasync and open_sync.</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >Compare file sync methods using one 8kB write:</font></div><div><font size="2"   >(in wal_sync_method preference order, except fdatasync</font></div><div><font size="2"   >is Linux's default)</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; open_datasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;n/a*</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fdatasync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;8086.756 ops/sec &nbsp; &nbsp; 124 usecs/op</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; fsync &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;7312.509 ops/sec &nbsp; &nbsp; 137 usecs/op</font></div><div><br></div></div><div><div><font size="2"   >sdc &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 1094.00 &nbsp; &nbsp; 0.00 10940.00 &nbsp; &nbsp;20.00 &nbsp; &nbsp; 0.04 &nbsp; &nbsp;0.03 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.03 &nbsp; 0.03 &nbsp; 3.50</font></div><div><font size="2"   >sdb &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 1094.00 &nbsp; &nbsp; 0.00 10940.00 &nbsp; &nbsp;20.00 &nbsp; &nbsp; 0.03 &nbsp; &nbsp;0.03 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.03 &nbsp; 0.03 &nbsp; 3.10</font></div><div><font size="2"   >sdd &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 1094.00 &nbsp; &nbsp; 0.00 10940.00 &nbsp; &nbsp;20.00 &nbsp; &nbsp; 0.04 &nbsp; &nbsp;0.03 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.03 &nbsp; 0.03 &nbsp; 3.50</font></div><div><font size="2"   >sdh &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 1092.00 &nbsp; &nbsp; 0.00 10920.00 &nbsp; &nbsp;20.00 &nbsp; &nbsp; 0.04 &nbsp; &nbsp;0.04 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.04 &nbsp; 0.04 &nbsp; 4.20</font></div><div><font size="2"   >sdf &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 1094.00 &nbsp; &nbsp; 0.00 10940.00 &nbsp; &nbsp;20.00 &nbsp; &nbsp; 0.04 &nbsp; &nbsp;0.04 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.04 &nbsp; 0.03 &nbsp; 3.70</font></div><div><font size="2"   >sdi &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 1092.00 &nbsp; &nbsp; 0.00 10920.00 &nbsp; &nbsp;20.00 &nbsp; &nbsp; 0.03 &nbsp; &nbsp;0.03 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.03 &nbsp; 0.03 &nbsp; 3.10</font></div><div><font size="2"   >sdg &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 1094.00 &nbsp; &nbsp; 0.00 10940.00 &nbsp; &nbsp;20.00 &nbsp; &nbsp; 0.03 &nbsp; &nbsp;0.03 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.03 &nbsp; 0.03 &nbsp; 2.90</font></div><div><font size="2"   >sde &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 1094.00 &nbsp; &nbsp; 0.00 10940.00 &nbsp; &nbsp;20.00 &nbsp; &nbsp; 0.04 &nbsp; &nbsp;0.03 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.03 &nbsp; 0.03 &nbsp; 3.60</font></div><div><font size="2"   >sdl &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 1092.00 &nbsp; &nbsp; 0.00 10920.00 &nbsp; &nbsp;20.00 &nbsp; &nbsp; 0.02 &nbsp; &nbsp;0.02 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.02 &nbsp; 0.02 &nbsp; 2.10</font></div><div><font size="2"   >sdk &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 1094.00 &nbsp; &nbsp; 0.00 10940.00 &nbsp; &nbsp;20.00 &nbsp; &nbsp; 0.04 &nbsp; &nbsp;0.03 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.03 &nbsp; 0.03 &nbsp; 3.70</font></div><div><font size="2"   >sdm &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 1092.00 &nbsp; &nbsp; 0.00 10920.00 &nbsp; &nbsp;20.00 &nbsp; &nbsp; 0.03 &nbsp; &nbsp;0.03 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.03 &nbsp; 0.03 &nbsp; 3.00</font></div><div><font size="2"   >sdj &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 &nbsp; &nbsp; 0.00 &nbsp; &nbsp;0.00 1094.00 &nbsp; &nbsp; 0.00 10940.00 &nbsp; &nbsp;20.00 &nbsp; &nbsp; 0.04 &nbsp; &nbsp;0.04 &nbsp; &nbsp;0.00 &nbsp; &nbsp;0.04 &nbsp; 0.04 &nbsp; 3.90</font></div></div><p></p></pre></div><div><br></div>[参考]<wbr><div>1.&nbsp;<a style="line-height: 28px;" target="_blank" href="http://blog.163.com/digoal@126/blog/static/1638770402014699041427/"   >http://blog.163.com/digoal@126/blog/static/1638770402014699041427/</a></div><div>2.&nbsp;<a target="_blank" href="http://blog.163.com/digoal@126/blog/static/163877040201463101652528/"   >http://blog.163.com/digoal@126/blog/static/163877040201463101652528/</a></div><div>3.&nbsp;<a target="_blank" href="http://blog.163.com/digoal@126/blog/static/1638770402014528115551323/"   >http://blog.163.com/digoal@126/blog/static/1638770402014528115551323/</a></div><div>4.&nbsp;<a target="_blank" href="http://blog.163.com/digoal@126/blog/static/16387704020145264116819/"   >http://blog.163.com/digoal@126/blog/static/16387704020145264116819/</a></div><div>5.&nbsp;<a target="_blank" href="http://blog.163.com/digoal@126/blog/static/1638770402014526992910/"   >http://blog.163.com/digoal@126/blog/static/1638770402014526992910/</a></div><div>6.&nbsp;<a target="_blank" href="http://blog.163.com/digoal@126/blog/static/16387704020145198321025/"   >http://blog.163.com/digoal@126/blog/static/16387704020145198321025/</a></div><div>7.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="https://github.com/facebook/flashcache"   >https://github.com/facebook/flashcache</a></div><div>8.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Logical_Volume_Manager_Administration/LV.html#LV_stripecreate"   >https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Logical_Volume_Manager_Administration/LV.html#LV_stripecreate</a></div>
<a rel="nofollow" href="http://info.flagcounter.com/h9V1"   ><img title="CentOS 7 lvm cache dev VS zfs VS flashcache VS bcache VS direct SSD - 德哥@Digoal - PostgreSQL research"   src="http://s03.flagcounter.com/count/h9V1/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_12/viewers_0/labels_0/pageviews_0/flags_0/"   alt="Flag Counter"   border="0"   ></a></div>
	</div>
</div>
</body>
</html>