<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">PostgreSQL HA manual with shared disk use RHCS - 1</h2>
	<h5 id="">2014-09-10 20:55:19&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/163877040201481085344535/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;"><div>应朋友要求, 写一篇RHCS利用共享存储的PostgreSQL HA部署手册 :&nbsp;</div><div><span style="line-height: 28px;"   >集群环境:&nbsp;</span></div><div>2台X86服务器, 共享存储.</div><div>操作系统要求: CentOS 6.5 x64</div><div>数据库版本要求: PostgreSQL 9.3.5</div><div>共享存储要求: 配置多路径</div><div>网络要求:&nbsp;</div><div>&nbsp; &nbsp; 两台主机在同一局域网内, 并且允许发送和接收多播包.</div><div>fence设备要求:</div><div>&nbsp; &nbsp; fence设备和主机网络在同一局域网内, 并且可以互通.</div><div>&nbsp; &nbsp; fence设备支持ipmi接口, 允许使用ipmi命令开关机.</div><div><br></div><div>安装依赖包:&nbsp;</div><div><pre class="prettyprint"   ><p><font size="2"   >yum -y install glib2 lrzsz sysstat e4fsprogs xfsprogs ntp readline-devel zlib zlib-devel openssl openssl-devel pam-devel libxml2-devel libxslt-devel python-devel tcl-devel gcc make smartmontools flex bison perl perl-devel perl-ExtUtils* OpenIPMI-tools openldap openldap-devel cluster rgmanager* cman* lvm2* gfs2* cmirror ccs device-mapper-multipath</font></p></pre></div><div><br></div><div>磁盘规划:&nbsp;</div><div>以下目录建议使用独立的块设备. pg_xlog要求极好的IOPS能力.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >pg_xlog, 400GB</font></div><div><font size="2"   >pg_arch, pg_log, 2TB</font></div><div><font size="2"   >$PGDATA, 100GB</font></div><div><font size="2"   >tablespace dir, 1TB/dir</font></div><div><font size="2"   >default tablespace dir, 1TB</font></div><div><font size="2"   >default temp tablespace dir, 1TB</font></div><p></p></pre></div><div><br></div><div><div>目录结构和挂载示例 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >/dev/mapper/vgdata01-lv01 &nbsp;/data01 &nbsp;pg_xlog &nbsp;400GB</font></div><div><font size="2"   >/dev/mapper/vgdata01-lv02 &nbsp;/data02 &nbsp;$PGDATA &nbsp;100GB</font></div><div><font size="2"   >/dev/mapper/vgdata01-lv03 &nbsp;/data03 &nbsp;tbs_dir1 1TB</font></div><div><font size="2"   >/dev/mapper/vgdata01-lv04 &nbsp;/data04 &nbsp;tbs_dir2 1TB</font></div><div><font size="2"   >/dev/mapper/vgdata01-lv05 &nbsp;/data05 &nbsp;pg_arch, pg_log 2TB</font></div><p></p></pre></div><div>.... 表空间扩展后说(顺序可添加块设备, 新建PV, 扩展VG, 扩展LV, 扩展文件系统)</div><div><br></div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >/data01/pgdata/pg_xlog</font></div><div><font size="2"   >/data02/pgdata/pg_root</font></div><div><font size="2"   >/data03/pgdata/pg_tbs/tbs_def</font></div><div><font size="2"   >/data03/pgdata/pg_tbs/tbs_tmp1</font></div><div><font size="2"   >/data03/pgdata/pg_tbs/tbs1</font></div><div><font size="2"   >/data04/pgdata/pg_tbs/tbs2</font></div><div><font size="2"   >/data05/pgdata/pg_tbs/pg_arch</font></div><div><font size="2"   >/data05/pgdata/pg_tbs/pg_log</font></div><div><font size="2"   >chown -R postgres:postgres /data0*/pgdata</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >postgresql.conf</font></div><div><font size="2"   >default_tablespace = 'tbs_def' &nbsp;# on /data04</font></div><div><font size="2"   >temp_tablespaces = 'tbs_tmp1' &nbsp; # on /data04</font></div><p></p></pre></div></div><div><br></div><div>安装步骤:</div><div>(实际主机IP地址和FENCE设备地址请更改)</div><div><br></div><div>安装必要的包 :&nbsp;</div><div><pre class="prettyprint"   ><p><font size="2"   >yum install -y glib2 lrzsz sysstat e4fsprogs xfsprogs ntp readline-devel zlib zlib-devel openssl openssl-devel pam-devel libxml2-devel libxslt-devel python-devel tcl-devel gcc make smartmontools flex bison perl perl-devel perl-ExtUtils* OpenIPMI-tools openldap openldap-devel cluster rgmanager* cman* lvm2* gfs2* cmirror ccs device-mapper-multipath</font></p></pre></div><div><br></div><div>关闭这两台主机的高级电源管理服务, 方便fence.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># chkconfig acpid off</font></div><div></div><p></p></pre></div><div>系统配置:</div><div>时钟同步, 如果不能访问外网, 可以与局域网内部的时钟服务器同步.</div><div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># crontab -e</font></div><div><font size="2"   >&nbsp; -- 8 * * * * /usr/sbin/ntpdate asia.pool.ntp.org &amp;&amp; /sbin/hwclock --systohc</font></div><div><font size="2"   >/usr/sbin/ntpdate asia.pool.ntp.org &amp;&amp; /sbin/hwclock --systohc</font></div><p></p></pre></div><div><br></div><div>修改时区</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># vi /etc/sysconfig/clock&nbsp;</font></div><div><font size="2"   >&nbsp; -- ZONE="Asia/Shanghai"</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;UTC=false</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp;ARC=false</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ># rm /etc/localtime&nbsp;</font></div><div><font size="2"   ># cp /usr/share/zoneinfo/PRC /etc/localtime</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ># vi /etc/sysconfig/i18n</font></div><div><font size="2"   >&nbsp; -- LANG="en_US.UTF-8"</font></div><p></p></pre></div><div><br></div><div>关闭不必要的服务</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >chkconfig acpid off</font></div><div><font size="2"   >chkconfig avahi-daemon off</font></div><div><font size="2"   >chkconfig bluetooth off</font></div><div><font size="2"   >chkconfig hidd off</font></div><div><font size="2"   >chkconfig smartd off</font></div><div><font size="2"   >chkconfig yum-updatesd off</font></div><div><font size="2"   >chkconfig hplip off</font></div><div><font size="2"   >chkconfig isdn off</font></div><div><font size="2"   >chkconfig iscsi off</font></div><div><font size="2"   >chkconfig iscsid off</font></div><div><font size="2"   >chkconfig multipathd on</font></div><p></p></pre></div><div><br></div><div>关闭公钥认证</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># vi /etc/ssh/sshd_config</font></div><div><font size="2"   >UseDNS no</font></div><div><font size="2"   >PubkeyAuthentication no</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ># vi /etc/ssh/ssh_config</font></div><div><font size="2"   >GSSAPIAuthentication no</font></div><p></p></pre></div><div><br></div><div>修改内核参数以及资源限制 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># vi /etc/sysctl.conf</font></div><div><font size="2"   >kernel.shmmni = 4096</font></div><div><font size="2"   >kernel.sem = 50100 64128000 50100 1280</font></div><div><font size="2"   >fs.file-max = 7672460</font></div><div><font size="2"   >net.ipv4.ip_local_port_range = 9000 65000</font></div><div><font size="2"   >net.core.rmem_default = 1048576</font></div><div><font size="2"   >net.core.rmem_max = 4194304</font></div><div><font size="2"   >net.core.wmem_default = 262144</font></div><div><font size="2"   >net.core.wmem_max = 1048576</font></div><div><font size="2"   >net.ipv4.tcp_tw_recycle = 1</font></div><div><font size="2"   >net.ipv4.tcp_max_syn_backlog = 4096</font></div><div><font size="2"   >net.core.netdev_max_backlog = 10000</font></div><div><font size="2"   >vm.overcommit_memory = 0</font></div><div><font size="2"   >net.ipv4.ip_conntrack_max = 655360</font></div><div><font size="2"   >fs.aio-max-nr = 1048576</font></div><div><font size="2"   >net.ipv4.tcp_timestamps = 0</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ># sysctl -p</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ># vi /etc/security/limits.conf</font></div><div><font size="2"   >* soft &nbsp; &nbsp;nofile &nbsp;131072</font></div><div><font size="2"   >* hard &nbsp; &nbsp;nofile &nbsp;131072</font></div><div><font size="2"   >* soft &nbsp; &nbsp;nproc &nbsp; 131072</font></div><div><font size="2"   >* hard &nbsp; &nbsp;nproc &nbsp; 131072</font></div><div><font size="2"   >* soft &nbsp; &nbsp;core &nbsp; &nbsp;unlimited</font></div><div><font size="2"   >* hard &nbsp; &nbsp;core &nbsp; &nbsp;unlimited</font></div><div><font size="2"   >* soft &nbsp; &nbsp;memlock 50000000</font></div><div><font size="2"   >* hard &nbsp; &nbsp;memlock 50000000</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ># vi /etc/security/limits.d/90-nproc.conf&nbsp;</font></div><div><font size="2"   ># 注释以下2行</font></div><div><div><font size="2"   >#* &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;soft &nbsp; &nbsp;nproc &nbsp; &nbsp; 1024</font></div><div><font size="2"   >#root &nbsp; &nbsp; &nbsp; soft &nbsp; &nbsp;nproc &nbsp; &nbsp; unlimited</font></div><div><font size="2"   >* soft &nbsp; &nbsp;nproc &nbsp; 131072</font></div><div><font size="2"   >* hard &nbsp; &nbsp;nproc &nbsp; 131073</font></div></div><p></p></pre></div><div><br></div><div>关闭selinux</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># vi /etc/sysconfig/selinux</font></div><div><font size="2"   >SELINUX=disabled</font></div><p></p></pre></div><div><br></div><div>配置防火墙 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><div><font size="2"   ># vi /etc/sysconfig/iptables</font></div><div><font size="2"   ># 开启集群中主机的相互访问, 需要访问数据库端口的应用的访问权限等, 例如 :&nbsp;</font></div></div><div><div><font size="2"   ># cat /etc/sysconfig/iptables</font></div><div><font size="2"   ># Firewall configuration written by system-config-firewall</font></div><div><font size="2"   ># Manual customization of this file is not recommended.</font></div><div><font size="2"   >*filter</font></div><div><font size="2"   >:INPUT ACCEPT [0:0]</font></div><div><font size="2"   >:FORWARD ACCEPT [0:0]</font></div><div><font size="2"   >:OUTPUT ACCEPT [0:0]</font></div><div><font size="2"   >-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT</font></div><div><font size="2"   >-A INPUT -p icmp -j ACCEPT</font></div><div><font size="2"   >-A INPUT -i lo -j ACCEPT</font></div><div><font size="2"   >-A INPUT -s 192.168.0.0/16 -j ACCEPT</font></div><div><font size="2"   >-A INPUT -s 10.0.0.0/8 -j ACCEPT</font></div><div><font size="2"   >-A INPUT -s 172.16.0.0/16 -j ACCEPT</font></div><div><font size="2"   >-A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT</font></div><div><font size="2"   >-A INPUT -j REJECT --reject-with icmp-host-prohibited</font></div><div><font size="2"   >-A FORWARD -j REJECT --reject-with icmp-host-prohibited</font></div><div><font size="2"   >COMMIT</font></div></div><p></p></pre></div></div><div><br></div><div>创建cluster.conf配置文件. 如果配置文件已经存在的话会覆盖掉. 集群名yumpg001.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 ~]# ccs -f /etc/cluster/cluster.conf --createcluster yumpg001</font></div><div></div><p></p></pre></div><div>添加两台主机.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addnode 192.168.10.146</font></div><div><font size="2"   >Node 192.168.10.146 added.</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addnode 192.168.10.150</font></div><div><font size="2"   >Node 192.168.10.150 added.</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --lsnodes</font></div><div><font size="2"   >192.168.10.146: nodeid=1</font></div><div><font size="2"   >192.168.10.150: nodeid=2</font></div><p></p></pre></div><div><br></div><div>添加完后, 配置文件如下</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# cat /etc/cluster/cluster.conf&nbsp;</font></div><div><font size="2"   >&lt;cluster config_version="3" name="yumpg001"&gt;</font></div><div><font size="2"   >&nbsp; &lt;fence_daemon/&gt;</font></div><div><font size="2"   >&nbsp; &lt;clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.146" nodeid="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.150" nodeid="2"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &lt;cman/&gt;</font></div><div><font size="2"   >&nbsp; &lt;fencedevices/&gt;</font></div><div><font size="2"   >&nbsp; &lt;rm&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;failoverdomains/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;resources/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/rm&gt;</font></div><div><font size="2"   >&lt;/cluster&gt;</font></div><p></p></pre></div><div><br></div><div>为两台主机添加两个fence方法, 方法名字随意.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addmethod BMC 192.168.10.146</font></div><div><font size="2"   >Method BMC added to 192.168.10.146.</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addmethod BMC 192.168.10.150</font></div><div><font size="2"   >Method BMC added to 192.168.10.150.</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# cat /etc/cluster/cluster.conf&nbsp;</font></div><div><font size="2"   >&lt;cluster config_version="5" name="yumpg001"&gt;</font></div><div><font size="2"   >&nbsp; &lt;fence_daemon/&gt;</font></div><div><font size="2"   >&nbsp; &lt;clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.146" nodeid="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.150" nodeid="2"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &lt;/clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &lt;cman/&gt;</font></div><div><font size="2"   >&nbsp; &lt;fencedevices/&gt;</font></div><div><font size="2"   >&nbsp; &lt;rm&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;failoverdomains/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;resources/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/rm&gt;</font></div><div><font size="2"   >&lt;/cluster&gt;</font></div><p></p></pre></div><div><br></div><div>设置fence的属性, fail延迟和加入延迟.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --setfencedaemon post_fail_delay=6 post_join_delay=30</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# cat /etc/cluster/cluster.conf&nbsp;</font></div><div><font size="2"   >&lt;cluster config_version="8" name="yumpg001"&gt;</font></div><div><font size="2"   >&nbsp; &lt;fence_daemon post_fail_delay="6" post_join_delay="30"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.146" nodeid="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.150" nodeid="2"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &lt;/clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &lt;cman/&gt;</font></div><div><font size="2"   >&nbsp; &lt;fencedevices/&gt;</font></div><div><font size="2"   >&nbsp; &lt;rm&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;failoverdomains/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;resources/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/rm&gt;</font></div><div><font size="2"   >&lt;/cluster&gt;</font></div><p></p></pre></div><div><br></div><div>配置服务器的ipmi接口.</div><div>一般在bios或WEB中可以配置, 注意开启用户的ipmi功能, 选择适当的角色.&nbsp;</div><div>以两台联想的服务器为例, 角色设置为OPERATOR.</div><div>测试ipmi管理是否正常 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-150 ~]# fence_ipmilan -a 192.168.9.66 -l user2014 -p abc -o status -L OPERATOR</font></div><div><font size="2"   >Getting status of IPMI:192.168.9.66...Chassis power = On</font></div><div><font size="2"   >Done</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@db-192-168-10-150 ~]# fence_ipmilan -a 192.168.9.72 -l user -p abc -o status -L OPERATOR</font></div><div><font size="2"   >Getting status of IPMI:192.168.9.72...Chassis power = On</font></div><div><font size="2"   >Done</font></div><p></p></pre></div><div><br></div><div>查看操作系统支持的fence设备, 以及fence设备对应的配置项.</div><div>这里用到的agent为fence_ipmilan</div><div>添加两个fence设备, 对应的用户密码等属性. fence设备的名称注意区分, 分别用于两台主机的fence.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addfencedev fence_146 agent=fence_ipmilan ipaddr=192.168.9.66 login=user2014 passwd=abc privlvl=OPERATOR</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addfencedev fence_150 agent=fence_ipmilan ipaddr=192.168.9.72 login=user passwd=abc privlvl=OPERATOR</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# cat /etc/cluster/cluster.conf&nbsp;</font></div><div><font size="2"   >&lt;cluster config_version="10" name="yumpg001"&gt;</font></div><div><font size="2"   >&nbsp; &lt;fence_daemon post_fail_delay="6" post_join_delay="30"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.146" nodeid="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.150" nodeid="2"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &lt;/clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &lt;cman/&gt;</font></div><div><font size="2"   >&nbsp; &lt;fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ipmilan" ipaddr="192.168.9.66" login="user2014" name="fence_146" passwd="abc" privlvl="OPERATOR"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ipmilan" ipaddr="192.168.9.72" login="user" name="fence_150" passwd="abc" privlvl="OPERATOR"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &lt;rm&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;failoverdomains/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;resources/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/rm&gt;</font></div><div><font size="2"   >&lt;/cluster&gt;</font></div><p></p></pre></div><div><br></div><div>为每台主机添加对应的fence操作, 注意对应的fence设备名, 是上一步添加的fence设备名.</div><div>我们这里使用到的是action=off和action=on, 用于关机和开机.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addfenceinst fence_146 192.168.10.146 BMC action=off</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addfenceinst fence_146 192.168.10.146 BMC action=on</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addfenceinst fence_150 192.168.10.150 BMC action=off</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addfenceinst fence_150 192.168.10.150 BMC action=on</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# cat /etc/cluster/cluster.conf&nbsp;</font></div><div><font size="2"   >&lt;cluster config_version="12" name="yumpg001"&gt;</font></div><div><font size="2"   >&nbsp; &lt;fence_daemon post_fail_delay="6" post_join_delay="30"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.146" nodeid="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="off" name="fence_146"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="on" name="fence_146"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.150" nodeid="2"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="off" name="fence_150"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="on" name="fence_150"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &lt;/clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &lt;cman/&gt;</font></div><div><font size="2"   >&nbsp; &lt;fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ipmilan" ipaddr="192.168.9.66" login="user2014" name="fence_146" passwd="abc" privlvl="OPERATOR"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ipmilan" ipaddr="192.168.9.72" login="user" name="fence_150" passwd="abc" privlvl="OPERATOR"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &lt;rm&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;failoverdomains/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;resources/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/rm&gt;</font></div><div><font size="2"   >&lt;/cluster&gt;</font></div><p></p></pre></div><div><br></div><div>新建failover域:&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addfailoverdomain yumpg001_fd restricted ordered nofailback</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# cat /etc/cluster/cluster.conf&nbsp;</font></div><div><font size="2"   >&lt;cluster config_version="13" name="yumpg001"&gt;</font></div><div><font size="2"   >&nbsp; &lt;fence_daemon post_fail_delay="6" post_join_delay="30"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.146" nodeid="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="off" name="fence_146"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="on" name="fence_146"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.150" nodeid="2"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="off" name="fence_150"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="on" name="fence_150"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &lt;/clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &lt;cman/&gt;</font></div><div><font size="2"   >&nbsp; &lt;fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ipmilan" ipaddr="192.168.9.66" login="user2014" name="fence_146" passwd="abc" privlvl="OPERATOR"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ipmilan" ipaddr="192.168.9.72" login="user" name="fence_150" passwd="abc" privlvl="OPERATOR"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &lt;rm&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;failoverdomains&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;failoverdomain name="yumpg001_fd" nofailback="1" ordered="1" restricted="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/failoverdomains&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;resources/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/rm&gt;</font></div><div><font size="2"   >&lt;/cluster&gt;</font></div><p></p></pre></div><div><br></div><div>把两台主机添加到failover域:&nbsp;</div><div>优先级都设置为1.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addfailoverdomainnode yumpg001_fd 192.168.10.146 1</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addfailoverdomainnode yumpg001_fd 192.168.10.150 1</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# cat /etc/cluster/cluster.conf&nbsp;</font></div><div><font size="2"   >&lt;cluster config_version="15" name="yumpg001"&gt;</font></div><div><font size="2"   >&nbsp; &lt;fence_daemon post_fail_delay="6" post_join_delay="30"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.146" nodeid="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="off" name="fence_146"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="on" name="fence_146"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.150" nodeid="2"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="off" name="fence_150"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="on" name="fence_150"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &lt;/clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &lt;cman/&gt;</font></div><div><font size="2"   >&nbsp; &lt;fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ipmilan" ipaddr="192.168.9.66" login="user2014" name="fence_146" passwd="abc" privlvl="OPERATOR"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ipmilan" ipaddr="192.168.9.72" login="user" name="fence_150" passwd="abc" privlvl="OPERATOR"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &lt;rm&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;failoverdomains&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;failoverdomain name="yumpg001_fd" nofailback="1" ordered="1" restricted="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;failoverdomainnode name="192.168.10.146" priority="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;failoverdomainnode name="192.168.10.150" priority="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/failoverdomain&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/failoverdomains&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;resources/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/rm&gt;</font></div><div><font size="2"   >&lt;/cluster&gt;</font></div><p></p></pre></div><div><br></div><div>列出系统支持的资源, 以及资源对应的配置项.</div><div>添加虚拟IP资源.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addresource ip address=192.168.10.151 monitor_link=1</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# cat /etc/cluster/cluster.conf&nbsp;</font></div><div><font size="2"   >&lt;cluster config_version="20" name="yumpg001"&gt;</font></div><div><font size="2"   >&nbsp; &lt;fence_daemon post_fail_delay="6" post_join_delay="30"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.146" nodeid="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="off" name="fence_146"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="on" name="fence_146"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.150" nodeid="2"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="off" name="fence_150"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="on" name="fence_150"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &lt;/clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &lt;cman/&gt;</font></div><div><font size="2"   >&nbsp; &lt;fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ipmilan" ipaddr="192.168.9.66" login="user2014" name="fence_146" passwd="abc" privlvl="OPERATOR"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ipmilan" ipaddr="192.168.9.72" login="user" name="fence_150" passwd="abc" privlvl="OPERATOR"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &lt;rm&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;failoverdomains&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;failoverdomain name="yumpg001_fd" nofailback="1" ordered="1" restricted="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;failoverdomainnode name="192.168.10.146" priority="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;failoverdomainnode name="192.168.10.150" priority="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/failoverdomain&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/failoverdomains&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;resources&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;ip address="192.168.10.151" monitor_link="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/resources&gt;</font></div><div><font size="2"   >&nbsp; &lt;/rm&gt;</font></div><div><font size="2"   >&lt;/cluster&gt;</font></div><p></p></pre></div><div><br></div><div>添加服务:&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addservice yumpg001_pg domain=yumpg001_fd autostart=0&nbsp;</font></div><div></div><p></p></pre></div><div>在上一步添加的服务中, 添加子服务, 即资源.&nbsp;</div><div>把IP资源作为子服务添加到这个服务下.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --addsubservice yumpg001_pg ip ref=192.168.10.151</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# cat /etc/cluster/cluster.conf&nbsp;</font></div><div><font size="2"   >&lt;cluster config_version="27" name="yumpg001"&gt;</font></div><div><font size="2"   >&nbsp; &lt;fence_daemon post_fail_delay="6" post_join_delay="30"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.146" nodeid="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="off" name="fence_146"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="on" name="fence_146"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.150" nodeid="2"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="off" name="fence_150"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="on" name="fence_150"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &lt;/clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &lt;cman/&gt;</font></div><div><font size="2"   >&nbsp; &lt;fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ipmilan" ipaddr="192.168.9.66" login="user2014" name="fence_146" passwd="abc" privlvl="OPERATOR"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ipmilan" ipaddr="192.168.9.72" login="user" name="fence_150" passwd="abc" privlvl="OPERATOR"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &lt;rm&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;failoverdomains&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;failoverdomain name="yumpg001_fd" nofailback="1" ordered="1" restricted="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;failoverdomainnode name="192.168.10.146" priority="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;failoverdomainnode name="192.168.10.150" priority="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/failoverdomain&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/failoverdomains&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;resources&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;ip address="192.168.10.151" monitor_link="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/resources&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;service autostart="0" domain="yumpg001_fd" name="yumpg001_pg"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;ip ref="192.168.10.151"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/service&gt;</font></div><div><font size="2"   >&nbsp; &lt;/rm&gt;</font></div><div><font size="2"   >&lt;/cluster&gt;</font></div><p></p></pre></div><div><br></div><div>设置cluster management的参数, 因为集群只有2台主机, 投票时单节点无法满足超过一半的票数.</div><div>需要设置这里的CMAN属性为2节点, 期望票数为1.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --setcman two_node=1 expected_votes=1</font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# cat /etc/cluster/cluster.conf&nbsp;</font></div><div><font size="2"   >&lt;cluster config_version="2" name="yumpg001"&gt;</font></div><div><font size="2"   >&nbsp; &lt;fence_daemon post_fail_delay="6" post_join_delay="30"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.146" nodeid="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="off" name="fence_146"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="on" name="fence_146"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;clusternode name="192.168.10.150" nodeid="2"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;method name="BMC"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="off" name="fence_150"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;device action="on" name="fence_150"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;/method&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/fence&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/clusternode&gt;</font></div><div><font size="2"   >&nbsp; &lt;/clusternodes&gt;</font></div><div><font size="2"   >&nbsp; &lt;cman expected_votes="1" two_node="1"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ipmilan" ipaddr="192.168.9.66" login="user2014" name="fence_146" passwd="abc" privlvl="OPERATOR"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;fencedevice agent="fence_ipmilan" ipaddr="192.168.9.72" login="user" name="fence_150" passwd="abc" privlvl="OPERATOR"/&gt;</font></div><div><font size="2"   >&nbsp; &lt;/fencedevices&gt;</font></div><div><font size="2"   >&nbsp; &lt;rm&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;failoverdomains&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;failoverdomain name="yumpg001_fd" nofailback="1" ordered="1" restricted="1"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;failoverdomainnode name="192.168.10.146" priority="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &lt;failoverdomainnode name="192.168.10.150" priority="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;/failoverdomain&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/failoverdomains&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;resources&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;ip address="192.168.10.151" monitor_link="1"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/resources&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;service autostart="0" domain="yumpg001_fd" name="yumpg001_pg"&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &lt;ip ref="192.168.10.151"/&gt;</font></div><div><font size="2"   >&nbsp; &nbsp; &lt;/service&gt;</font></div><div><font size="2"   >&nbsp; &lt;/rm&gt;</font></div><div><font size="2"   >&lt;/cluster&gt;</font></div><p></p></pre></div><div><br></div><div>开启所有组件的日志</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ccs -f /etc/cluster/cluster.conf --setlogging</font></div><div></div><p></p></pre></div><div>把/etc/cluster/cluster.conf拷贝到集群中的另一台主机上.</div><div><br></div><div>确保两台主机可以相互通信, 如果开启了iptables 的话, 需要配置一下防火墙(iptables).</div><div>例如 :&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># cat /etc/sysconfig/iptables</font></div><div><font size="2"   ># Firewall configuration written by system-config-firewall</font></div><div><font size="2"   ># Manual customization of this file is not recommended.</font></div><div><font size="2"   >*filter</font></div><div><font size="2"   >:INPUT ACCEPT [0:0]</font></div><div><font size="2"   >:FORWARD ACCEPT [0:0]</font></div><div><font size="2"   >:OUTPUT ACCEPT [0:0]</font></div><div><font size="2"   >-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT</font></div><div><font size="2"   >-A INPUT -p icmp -j ACCEPT</font></div><div><font size="2"   >-A INPUT -i lo -j ACCEPT</font></div><div><font size="2"   >-A INPUT -s 192.168.0.0/16 -j ACCEPT</font></div><div><font size="2"   >-A INPUT -s 10.0.0.0/8 -j ACCEPT</font></div><div><font size="2"   >-A INPUT -s 172.16.0.0/16 -j ACCEPT</font></div><div><font size="2"   >-A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT</font></div><div><font size="2"   >-A INPUT -j REJECT --reject-with icmp-host-prohibited</font></div><div><font size="2"   >-A FORWARD -j REJECT --reject-with icmp-host-prohibited</font></div><div><font size="2"   >COMMIT</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ># service iptables reload</font></div><div><font size="2"   >iptables: Trying to reload firewall rules: [ &nbsp;OK &nbsp;]</font></div><p></p></pre></div><div><br></div><div>然后两个节点同时启动cman服务, 注意是同时, 否则另一个节点会因为加入延迟超时被fence掉.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# service cman start</font></div><div><font size="2"   >Starting cluster:&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp;Checking if cluster has been disabled at boot... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Checking Network Manager... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Global setup... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Loading kernel modules... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Mounting configfs... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting cman... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Waiting for quorum... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting fenced... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting dlm_controld... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Tuning DLM kernel config... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting gfs_controld... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Unfencing self... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Joining fence domain... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@db-192-168-10-150 ~]# service cman start</font></div><div><font size="2"   >Starting cluster:&nbsp;</font></div><div><font size="2"   >&nbsp; &nbsp;Checking if cluster has been disabled at boot... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Checking Network Manager... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Global setup... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Loading kernel modules... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Mounting configfs... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting cman... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Waiting for quorum... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting fenced... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting dlm_controld... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Tuning DLM kernel config... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Starting gfs_controld... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Unfencing self... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >&nbsp; &nbsp;Joining fence domain... [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >[root@db-192-168-10-150 ~]# service rgmanager start</font></div><div><font size="2"   >Starting Cluster Service Manager: [ &nbsp;OK &nbsp;]</font></div><p></p></pre></div><div><br></div><div>2个节点都启动资源管理服务</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# service rgmanager start</font></div><div><font size="2"   >Starting Cluster Service Manager: [ &nbsp;OK &nbsp;]</font></div><p></p></pre></div><div><br></div><div>查看集群状态</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# clustat</font></div><div><font size="2"   >Cluster Status for yumpg001 @ Wed May 28 10:18:16 2014</font></div><div><font size="2"   >Member Status: Quorate</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp;Member Name &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ID &nbsp; Status</font></div><div><font size="2"   >&nbsp;------ ---- &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ---- ------</font></div><div><font size="2"   >&nbsp;192.168.10.146 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1 Online, Local, rgmanager</font></div><div><font size="2"   >&nbsp;192.168.10.150 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2 Online, rgmanager</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp;Service Name &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Owner (Last) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; State &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp;------- ---- &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ----- ------ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ----- &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp;service:yumpg001_pg &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (none) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; disabled &nbsp; &nbsp; &nbsp;</font></div><p></p></pre></div><div><br></div><div>使用clusvcadm启动服务.</div><div>我们这里的服务yumpg001_pg中只包含了1个虚拟IP地址资源.</div><div><br></div><div>服务启动后, 这个虚拟IP就跑在某台主机上了.&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# clusvcadm -e yumpg001_pg</font></div><div><font size="2"   >Local machine trying to enable service:yumpg001_pg...Success</font></div><div><font size="2"   >service:yumpg001_pg is now running on 192.168.10.146</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >[root@db-192-168-10-146 yum.repos.d]# ping 192.168.10.151</font></div><div><font size="2"   >PING 192.168.10.151 (192.168.10.151) 56(84) bytes of data.</font></div><div><font size="2"   >64 bytes from 192.168.10.151: icmp_seq=1 ttl=64 time=0.077 ms</font></div><div><font size="2"   >64 bytes from 192.168.10.151: icmp_seq=2 ttl=64 time=0.032 ms</font></div><p></p></pre></div><div><br></div><div>切换测试, 把主节点的</div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-146 ~]# ifdown eth0</font></div><div></div><p></p></pre><div><span style="line-height: 28px;"   >查看另一台主机的日志</span></div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-150 ~]# tail -f -n 1 /var/log/messages</font></div><div><font size="2"   >May 28 13:31:30 db-192-168-10-150 rgmanager[2534]: State change: 192.168.10.146 UP</font></div><div><font size="2"   >May 28 13:33:31 db-192-168-10-150 corosync[2272]: &nbsp; [TOTEM ] A processor failed, forming new configuration.</font></div><div><font size="2"   >May 28 13:33:33 db-192-168-10-150 corosync[2272]: &nbsp; [QUORUM] Members[1]: 2</font></div><div><font size="2"   >May 28 13:33:33 db-192-168-10-150 corosync[2272]: &nbsp; [TOTEM ] A processor joined or left the membership and a new membership was formed.</font></div><div><font size="2"   >May 28 13:33:33 db-192-168-10-150 rgmanager[2534]: State change: 192.168.10.146 DOWN</font></div><div><font size="2"   >May 28 13:33:33 db-192-168-10-150 corosync[2272]: &nbsp; [CPG &nbsp; ] chosen downlist: sender r(0) ip(192.168.10.150) ; members(old:2 left:1)</font></div><div><font size="2"   >May 28 13:33:33 db-192-168-10-150 kernel: dlm: closing connection to node 1</font></div><div><font size="2"   >May 28 13:33:33 db-192-168-10-150 corosync[2272]: &nbsp; [MAIN &nbsp;] Completed service synchronization, ready to provide service.</font></div><div><font size="2"   >May 28 13:33:39 db-192-168-10-150 fenced[2327]: fencing node 192.168.10.146</font></div><div><font size="2"   >May 28 13:33:54 db-192-168-10-150 fenced[2327]: fence 192.168.10.146 success</font></div><div><font size="2"   >May 28 13:33:55 db-192-168-10-150 rgmanager[2534]: Taking over service service:yumpg001_pg from down member 192.168.10.146</font></div><div><font size="2"   >May 28 13:33:55 db-192-168-10-150 rgmanager[3479]: [ip] Adding IPv4 address 192.168.10.151/24 to eth0</font></div><div><font size="2"   >May 28 13:33:58 db-192-168-10-150 rgmanager[2534]: Service service:yumpg001_pg started</font></div><p></p></pre></div><div>fence成功后, 服务yumpg001_pg 切换到这台主机了.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-150 ~]# clustat</font></div><div><font size="2"   >Cluster Status for yumpg001 @ Wed May 28 10:22:37 2014</font></div><div><font size="2"   >Member Status: Quorate</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp;Member Name &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ID &nbsp; Status</font></div><div><font size="2"   >&nbsp;------ ---- &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ---- ------</font></div><div><font size="2"   >&nbsp;192.168.10.146 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1 Offline</font></div><div><font size="2"   >&nbsp;192.168.10.150 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2 Online, Local, rgmanager</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp;Service Name &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Owner (Last) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; State &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp;------- ---- &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ----- ------ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ----- &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp;service:yumpg001_pg &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 192.168.10.150 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;started</font></div><p></p></pre></div><div><br></div><div>这个例子的fence包含了关机和开机操作, 所以一段时间后可以看到被fence掉的主机重启了.</div><div>重启后, 我们需要做的是把它的cman和rgmanager服务开启来.&nbsp;</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># service cman start</font></div><div><font size="2"   ># service rgmanager start</font></div><p></p></pre></div><div>然后看这个集群的状态</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@db-192-168-10-150 ~]# clustat</font></div><div><font size="2"   >Cluster Status for yumpg001 @ Wed May 28 10:29:42 2014</font></div><div><font size="2"   >Member Status: Quorate</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp;Member Name &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ID &nbsp; Status</font></div><div><font size="2"   >&nbsp;------ ---- &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ---- ------</font></div><div><font size="2"   >&nbsp;192.168.10.146 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1 Online</font></div><div><font size="2"   >&nbsp;192.168.10.150 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2 Online, Local, rgmanager</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >&nbsp;Service Name &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Owner (Last) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; State &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp;------- ---- &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ----- ------ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ----- &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</font></div><div><font size="2"   >&nbsp;service:yumpg001_pg &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 192.168.10.150 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;started</font></div><p></p></pre></div><div>到这里, HA就搭建完成了.</div><div><br></div><div><br></div><div>接下来配置存储和数据库, 并将数据库添加到HA里面来.</div><div><br></div><div>配置块设备多路径软件(略)</div><div>参考multipathd或厂商手册.</div><div><br></div><div>配置multipath参考例子:</div><div>CentOS 5.x, 使用scsi_id得到wwn</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   ># for i in `cat /proc/partitions | awk '{print $4}' |grep sd`; do echo "### $i: `scsi_id -g -u -s /block/$i`"; done</font></div><div><font size="2"   >### sda: 36001438005de97860000b00000d20000</font></div><div><font size="2"   >### sdb: 36001438005de97860000b00000d60000</font></div><div><font size="2"   >### sdc: 36001438005de97860000b00000d20000</font></div><div><font size="2"   >### sdd: 36001438005de97860000b00000d60000</font></div><div><font size="2"   >### sde: 36001438005de97860000b00000d20000</font></div><div><font size="2"   >### sdf: 36001438005de97860000b00000d60000</font></div><div><font size="2"   >### sdg: 36001438005de97860000b00000d20000</font></div><div><font size="2"   >### sdh: 36001438005de97860000b00000d60000</font></div><p></p></pre></div><div>然后根据这些ID编写/etc/multipath.conf</div><div><br></div><div>CentOS 6.x, 不需要这么麻烦, 只要启动multipathd进程, 就可以得到wwn, 然后编写multipath.conf</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_204 ~]# multipath -ll</font></div><div><font size="2"   >mpathc (36001438005de97860000b00000ce0000) dm-1 HP,HSV400</font></div><div><font size="2"   >size=350G features='1 queue_if_no_path' hwhandler='0' wp=rw</font></div><div><font size="2"   >|-+- policy='round-robin 0' prio=130 status=active</font></div><div><font size="2"   >| |- 1:0:1:2 sde 8:64 &nbsp;active ready running</font></div><div><font size="2"   >| `- 2:0:1:2 sdi 8:128 active ready running</font></div><div><font size="2"   >`-+- policy='round-robin 0' prio=10 status=enabled</font></div><div><font size="2"   >&nbsp; |- 1:0:0:2 sdc 8:32 &nbsp;active ready running</font></div><div><font size="2"   >&nbsp; `- 2:0:0:2 sdg 8:96 &nbsp;active ready running</font></div><div><font size="2"   >mpathb (36001438005de97860000b00000ca0000) dm-0 HP,HSV400</font></div><div><font size="2"   >size=350G features='1 queue_if_no_path' hwhandler='0' wp=rw</font></div><div><font size="2"   >|-+- policy='round-robin 0' prio=130 status=active</font></div><div><font size="2"   >| |- 1:0:1:1 sdd 8:48 &nbsp;active ready running</font></div><div><font size="2"   >| `- 2:0:1:1 sdh 8:112 active ready running</font></div><div><font size="2"   >`-+- policy='round-robin 0' prio=10 status=enabled</font></div><div><font size="2"   >&nbsp; |- 1:0:0:1 sdb 8:16 &nbsp;active ready running</font></div><div><font size="2"   >&nbsp; `- 2:0:0:1 sdf 8:80 &nbsp;active ready running</font></div><p></p></pre></div><div>如果您的环境使用了其他多路径软件, 则不需要配置multipathd, 例如EMC的PowerPath.</div><div><br></div><div>编写multipath.conf, 两个节点都需要配置, 注意如果两个主机的本地硬盘命名规则不一样的话, blacklist也需要注意.</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_204 ~]# vi /etc/multipath.conf</font></div><div><font size="2"   ># multipath.conf written by anaconda</font></div><div><font size="2"   ><br></font></div><div><font size="2"   >defaults {</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;udev_dir &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /dev</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;polling_interval &nbsp; &nbsp; &nbsp; &nbsp; 10</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;path_grouping_policy &nbsp; &nbsp; failover</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;getuid_callout &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "/sbin/scsi_id -g -u -s /block/%n"</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;path_checker &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; readsector0</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;rr_min_io &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;100</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;rr_weight &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;priorities</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;failback &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; immediate</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;no_path_retry &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;fail</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;user_friendly_names &nbsp; &nbsp; &nbsp;yes</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;flush_on_last_del &nbsp; &nbsp; &nbsp; &nbsp;yes</font></div><div><font size="2"   >}</font></div><div><font size="2"   >blacklist {</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;devnode "^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*"</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;devnode "^hd[a-z]"</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;devnode "^cciss!c[0-9]d[0-9]*"</font></div><div><font size="2"   >}</font></div><div><font size="2"   >multipaths {</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; multipath {</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; wwid "36001438005de97860000b00000ca0000"</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; alias &nbsp; &nbsp;e06_eva_vd4</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; }</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; multipath {</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; wwid "36001438005de97860000b00000ce0000"</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; alias &nbsp; &nbsp;e06_eva_vd3</font></div><div><font size="2"   >&nbsp; &nbsp; &nbsp; &nbsp; }</font></div><div><font size="2"   >}</font></div><p></p></pre></div><div>重启multipathd 服务, 并且加入自动启动</div><div><pre class="prettyprint"   ><p></p><div><font size="2"   >[root@172_16_13_204 ~]# service multipathd restart</font></div><div><font size="2"   >ok</font></div><div><font size="2"   >Stopping multipathd daemon: [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >Starting multipathd daemon: [ &nbsp;OK &nbsp;]</font></div><div><font size="2"   >[root@172_16_13_204 ~]# multipath -ll</font></div><div><font size="2"   >e06_eva_vd4 (36001438005de97860000b00000ca0000) dm-0 HP,HSV400</font></div><div><font size="2"   >size=350G features='1 queue_if_no_path' hwhandler='0' wp=rw</font></div><div><font size="2"   >|-+- policy='round-robin 0' prio=130 status=active</font></div><div><font size="2"   >| |- 1:0:1:1 sdd 8:48 &nbsp;active ready running</font></div><div><font size="2"   >| `- 2:0:1:1 sdh 8:112 active ready running</font></div><div><font size="2"   >`-+- policy='round-robin 0' prio=10 status=enabled</font></div><div><font size="2"   >&nbsp; |- 1:0:0:1 sdb 8:16 &nbsp;active ready running</font></div><div><font size="2"   >&nbsp; `- 2:0:0:1 sdf 8:80 &nbsp;active ready running</font></div><div><font size="2"   >e06_eva_vd3 (36001438005de97860000b00000ce0000) dm-1 HP,HSV400</font></div><div><font size="2"   >size=350G features='1 queue_if_no_path' hwhandler='0' wp=rw</font></div><div><font size="2"   >|-+- policy='round-robin 0' prio=130 status=active</font></div><div><font size="2"   >| |- 1:0:1:2 sde 8:64 &nbsp;active ready running</font></div><div><font size="2"   >| `- 2:0:1:2 sdi 8:128 active ready running</font></div><div><font size="2"   >`-+- policy='round-robin 0' prio=10 status=enabled</font></div><div><font size="2"   >&nbsp; |- 1:0:0:2 sdc 8:32 &nbsp;active ready running</font></div><div><font size="2"   >&nbsp; `- 2:0:0:2 sdg 8:96 &nbsp;active ready running</font></div><div><font size="2"   ><br></font></div><div><font size="2"   ># chkconfig multipathd on</font></div><p></p></pre></div><div><br></div><div>(续)</div><div><a target="_blank" href="http://blog.163.com/digoal@126/blog/static/163877040201481085624211/"   >http://blog.163.com/digoal@126/blog/static/163877040201481085624211/</a></div><div><br></div><wbr>
<a rel="nofollow" href="http://info.flagcounter.com/h9V1"   ><img title="PostgreSQL HA manual with shared disk use RHCS - 1 - 德哥@Digoal - PostgreSQL research"   src="http://s03.flagcounter.com/count/h9V1/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_12/viewers_0/labels_0/pageviews_0/flags_0/"   alt="Flag Counter"   border="0"   ></a></div>
	</div>
</div>
</body>
</html>