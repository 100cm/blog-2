<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">PostgreSQL Parallel Seq Scan patch</h2>
	<h5 id="">2014-12-23 8:19:01&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/163877040201411238191358/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;"><div>PostgreSQL 正在逐步实现并行查询, 这是一个使用多核进行顺序扫描的patch.</div><div>有兴趣的朋友可以尝试, 可以看到性能提升比较明显 .</div><div><br></div><div>As per discussion on another thread related to using</div><div>custom scan nodes for prototype of parallel sequence scan,</div><div>I have developed the same, but directly by adding</div><div>new nodes for parallel sequence scan. &nbsp;There might be</div><div>some advantages for developing this as a contrib</div><div>module by using custom scan nodes, however I think</div><div>we might get stucked after some point due to custom</div><div>scan node capability as pointed out by Andres.</div><div><br></div><div>The basic idea used is that while evaluating the cheapest</div><div>path for scan, optimizer will also evaluate if it can use</div><div>parallel seq path. &nbsp;Currently I have kept a very simple</div><div>model to calculate the cost of parallel sequence path which</div><div>is that divide the cost for CPU and disk by availble number</div><div>of worker backends (We can enhance it based on further</div><div>experiments and discussion; we need to consider worker startup</div><div>and dynamic shared memory setup cost as well). The work aka</div><div>scan of blocks is divided equally among all workers (except for</div><div>corner cases where blocks can't be equally divided among workers,</div><div>the last worker will be responsible for scanning the remaining blocks).</div><div><br></div><div>The number of worker backends that can be used for</div><div>parallel seq scan can be configured by using a new GUC</div><div>parallel_seqscan_degree, the default value of which is zero</div><div>and it means parallel seq scan will not be considered unless</div><div>user configures this value.</div><div><br></div><div>In ExecutorStart phase, initiate the required number of workers</div><div>as per parallel seq scan plan and setup dynamic shared memory and</div><div>share the information required for worker to execute the scan.</div><div>Currently I have just shared the relId, targetlist and number</div><div>of blocks to be scanned by worker, however I think we might want</div><div>to generate a plan for each of the workers in master backend and</div><div>then share the same to individual worker.</div><div>Now to fetch the data from multiple queues corresponding to each</div><div>worker a simple mechanism is used that is fetch from first queue</div><div>till all the data is consumed from same, then fetch from second</div><div>queue and so on. &nbsp;Also here master backend is responsible for just</div><div>getting the data from workers and passing it back to client.</div><div>I am sure that we can improve this strategy in many ways</div><div>like by making master backend to also perform scan for some</div><div>of the blocks rather than just getting data from workers and</div><div>a better strategy to fetch the data from multiple queues.</div><div><br></div><div>Worker backend will receive the information related to scan</div><div>from master backend and generate the plan from same and</div><div>execute that plan, so here the work to scan the data after</div><div>generating the plan is very much similar to exec_simple_query()</div><div>(i.e Create the portal and run it based on planned statement)</div><div>except that worker backends will initialize the block range it want to</div><div>scan in executor initialization phase (ExecInitSeqScan()).</div><div>Workers will exit after sending the data to master backend</div><div>which essentially means that for each execution we need</div><div>to initiate the workers, I think here we can improve by giving the</div><div>control for workers to postmaster so that we don't need to</div><div>initialize them each time during execution, however this can</div><div>be a totally separate optimization which is better to be done</div><div>independently of this patch.</div><div>As currently we don't have mechanism to share transaction</div><div>state, I have used separate transaction in worker backend to</div><div>execute the plan.</div><div><br></div><div>Any error in master backend either via backend worker or due</div><div>to other issue in master backend itself should terminate all the</div><div>workers before aborting the transaction.</div><div>We can't do it with the error context callback mechanism</div><div>(error_context_stack) which we use at other places in code, as</div><div>for this case we need it from the time workers are started till</div><div>the execution is complete (error_context_stack could get reset</div><div>once the control goes out of the function which has set it.)</div><div>One way could be that maintain the callback information in</div><div>TransactionState and use it to kill the workers before aborting</div><div>transaction in main backend. &nbsp;Another could be that have another</div><div>variable similar to error_context_stack (which will be used</div><div>specifically for storing the workers state), and kill the workers</div><div>in errfinish via callback. Currently I have handled it at the time of</div><div>detaching from shared memory.</div><div>Another point that needs to be taken care in worker backend is</div><div>that if any error occurs, we should *not* abort the transaction as</div><div>the transaction state is shared across all workers.</div><div><br></div><div>Currently the parallel seq scan will not be considered</div><div>for statements other than SELECT or if there is a join in</div><div>the statement or if statement contains quals or if target</div><div>list contains non-Var fields. We can definitely support</div><div>simple quals and targetlist other than non-Vars. &nbsp;By simple,</div><div>I means that it should not contain functions or some other</div><div>conditions which can't be pushed down to worker backend.</div><div><br></div><div>Behaviour of some simple statements with patch is as below:</div><div><br></div><div>postgres=# create table t1(c1 int, c2 char(500)) with (fillfactor=10);</div><div>CREATE TABLE</div><div><br></div><div>postgres=# insert into t1 values(generate_series(1,100),'amit');</div><div>INSERT 0 100</div><div><br></div><div>postgres=# explain select c1 from t1;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; QUERY PLAN</div><div>------------------------------------------------------</div><div>&nbsp;Seq Scan on t1 &nbsp;(cost=0.00..101.00 rows=100 width=4)</div><div>(1 row)</div><div><br></div><div><br></div><div>postgres=# set parallel_seqscan_degree=4;</div><div>SET</div><div>postgres=# explain select c1 from t1;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; QUERY PLAN</div><div>--------------------------------------------------------------</div><div>&nbsp;Parallel Seq Scan on t1 &nbsp;(cost=0.00..25.25 rows=100 width=4)</div><div>&nbsp; &nbsp;Number of Workers: 4</div><div>&nbsp; &nbsp;Number of Blocks Per Workers: 25</div><div>(3 rows)</div><div><br></div><div><br></div><div>postgres=# explain select Distinct(c1) from t1;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;QUERY PLAN</div><div>--------------------------------------------------------------------</div><div>&nbsp;HashAggregate &nbsp;(cost=25.50..26.50 rows=100 width=4)</div><div>&nbsp; &nbsp;Group Key: c1</div><div>&nbsp; &nbsp;-&gt; &nbsp;Parallel Seq Scan on t1 &nbsp;(cost=0.00..25.25 rows=100 width=4)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Number of Workers: 4</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Number of Blocks Per Workers: 25</div><div>(5 rows)</div><div><br></div><div><br></div><div>Attached patch is just to facilitate the discussion about the</div><div>parallel seq scan and may be some other dependent tasks like</div><div>sharing of various states like combocid, snapshot with parallel</div><div>workers. &nbsp;It is by no means ready to do any complex test, ofcourse</div><div>I will work towards making it more robust both in terms of adding</div><div>more stuff and doing performance optimizations.</div><div><br></div><div>Thoughts/Suggestions?</div><div><br></div><div>With Regards,</div><div>Amit Kapila.</div><div>EnterpriseDB: http://www.enterprisedb.com</div><div><br></div><div>[参考]</div><div>1.&nbsp;<a style="line-height: 28px;" target="_blank" rel="nofollow" href="http://www.postgresql.org/message-id/flat/CAA4eK1KHWha5_NqxFZFBZ=ZFkkBSwf+2Z6htJFV+YVY_LW9cQA@mail.gmail.com#CAA4eK1KHWha5_NqxFZFBZ=ZFkkBSwf+2Z6htJFV+YVY_LW9cQA@mail.gmail.com"   >http://www.postgresql.org/message-id/flat/CAA4eK1KHWha5_NqxFZFBZ=ZFkkBSwf+2Z6htJFV+YVY_LW9cQA@mail.gmail.com#CAA4eK1KHWha5_NqxFZFBZ=ZFkkBSwf+2Z6htJFV+YVY_LW9cQA@mail.gmail.com</a></div><wbr>
<a rel="nofollow" href="http://info.flagcounter.com/h9V1"   ><img title="PostgreSQL Parallel Seq Scan patch - 德哥@Digoal - PostgreSQL research"   src="http://s03.flagcounter.com/count/h9V1/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_12/viewers_0/labels_0/pageviews_0/flags_0/"   alt="Flag Counter"   border="0"   ></a></div>
	</div>
</div>
</body>
</html>